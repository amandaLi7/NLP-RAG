[
  {
    "profName": "Mona Diab",
    "authorId": "2138579860",
    "authorName": "Mona T. Diab",
    "authorUrl": "https://www.semanticscholar.org/author/2138579860",
    "authorHIndex": 10,
    "authorAffiliations": [],
    "authorPaperCount": 23,
    "authorCitationCount": 2128,
    "paperId": "0a94fbb5e1c93513523f00e75d672ef4553861f9",
    "externalIds": {
      "DBLP": "journals/corr/abs-2306-05836",
      "ArXiv": "2306.05836",
      "DOI": "10.48550/arXiv.2306.05836",
      "CorpusId": 259129342
    },
    "url": "https://www.semanticscholar.org/paper/0a94fbb5e1c93513523f00e75d672ef4553861f9",
    "title": "Can Large Language Models Infer Causation from Correlation?",
    "abstract": "Causal inference is one of the hallmarks of human intelligence. While the field of CausalNLP has attracted much interest in the recent years, existing causal inference datasets in NLP primarily rely on discovering causality from empirical knowledge (e.g., commonsense knowledge). In this work, we propose the first benchmark dataset to test the pure causal inference skills of large language models (LLMs). Specifically, we formulate a novel task Corr2Cause, which takes a set of correlational statements and determines the causal relationship between the variables. We curate a large-scale dataset of more than 200K samples, on which we evaluate seventeen existing LLMs. Through our experiments, we identify a key shortcoming of LLMs in terms of their causal inference skills, and show that these models achieve almost close to random performance on the task. This shortcoming is somewhat mitigated when we try to re-purpose LLMs for this skill via finetuning, but we find that these models still fail to generalize -- they can only perform causal inference in in-distribution settings when variable names and textual expressions used in the queries are similar to those in the training set, but fail in out-of-distribution settings generated by perturbing these queries. Corr2Cause is a challenging task for LLMs, and would be helpful in guiding future research on improving LLMs' pure reasoning skills and generalizability. Our data is at https://huggingface.co/datasets/causalnlp/corr2cause. Our code is at https://github.com/causalNLP/corr2cause.",
    "venue": "arXiv.org",
    "year": 2023,
    "referenceCount": 49,
    "citationCount": 27,
    "influentialCitationCount": 1,
    "isOpenAccess": true,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/2306.05836",
      "status": null
    },
    "fieldsOfStudy": [
      "Computer Science"
    ],
    "journal": {
      "volume": "abs/2306.05836",
      "name": "ArXiv"
    },
    "authors": [
      {
        "authorId": "2111472502",
        "name": "Zhijing Jin"
      },
      {
        "authorId": "146961917",
        "name": "Jiarui Liu"
      },
      {
        "authorId": "2114227440",
        "name": "Zhiheng Lyu"
      },
      {
        "authorId": "1753626755",
        "name": "Spencer Poff"
      },
      {
        "authorId": "2790926",
        "name": "Mrinmaya Sachan"
      },
      {
        "authorId": "2105984203",
        "name": "Rada Mihalcea"
      },
      {
        "authorId": "2138579860",
        "name": "Mona T. Diab"
      },
      {
        "authorId": "1707625",
        "name": "B. Scholkopf"
      }
    ]
  },
  {
    "profName": "Mona Diab",
    "authorId": "2138579860",
    "authorName": "Mona T. Diab",
    "authorUrl": "https://www.semanticscholar.org/author/2138579860",
    "authorHIndex": 10,
    "authorAffiliations": [],
    "authorPaperCount": 23,
    "authorCitationCount": 2128,
    "paperId": "4286d07449447f3bfffc1eeb2ee0de9b00dfadfd",
    "externalIds": {
      "DBLP": "conf/acl/YuWGAVJGDC23",
      "DOI": "10.18653/v1/2023.acl-long.60",
      "CorpusId": 259370626
    },
    "url": "https://www.semanticscholar.org/paper/4286d07449447f3bfffc1eeb2ee0de9b00dfadfd",
    "title": "ALERT: Adapt Language Models to Reasoning Tasks",
    "abstract": null,
    "venue": "Annual Meeting of the Association for Computational Linguistics",
    "year": 2023,
    "referenceCount": 0,
    "citationCount": 0,
    "influentialCitationCount": 0,
    "isOpenAccess": true,
    "openAccessPdf": {
      "url": "https://aclanthology.org/2023.acl-long.60.pdf",
      "status": null
    },
    "fieldsOfStudy": [
      "Computer Science"
    ],
    "journal": {
      "pages": "1055-1081"
    },
    "authors": [
      {
        "authorId": "2114104308",
        "name": "Ping Yu"
      },
      {
        "authorId": "1785372925",
        "name": "Tianlu Wang"
      },
      {
        "authorId": "100664938",
        "name": "O. Yu. Golovneva"
      },
      {
        "authorId": "2006905770",
        "name": "Badr AlKhamissi"
      },
      {
        "authorId": "1799945508",
        "name": "Siddharth Verma"
      },
      {
        "authorId": "2111472502",
        "name": "Zhijing Jin"
      },
      {
        "authorId": "134007132",
        "name": "Gargi Ghosh"
      },
      {
        "authorId": "2138579860",
        "name": "Mona T. Diab"
      },
      {
        "authorId": "1709797",
        "name": "Asli Celikyilmaz"
      }
    ]
  },
  {
    "profName": "Mona Diab",
    "authorId": "2138579860",
    "authorName": "Mona T. Diab",
    "authorUrl": "https://www.semanticscholar.org/author/2138579860",
    "authorHIndex": 10,
    "authorAffiliations": [],
    "authorPaperCount": 23,
    "authorCitationCount": 2128,
    "paperId": "5e2f8088647e357bb6440d271ed1fcc4d5ed7e7c",
    "externalIds": {
      "ACL": "2023.clinicalnlp-1.55",
      "DBLP": "conf/acl-clinicalnlp/AlQahtaniSDY23",
      "DOI": "10.18653/v1/2023.clinicalnlp-1.55",
      "CorpusId": 259833895
    },
    "url": "https://www.semanticscholar.org/paper/5e2f8088647e357bb6440d271ed1fcc4d5ed7e7c",
    "title": "Care4Lang at MEDIQA-Chat 2023: Fine-tuning Language Models for Classifying and Summarizing Clinical Dialogues",
    "abstract": "Summarizing medical conversations is one of the tasks proposed by MEDIQA-Chat to promote research on automatic clinical note generation from doctor-patient conversations. In this paper, we present our submission to this task using fine-tuned language models, including T5, BART and BioGPT models. The fine-tuned models are evaluated using ensemble metrics including ROUGE, BERTScore andBLEURT. Among the fine-tuned models, Flan-T5 achieved the highest aggregated score for dialogue summarization.",
    "venue": "Clinical Natural Language Processing Workshop",
    "year": 2023,
    "referenceCount": 18,
    "citationCount": 1,
    "influentialCitationCount": 0,
    "isOpenAccess": true,
    "openAccessPdf": {
      "url": "https://aclanthology.org/2023.clinicalnlp-1.55.pdf",
      "status": null
    },
    "fieldsOfStudy": [
      "Computer Science"
    ],
    "journal": {
      "pages": "524-528"
    },
    "authors": [
      {
        "authorId": "2057134736",
        "name": "Amal AlQahtani"
      },
      {
        "authorId": "66799313",
        "name": "R. Salama"
      },
      {
        "authorId": "2138579860",
        "name": "Mona T. Diab"
      },
      {
        "authorId": "145555732",
        "name": "Abdou Youssef"
      }
    ]
  },
  {
    "profName": "Mona Diab",
    "authorId": "2138579860",
    "authorName": "Mona T. Diab",
    "authorUrl": "https://www.semanticscholar.org/author/2138579860",
    "authorHIndex": 10,
    "authorAffiliations": [],
    "authorPaperCount": 23,
    "authorCitationCount": 2128,
    "paperId": "99bfe503743c5ec8e16e50ab8438159cdb533a89",
    "externalIds": {
      "DBLP": "journals/corr/abs-2310-04988",
      "ArXiv": "2310.04988",
      "DOI": "10.48550/arXiv.2310.04988",
      "CorpusId": 263831293
    },
    "url": "https://www.semanticscholar.org/paper/99bfe503743c5ec8e16e50ab8438159cdb533a89",
    "title": "The Troubling Emergence of Hallucination in Large Language Models - An Extensive Definition, Quantification, and Prescriptive Remediations",
    "abstract": "The recent advancements in Large Language Models (LLMs) have garnered widespread acclaim for their remarkable emerging capabilities. However, the issue of hallucination has parallelly emerged as a by-product, posing significant concerns. While some recent endeavors have been made to identify and mitigate different types of hallucination, there has been a limited emphasis on the nuanced categorization of hallucination and associated mitigation methods. To address this gap, we offer a fine-grained discourse on profiling hallucination based on its degree, orientation, and category, along with offering strategies for alleviation. As such, we define two overarching orientations of hallucination: (i) factual mirage (FM) and (ii) silver lining (SL). To provide a more comprehensive understanding, both orientations are further sub-categorized into intrinsic and extrinsic, with three degrees of severity - (i) mild, (ii) moderate, and (iii) alarming. We also meticulously categorize hallucination into six types: (i) acronym ambiguity, (ii) numeric nuisance, (iii) generated golem, (iv) virtual voice, (v) geographic erratum, and (vi) time wrap. Furthermore, we curate HallucInation eLiciTation (HILT), a publicly available dataset comprising of 75,000 samples generated using 15 contemporary LLMs along with human annotations for the aforementioned categories. Finally, to establish a method for quantifying and to offer a comparative spectrum that allows us to evaluate and rank LLMs based on their vulnerability to producing hallucinations, we propose Hallucination Vulnerability Index (HVI). We firmly believe that HVI holds significant value as a tool for the wider NLP community, with the potential to serve as a rubric in AI-related policy-making. In conclusion, we propose two solution strategies for mitigating hallucinations.",
    "venue": "Conference on Empirical Methods in Natural Language Processing",
    "year": 2023,
    "referenceCount": 59,
    "citationCount": 19,
    "influentialCitationCount": 2,
    "isOpenAccess": true,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2310.04988",
      "status": null
    },
    "fieldsOfStudy": [
      "Computer Science"
    ],
    "journal": {
      "pages": "2541-2573"
    },
    "authors": [
      {
        "authorId": "9460529",
        "name": "Vipula Rawte"
      },
      {
        "authorId": "2257001500",
        "name": "Swagata Chakraborty"
      },
      {
        "authorId": "2257001966",
        "name": "Agnibh Pathak"
      },
      {
        "authorId": "2189479826",
        "name": "Anubhav Sarkar"
      },
      {
        "authorId": "2103483687",
        "name": "S.M. Towhidul Islam Tonmoy"
      },
      {
        "authorId": "2229651428",
        "name": "Islam Tonmoy"
      },
      {
        "authorId": "40016108",
        "name": "Aman Chadha"
      },
      {
        "authorId": "2064342742",
        "name": "Amit P. Sheth"
      },
      {
        "authorId": "2258322706",
        "name": "Amitava Das"
      },
      {
        "authorId": "2076602721",
        "name": "Paris"
      },
      {
        "authorId": "2064327462",
        "name": "A. Sridhar"
      },
      {
        "authorId": "2238206449",
        "name": "Erik Visser"
      },
      {
        "authorId": "2257006156",
        "name": "Improved"
      },
      {
        "authorId": "2258099188",
        "name": "Jianlin Su"
      },
      {
        "authorId": "2257339854",
        "name": "Yu Lu"
      },
      {
        "authorId": "1382633722",
        "name": "Shengfeng Pan"
      },
      {
        "authorId": "2159557286",
        "name": "Ahmed Murtadha"
      },
      {
        "authorId": "2079396269",
        "name": "Bo Wen"
      },
      {
        "authorId": "2257345549",
        "name": "Yunfeng Liu"
      },
      {
        "authorId": "2257006862",
        "name": "Roformer"
      },
      {
        "authorId": "46199305",
        "name": "Rohan Taori"
      },
      {
        "authorId": "2708454",
        "name": "Ishaan Gulrajani"
      },
      {
        "authorId": "2256233130",
        "name": "Tianyi Zhang"
      },
      {
        "authorId": "2257007362",
        "name": "Yann Dubois"
      },
      {
        "authorId": "2250724754",
        "name": "Xuechen Li"
      },
      {
        "authorId": "1412355294",
        "name": "Carlos Guestrin"
      },
      {
        "authorId": "2256995425",
        "name": "Percy Liang"
      },
      {
        "authorId": "2117567142",
        "name": "Tatsunori Hashimoto"
      },
      {
        "authorId": "2250092519",
        "name": "Stanford"
      },
      {
        "authorId": "2113243762",
        "name": "Hugo Touvron"
      },
      {
        "authorId": "46183616",
        "name": "Thibaut Lavril"
      },
      {
        "authorId": "1410231361",
        "name": "Gautier Izacard"
      },
      {
        "authorId": "1490887583",
        "name": "Xavier Martinet"
      },
      {
        "authorId": "114952298",
        "name": "Marie-Anne Lachaux"
      },
      {
        "authorId": "47733973",
        "name": "Timoth\u00e9e Lacroix"
      },
      {
        "authorId": "3361236",
        "name": "Baptiste Rozi\u00e8re"
      },
      {
        "authorId": "39589154",
        "name": "Naman Goyal"
      },
      {
        "authorId": "2072738644",
        "name": "Eric Hambro"
      },
      {
        "authorId": "2209986197",
        "name": "Faisal Azhar"
      },
      {
        "authorId": "2166043087",
        "name": "Aurelien Rodriguez"
      },
      {
        "authorId": "2319608",
        "name": "Armand Joulin"
      },
      {
        "authorId": "2257007291",
        "name": "Thomas Wolf"
      },
      {
        "authorId": "1380459402",
        "name": "Lysandre Debut"
      },
      {
        "authorId": "51918868",
        "name": "Victor Sanh"
      },
      {
        "authorId": "40811585",
        "name": "Julien Chaumond"
      },
      {
        "authorId": "40899333",
        "name": "Clement Delangue"
      },
      {
        "authorId": "1382164294",
        "name": "Anthony Moi"
      },
      {
        "authorId": "1382164165",
        "name": "Pierric Cistac"
      },
      {
        "authorId": "1382164170",
        "name": "Tim Rault"
      },
      {
        "authorId": "2185329",
        "name": "R\u00e9mi Louf"
      },
      {
        "authorId": "2257005341",
        "name": "Morgan Funtow-icz"
      },
      {
        "authorId": "48776237",
        "name": "Joe Davison"
      },
      {
        "authorId": "88728159",
        "name": "Sam Shleifer"
      },
      {
        "authorId": "138609838",
        "name": "Patrick von Platen"
      },
      {
        "authorId": "2257128341",
        "name": "Clara Ma"
      },
      {
        "authorId": "2262249",
        "name": "Yacine Jernite"
      },
      {
        "authorId": "3008389",
        "name": "Julien Plu"
      },
      {
        "authorId": "2257127518",
        "name": "Canwen Xu"
      },
      {
        "authorId": "1379806208",
        "name": "Teven Le Scao"
      },
      {
        "authorId": "103682620",
        "name": "Sylvain Gugger"
      },
      {
        "authorId": "2125818054",
        "name": "Mariama Drame"
      },
      {
        "authorId": "2113836945",
        "name": "Quentin Lhoest"
      },
      {
        "authorId": "2238121623",
        "name": "Susan Zhang"
      },
      {
        "authorId": "3849208",
        "name": "Stephen Roller"
      },
      {
        "authorId": "2347956",
        "name": "Mikel Artetxe"
      },
      {
        "authorId": "2108267192",
        "name": "Moya Chen"
      },
      {
        "authorId": "2257570528",
        "name": "Shuohui Chen"
      },
      {
        "authorId": "2257006163",
        "name": "Christopher De-wan"
      },
      {
        "authorId": "2138579860",
        "name": "Mona T. Diab"
      },
      {
        "authorId": "2257006892",
        "name": "Xi Xian Li"
      },
      {
        "authorId": "2257007395",
        "name": "Todor Victoria Lin"
      },
      {
        "authorId": "40511414",
        "name": "Myle Ott"
      },
      {
        "authorId": "35752280",
        "name": "Kurt Shuster"
      },
      {
        "authorId": "2257006894",
        "name": "Punit Daniel Simig"
      },
      {
        "authorId": "2257006866",
        "name": "Singh Koura"
      },
      {
        "authorId": "2257007723",
        "name": "Anjali Sridhar"
      },
      {
        "authorId": "2238056517",
        "name": "Tianlu Wang"
      },
      {
        "authorId": "2257007614",
        "name": "Luke Zettlemoyer. 2022"
      },
      {
        "authorId": "2052152920",
        "name": "Daniel M. Ziegler"
      },
      {
        "authorId": "1387983862",
        "name": "Nisan Stiennon"
      },
      {
        "authorId": "2257137166",
        "name": "Jeffrey Wu"
      },
      {
        "authorId": "2257135738",
        "name": "Tom Brown"
      },
      {
        "authorId": "38909097",
        "name": "Alec Radford"
      },
      {
        "authorId": "2698777",
        "name": "Dario Amodei"
      },
      {
        "authorId": "2257006890",
        "name": "Paul F. Chris-tiano"
      }
    ]
  },
  {
    "profName": "Mona Diab",
    "authorId": "2138579860",
    "authorName": "Mona T. Diab",
    "authorUrl": "https://www.semanticscholar.org/author/2138579860",
    "authorHIndex": 10,
    "authorAffiliations": [],
    "authorPaperCount": 23,
    "authorCitationCount": 2128,
    "paperId": "c218cd1772999517b137bbbc9872c4f67e540b7f",
    "externalIds": {
      "DBLP": "journals/corr/abs-2305-12001",
      "ACL": "2023.nlrse-1.10",
      "ArXiv": "2305.12001",
      "DOI": "10.18653/v1/2023.nlrse-1.10",
      "CorpusId": 258832540
    },
    "url": "https://www.semanticscholar.org/paper/c218cd1772999517b137bbbc9872c4f67e540b7f",
    "title": "OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models",
    "abstract": "We conduct a thorough investigation into the reasoning capabilities of Large Language Models (LLMs), focusing specifically on the Open Pretrained Transformers (OPT) models as a representative of such models. Our study entails finetuning three different sizes of OPT on a carefully curated reasoning corpus, resulting in two sets of finetuned models: OPT-R, finetuned without explanations, and OPT-RE, finetuned with explanations. We then evaluate all models on 57 out-of-domain tasks drawn from the Super-NaturalInstructions benchmark, covering 26 distinct reasoning skills, utilizing three prompting techniques. Through a comprehensive grid of 27 configurations and 6,156 test evaluations, we investigate the dimensions of finetuning, prompting, and scale to understand the role of explanations on different reasoning skills. Our findings reveal that having explanations in the fewshot exemplar has no significant impact on the model\u2019s performance when the model is finetuned, while positively affecting the non-finetuned counterpart. Moreover, we observe a slight yet consistent increase in classification accuracy as we incorporate explanations during prompting and finetuning, respectively. Finally, we offer insights on which reasoning skills benefit the most from incorporating explanations during finetuning and prompting, such as Numerical (+20.4%) and Analogical (+13.9%) reasoning, as well as skills that exhibit negligible or negative effects.",
    "venue": "NLRSE",
    "year": 2023,
    "referenceCount": 28,
    "citationCount": 2,
    "influentialCitationCount": 0,
    "isOpenAccess": true,
    "openAccessPdf": {
      "url": "https://aclanthology.org/2023.nlrse-1.10.pdf",
      "status": null
    },
    "fieldsOfStudy": [
      "Computer Science"
    ],
    "journal": {
      "volume": "abs/2305.12001",
      "name": "ArXiv"
    },
    "authors": [
      {
        "authorId": "2006905770",
        "name": "Badr AlKhamissi"
      },
      {
        "authorId": "1799945508",
        "name": "Siddharth Verma"
      },
      {
        "authorId": "2114104308",
        "name": "Ping Yu"
      },
      {
        "authorId": "2111472502",
        "name": "Zhijing Jin"
      },
      {
        "authorId": "1709797",
        "name": "Asli Celikyilmaz"
      },
      {
        "authorId": "2138579860",
        "name": "Mona T. Diab"
      }
    ]
  },
  {
    "profName": "Mona Diab",
    "authorId": "2138579860",
    "authorName": "Mona T. Diab",
    "authorUrl": "https://www.semanticscholar.org/author/2138579860",
    "authorHIndex": 10,
    "authorAffiliations": [],
    "authorPaperCount": 23,
    "authorCitationCount": 2128,
    "paperId": "f727f928e7e179307d8d4a1da2387393f2bd7915",
    "externalIds": {
      "ACL": "2023.eacl-main.199",
      "DBLP": "conf/eacl/HaseDCLKSBI23",
      "DOI": "10.18653/v1/2023.eacl-main.199",
      "CorpusId": 258378150
    },
    "url": "https://www.semanticscholar.org/paper/f727f928e7e179307d8d4a1da2387393f2bd7915",
    "title": "Methods for Measuring, Updating, and Visualizing Factual Beliefs in Language Models",
    "abstract": "Language models can memorize a considerable amount of factual information during pretraining that can be elicited through prompting or finetuning models on tasks like question answering. In this paper, we discuss approaches to measuring model factual beliefs, updating incorrect factual beliefs in models, and visualizing graphical relationships between factual beliefs. Our main contributions include: (1) new metrics for evaluating belief-updating methods focusing on the logical consistency of beliefs, (2) a training objective for Sequential, Local, and Generalizing updates (SLAG) that improves the performance of existing hypernetwork approaches, and (3) the introduction of the belief graph, a new form of visualization for language models that shows relationships between stored model beliefs. Our experiments suggest that models show only limited consistency between factual beliefs, but update methods can both fix incorrect model beliefs and greatly improve their consistency. Although off-the-shelf optimizers are surprisingly strong belief-updating baselines, our learned optimizers can outperform them in more difficult settings than have been considered in past work.",
    "venue": "Conference of the European Chapter of the Association for Computational Linguistics",
    "year": 2023,
    "referenceCount": 30,
    "citationCount": 26,
    "influentialCitationCount": 1,
    "isOpenAccess": true,
    "openAccessPdf": {
      "url": "https://aclanthology.org/2023.eacl-main.199.pdf",
      "status": null
    },
    "fieldsOfStudy": [
      "Computer Science"
    ],
    "journal": {
      "pages": "2706-2723"
    },
    "authors": [
      {
        "authorId": "144625004",
        "name": "Peter Hase"
      },
      {
        "authorId": "2138579860",
        "name": "Mona T. Diab"
      },
      {
        "authorId": "1709797",
        "name": "Asli Celikyilmaz"
      },
      {
        "authorId": "2116235416",
        "name": "Xian Li"
      },
      {
        "authorId": "1714932",
        "name": "Zornitsa Kozareva"
      },
      {
        "authorId": "1759422",
        "name": "Veselin Stoyanov"
      },
      {
        "authorId": "143977268",
        "name": "Mohit Bansal"
      },
      {
        "authorId": "1900163",
        "name": "Srini Iyer"
      }
    ]
  }
]