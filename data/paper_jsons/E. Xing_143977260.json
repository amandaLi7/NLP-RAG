[
  {
    "profName": "Eric P. Xing",
    "authorId": "143977260",
    "authorName": "E. Xing",
    "authorUrl": "https://www.semanticscholar.org/author/143977260",
    "authorHIndex": 103,
    "authorAffiliations": [],
    "authorPaperCount": 631,
    "authorCitationCount": 46108,
    "paperId": "075b751201f549daeba9840f78768f4ceb507e17",
    "externalIds": {
      "DBLP": "journals/corr/abs-2306-07916",
      "ArXiv": "2306.07916",
      "DOI": "10.48550/arXiv.2306.07916",
      "CorpusId": 259144964
    },
    "url": "https://www.semanticscholar.org/paper/075b751201f549daeba9840f78768f4ceb507e17",
    "title": "Identification of Nonlinear Latent Hierarchical Models",
    "abstract": "Identifying latent variables and causal structures from observational data is essential to many real-world applications involving biological data, medical data, and unstructured data such as images and languages. However, this task can be highly challenging, especially when observed variables are generated by causally related latent variables and the relationships are nonlinear. In this work, we investigate the identification problem for nonlinear latent hierarchical causal models in which observed variables are generated by a set of causally related latent variables, and some latent variables may not have observed children. We show that the identifiability of causal structures and latent variables (up to invertible transformations) can be achieved under mild assumptions: on causal structures, we allow for multiple paths between any pair of variables in the graph, which relaxes latent tree assumptions in prior work; on structural functions, we permit general nonlinearity and multi-dimensional continuous variables, alleviating existing work's parametric assumptions. Specifically, we first develop an identification criterion in the form of novel identifiability guarantees for an elementary latent variable model. Leveraging this criterion, we show that both causal structures and latent variables of the hierarchical model can be identified asymptotically by explicitly constructing an estimation procedure. To the best of our knowledge, our work is the first to establish identifiability guarantees for both causal structures and latent variables in nonlinear latent hierarchical models.",
    "venue": "arXiv.org",
    "year": 2023,
    "referenceCount": 47,
    "citationCount": 5,
    "influentialCitationCount": 0,
    "isOpenAccess": true,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/2306.07916",
      "status": null
    },
    "fieldsOfStudy": [
      "Computer Science",
      "Mathematics"
    ],
    "journal": {
      "volume": "abs/2306.07916",
      "name": "ArXiv"
    },
    "authors": [
      {
        "authorId": "2069275317",
        "name": "Lingjing Kong"
      },
      {
        "authorId": "1938684",
        "name": "Biwei Huang"
      },
      {
        "authorId": "47060248",
        "name": "Feng Xie"
      },
      {
        "authorId": "143977260",
        "name": "E. Xing"
      },
      {
        "authorId": "1784472",
        "name": "Yuejie Chi"
      },
      {
        "authorId": "2119016656",
        "name": "Kun Zhang"
      }
    ]
  },
  {
    "profName": "Eric P. Xing",
    "authorId": "143977260",
    "authorName": "E. Xing",
    "authorUrl": "https://www.semanticscholar.org/author/143977260",
    "authorHIndex": 103,
    "authorAffiliations": [],
    "authorPaperCount": 631,
    "authorCitationCount": 46108,
    "paperId": "8cc1cd002bfc36a8cba8bcbe63d32eacc656097f",
    "externalIds": {
      "DBLP": "conf/cvpr/LiuZCZYELX23",
      "ArXiv": "2303.10598",
      "DOI": "10.1109/CVPR52729.2023.00806",
      "CorpusId": 257632294
    },
    "url": "https://www.semanticscholar.org/paper/8cc1cd002bfc36a8cba8bcbe63d32eacc656097f",
    "title": "StyleRF: Zero-Shot 3D Style Transfer of Neural Radiance Fields",
    "abstract": "3D style transfer aims to render stylized novel views of a 3D scene with multiview consistency. However, most existing work suffers from a three-way dilemma over accurate geometry reconstruction, high-quality stylization, and being generalizable to arbitrary new styles. We propose StyleRF (Style Radiance Fields), an innovative 3D style transfer technique that resolves the three-way dilemma by performing style transformation within the feature space of a radiance field. StyleRF employs an explicit grid of high-level features to represent 3D scenes, with which highfidelity geometry can be reliably restored via volume rendering. In addition, it transforms the grid features according to the reference style which directly leads to high-quality zero-shot style transfer. StyleRF consists of two innovative designs. The first is sampling-invariant content transformation that makes the transformation invariant to the holistic statistics of the sampled 3D points and accordingly ensures multi-view consistency. The second is deferred style transformation of 2D feature maps which is equivalent to the transformation of 3D points but greatly reduces memory footprint without degrading multi-view consistency. Extensive experiments show that StyleRF achieves superior 3D stylization quality with precise geometry reconstruction and it can generalize to various new styles in a zero-shot manner. Project website: https://kunhao-liu.github.io/StyleRF/",
    "venue": "Computer Vision and Pattern Recognition",
    "year": 2023,
    "referenceCount": 74,
    "citationCount": 12,
    "influentialCitationCount": 3,
    "isOpenAccess": true,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2303.10598",
      "status": null
    },
    "fieldsOfStudy": [
      "Computer Science"
    ],
    "journal": {
      "pages": "8338-8348",
      "name": "2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)"
    },
    "authors": [
      {
        "authorId": "2212199002",
        "name": "Kunhao Liu"
      },
      {
        "authorId": "51111483",
        "name": "Fangneng Zhan"
      },
      {
        "authorId": "2109275146",
        "name": "Yiwen Chen"
      },
      {
        "authorId": "2121386031",
        "name": "Jiahui Zhang"
      },
      {
        "authorId": "101206696",
        "name": "Yingchen Yu"
      },
      {
        "authorId": "30889568",
        "name": "Abdulmotaleb El Saddik"
      },
      {
        "authorId": "1771189",
        "name": "Shijian Lu"
      },
      {
        "authorId": "143977260",
        "name": "E. Xing"
      }
    ]
  },
  {
    "profName": "Eric P. Xing",
    "authorId": "143977260",
    "authorName": "E. Xing",
    "authorUrl": "https://www.semanticscholar.org/author/143977260",
    "authorHIndex": 103,
    "authorAffiliations": [],
    "authorPaperCount": 631,
    "authorCitationCount": 46108,
    "paperId": "a0a79dad89857a96f8f71b14238e5237cbfc4787",
    "externalIds": {
      "DBLP": "journals/corr/abs-2306-05685",
      "ArXiv": "2306.05685",
      "DOI": "10.48550/arXiv.2306.05685",
      "CorpusId": 259129398
    },
    "url": "https://www.semanticscholar.org/paper/a0a79dad89857a96f8f71b14238e5237cbfc4787",
    "title": "Judging LLM-as-a-judge with MT-Bench and Chatbot Arena",
    "abstract": "Evaluating large language model (LLM) based chat assistants is challenging due to their broad capabilities and the inadequacy of existing benchmarks in measuring human preferences. To address this, we explore using strong LLMs as judges to evaluate these models on more open-ended questions. We examine the usage and limitations of LLM-as-a-judge, including position, verbosity, and self-enhancement biases, as well as limited reasoning ability, and propose solutions to mitigate some of them. We then verify the agreement between LLM judges and human preferences by introducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80% agreement, the same level of agreement between humans. Hence, LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain. Additionally, we show our benchmark and traditional benchmarks complement each other by evaluating several variants of LLaMA and Vicuna. The MT-bench questions, 3K expert votes, and 30K conversations with human preferences are publicly available at https://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge.",
    "venue": "arXiv.org",
    "year": 2023,
    "referenceCount": 59,
    "citationCount": 680,
    "influentialCitationCount": 125,
    "isOpenAccess": true,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2306.05685",
      "status": null
    },
    "fieldsOfStudy": [
      "Computer Science"
    ],
    "journal": {
      "volume": "abs/2306.05685",
      "name": "ArXiv"
    },
    "authors": [
      {
        "authorId": "2149970173",
        "name": "Lianmin Zheng"
      },
      {
        "authorId": "2537924",
        "name": "Wei-Lin Chiang"
      },
      {
        "authorId": "2209360681",
        "name": "Ying Sheng"
      },
      {
        "authorId": "92721493",
        "name": "Siyuan Zhuang"
      },
      {
        "authorId": "1390573666",
        "name": "Zhanghao Wu"
      },
      {
        "authorId": "2152482391",
        "name": "Yonghao Zhuang"
      },
      {
        "authorId": "143872641",
        "name": "Zi Lin"
      },
      {
        "authorId": "2141335450",
        "name": "Zhuohan Li"
      },
      {
        "authorId": "2117961435",
        "name": "Dacheng Li"
      },
      {
        "authorId": "143977260",
        "name": "E. Xing"
      },
      {
        "authorId": "145140331",
        "name": "Haotong Zhang"
      },
      {
        "authorId": "144307989",
        "name": "Joseph Gonzalez"
      },
      {
        "authorId": "2055174324",
        "name": "I. Stoica"
      }
    ]
  },
  {
    "profName": "Eric P. Xing",
    "authorId": "143977260",
    "authorName": "E. Xing",
    "authorUrl": "https://www.semanticscholar.org/author/143977260",
    "authorHIndex": 103,
    "authorAffiliations": [],
    "authorPaperCount": 631,
    "authorCitationCount": 46108,
    "paperId": "dcb4f2b9b0e6da0d629878d1ad0469aee3df2020",
    "externalIds": {
      "DBLP": "journals/corr/abs-2306-04898",
      "ArXiv": "2306.04898",
      "DOI": "10.1109/CVPR52729.2023.00765",
      "CorpusId": 259108864
    },
    "url": "https://www.semanticscholar.org/paper/dcb4f2b9b0e6da0d629878d1ad0469aee3df2020",
    "title": "Understanding Masked Autoencoders via Hierarchical Latent Variable Models",
    "abstract": "Masked autoencoder (MAE), a simple and effective self-supervised learning framework based on the reconstruction of masked image regions, has recently achieved prominent success in a variety of vision tasks. Despite the emergence of intriguing empirical observations on MAE, a theoretically principled understanding is still lacking. In this work, we formally characterize and justify existing empirical in-sights and provide theoretical guarantees of MAE. We formulate the underlying data-generating process as a hierarchical latent variable model, and show that under reasonable assumptions, MAE provably identifies a set of latent variables in the hierarchical model, explaining why MAE can extract high-level information from pixels. Further, we show how key hyperparameters in MAE (the masking ratio and the patch size) determine which true latent variables to be recovered, therefore influencing the level of semantic information in the representation. Specifically, extremely large or small masking ratios inevitably lead to low-level representations. Our theory offers coherent explanations of existing empirical observations and provides insights for potential empirical improvements and fundamental limitations of the masked-reconstruction paradigm. We conduct extensive experiments to validate our theoretical insights.",
    "venue": "Computer Vision and Pattern Recognition",
    "year": 2023,
    "referenceCount": 74,
    "citationCount": 8,
    "influentialCitationCount": 0,
    "isOpenAccess": true,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2306.04898",
      "status": null
    },
    "fieldsOfStudy": [
      "Computer Science"
    ],
    "journal": {
      "pages": "7918-7928",
      "name": "2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)"
    },
    "authors": [
      {
        "authorId": "2069275317",
        "name": "Lingjing Kong"
      },
      {
        "authorId": "1384374825",
        "name": "Martin Q. Ma"
      },
      {
        "authorId": "2155315836",
        "name": "Guan-Hong Chen"
      },
      {
        "authorId": "143977260",
        "name": "E. Xing"
      },
      {
        "authorId": "1784472",
        "name": "Yuejie Chi"
      },
      {
        "authorId": "49933077",
        "name": "Louis-Philippe Morency"
      },
      {
        "authorId": "2175349484",
        "name": "Kun Zhang"
      }
    ]
  }
]