[
  {
    "profName": "Fernando-Diaz",
    "authorId": "145472333",
    "authorName": "Fernando Diaz",
    "authorUrl": "https://www.semanticscholar.org/author/145472333",
    "authorHIndex": 45,
    "authorAffiliations": [],
    "authorPaperCount": 142,
    "authorCitationCount": 7996,
    "paperId": "55704caaf3d31e1795a1ca0c3bed9e77ae3a3c95",
    "externalIds": {
      "DBLP": "journals/corr/abs-2306-07908",
      "ArXiv": "2306.07908",
      "DOI": "10.48550/arXiv.2306.07908",
      "CorpusId": 259145213
    },
    "url": "https://www.semanticscholar.org/paper/55704caaf3d31e1795a1ca0c3bed9e77ae3a3c95",
    "title": "Best-Case Retrieval Evaluation: Improving the Sensitivity of Reciprocal Rank with Lexicographic Precision",
    "abstract": "Across a variety of ranking tasks, researchers use reciprocal rank to measure the effectiveness for users interested in exactly one relevant item. Despite its widespread use, evidence suggests that reciprocal rank is brittle when discriminating between systems. This brittleness, in turn, is compounded in modern evaluation settings where current, high-precision systems may be difficult to distinguish. We address the lack of sensitivity of reciprocal rank by introducing and connecting it to the concept of best-case retrieval, an evaluation method focusing on assessing the quality of a ranking for the most satisfied possible user across possible recall requirements. This perspective allows us to generalize reciprocal rank and define a new preference-based evaluation we call lexicographic precision or lexiprecision. By mathematical construction, we ensure that lexiprecision preserves differences detected by reciprocal rank, while empirically improving sensitivity and robustness across a broad set of retrieval and recommendation tasks.",
    "venue": "arXiv.org",
    "year": 2023,
    "referenceCount": 24,
    "citationCount": 2,
    "influentialCitationCount": 0,
    "isOpenAccess": true,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/2306.07908",
      "status": null
    },
    "fieldsOfStudy": [
      "Computer Science"
    ],
    "journal": {
      "volume": "abs/2306.07908",
      "name": "ArXiv"
    },
    "authors": [
      {
        "authorId": "145472333",
        "name": "Fernando Diaz"
      }
    ]
  },
  {
    "profName": "Fernando-Diaz",
    "authorId": "145472333",
    "authorName": "Fernando Diaz",
    "authorUrl": "https://www.semanticscholar.org/author/145472333",
    "authorHIndex": 45,
    "authorAffiliations": [],
    "authorPaperCount": 142,
    "authorCitationCount": 7996,
    "paperId": "567f6bc975deb3d728feec9bfcf7d4036ceabb12",
    "externalIds": {
      "DBLP": "journals/corr/abs-2308-14601",
      "ArXiv": "2308.14601",
      "DOI": "10.48550/arXiv.2308.14601",
      "CorpusId": 261243847
    },
    "url": "https://www.semanticscholar.org/paper/567f6bc975deb3d728feec9bfcf7d4036ceabb12",
    "title": "Fairness Through Domain Awareness: Mitigating Popularity Bias For Music Discovery",
    "abstract": "As online music platforms grow, music recommender systems play a vital role in helping users navigate and discover content within their vast musical databases. At odds with this larger goal, is the presence of popularity bias, which causes algorithmic systems to favor mainstream content over, potentially more relevant, but niche items. In this work we explore the intrinsic relationship between music discovery and popularity bias. To mitigate this issue we propose a domain-aware, individual fairness-based approach which addresses popularity bias in graph neural network (GNNs) based recommender systems. Our approach uses individual fairness to reflect a ground truth listening experience, i.e., if two songs sound similar, this similarity should be reflected in their representations. In doing so, we facilitate meaningful music discovery that is robust to popularity bias and grounded in the music domain. We apply our BOOST methodology to two discovery based tasks, performing recommendations at both the playlist level and user level. Then, we ground our evaluation in the cold start setting, showing that our approach outperforms existing fairness benchmarks in both performance and recommendation of lesser-known content. Finally, our analysis explains why our proposed methodology is a novel and promising approach to mitigating popularity bias and improving the discovery of new and niche content in music recommender systems.",
    "venue": "arXiv.org",
    "year": 2023,
    "referenceCount": 79,
    "citationCount": 0,
    "influentialCitationCount": 0,
    "isOpenAccess": true,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2308.14601",
      "status": null
    },
    "fieldsOfStudy": [
      "Computer Science"
    ],
    "journal": {
      "volume": "abs/2308.14601",
      "name": "ArXiv"
    },
    "authors": [
      {
        "authorId": "2184295196",
        "name": "Rebecca Salganik"
      },
      {
        "authorId": "145472333",
        "name": "Fernando Diaz"
      },
      {
        "authorId": "2086602",
        "name": "G. Farnadi"
      }
    ]
  },
  {
    "profName": "Fernando-Diaz",
    "authorId": "145472333",
    "authorName": "Fernando Diaz",
    "authorUrl": "https://www.semanticscholar.org/author/145472333",
    "authorHIndex": 45,
    "authorAffiliations": [],
    "authorPaperCount": 142,
    "authorCitationCount": 7996,
    "paperId": "5e1ba2d4416333dd6f6a31a4ff4221b40dfb74b1",
    "externalIds": {
      "DBLP": "conf/trec/EkstrandRM021",
      "ArXiv": "2302.10856",
      "DOI": "10.48550/arXiv.2302.10856",
      "CorpusId": 214667072
    },
    "url": "https://www.semanticscholar.org/paper/5e1ba2d4416333dd6f6a31a4ff4221b40dfb74b1",
    "title": "Overview of the TREC 2021 Fair Ranking Track",
    "abstract": "The TREC Fair Ranking Track aims to provide a platform for participants to develop and evaluate novel retrieval algorithms that can provide a fair exposure to a mixture of demographics or attributes, such as ethnicity, that are represented by relevant documents in response to a search query. For example, particular demographics or attributes can be represented by the documents' topical content or authors. The 2021 Fair Ranking Track adopted a resource allocation task. The task focused on supporting Wikipedia editors who are looking to improve the encyclopedia's coverage of topics under the purview of a WikiProject. WikiProject coordinators and/or Wikipedia editors search for Wikipedia documents that are in need of editing to improve the quality of the article. The 2021 Fair Ranking track aimed to ensure that documents that are about, or somehow represent, certain protected characteristics receive a fair exposure to the Wikipedia editors, so that the documents have an fair opportunity of being improved and, therefore, be well-represented in Wikipedia. The under-representation of particular protected characteristics in Wikipedia can result in systematic biases that can have a negative human, social, and economic impact, particularly for disadvantaged or protected societal groups.",
    "venue": "Text Retrieval Conference",
    "year": 2023,
    "referenceCount": 16,
    "citationCount": 27,
    "influentialCitationCount": 3,
    "isOpenAccess": true,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/2302.10856",
      "status": null
    },
    "fieldsOfStudy": [
      "Computer Science"
    ],
    "journal": {
      "volume": "abs/2302.10856",
      "name": "ArXiv"
    },
    "authors": [
      {
        "authorId": "31908706",
        "name": "Asia J. Biega"
      },
      {
        "authorId": "145472333",
        "name": "Fernando Diaz"
      },
      {
        "authorId": "2386667",
        "name": "Michael D. Ekstrand"
      },
      {
        "authorId": "41018147",
        "name": "Sebastian Kohlmeier"
      }
    ]
  }
]