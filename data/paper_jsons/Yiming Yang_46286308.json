[
  {
    "profName": "Yiming Yang",
    "authorId": "46286308",
    "authorName": "Yiming Yang",
    "authorUrl": "https://www.semanticscholar.org/author/46286308",
    "authorHIndex": 17,
    "authorAffiliations": [],
    "authorPaperCount": 43,
    "authorCitationCount": 1532,
    "paperId": "02ce4d3f93902a94ec2b57630b77696b7f18c84a",
    "externalIds": {
      "ACL": "2023.acl-long.832",
      "ArXiv": "2305.14963",
      "DBLP": "journals/corr/abs-2305-14963",
      "DOI": "10.48550/arXiv.2305.14963",
      "CorpusId": 258865225
    },
    "url": "https://www.semanticscholar.org/paper/02ce4d3f93902a94ec2b57630b77696b7f18c84a",
    "title": "PESCO: Prompt-enhanced Self Contrastive Learning for Zero-shot Text Classification",
    "abstract": "We present PESCO, a novel contrastive learning framework that substantially improves the performance of zero-shot text classification. We formulate text classification as a neural text retrieval problem where each document is treated as a query, and the system learns the mapping from each query to the relevant class labels by (1) adding prompts to enhance label retrieval, and (2) using retrieved labels to enrich the training set in a self-training loop of contrastive learning. PESCO achieves state-of-the-art performance on four benchmark text classification datasets. On DBpedia, we achieve 98.5% accuracy without any labeled data, which is close to the fully-supervised result. Extensive experiments and analyses show all the components of PESCO are necessary for improving the performance of zero-shot text classification.",
    "venue": "Annual Meeting of the Association for Computational Linguistics",
    "year": 2023,
    "referenceCount": 48,
    "citationCount": 2,
    "influentialCitationCount": 0,
    "isOpenAccess": true,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/2305.14963",
      "status": null
    },
    "fieldsOfStudy": [
      "Computer Science"
    ],
    "journal": {
      "pages": "14897-14911"
    },
    "authors": [
      {
        "authorId": "46394797",
        "name": "Yau-Shian Wang"
      },
      {
        "authorId": "27531332",
        "name": "Ta-Chung Chi"
      },
      {
        "authorId": "46752970",
        "name": "Ruohong Zhang"
      },
      {
        "authorId": "46286308",
        "name": "Yiming Yang"
      }
    ],
    "tldr": "PESCO is presented, a novel contrastive learning framework that substantially improves the performance of zero-shot text classification and achieves state-of-the-art performance on four benchmark text classification datasets."
  },
  {
    "profName": "Yiming Yang",
    "authorId": "46286308",
    "authorName": "Yiming Yang",
    "authorUrl": "https://www.semanticscholar.org/author/46286308",
    "authorHIndex": 17,
    "authorAffiliations": [],
    "authorPaperCount": 43,
    "authorCitationCount": 1532,
    "paperId": "1786a2f9140ed7211b21302977de64e948b92308",
    "externalIds": {
      "ArXiv": "2302.07867",
      "DBLP": "journals/corr/abs-2302-07867",
      "DOI": "10.48550/arXiv.2302.07867",
      "CorpusId": 256868633
    },
    "url": "https://www.semanticscholar.org/paper/1786a2f9140ed7211b21302977de64e948b92308",
    "title": "Learning Performance-Improving Code Edits",
    "abstract": "The waning of Moore's Law has shifted the focus of the tech industry towards alternative methods for continued performance gains. While optimizing compilers are a standard tool to help increase program efficiency, programmers continue to shoulder much responsibility in crafting and refactoring code with better performance characteristics. In this paper, we investigate the ability of large language models (LLMs) to suggest functionally correct, performance improving code edits. We hypothesize that language models can suggest such edits in ways that would be impractical for static analysis alone. We investigate these questions by curating a large-scale dataset of Performance-Improving Edits, PIE. PIE contains trajectories of programs, where a programmer begins with an initial, slower version and iteratively makes changes to improve the program's performance. We use PIE to evaluate and improve the capacity of large language models. Specifically, use examples from PIE to fine-tune multiple variants of CODEGEN, a billion-scale Transformer-decoder model. Additionally, we use examples from PIE to prompt OpenAI's CODEX using a few-shot prompting. By leveraging PIE, we find that both CODEX and CODEGEN can generate performance-improving edits, with speedups of more than 2.5x for over 25% of the programs, for C++ and Python, even after the C++ programs were compiled using the O3 optimization level. Crucially, we show that PIE allows CODEGEN, an open-sourced and 10x smaller model than CODEX, to match the performance of CODEX on this challenging task. Overall, this work opens new doors for creating systems and methods that can help programmers write efficient code.",
    "venue": "arXiv.org",
    "year": 2023,
    "referenceCount": 87,
    "citationCount": 26,
    "influentialCitationCount": 3,
    "isOpenAccess": true,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/2302.07867",
      "status": null
    },
    "fieldsOfStudy": [
      "Computer Science"
    ],
    "journal": {
      "volume": "abs/2302.07867",
      "name": "ArXiv"
    },
    "authors": [
      {
        "authorId": "21626987",
        "name": "Aman Madaan"
      },
      {
        "authorId": "2129995371",
        "name": "Alex Shypula"
      },
      {
        "authorId": "47051926",
        "name": "Uri Alon"
      },
      {
        "authorId": "33798741",
        "name": "Milad Hashemi"
      },
      {
        "authorId": "1770926",
        "name": "Parthasarathy Ranganathan"
      },
      {
        "authorId": "46286308",
        "name": "Yiming Yang"
      },
      {
        "authorId": "1700325",
        "name": "Graham Neubig"
      },
      {
        "authorId": "2112229",
        "name": "A. Yazdanbakhsh"
      }
    ],
    "tldr": "This paper investigates the ability of large language models (LLMs) to suggest functionally correct, performance improving code edits, and hypothesizes that language models can suggest such edits in ways that would be impractical for static analysis alone."
  },
  {
    "profName": "Yiming Yang",
    "authorId": "46286308",
    "authorName": "Yiming Yang",
    "authorUrl": "https://www.semanticscholar.org/author/46286308",
    "authorHIndex": 17,
    "authorAffiliations": [],
    "authorPaperCount": 43,
    "authorCitationCount": 1532,
    "paperId": "1804dc14b1cf7bbae96bf3215997e9f14425d622",
    "externalIds": {
      "ArXiv": "2304.11872",
      "DBLP": "journals/corr/abs-2304-11872",
      "DOI": "10.48550/arXiv.2304.11872",
      "CorpusId": 258297998
    },
    "url": "https://www.semanticscholar.org/paper/1804dc14b1cf7bbae96bf3215997e9f14425d622",
    "title": "Generation-driven Contrastive Self-training for Zero-shot Text Classification with Instruction-tuned GPT",
    "abstract": "Moreover, GPT-based zero-shot classification models tend to make independent predictions over test instances, which can be sub-optimal as the instance correlations and the decision boundaries in the target space are ignored. To address these difficulties and limitations, we propose a new approach to zero-shot text classification, namely \\ourmodelshort, which leverages the strong generative power of GPT to assist in training a smaller, more adaptable, and efficient sentence encoder classifier with contrastive self-training. Specifically, GenCo applies GPT in two ways: firstly, it generates multiple augmented texts for each input instance to enhance the semantic embedding of the instance and improve the mapping to relevant labels; secondly, it generates augmented texts conditioned on the predicted label during self-training, which makes the generative process tailored to the decision boundaries in the target space. In our experiments, GenCo outperforms previous state-of-the-art methods on multiple benchmark datasets, even when only limited in-domain text data is available.",
    "venue": "arXiv.org",
    "year": 2023,
    "referenceCount": 24,
    "citationCount": 4,
    "influentialCitationCount": 1,
    "isOpenAccess": true,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/2304.11872",
      "status": null
    },
    "fieldsOfStudy": [
      "Computer Science"
    ],
    "journal": {
      "volume": "abs/2304.11872",
      "name": "ArXiv"
    },
    "authors": [
      {
        "authorId": "46752970",
        "name": "Ruohong Zhang"
      },
      {
        "authorId": "46394797",
        "name": "Yau-Shian Wang"
      },
      {
        "authorId": "46286308",
        "name": "Yiming Yang"
      }
    ],
    "tldr": "This work proposes a new approach to zero-shot text classification, namely \\ourmodelshort, which leverages the strong generative power of GPT to assist in training a smaller, more adaptable, and efficient sentence encoder classifier with contrastive self-training."
  },
  {
    "profName": "Yiming Yang",
    "authorId": "46286308",
    "authorName": "Yiming Yang",
    "authorUrl": "https://www.semanticscholar.org/author/46286308",
    "authorHIndex": 17,
    "authorAffiliations": [],
    "authorPaperCount": 43,
    "authorCitationCount": 1532,
    "paperId": "3aaf6a2cbad5850ad81ab5c163599cb3d523436f",
    "externalIds": {
      "DBLP": "journals/corr/abs-2303-17651",
      "ArXiv": "2303.17651",
      "DOI": "10.48550/arXiv.2303.17651",
      "CorpusId": 257900871
    },
    "url": "https://www.semanticscholar.org/paper/3aaf6a2cbad5850ad81ab5c163599cb3d523436f",
    "title": "Self-Refine: Iterative Refinement with Self-Feedback",
    "abstract": "Like humans, large language models (LLMs) do not always generate the best output on their first try. Motivated by how humans refine their written text, we introduce Self-Refine, an approach for improving initial outputs from LLMs through iterative feedback and refinement. The main idea is to generate an initial output using an LLMs; then, the same LLMs provides feedback for its output and uses it to refine itself, iteratively. Self-Refine does not require any supervised training data, additional training, or reinforcement learning, and instead uses a single LLM as the generator, refiner, and feedback provider. We evaluate Self-Refine across 7 diverse tasks, ranging from dialog response generation to mathematical reasoning, using state-of-the-art (GPT-3.5, ChatGPT, and GPT-4) LLMs. Across all evaluated tasks, outputs generated with Self-Refine are preferred by humans and automatic metrics over those generated with the same LLM using conventional one-step generation, improving by ~20% absolute on average in task performance. Our work demonstrates that even state-of-the-art LLMs like GPT-4 can be further improved at test time using our simple, standalone approach.",
    "venue": "arXiv.org",
    "year": 2023,
    "referenceCount": 52,
    "citationCount": 383,
    "influentialCitationCount": 25,
    "isOpenAccess": true,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/2303.17651",
      "status": null
    },
    "fieldsOfStudy": [
      "Computer Science"
    ],
    "journal": {
      "volume": "abs/2303.17651",
      "name": "ArXiv"
    },
    "authors": [
      {
        "authorId": "21626987",
        "name": "Aman Madaan"
      },
      {
        "authorId": "1721168",
        "name": "Niket Tandon"
      },
      {
        "authorId": "1491232062",
        "name": "Prakhar Gupta"
      },
      {
        "authorId": "1474550731",
        "name": "Skyler Hallinan"
      },
      {
        "authorId": "49715441",
        "name": "Luyu Gao"
      },
      {
        "authorId": "35823986",
        "name": "Sarah Wiegreffe"
      },
      {
        "authorId": "47051926",
        "name": "Uri Alon"
      },
      {
        "authorId": "46217681",
        "name": "Nouha Dziri"
      },
      {
        "authorId": "9358910",
        "name": "Shrimai Prabhumoye"
      },
      {
        "authorId": "46286308",
        "name": "Yiming Yang"
      },
      {
        "authorId": "2129663",
        "name": "S. Welleck"
      },
      {
        "authorId": "3165738",
        "name": "Bodhisattwa Prasad Majumder"
      },
      {
        "authorId": "2152953535",
        "name": "Shashank Gupta"
      },
      {
        "authorId": "2112229",
        "name": "A. Yazdanbakhsh"
      },
      {
        "authorId": "48323507",
        "name": "Peter Clark"
      }
    ],
    "tldr": "Self-Refine is introduced, an approach for improving initial outputs from LLMs through iterative feedback and refinement that demonstrates that even state-of-the-art LLMs like GPT-4 can be further improved at test time using this simple, standalone approach."
  },
  {
    "profName": "Yiming Yang",
    "authorId": "46286308",
    "authorName": "Yiming Yang",
    "authorUrl": "https://www.semanticscholar.org/author/46286308",
    "authorHIndex": 17,
    "authorAffiliations": [],
    "authorPaperCount": 43,
    "authorCitationCount": 1532,
    "paperId": "3c92fd24ea2a49aeba4b368abe3ef13cbce40987",
    "externalIds": {
      "DBLP": "conf/eacl/ZhangWYYVL23",
      "ACL": "2023.findings-eacl.81",
      "DOI": "10.18653/v1/2023.findings-eacl.81",
      "CorpusId": 258378221
    },
    "url": "https://www.semanticscholar.org/paper/3c92fd24ea2a49aeba4b368abe3ef13cbce40987",
    "title": "Long-tailed Extreme Multi-label Text Classification by the Retrieval of Generated Pseudo Label Descriptions",
    "abstract": "Extreme Multi-label Text Classification (XMTC) has been a tough challenge in machine learning research and applications due to the sheer sizes of the label spaces and the severe data scarcity problem associated with the long tail of rare labels in highly skewed distributions. This paper addresses the challenge of tail label prediction by leveraging the power of dense neural retrieval model in mapping input documents (as queries) to relevant label descriptions. To further enhance the quality of label descriptions, we propose to generate pseudo label descriptions from a trained bag-of-words (BoW) classifier, which demonstrates better classification performance under severe scarce data conditions.The proposed approach achieves the state-of-the-art (SOTA) performance of overall label prediction on XMTC benchmark datasets and especially outperforms the SOTA models in the tail label prediction. We also provide a theoretical analysis for relating the BoW and neural models w.r.t. performance lower bound.",
    "venue": "Findings",
    "year": 2023,
    "referenceCount": 29,
    "citationCount": 2,
    "influentialCitationCount": 0,
    "isOpenAccess": true,
    "openAccessPdf": {
      "url": "https://aclanthology.org/2023.findings-eacl.81.pdf",
      "status": null
    },
    "fieldsOfStudy": [
      "Computer Science"
    ],
    "journal": {
      "pages": "1062-1076"
    },
    "authors": [
      {
        "authorId": "46752970",
        "name": "Ruohong Zhang"
      },
      {
        "authorId": "46394797",
        "name": "Yau-Shian Wang"
      },
      {
        "authorId": "46286308",
        "name": "Yiming Yang"
      },
      {
        "authorId": "15121583",
        "name": "Donghan Yu"
      },
      {
        "authorId": "2161340676",
        "name": "Tom Vu"
      },
      {
        "authorId": "2066699630",
        "name": "Li Lei"
      }
    ],
    "tldr": "This paper addresses the challenge of tail label prediction by leveraging the power of dense neural retrieval model in mapping input documents to relevant label descriptions and generates pseudo label descriptions from a trained bag-of-words (BoW) classifier, which demonstrates better classification performance under severe scarce data conditions."
  },
  {
    "profName": "Yiming Yang",
    "authorId": "46286308",
    "authorName": "Yiming Yang",
    "authorUrl": "https://www.semanticscholar.org/author/46286308",
    "authorHIndex": 17,
    "authorAffiliations": [],
    "authorPaperCount": 43,
    "authorCitationCount": 1532,
    "paperId": "4ce987d4f8ae0f4680808c318980d42a82b9aa89",
    "externalIds": {
      "DBLP": "journals/corr/abs-2302-01925",
      "ArXiv": "2302.01925",
      "DOI": "10.48550/arXiv.2302.01925",
      "CorpusId": 256598356
    },
    "url": "https://www.semanticscholar.org/paper/4ce987d4f8ae0f4680808c318980d42a82b9aa89",
    "title": "Learning a Fourier Transform for Linear Relative Positional Encodings in Transformers",
    "abstract": "We propose a new class of linear Transformers called FourierLearner-Transformers (FLTs), which incorporate a wide range of relative positional encoding mechanisms (RPEs). These include regular RPE techniques applied for nongeometric data, as well as novel RPEs operating on the sequences of tokens embedded in higher-dimensional Euclidean spaces (e.g. point clouds). FLTs construct the optimal RPE mechanism implicitly by learning its spectral representation. As opposed to other architectures combining efficient low-rank linear attention with RPEs, FLTs remain practical in terms of their memory usage and do not require additional assumptions about the structure of the RPE-mask. FLTs allow also for applying certain structural inductive bias techniques to specify masking strategies, e.g. they provide a way to learn the so-called local RPEs introduced in this paper and providing accuracy gains as compared with several other linear Transformers for language modeling. We also thoroughly tested FLTs on other data modalities and tasks, such as: image classification and 3D molecular modeling. For 3D-data FLTs are, to the best of our knowledge, the first Transformers architectures providing RPE-enhanced linear attention.",
    "venue": "arXiv.org",
    "year": 2023,
    "referenceCount": 60,
    "citationCount": 5,
    "influentialCitationCount": 1,
    "isOpenAccess": true,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/2302.01925",
      "status": null
    },
    "fieldsOfStudy": [
      "Computer Science"
    ],
    "journal": {
      "volume": "abs/2302.01925",
      "name": "ArXiv"
    },
    "authors": [
      {
        "authorId": "1805203",
        "name": "K. Choromanski"
      },
      {
        "authorId": "2119028865",
        "name": "Shanda Li"
      },
      {
        "authorId": "52314889",
        "name": "Valerii Likhosherstov"
      },
      {
        "authorId": "89890133",
        "name": "Kumar Avinava Dubey"
      },
      {
        "authorId": "2108801920",
        "name": "Shengjie Luo"
      },
      {
        "authorId": "1391126980",
        "name": "Di He"
      },
      {
        "authorId": "46286308",
        "name": "Yiming Yang"
      },
      {
        "authorId": "2227764",
        "name": "Tam\u00e1s Sarl\u00f3s"
      },
      {
        "authorId": "2151791144",
        "name": "Thomas Weingarten"
      },
      {
        "authorId": "145689461",
        "name": "Adrian Weller"
      }
    ],
    "tldr": "FLTs are the first Transformers architectures providing RPE-enhanced linear attention and provide a way to learn the so-called local RPEs introduced in this paper and providing accuracy gains as compared with several other linear Transformers for language modeling."
  },
  {
    "profName": "Yiming Yang",
    "authorId": "46286308",
    "authorName": "Yiming Yang",
    "authorUrl": "https://www.semanticscholar.org/author/46286308",
    "authorHIndex": 17,
    "authorAffiliations": [],
    "authorPaperCount": 43,
    "authorCitationCount": 1532,
    "paperId": "846f60ef3b98590c7ad1d84727c66a08cc2258c8",
    "externalIds": {
      "DBLP": "journals/corr/abs-2308-03725",
      "ArXiv": "2308.03725",
      "DOI": "10.48550/arXiv.2308.03725",
      "CorpusId": 260681733
    },
    "url": "https://www.semanticscholar.org/paper/846f60ef3b98590c7ad1d84727c66a08cc2258c8",
    "title": "Efficient Temporal Sentence Grounding in Videos with Multi-Teacher Knowledge Distillation",
    "abstract": "Temporal Sentence Grounding in Videos (TSGV) aims to detect the event timestamps described by the natural language query from untrimmed videos. This paper discusses the challenge of achieving efficient computation in TSGV models while maintaining high performance. Most existing approaches exquisitely design complex architectures to improve accuracy with extra layers and loss, suffering from inefficiency and heaviness. Although some works have noticed that, they only make an issue of feature fusion layers, which can hardly enjoy the highspeed merit in the whole clunky network. To tackle this problem, we propose a novel efficient multi-teacher model (EMTM) based on knowledge distillation to transfer diverse knowledge from both heterogeneous and isomorphic networks. Specifically, We first unify different outputs of the heterogeneous models into one single form. Next, a Knowledge Aggregation Unit (KAU) is built to acquire high-quality integrated soft labels from multiple teachers. After that, the KAU module leverages the multi-scale video and global query information to adaptively determine the weights of different teachers. A Shared Encoder strategy is then proposed to solve the problem that the student shallow layers hardly benefit from teachers, in which an isomorphic teacher is collaboratively trained with the student to align their hidden states. Extensive experimental results on three popular TSGV benchmarks demonstrate that our method is both effective and efficient without bells and whistles.",
    "venue": "arXiv.org",
    "year": 2023,
    "referenceCount": 31,
    "citationCount": 7,
    "influentialCitationCount": 0,
    "isOpenAccess": true,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2308.03725",
      "status": null
    },
    "fieldsOfStudy": [
      "Computer Science"
    ],
    "journal": {
      "volume": "abs/2308.03725",
      "name": "ArXiv"
    },
    "authors": [
      {
        "authorId": "2070441728",
        "name": "Renjie Liang"
      },
      {
        "authorId": "46286308",
        "name": "Yiming Yang"
      },
      {
        "authorId": "2212706205",
        "name": "Hui Lu"
      },
      {
        "authorId": "2160115945",
        "name": "Li Li"
      }
    ],
    "tldr": "A novel efficient multi-teacher model (EMTM) based on knowledge distillation to transfer diverse knowledge from both heterogeneous and isomorphic networks is proposed, which is both effective and efficient without bells and whistles."
  },
  {
    "profName": "Yiming Yang",
    "authorId": "46286308",
    "authorName": "Yiming Yang",
    "authorUrl": "https://www.semanticscholar.org/author/46286308",
    "authorHIndex": 17,
    "authorAffiliations": [],
    "authorPaperCount": 43,
    "authorCitationCount": 1532,
    "paperId": "88884b8806262a4095036041e3567d450dba39f7",
    "externalIds": {
      "DBLP": "journals/corr/abs-2305-06983",
      "ArXiv": "2305.06983",
      "DOI": "10.48550/arXiv.2305.06983",
      "CorpusId": 258615731
    },
    "url": "https://www.semanticscholar.org/paper/88884b8806262a4095036041e3567d450dba39f7",
    "title": "Active Retrieval Augmented Generation",
    "abstract": "Despite the remarkable ability of large language models (LMs) to comprehend and generate language, they have a tendency to hallucinate and create factually inaccurate output. Augmenting LMs by retrieving information from external knowledge resources is one promising solution. Most existing retrieval augmented LMs employ a retrieve-and-generate setup that only retrieves information once based on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout generation is essential. In this work, we provide a generalized view of active retrieval augmented generation, methods that actively decide when and what to retrieve across the course of the generation. We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens. We test FLARE along with baselines comprehensively over 4 long-form knowledge-intensive generation tasks/datasets. FLARE achieves superior or competitive performance on all tasks, demonstrating the effectiveness of our method. Code and datasets are available at https://github.com/jzbjyb/FLARE.",
    "venue": "Conference on Empirical Methods in Natural Language Processing",
    "year": 2023,
    "referenceCount": 78,
    "citationCount": 46,
    "influentialCitationCount": 6,
    "isOpenAccess": true,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/2305.06983",
      "status": null
    },
    "fieldsOfStudy": [
      "Computer Science"
    ],
    "journal": {
      "volume": "abs/2305.06983",
      "name": "ArXiv"
    },
    "authors": [
      {
        "authorId": "2669515",
        "name": "Zhengbao Jiang"
      },
      {
        "authorId": "40027632",
        "name": "Frank F. Xu"
      },
      {
        "authorId": "49715441",
        "name": "Luyu Gao"
      },
      {
        "authorId": "48064856",
        "name": "Zhiqing Sun"
      },
      {
        "authorId": "1409707585",
        "name": "Qian Liu"
      },
      {
        "authorId": "2173509991",
        "name": "Jane Dwivedi-Yu"
      },
      {
        "authorId": "46286308",
        "name": "Yiming Yang"
      },
      {
        "authorId": "144987107",
        "name": "Jamie Callan"
      },
      {
        "authorId": "1700325",
        "name": "Graham Neubig"
      }
    ],
    "tldr": "This work proposes Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens."
  },
  {
    "profName": "Yiming Yang",
    "authorId": "46286308",
    "authorName": "Yiming Yang",
    "authorUrl": "https://www.semanticscholar.org/author/46286308",
    "authorHIndex": 17,
    "authorAffiliations": [],
    "authorPaperCount": 43,
    "authorCitationCount": 1532,
    "paperId": "938d2951ba3aa26f3752d489c3c044ae67d5e809",
    "externalIds": {
      "DBLP": "conf/sigir/YuY23",
      "DOI": "10.1145/3539618.3592052",
      "CorpusId": 259949733
    },
    "url": "https://www.semanticscholar.org/paper/938d2951ba3aa26f3752d489c3c044ae67d5e809",
    "title": "Retrieval-Enhanced Generative Model for Large-Scale Knowledge Graph Completion",
    "abstract": "The task of knowledge graph completion (KGC) is of great importance. To achieve scalability when dealing with large-scale knowledge graphs, recent works formulate KGC as a sequence-to-sequence process, where the incomplete triplet (input) and the missing entity (output) are both verbalized as text sequences. However, inference with these methods relies solely on the model parameters for implicit reasoning and neglects the use of KG itself, which limits the performance since the model lacks the capacity to memorize a vast number of triplets. To tackle this issue, we introduce ReSKGC, a Retrieval-enhanced Seq2seq KGC model, which selects semantically relevant triplets from the KG and uses them as evidence to guide output generation with explicit reasoning. Our method has demonstrated state-of-the-art performance on benchmark datasets Wikidata5M and WikiKG90Mv2, which contain about 5M and 90M entities, respectively.",
    "venue": "Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",
    "year": 2023,
    "referenceCount": 34,
    "citationCount": 0,
    "influentialCitationCount": 0,
    "isOpenAccess": true,
    "openAccessPdf": {
      "url": "https://dl.acm.org/doi/pdf/10.1145/3539618.3592052",
      "status": null
    },
    "fieldsOfStudy": [
      "Computer Science"
    ],
    "journal": {
      "name": "Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval"
    },
    "authors": [
      {
        "authorId": "2111506236",
        "name": "Donghan Yu"
      },
      {
        "authorId": "46286308",
        "name": "Yiming Yang"
      }
    ],
    "tldr": "ReSKGC is introduced, a Retrieval-enhanced Seq2seq KGC model, which selects semantically relevant triplets from the KG and uses them as evidence to guide output generation with explicit reasoning, and has demonstrated state-of-the-art performance on benchmark datasets Wikidata5M and WikiKG90Mv2."
  },
  {
    "profName": "Yiming Yang",
    "authorId": "46286308",
    "authorName": "Yiming Yang",
    "authorUrl": "https://www.semanticscholar.org/author/46286308",
    "authorHIndex": 17,
    "authorAffiliations": [],
    "authorPaperCount": 43,
    "authorCitationCount": 1532,
    "paperId": "b4a6c010724f0459c9791018e34a982cf96987cf",
    "externalIds": {
      "ArXiv": "2305.11860",
      "DBLP": "conf/emnlp/AggarwalY23",
      "DOI": "10.18653/v1/2023.emnlp-main.761",
      "CorpusId": 258823191
    },
    "url": "https://www.semanticscholar.org/paper/b4a6c010724f0459c9791018e34a982cf96987cf",
    "title": "Let's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning and Coding with LLMs",
    "abstract": "A popular approach for improving the correctness of output from large language models (LLMs) is Self-Consistency - poll the LLM multiple times and output the most frequent solution. Existing Self-Consistency techniques always generate a constant number of samples per question, where a better approach will be to non-uniformly distribute the available budget based on the amount of agreement in the samples generated so far. In response, we introduce Adaptive-Consistency, a cost-efficient, model-agnostic technique that dynamically adjusts the number of samples per question using a lightweight stopping criterion. Our experiments over 17 reasoning and code generation datasets and three LLMs demonstrate that Adaptive-Consistency reduces sample budget by up to 7.9 times with an average accuracy drop of less than 0.1%. Our code and data are available at https://www.sample-step-by-step.info",
    "venue": "Conference on Empirical Methods in Natural Language Processing",
    "year": 2023,
    "referenceCount": 54,
    "citationCount": 9,
    "influentialCitationCount": 1,
    "isOpenAccess": true,
    "openAccessPdf": {
      "url": "https://aclanthology.org/2023.emnlp-main.761.pdf",
      "status": null
    },
    "fieldsOfStudy": [
      "Computer Science"
    ],
    "journal": {
      "pages": "12375-12396"
    },
    "authors": [
      {
        "authorId": "2114841965",
        "name": "Pranjal Aggarwal"
      },
      {
        "authorId": "21626987",
        "name": "Aman Madaan"
      },
      {
        "authorId": "46286308",
        "name": "Yiming Yang"
      },
      {
        "authorId": "2674444",
        "name": "Mausam"
      }
    ],
    "tldr": "Adaptive-Consistency is introduced, a cost-efficient, model-agnostic technique that dynamically adjusts the number of samples per question using a lightweight stopping criterion that reduces sample budget by up to 7.9 times with an average accuracy drop of less than 0.1%."
  },
  {
    "profName": "Yiming Yang",
    "authorId": "46286308",
    "authorName": "Yiming Yang",
    "authorUrl": "https://www.semanticscholar.org/author/46286308",
    "authorHIndex": 17,
    "authorAffiliations": [],
    "authorPaperCount": 43,
    "authorCitationCount": 1532,
    "paperId": "e01515c6138bc525f7aec30fc85f2adf028d4156",
    "externalIds": {
      "DBLP": "journals/corr/abs-2305-03047",
      "ArXiv": "2305.03047",
      "DOI": "10.48550/arXiv.2305.03047",
      "CorpusId": 258479665
    },
    "url": "https://www.semanticscholar.org/paper/e01515c6138bc525f7aec30fc85f2adf028d4156",
    "title": "Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision",
    "abstract": "Recent AI-assistant agents, such as ChatGPT, predominantly rely on supervised fine-tuning (SFT) with human annotations and reinforcement learning from human feedback (RLHF) to align the output of large language models (LLMs) with human intentions, ensuring they are helpful, ethical, and reliable. However, this dependence can significantly constrain the true potential of AI-assistant agents due to the high cost of obtaining human supervision and the related issues on quality, reliability, diversity, self-consistency, and undesirable biases. To address these challenges, we propose a novel approach called SELF-ALIGN, which combines principle-driven reasoning and the generative power of LLMs for the self-alignment of AI agents with minimal human supervision. Our approach encompasses four stages: first, we use an LLM to generate synthetic prompts, and a topic-guided method to augment the prompt diversity; second, we use a small set of human-written principles for AI models to follow, and guide the LLM through in-context learning from demonstrations (of principles application) to produce helpful, ethical, and reliable responses to user's queries; third, we fine-tune the original LLM with the high-quality self-aligned responses so that the resulting model can generate desirable responses for each query directly without the principle set and the demonstrations anymore; and finally, we offer a refinement step to address the issues of overly-brief or indirect responses. Applying SELF-ALIGN to the LLaMA-65b base language model, we develop an AI assistant named Dromedary. With fewer than 300 lines of human annotations (including<200 seed prompts, 16 generic principles, and 5 exemplars for in-context learning). Dromedary significantly surpasses the performance of several state-of-the-art AI systems, including Text-Davinci-003 and Alpaca, on benchmark datasets with various settings.",
    "venue": "arXiv.org",
    "year": 2023,
    "referenceCount": 79,
    "citationCount": 109,
    "influentialCitationCount": 13,
    "isOpenAccess": true,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/2305.03047",
      "status": null
    },
    "fieldsOfStudy": [
      "Computer Science"
    ],
    "journal": {
      "volume": "abs/2305.03047",
      "name": "ArXiv"
    },
    "authors": [
      {
        "authorId": "48064856",
        "name": "Zhiqing Sun"
      },
      {
        "authorId": "2714199",
        "name": "Yikang Shen"
      },
      {
        "authorId": "2107604346",
        "name": "Qinhong Zhou"
      },
      {
        "authorId": "2118083343",
        "name": "Hongxin Zhang"
      },
      {
        "authorId": "2111329651",
        "name": "Zhenfang Chen"
      },
      {
        "authorId": "2064715218",
        "name": "David D. Cox"
      },
      {
        "authorId": "46286308",
        "name": "Yiming Yang"
      },
      {
        "authorId": "2056157586",
        "name": "Chuang Gan"
      }
    ],
    "tldr": "An AI assistant named Dromedary is developed, which combines principle-driven reasoning and the generative power of LLMs for the self-alignment of AI agents with minimal human supervision and significantly surpasses the performance of several state-of-the-art AI systems on benchmark datasets with various settings."
  },
  {
    "profName": "Yiming Yang",
    "authorId": "46286308",
    "authorName": "Yiming Yang",
    "authorUrl": "https://www.semanticscholar.org/author/46286308",
    "authorHIndex": 17,
    "authorAffiliations": [],
    "authorPaperCount": 43,
    "authorCitationCount": 1532,
    "paperId": "fe9fe9f15f24fbbb19b62bcd9a3418511a699b84",
    "externalIds": {
      "DBLP": "journals/corr/abs-2305-13122",
      "ArXiv": "2305.13122",
      "DOI": "10.48550/arXiv.2305.13122",
      "CorpusId": 258832463
    },
    "url": "https://www.semanticscholar.org/paper/fe9fe9f15f24fbbb19b62bcd9a3418511a699b84",
    "title": "Policy Representation via Diffusion Probability Model for Reinforcement Learning",
    "abstract": "Popular reinforcement learning (RL) algorithms tend to produce a unimodal policy distribution, which weakens the expressiveness of complicated policy and decays the ability of exploration. The diffusion probability model is powerful to learn complicated multimodal distributions, which has shown promising and potential applications to RL. In this paper, we formally build a theoretical foundation of policy representation via the diffusion probability model and provide practical implementations of diffusion policy for online model-free RL. Concretely, we character diffusion policy as a stochastic process, which is a new approach to representing a policy. Then we present a convergence guarantee for diffusion policy, which provides a theory to understand the multimodality of diffusion policy. Furthermore, we propose the DIPO which is an implementation for model-free online RL with DIffusion POlicy. To the best of our knowledge, DIPO is the first algorithm to solve model-free online RL problems with the diffusion model. Finally, extensive empirical results show the effectiveness and superiority of DIPO on the standard continuous control Mujoco benchmark.",
    "venue": "arXiv.org",
    "year": 2023,
    "referenceCount": 97,
    "citationCount": 4,
    "influentialCitationCount": 0,
    "isOpenAccess": true,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/2305.13122",
      "status": null
    },
    "fieldsOfStudy": [
      "Computer Science"
    ],
    "journal": {
      "volume": "abs/2305.13122",
      "name": "ArXiv"
    },
    "authors": [
      {
        "authorId": "150196660",
        "name": "Long Yang"
      },
      {
        "authorId": "2218293583",
        "name": "Zhixiong Huang"
      },
      {
        "authorId": "2218119181",
        "name": "Fenghao Lei"
      },
      {
        "authorId": "2218100325",
        "name": "Yucun Zhong"
      },
      {
        "authorId": "46286308",
        "name": "Yiming Yang"
      },
      {
        "authorId": "47967033",
        "name": "Cong Fang"
      },
      {
        "authorId": "2992234",
        "name": "Shiting Wen"
      },
      {
        "authorId": "2218029625",
        "name": "Binbin Zhou"
      },
      {
        "authorId": "33383055",
        "name": "Zhouchen Lin"
      }
    ],
    "tldr": "A theoretical foundation of policy representation via the diffusion probability model is formally built, a convergence guarantee for diffusion policy is presented, and the DIPO is proposed, which is an implementation for model-free online RL with DIffusion POlicy."
  }
]