## PROFNAME
Bhiksha Raj
## AUTHORID
1681921
## AUTHORNAME
B. Raj
## AUTHORURL
https://www.semanticscholar.org/author/1681921
## AUTHORHINDEX
54
## AUTHORAFFILIATIONS
[]
## AUTHORPAPERCOUNT
404
## AUTHORCITATIONCOUNT
14485
## PAPERID
078f86c6a691806cc71bbef1e734f75690db0ffc
## EXTERNALIDS
{'DBLP': 'journals/corr/abs-2304-02135', 'ArXiv': '2304.02135', 'DOI': '10.1109/CVPR52729.2023.01914', 'CorpusId': 257952618}
## URL
https://www.semanticscholar.org/paper/078f86c6a691806cc71bbef1e734f75690db0ffc
## TITLE
FREDOM: Fairness Domain Adaptation Approach to Semantic Scene Understanding
## ABSTRACT
Although Domain Adaptation in Semantic Scene Segmentation has shown impressive improvement in recent years, the fairness concerns in the domain adaptation have yet to be well defined and addressed. In addition, fairness is one of the most critical aspects when deploying the segmentation models into human-related real-world applications, e.g., autonomous driving, as any unfair predictions could influence human safety. In this paper, we propose a novel Fairness Domain Adaptation (FREDOM) approach to semantic scene segmentation. In particular, from the proposed formulated fairness objective, a new adaptation framework will be introduced based on the fair treatment of class distributions. Moreover, to generally model the context of structural dependency, a new conditional structural constraint is introduced to impose the consistency of predicted segmentation. Thanks to the proposed Conditional Structure Network, the self-attention mechanism has sufficiently modeled the structural information of segmentation. Through the ablation studies, the proposed method has shown the performance improvement of the segmentation models and promoted fairness in the model predictions. The experimental results on the two standard benchmarks, i.e., SYNTHIA $\rightarrow$ Cityscapes and GTA5 $\rightarrow$ Cityscapes, have shown that our method achieved State-of-the-Art (SOTA) performance11The implementation of FREDOM is available at https://github.com/uark-cviu/FREDOM
## VENUE
Computer Vision and Pattern Recognition
## YEAR
2023
## REFERENCECOUNT
55
## CITATIONCOUNT
8
## INFLUENTIALCITATIONCOUNT
0
## ISOPENACCESS
True
## OPENACCESSPDF
{'url': 'https://arxiv.org/pdf/2304.02135', 'status': None}
## FIELDSOFSTUDY
['Computer Science']
## JOURNAL
{'pages': '19988-19997', 'name': '2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)'}
## AUTHORS
[{'authorId': '35659935', 'name': 'Thanh-Dat Truong'}, {'authorId': '144556913', 'name': 'Ngan T. H. Le'}, {'authorId': '1681921', 'name': 'B. Raj'}, {'authorId': '145863239', 'name': 'J. Cothren'}, {'authorId': '1769788', 'name': 'Khoa Luu'}]
## TLDR
This paper proposes a novel Fairness Domain Adaptation (FREDOM) approach to semantic scene segmentation, where a new adaptation framework will be introduced based on the fair treatment of class distributions to generally model the context of structural dependency.
