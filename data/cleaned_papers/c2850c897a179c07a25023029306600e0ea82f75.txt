Technological Univ ersity Dublin Technological Univ ersity Dublin
ARROW@TU Dublin ARROW@TU Dublin
Conf erence papers School of Computer Science
Queer In AI  A Case Study in Community-Led P articipat ory AI Queer In AI  A Case Study in Community-Led P articipat ory AI
Univ ersity of California, USA
Univ ersity of California, USA
See next page for additional authors
Follow this and additional works at  https / /arrow.tudublin.ie/scschcomcon
 Part of the Computer Engineering Commons , and the Social and Beha vioral Sciences Commons
Recommended Citation Recommended Citation
Ovalle, Anaelia  Subr amonian, Arjun  Singh, Ashwiin  V oelck er, Claas  Sutherland, Danica  Locatelli, Da vide 
Breznik, E va  Klubicka, F elip  Y uan, Hang  J, Hetvi  Zhang, Huan  Shrir am, Jaide v  Lehman, Kruno  Soldaini,
Luca  Sap, Maar ten  Deisenr oth, Mar c Peter  P acheco, Maria Leonor  Ryskina, Maria  Mundt, Mar tin 
Agar wal, Melind  McLean, Nyx  X u, Pan  Pr anav, A.  K orpan, Raj  Ra y, Ruchir a  Mathew , Sar ah  Ar ora,
Sarthak  John, S.T .  Anand, T anvi  Agr awal, Vishakha  Agnew , William  Long, Y anan  W ang, Zijie J.  T alat,
Zeerak  Ghosh, A vijit  Dennler , Nathaniel  Nosewor thy, Michael  Jha, Shar vani  Ba ylor, Emi  Joshi, Adity a 
Bilenko, Natalia Y .  McNamar a, Andr ew  Gontijo-Lopes, Raphael  Markham, Alex  Dong, E vyn  Ka y, Jackie 
Saraswat, Manu  V ytla, Nikhil  and Stark, L uke, "Queer In AI  A Case Study in Community-Led P articipat ory
AI" (2023). Conf erence papers . 407.
https / /arrow.tudublin.ie/scschcomcon/407
This Conf erence P aper is br ought t o you for fr ee and open access b y the School of Computer Science at
ARROW@TU Dublin. It has been accepted for inclusion in Conf erence papers b y an authoriz ed administr ator of
ARROW@TU Dublin. F or mor e information, please contact arrow.admin@tudublin.ie, aisling.co yne@tudublin.ie,
gerard.connolly@tudublin.ie, v era.kilshaw@tudublin.ie .
This work is licensed under a Creativ e Commons A ttribution-Shar e Alik e 4.0 International License . Authors Authors
Anaelia Ov alle, Arjun Subr amonian, Ashwiin Singh, Claas V oelck er, Danica Sutherland, Da vide Locatelli,
Eva Breznik, F elip Klubicka, Hang Y uan, Hetvi J, Huan Zhang, Jaide v Shrir am, Kruno Lehman, L uca
Soldaini, Maar ten Sap, Mar c Peter Deisenr oth, Maria Leonor P acheco, Maria Ryskina, Mar tin Mundt,
Melind Agar wal, Nyx McLean, P an X u, A. Pr anav, Raj K orpan, Ruchir a Ra y, Sar ah Mathew , Sar thak Ar ora,
S.T. John, T anvi Anand, Vishakha Agr awal, William Agnew , Yanan Long, Zijie J. W ang, Z eerak Talat, A vijit
Ghosh, Nathaniel Dennler , Michael Nosewor thy, Shar vani Jha, Emi Ba ylor, Adity a Joshi, Natalia Y . Bilenko,
Andr ew McNamar a, Raphael Gontijo-Lopes, Alex Markham, E vyn Dong, Jackie Ka y, Manu Sar aswat, Nikhil
Vytla, and L uke Stark
This conf erence paper is a vailable at ARROW@TU Dublin  https / /arrow.tudublin.ie/scschcomcon/407 Queer In AI  A Case Study in Community-Led Participatory AI
Organizers of QueerInAI
Many CountriesAnaelia Ovalle
Queer in AI & University of
California, Los Angeles
Queer in AI & University of
California, Los Angeles
Queer in AI & University of Toronto,
CanadaDanica J. Sutherland
Queer in AI & University of British
Queer in AI & Uppsala University
Queer in AI & ADAPT Centre,
Technological University Dublin
United KingdomHetvi J
United KingdomHuan Zhang
Queer in AI & University of
California, San Diego
SwitzerlandLuca Soldaini
Queer in AI & Allen Institute for AI
Queer in AI & Language Technologies
Institute, Carnegie Mellon University
& Allen Institute for AI
USAMarc Peter Deisenroth
Queer in AI & University College
United KingdomMaria Leonor Pacheco
Queer in AI & University of Colorado
Queer in AI & TU Darmstadt &
GermanyMilind Agarwal
Queer in AI & George Mason
Queer in AI & Rhodes University
Queer in AI & Duke University
Queer in AI & Iona University
Queer in AI & Georgia Institute of
Queer in AI & Aalto University
Queer in AI & University of
Queer in AI & University of Chicago
Queer in AI & Georgia Tech
Queer in AI & Northeastern
USAMichael Noseworthy
Queer In AI & SEEK, Australia
AustraliaNatalia Y. Bilenko
Queer in AI & Microsoft
CanadaRaphael Gontijo-Lopes
United KingdomManu Saraswat
Queer in AI & Western University
Queerness and queer people face an uncertain future in the face
of ever more widely deployed and invasive artificial intelligence
(AI). These technologies have caused numerous harms to queer
people, including privacy violations, censoring and downranking
queer content, exposing queer people and spaces to harassment
by making them hypervisible, deadnaming and outing queer people.
 More broadly, they have violated core tenets of queerness by
classifying and controlling queer identities. In response to this, the
queer community in AI has organized Queer in AI, a global, decentralized,
 volunteer-run grassroots organization that employs
intersectional and community-led participatory design to build an
inclusive and equitable AI future. In this paper, we present Queer in
AI as a case study for community-led participatory design in AI. We
examine how participatory design and intersectional tenets started
and shaped this community s programs over the years. We discuss
different challenges that emerged in the process, look at ways this
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
FAccT  23, June 12 15, 2023, Chicago, IL, USA
 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0192-4/23/06. . . $15.00
https //doi.org/10.1145/3593013.3594134organization has fallen short of operationalizing participatory and
intersectional principles, and then assess the organization s impact.
Queer in AI provides important lessons and insights for practitioners
 and theorists of participatory methods broadly through
its rejection of hierarchy in favor of decentralization, success at
building aid and programs by and for the queer community, and
effort to change actors and institutions outside of the queer community.
 Finally, we theorize how communities like Queer in AI
contribute to the participatory design in AI more broadly by fostering
 cultures of participation in AI, welcoming and empowering
marginalized participants, critiquing poor or exploitative participatory
 practices, and bringing participation to institutions outside of
individual research projects. Queer in AI s work serves as a case
study of grassroots activism and participatory methods within AI,
demonstrating the potential of community-led participatory methods
 and intersectional praxis, while also providing challenges, case
studies, and nuanced insights to researchers developing and using
participatory methods.
ACM Reference Format 
Organizers of QueerInAI, Anaelia Ovalle, Arjun Subramonian, Ashwin
Singh, Claas Voelcker, Danica J. Sutherland, Davide Locatelli, Eva Breznik,
Filip Klubiƒçka, Hang Yuan, Hetvi J, Huan Zhang, Jaidev Shriram, Kruno
Lehman, Luca Soldaini, Maarten Sap, Marc Peter Deisenroth, Maria Leonor
Pacheco, Maria Ryskina, Martin Mundt, Milind Agarwal, Nyx McLean, Pan
Xu, A Pranav, Raj Korpan, Ruchira Ray, Sarah Mathew, Sarthak Arora, ST
John, Tanvi Anand, Vishakha Agrawal, William Agnew, Yanan Long, Zijie J.
Wang, Zeerak Talat, Avijit Ghosh, Nathaniel Dennler, Michael Noseworthy,
1883Queer In AI  A Case Study in Community-Led Participatory AI FAccT  23, June 12 15, 2023, Chicago, IL, USA
Sharvani Jha, Emi Baylor, Aditya Joshi, Natalia Y. Bilenko, Andrew McNamara,
 Raphael Gontijo-Lopes, Alex Markham, Evyn D Àáong, Jackie Kay, Manu
Saraswat, Nikhil Vytla, and Luke Stark. 2023. Queer In AI  A Case Study in
Community-Led Participatory AI. In 2023 ACM Conference on Fairness, Accountability,
 and Transparency (FAccT  23), June 12 15, 2023, Chicago, IL, USA.
ACM, New York, NY, USA, 14 pages. https //doi.org/10.1145/3593013.3594134
Artificial intelligence (AI) has seen enormous developments in recent
 years, such as substantial advances in protein modeling, drug
discovery, weather prediction, and personalized medicine [ 67,102,
128]. The ubiquity of unregulated AI within socio-technical systems,
 however, often produces discriminatory outcomes and harms
marginalized communities globally [ 8,10,66]. For queer people in
particular, machine learning models learn brittle, toxic representations
 that cause representational and allocational harms, from
misgendering to healthcare discrimination [ 32,37,70,124]. Identifying
 and mitigating harmful outcomes has led to the development
of computational and socio-technical methods for achieving fairness
 [ 13,29,86], including automatic evaluation and unfairness
mitigation techniques [ 16,41,86]. While such approaches have
the potential to mitigate harms for queer people in domains like
fighting online abuse, health, and employment [ 124], computational
 techniques generally encode narrow conceptualizations of
fairness where queer identities are assumed to be known, observable,
 measurable, discrete, and static [ 81]. By locating the source of
unfairness in individuals or in specific design decisions [ 129], computational
 approaches to fairness can reinforce existing power relations
 [ 35,68], including marginalized communities only in predatory
 ways [ 53] or as  ethics washing  [ 112] (cf. Appendix  A for
an extended critique of computational approaches to fairness).
Participatory methods address some of these limitations. Involving
 users as co-designers holds great potential for dismantling
power relations and empowering marginalized communities that
are disproportionately impacted by AI [ 9,74,119]. Reflexivity in
participatory methods encourages transparency during the design
process itself, as opposed to a detrimental  innovate first, fix later 
approach to building trustworthy AI [ 48]. By establishing the valueladen
 nature of technologies, it can prevent personal biases, beliefs
and values from seeping into AI systems unexamined.
Unfortunately, there are many challenges to incorporating participatory
 approaches across top-down structures, such as corporations
 that operate within capitalism. Popular modes of participation
within AI suffer from extractive and exploitative forms of community
 involvement or  participation washing  [ 112]. For example,
a recent report [ 95] sheds light on how OpenAI used exploitative
labor practices to make ChatGPT less toxic, subjecting Kenyan
workers to psychologically distressing content1without sufficient
provision for mental health support. Gray and Suri [56] also uncovers
 many exploitative labor practices performed by minorities to
More fundamentally, we question whether marginalized communities
 should engage in designing with the creators of harmful
AI systems that prioritize profit over their safety. Even in projects
where communities are involved, engagement is too often limited
1This content included examples of sexual abuse, hate speech, violence, murder, child
abuse, rape, animal abuse, torture and self-harm.in scope and time. Contrary to participation being controlled by
the corporations and states the design and own AI, we argue in the
favor of shifting power towards marginalized groups and centering
their experiences. We call for a culture of participation in AI to
address this, one that enables deep and long-term participation in
AI research, institutions, and practices.
Over the years, the AI community has witnessed several
community-led efforts from marginalized communities, each
tackling issues of inequality that arise along various axes of
marginalization  these include Black in AI [ 12], LatinX in AI [ 77],
Women in Machine Learning [ 133], Masakhane [ 84], Widening
NLP [ 130], Diversity in AI [ 36], Indigenous in AI [ 64], Queer in
HCI [ 34], the Indigenous Protocol and AI Working Group [ 79], the
Deep Learning Indaba [ 31], Khipu [ 73], North Africans in ML [ 91],
{Dis}Ability in AI [ 63], Te Hiku Media [ 47], and Muslims in ML [ 88].
These organizations have worked in AI ethics, advocated against
AI harms, provided longstanding venues and visibility for AI
ethics research within major ML and NLP conferences, resolved
inclusion issues with those venues, and developed community-led
datasets, models, and other technology. Most importantly, they
have advanced participation by marginalized communities in AI
research and development at large, nurturing countless researchers
and practitioners with community, mentorship, financial aid,
and innumerable other forms of help with the many barriers
marginalized people face in AI. These groups have made AI much
more diverse, and strengthened the voices of marginalized people
In this work, we argue that AI ethicists who value participatory
methods as a means for making ethical AI should engage with participatory
 and community-lead AI ethics organizations, and study
their organizational, strategic, and administrative work through
which they are advancing participation and building cultures of
participation. This often difficult process involves navigating the
complexities of combining inquiry with praxis, and sheds light on
differences between participatory approaches.
To this end, we offer a case study analyzing Queer in AI, a grassroots
 organization that aims to raise awareness of queer issues in
AI/ML, foster a community of queer researchers and celebrate the
work of queer scientists. Operating primarily as an online community
 over Slack, the organization runs various programs and
initiatives towards fulfilling its mission. We analyze and critique
its principles, methodology, initiatives, and impact over the years
as a case study of community-led participatory methods in AI.
Our key contributions are 
 We document salient forms of marginalization and oppression
 that particularly affect queer people ( 2).
 We present the organizing principles and programs of Queer
in AI ( 3), including how they started, major changes, and
qualitative and quantitative analyses of impacts ( 4).
 We analyze challenges and shortcomings of Queer in AI ( 5).
 We present an argument for conducting more and valuing
AI ethics research that combines inquiry and praxis ( 6).
Positionality Statement Most authors of this paper are formally
trained as computer scientists, with some also having training in
gender theory or related fields. All authors have informal training
in queer studies through activism and advocacy. Our backgrounds
1884FAccT  23, June 12 15, 2023, Chicago, IL, USA Organizers of Queer in AI, et al.
Community ResponseGraduate School Application
Financial Aid Program
Trans-Inclusive Publishing
Tensions and ChallengesHierarchy Accessibility
Core PrinciplesDecentralized
OrganizingIntersectionality
OutcomesEquity Inclusivity
Community Role Models
Figure 1  Overview of Queer in AI s core principles, community responses, programming outcomes, and tensions and challenges.
influence this work s design, decisions, and development. We do
our best to position our work in a global context, with authors from
Asia, Europe, South Africa, South America, and North America.
2 MARGINALIZATION OF QUEER PEOPLE IN
Hegemonic forms of AI focus on classifying complex people and
situations into narrow categories at the cost of context, and are
often built to support surveillance, prediction, and control   designs
 which are fundamentally incompatible with queer identities
 rooted in the freedom of being [ 71]. The framing and use of
common AI systems that interact with gender are thus often problematic,
 and inherently cisnormative and heteronormative, so that
even well-meaning, purportedly inclusive AI projects are prone
to  designing out  certain queer lives [ 59]. Documented harms
across various AI applications are numerous, and sometimes lifethreatening.
 These include physiognomic and phrenologic applications
 such as computer vision to (falsely) infer gender and sexuality
 [ 4,70,72,80,107,108,118]. AI-enabled surveillance systems,
in conjunction with surveillance of online spaces such as dating
apps by states, corporations, and even individuals have outed queer
people, compromising their privacy and safety [ 22,61,92,94]. Online
 spaces, especially social media platforms, have insufficient
and poorly explained privacy and security tools, requiring community
 education and adaptation to meet the needs of queer people
 [33,54,96]. Their moderation enables widespread censorship
of queer words and identities [ 30,43,111,113], while also subjecting
 queer communities to disproportionate online harassment
and hate speech [ 97,125]. Some of these harms can be traced to
large language models (LLMs) trained on datasets containing hate
speech and censored queer words, leading search systems to avoid
queer content and content moderation systems to more often tag it
as suspect [ 37,55]. LLMs also overwhelmingly fail to account for
non-binary genders and pronouns, contributing to erasure of these
In the US, queer people are (at least) 20% less represented in
STEM than in the national population, and experience higher levels
 of  career limitations, harassment, and professional devaluation 
 [ 19]. Consequently, queer scientists often face  systematically
more negative workplace experiences than their non-LGBT colleagues 
 [ 20], and  leave STEM at an alarming rate  [ 51]. The
exclusion of queer people from science comes with significant
consequences, both for queer scientists and queer people further
marginalized by fields that do not understand or care about them.The medical profession s response to the HIV/AIDS crisis was fatally
 slow until pressured by heroic activism [ 110]  a medical field
that had included and empowered queer people may have saved
many queer lives. Similarly, the American Psychiatric Association
classified homosexuality as a mental illness until 1973, greatly contributing
 to the stigmatization of queer people around the world,
until queer activists pressured the group for change [ 38]. Recent initiatives
 have inverted this dynamics, centering queer communities
in descisions about mental healthcare [74].
One hurdle in understanding the marginalization of LGBTQIA 
people in STEM is a lack of demographic data on sexual orientation
and gender identity [ 51]. The US s National Science Foundation has
delayed the collection of such data for years, despite the urging of
queer scientists [ 76]. Taking matters into its own hands, Queer in AI
administers an annual survey of its global community to uncover
the demographics and challenges faced by queer researchers in
AI (discussed in detail in Appendix  B). In Queer in AI s 2021-22
community survey ( ùëÅ 252), 74% of members reported a lack of
role models and 77% reported a lack of community as obstacles in
their journey of becoming an AI practitioner.
There is a dire lack of studies and data on queer scientists  experiences
 in the Global South, where colonial histories have led
to the criminalization of queerness [ 1 3]. Queer in AI organizers
from Turkey, Colombia, and India have shared that much queer
activism in these countries focuses on survival and gaining basic
human rights, recognition and respect in society, amid high levels
of discrimination, violence, and psychological distress [ 23]. They
perceive being out and working towards queer visibility in STEM
fields to be beyond luxuries, especially given the dominant (cisnormative,
 heteronormative) view that identity and profession should
be  kept separate.  Barriers to acceptance are only amplified for
queer individuals also marginalized on intersecting axes like class
3 CORE PRINCIPLES OF QUEER IN AI
Three governing principles drive Queer in AI s mission to raise
awareness of queer issues in AI and foster a community of queer
researchers  (i) decentralized organizing, (ii) intersectionality, and
(iii) community-led initiatives. Overall, Queer in AI s decentralized
operations allow for swift community-led initiatives towards its
mission ( 3.1), which center on intersectionality as critical inquiry
and praxis ( 3.2). In doing so, it acknowledges and continuously
works to account for  the complexities of multiple, competing, fluid,
and intersecting identities  [ 58]. Queer in AI s primary approach
1885Queer In AI  A Case Study in Community-Led Participatory AI FAccT  23, June 12 15, 2023, Chicago, IL, USA
consists of including people with diverse lived experiences in participatory
3.1 Participation and Decentralization
For its first two years, Queer in AI had a hierarchical structure,
with a president and officers. However, organizing and governance
of grassroots communities, and especially queer communities,
presents unique challenges. Queer people are incredibly diverse,
and choosing one or even a group of queer people to represent
the community as a whole is reductive and impossible. This is also
difficult for the organizers, with high-profile queer activists and
organizers frequently facing targeted harassment campaigns, and
Queer in AI organizers frequently reporting lack of time, external
support, or recognition for volunteering (cf. Figure A16). Queer in
AI thus adopted a decentralized organizing structure, to encourage
broad participation. Queer in AI minimizes distinctions between
organizers and members to encourage the entire community to
participate in organizing. Most volunteer coordination occurs
in the same Slack channel as is used for community discussion,
calls for help or feedback on programs mixed with memes,
introductions, personal news, and discussions of travel or pets. Of
the 49 active Slack channels only 4, where personally identifiable
information is discussed, are not public. Openness and embedding
in the community increase transparency and accountability  any
community member can view organizing discussions and join
in, with no more barrier to entry than joining a Slack channel.
It also helps provide the connection and joy for which 75%
of its organizers joined Queer in AI (cf. Figure A15). Fluidity
between member and organizer also makes it easier for community
members  areas and levels of engagement to ebb and flow over
time without losing their connection to the community.
3.2 Participation and Intersectionality
Over five years, Queer in AI s community has grown to about 870
members, geographically distributed across more than 47 countries
 (cf. Figure 2). The community members have diverse identities
across axes such as ethnicity, gender, class, disability, and caste.
About 20.3% of respondents identified as transgender, and 34.4%
identified as non-cisgender  34.9% identified as Black, Latinx, indigenous
 or a person of color  less than 2% identified as intersex.
Membership spans academia and industry, with about 16% of members
 pursuing an undergraduate degree, 21% in an industry role,
and 64% in academia, all with varying degrees of seniority (cf. Appendix
  B.6 for additional details of community demographics). As
a result, Queer in AI helps naturally bridge otherwise insular aisles
of power and social contexts.
As the queer community consistently experiences discrimination,
 stigmatization, and inequity [ 18,87], Queer in AI uses the
lens of intersectionality as a means of critical inquiry to identify
how interlocking forms of oppression, such as racism and sexism,
co-construct and exacerbate social and structural disparities [ 26].
To proactively dismantle injustices, Queer in AI centers the experiences
 of its members so that active participation in the Queer in AI
community results in the co-creation of initiatives, which reflect
of tackling such barriers, including economic ( 5.3), educational
( 4.1), and social ( 4.2) ones. By prioritizing fighting intersectionaloppression, Queer in AI attempts to empower its most marginalized
members to shape and control its programming, addressing key
challenges of participatory design such as the exclusion of marginalized
 people from participation [ 69], community power-sharing [ 27]
and the co-formation of knowledge [ 45]. In doing so, Queer in AI
works towards a system of resistant knowledge firmly grounded in
intersectionality s critical praxis [25, Chs. 3 & 4].
3.3 Participation and Community Leadership
3.3.1 Research. Various forms of community-engaged research
guide the dissemination of knowledge both within and outside
of Queer in AI and exist across a continuum, from communityinformed
 to community-involved to community-led. Communityinformed
 research consists of researchers inviting the community
to incorporate lived experience to guide research questions, data
collection, or data interpretation [ 60]. Towards more communityinvolved
 research, community members may be more involved
in decision-making processes and research planning [ 60,105]. At
the highest level of engagement, community-driven approaches
such as community-based participatory action research (PAR) centers
 shared collaborative decision-making between researchers and
community members across research design, knowledge creation,
intervention development, and policy-making [ 28,82,126]. In practice,
 entities outside of the organization may partner with Queer
in AI community members to form relationships designed to help
objectives oriented towards investigating and supporting  the pursuit
 of answers to the questions of their daily struggle and survival 
[121]. Individuals are often members of both other entities as well
as of Queer in AI so that members may operate from the role of
an external entity (e.g. researcher from a company) and at various
 depths of community engagement. The resulting knowledge
production is such that is  by the people, for the people  in which
research is not only seen as a process to create knowledge but
to also educate and mobilize for action [ 28,57]. By  putting community
 first , the distinction between participant and researcher
is removed. Community-based participatory action research thus
also serves as a decolonizing epistemological framework which
inherently interrogates power and privilege [46].
3.3.2 Response & resilience. Within Queer in AI, community resilience
 operates across dimensions including but not limited to the
social, political, and economic. Advocacy efforts operate across domains,
 tasks, resources, and activities within the organization [ 75].
Resources and activities are structural means towards tasks and
domains that reflect the Queer in AI mission. Specifically, resources
and activities are dedicated to raising awareness of queer issues in
AI/ML. Financial, educational, and social avenues are created within
the organization as a form of creating resilience and advocacy in
the face of oppressive sociotechnical barriers. Operating across 47
countries, Queer in AI primarily organizes through Slack, Zoom, a
dedicated mailing list, and social media platforms. Doing so makes
room for rapid and adaptive situational awareness within the online
community [ 117]. Besides the  internal  milieu of an organization,
Queer in AI is responsive to events in both reactive and proactive
forms. Digital volunteer efforts emerge as self-organizing responses
to external factors [ 24,42]. This work further details examples of
1886FAccT  23, June 12 15, 2023, Chicago, IL, USA Organizers of Queer in AI, et al.
Figure 2  Country of origin of the respondents to the Queer in AI s 2021 2022 demographic survey.
Table 1  Self-reported ethnicity, gender, and sexual orientation of the respondents to the Queer in AI s 2021 2022 demographic
survey. Write-in responses were aggregated by a team of Queer in AI organizers, with some falling into multiple categories (cf.
Figure A4).  Unaggregated  refers to responses that could not be adequately described with any subset of other categories 
however, responses in this group may overlap with the remaining categories. For options with fewer than 4 responses, exact
values are omitted for privacy.
Ethnicity Gender Sexual Orientation
Caucasian 127 Man 108 Queer 90
South Asian 34 Woman 95 Gay 89
East Asian 17 Non-binary 61 Bisexual 87
Black/African/African-American 13 Genderqueer 29 Pansexual 42
Latinx 13 Gender non-conforming 22 Lesbian 30
Mixed 12 Genderfluid 19 Asexual 26
Jewish 8 Agender 17 Unaggregated 29
Middle Eastern 8 Questioning 16
Southeast Asian 6 Unaggregated 16
how responses to acute external factors and larger efforts against
oppression manifest as Queer in AI initiatives.
4 QUEER IN AI INITIATIVES
The structure of Queer in AI is decentralized and includes volunteers,
 core organizers (extensive organizing experience with Queer
in AI) and a diversity, equity and inclusion admin (DEIA, a core
organizer who has a more active role in administrative duties). Most
of Queer in AI s communication is mediated by its Slack workspace.
A key aspect of Queer in AI s organizing lies in the transparency
of its operations and associated information exchanges, which predominantly
 take place over public Slack channels. There are only
four private channels on the workspace, which exist to preserve
privacy while facilitating discussions around personally identifiable
 information. The workspace has included the exchange of
over 133,000 messages (including individuals  one-to-one private
messages), of which over 25,000 have been sent in public channels,
accounting for the majority (57%) of total views. This transparency,
in conjunction with regular updates and outreach on Slack, keeps
community members involved in ongoing events and initiatives.Many of Queer in AI s initiatives have emerged from conversations
 and threads on public channels about discriminatory experiences
 with different institutions. For example, discussion around
exclusionary gender collection practices on conference registration
forms led to the creation of an inclusive conference guide (covered
in more detail in  4.3) and substantial improvements to relevant
conferences  practices. Similarly, significant advocacy against deadnaming
 in citations and conference proceedings ( 4.4) began from
discourse on public channels. Thus, as a space, Queer in AI s Slack is
effective at mobilizing community-led initiatives through decentralized
 organizing. Moreover, the emergence of these initiatives from
diverse yet intersecting shared queer experiences grounds them
in global contexts of social inequality and injustice. For instance,
Queer in AI s graduate school application financial aid program
( 4.1) and workshops and socials ( 4.2) target several particular
challenges rooted in non-Western contexts, centering otherwisemarginalized
 experiences. The organizational and volunteer work
that constitutes the administration of all these initiatives is thus
deeply intersectional.
1887Queer In AI  A Case Study in Community-Led Participatory AI FAccT  23, June 12 15, 2023, Chicago, IL, USA
We now examine four major initiatives in detail  Appendix  C
further describes efforts in policy advocacy.
4.1 Graduate School Application Financial Aid
Queer folks report a lack of community and queer role models due
to the underrepresentation of senior queer folks in academia. Thus,
supporting queer and low-income scholars financially helps bring
more marginalized voices into STEM academia, creating more opportunities
 for participatory research and technology design. To
address this, Queer in AI launched the Graduate School Application
 Fee Aid Program to improve queer representation and make
graduate programs accessible.
4.1.1 Financial challenges. The costs for graduate school applications
 prevent many low-income and international scientists from
accessing graduate programs, well before they can benefit from
many of the fellowships and need-based scholarships intended to
address exclusion. This process is costly  between the application
fees ( $50 $150 USD per program in North America and parts of
Europe), costs of required tests (e.g. GRE), test results and transcript
 delivery fees, and test preparation expenses, one round of
applications can easily amount to over $1,000 USD. International
applicants may be further required to pay for language proficiency
tests (e.g. TOEFL), translation services, and third-party credential
vetting. Although some schools offer fee waivers, they vary widely
from school to school, are often very limited in applicability, and
can require onerous documentation.
The majority of applicants apply to North American schools.
This is likely caused by the cultural dominance of Anglo-American
schools in the AI/ML space and the common practice of requiring
extensive standardized tests and application fees at these schools.2
Standardized tests like the GRE claim to level the playing field for
applicants, they institute barriers to individuals from the Global
South and reify colonialism under a veneer of fairness. Additionally,
 fees make these exams wholly inaccessible to many in the
Global South  the GRE costs three times the average monthly salary
in Ethiopia [ 11]. Data collected from Queer in AI s surveys have
been used to argue that departments should eliminate the GRE and
These financial challenges are particularly likely to be insurmountable
 for queer scientists, who may be cut off from familial
financial support, might pay out of pocket for gender-affirming
healthcare, and often incur additional expenses managing oppression
 and trauma. Queer people thus suffer from increased student
loan debt [ 83] and high rates of housing insecurity [ 131]. A complete
 critique of the graduate application process and its socioeconomical
 context is out of the scope of this paper. Queer in AI
believes it is nonetheless important to provide concrete aid right
now to applicants faced with the current system.
4.1.2 Mutual aid design. The design of the aid program is decentralized,
 community-led constituting volunteers with a diverse range
2While fees and standardized tests are the norms at many prominent institutions,
there are examples of alternative paths, such as the ELLIS PhD Program, a European
initiative for AI/ML PhD programs, which requires neither [44].of experiences with graduate school admissions [ 114]. This initiative
 keeps minimum barriers to receiving the aid by not seeking
to decide who is  deserving  of aid, avoiding imposing excessive
requirements for documenting eligibility and providing timely mentorship
 and help to the applicants for their submissions. Although,
the payment pipeline often disadvantages applicants from countries
 and territories where PayPal is not available or restrictions
are imposed on receiving transfers from the US.
4.1.3 Participatory learnings. Each aid applicant is treated as a
member of the community with a valuable perspective of their
own   the initiative actively seeks feedback from aid recipients
and encourages them to volunteer in the future, which would both
help improve the program and keep it sustainable. This feedback
indicated that aid recipients  demographics were more diverse than
Queer in AI s organizing team (Table 3), which helps Queer in AI
recruit more diverse volunteers and community members by first
directly, meaningfully helping them. Also, the feedback survey illustrates
 widespread deficiencies in existing admissions fee waivers 
such as lack of fee waivers (67%), unable to produce adequate documentation
 (14%) and the fear of outing themselves (10%). This aid
program allowed recipients to take admissions tests (56%), avoid
skipping essential expenses (54%) and avoid skipping groceries or
bills (40%). The vast majority of recipients reported the scholarship
 enabled them to apply to additional programs (around 6 on
4.1.4 Critical Reflections. The program operates with a tension
between opening opportunities to marginalized people from all
over the world and reinforcing the exclusionary practices of these
powerful institutions. In addition to funding influential and rich
academic institutions, the program also indirectly supports the
standardized testing industry. The limited amount of funds and
barriers to sending the money internationally often pose challenges
between the organizers and the aid recipients. In spite of that, Queer
in AI believes that it is crucial to provide timely aid regardless of
these barriers, even if doing so reinforces undesirable structures.
4.2 Workshops and Socials
In STEM disciplines, conferences can be a hostile setting for minoritized
 groups [ 85,104,134]. Queer in AI members in 2022 rated how
welcome they felt attending AI conferences at 3.38 on average ( ùúá1/2
  3) on a five-point Likert scale (cf. Appendix   B). Recognizing
this need, Queer in AI has organized workshops and networking
events since its very first informal meetup at NeurIPS 2017  as of
submission, 13 workshops and 35 social events in total (Table 4),
with a cumulative attendance of hundreds of participants.3These
events provide an opportunity to connect and network with other
queer scientists, spotlight work by members of Queer in AI, host
talks on topics relevant to its members, and arrange panels where
experts discuss topics at the intersection of AI, fairness, ethics, and
the queer community. The following subsections cover how Queer
in AI s principles influence event planning and enable them to
overcome challenges in the process.
3An exact count could not be obtained  to maintain attendees  privacy, Queer in AI
does not require signups for most events, and deletes names immediately after events
when they are required.
1888FAccT  23, June 12 15, 2023, Chicago, IL, USA Organizers of Queer in AI, et al.
Table 2  The Queer in AI Graduate School Application Fee Aid Program budget and impact per academic year, in USD.
Academic year Aid per applicant No. aid recipients Total aid Budget
2020/2021 up to $750 31 $16,689 $20,000
2021/2022 up to $1,250 81 $70,607 $73,768
2022/2023 (at time of writing) up to $1,250 48 $40,476 $41,711
Table 3  Gender, sexual orientation, romantic orientation and continent of scholarship recipients who filled the optional
feedback survey ( ùëõ 46out of ùëÅ 160total recipients). For options with fewer than 4 responses, exact values are omitted for
Gender Sexual Orientation Romantic Orientation Continent
Woman 20 Gay 18 Homoromantic 21 Asia 19
Man 18 Queer 16 Biromantic 13 North America 14
Genderqueer 7 Bisexual 12 Demiromantic 5 Africa 5
Non-binary 6 Lesbian 9 Grayromatic 5 Europe  3
Gender non-conforming 6 Asexual 4 Alloromantic  3 South America  3
Agender  3 Pansexual 4 Aromantic  3
Genderfluid  3 Demisexual  3 Heteroromantic  3
Questioning  3 Questioning  3
Table 4  Workshop and events organized by Queer in AI in 2017 2022 across conferences in AI. Events marked with pwere held
in person, vindicates virtual-only events, and hrefers to events that occurred in a  hybrid  format.
Year 2017 2018 2019 2020 2021 2022
EMNLPv ICMLvNeurIPSv5
AAAIpAACLvACLvCogSciv
COLINGvCORLvEMNLPvFAccTp
EMNLPvICLRvICMLvNAACLv
 at EMNLP 2021, Queer in AI co-hosted a workshop with WiNLP.
 at FAccT, Queer in AI hosted two CRAFT sessions.
4.2.1 Workshop Organizing. Queer in AI workshops and socials
are typically organized by members of the community planning
to attend the conference  no prior academic or organizing experience
 is required. Junior or new members of the community are
often encouraged to lead these initiatives while being mentored by
more experienced organizers throughout the process. Organizers,
DEIAs, and Queer in AI s financial stewards coordinate to secure
logistical, monetary and other miscellaneous needs of the event.
These include renting equipment to support accessibility, honoraria
for speakers, scholarships for attendees, refreshments for socials,
online outreach and promotion of the event, and so on. All of this
communication takes place asynchronously over Slack, or in Zoom
meetings scheduled across organizers  time zones. This decentralized
 approach also helps enable Queer in AI members spanning
different sub-fields in AI to tailor events to represent and serve
the needs of their sub-community. When prompted to rate how
welcome they felt at these workshops, the response was overwhelmingly
 positive, with about 47% of queer attendees rating it five out
of five on a Likert scale ( ùúá 4.16, ùúá1/2 4) (cf. Appendix   B6).
4.2.2 Panels and Talks at Workshops. Panels and talks at Queer in
AI are crucial as they help in amplifying queer voices and concerns
in our field. Many topics presented in the panels and keynotes have
later served a bigger impact in the AI field, such as talks on conference
 inclusivity and name change policies. Queer in AI encourages
a participatory approach to workshop design  by soliciting topicsand speaker ideas from community workspace. This approach has
allowed Queer in AI to host panels and talks on intersectional topics
that often do not have a presence at major AI/ML venues (for just
one example, a discussion on the intersection of queerness, caste
and AI at NeurIPS 2021 [ 99]). Queer in AI organizers spend tremendous
 effort by making the workshops as inclusive as possible by
providing fair honoraria to the speakers and organizing the events
in online, hybrid, and in-person settings.
4.2.3 Barriers and Challenges in Participation. AI conferences are
often not accessible for a sizable portion of queer researchers, especially
 those belonging to other marginalized backgrounds or from
countries with lower purchasing power or higher rates of discrimination
 towards queer people [ 127]. Primary reasons includes high
registration and travel costs. Out of all Queer in AI members who
reported being unable to attend conferences owing to lack of funding,
 88% identified as one of black, indigenous, person of color,
transgender, neurodivergent, or disabled (cf. Appendix   B6). While
Queer in AI tries to work with conference organizers to use DEI
funds for increasing the attendance of queer scientists, in many
cases conference organizers refuse to engage with Queer in AI s
requests. Queer in AI thus often provides a combination of travel
grants, registration waivers, and reimbursement for conferencerelated
 expenses to queer AI researchers. In other cases, unofficial
1889Queer In AI  A Case Study in Community-Led Participatory AI FAccT  23, June 12 15, 2023, Chicago, IL, USA
social events4near the conference venue and online virtual socials
 on gather.town are organized to accommodate excluded time
zones and overcome both financial and geographical access barriers.
Other barriers specific to the conference location, such as unsafe
legal and social climates5for queer people or exclusionary visa
processes, continue to significantly limit queer participation within
AI spaces. Finally, for conferences which are poorly equipped in
their support for disabled people, Queer in AI provides live captions
for all in-person and virtual events, and secures equipment to create
4.3 Advocacy for Improving Queer Inclusivity
As conferences moved online in response to the COVID-19 pandemic,
 Queer in AI organizers noted a series of operational failures
that could cause queer attendees to feel unsafe or unwelcome. Registration
 platforms demanded attendees to provide their legal names,
thus potentially deadnaming them  the use of pronoun badges for
speakers and attendees was rarely encouraged, or platforms did
not support displaying pronouns  virtual chat software blocked
common queer terms such as  queer  or  lesbian , thus preventing
queer attendees from communicating freely. Queer in AI organizers
worked closely with many conferences to resolve these issues, as
they had in prior settings ( 4.2), and ultimately decided to collect
recommendations aimed at highlighting best practices to ensure
safety, privacy, and accessibility for queer attendees at academic
conferences in AI in a collected guidance document.6
These recommendations began based on existing best practices
and experience with conference organizers, but were refined
through extensive iterative feedback from members of Queer in
AI and other affinity groups, incorporating many opinions and
ultimately achieving consensus among a broad group of contributors.
 The guide has recently been expanded to also cover in-person
events as conferences move to hybrid or in-person formats.
This queer advocacy to improve inclusivity covers two aspects 
improving queer safety and increasing queer representation.
4.3.1 Improving Queer Safety  As in any public space, queer
conference-goers might face discrimination based on their gender
and sexual orientation. Therefore, it is paramount for attendees
to be able to control what information they wish to disclose
to the organizers and attendees of a conference. Queer in AI
advocates mechanisms to (i) respect attendees  identities by
collecting gender and pronoun information in a manner that does
not misrepresent or erase queer identities, by creating forms with
inclusive gender categories and disclosing the data usage [ 106] (ii)
minimize the amount of personal information queer individuals
have to disclose [ 7] (for example, only collecting legal names
when absolutely necessary, and using responses about the gender
4These events are not officially included within the conference program but promoted
over Queer in AI s Slack and mailing list as well as social media. A recent example is
AAAI 2023 where the conference fees was exorbitantly high and negligible effort was
put into provision for registration waivers.
5EMNLP 2022 (in Abu Dhabi) predatorily included Queer in AI to obtain their approval
for conference safety measures  Queer in AI rejected this, due to the conference
operating at a different domain of power for trans people and the power inherent in
speaking for the entire queer community.
6The guide, originally published as [ 101], is a living document available at
queerinai.com/how-to-make-virtual-conferences-queer-friendly.and sexuality of attendees only for statistical purposes and in
anonymized form)  and (iii) ensure that mechanisms to report
disruptive or harmful behaviours are swift and effective. Queer in
AI recommends adopting a code of conduct ( e.g., [100,132]) to not
only establish communication norms, but also describe how policy
violations are handled [39].
4.3.2 Increasing Queer Representation and Participation  Queer researchers 
 needs are regularly ignored in many aspects of the research
 community  challenges include lack of academic support,
hostility from colleagues and advisors, inflexible name change policies,
 lack of representation in the research itself, and more [ 21].
Stronger inclusion efforts, both for representation and participation,
 can work towards addressing a lack of queer community and
role models [ 109]. To increase representation, Queer in AI strongly
encourages conference organizers to invite queer keynote speakers
and panelists, prioritizing those from marginalized backgrounds
(e.g., BIPOC or non-cisgender) [ 40]. Queer in AI recommends fair
and equal compensation based on effort rather than seniority for
all speakers [ 52,103]. As noted in previous sections, financial accessibility
 and a lack of community were the main barriers for queer
folks to feel included at conferences. Queer in AI strongly advocates
setting up spaces for queer folks to network and socialize with privacy
 measures and also providing subsidies for queer researchers
to attend virtual or in-person events.
4.3.3 Critical Reflection. This guide and advocacy are not without
their limitations. Most recommendations are still focused on virtual
 spaces and currently written guide lacks in-depth accessibility
recommendations. Queer in AI needs to collaborate with disabled
folks with a wider range of disabilities to document best practices
regarding accessibility accommodations. Most significantly, despite
organizers  efforts the guide has seen relatively modest adoption.
4.4 Trans-inclusive Publishing Advocacy
For many transgender, non-binary, and gender-diverse scholars
(as well as others), the continued circulation of a previous name
in publishing is a significant source of trauma [ 122]. Referring to
an author by a previous name without consent (deadnaming) may
effectively out their identity against their will. Queer in AI has
worked along with the Name Change Policy Working Group [ 89]
to advocate name change policies in AI venues, helping to establish
the name-change policies and procedures now adopted by most
AI-related venues [ 5,6,14,15,62,78,90,123] (cf. Appendix   C for
more about Queer in AI s advocacy and impact).
Even publishers with functional name change policies are often
woefully slow to implement them, and search engines can index
outdated information long after its correction [ 115,116]  moreover,
authors often use outdated bibliographic entries long after relevant
publications and search tools have been updated [ 120]. It is thus
vital to check the correctness of citations in submitted papers to
avoid propagating incorrect information. QueerInAI has thus developed
 a tool to check paper PDFs for mistaken citations. It searches
the ACL Anthology, DBLP, and arXiv for a close paper title match,
and prompts a correction if the paper s author list disagrees with
that source, detecting both deadnaming and incomplete or outdated
1890FAccT  23, June 12 15, 2023, Chicago, IL, USA Organizers of Queer in AI, et al.
author lists. DBLP in particular provides better name change support
 than many other platforms, via ORCID [ 93]. This toolkit has
been integrated into ACL publication camera-ready systems [ 98],
and Queer in AI hopes to expand it to other conferences. A demo
is available at qinai-name-check.streamlit.app.
Additionally, Queer in AI advocates publishers to promptly grant
name correction requests in any format, without unnecessary barriers
 or documentation requirements. Such changes should remove
all instances of authors  previous names from all records, or (at
the author s discretion) add disclaimers for media that cannot be
updated ( e.g., audio or video recordings). As the result of this advocacy,
 Queer in AI has helped institute effective name-change
processes at NAACL and EMNLP  and has worked with the Association
 for Computational Linguistics [ 49] to implement a name
change process, proactive measures to prevent the deadnaming of
trans authors, and protocols to handle authors  requests to keep
their videos private.
5 TENSIONS AND CHALLENGES
As reflexivity is a core tenet of intersectionality [ 25], this section
critically examines the tensions and challenges that emerge in the
operationalization of Queer in AI s principles within its initiatives.
From the issues with Queer in AI initiaitves discussed in the previous
 section, we find three common, root themes of hierarchy,
accessibility , and funding . We argue that these are not only critical
 challenges for Queer in AI, but deep challengesany participatory
or community-lead AI organization must address to be successful.
Decentralized organizing plays a vital role in minimizing power
distance and distinctions between members of Queer in AI. Even so,
there are notable distinctions between members who participate
in organizing, core organizers, and the DEIAs as paid contractors.
Queer in AI s core organizers and DEIAs help sustain the growth of
the organization through mentorship of new volunteers and institutional
 memory. In addition, they form a relatively large and diverse
group for deliberating on rare decisons that cannot be discussed
openly, such as those involving PII. Their existence does, however,
pose challenges in accessibility for people unfamiliar with navigating
 unstructured social networks, and can be non-transparent
to newer or less involved members. The core organizers also assume
 a more active role, sharing considerable power in steering
the direction of its initiatives. Queer in AI helps address these tensions
 by setting a fixed one-year tenure for DEIAs, and inducting
organizers who have been active throughout the preceding year
as core organizers. Resolving tensions between decentralization
and hierarchies created by knowledge and experience, or forced
by privacy concerns, nonetheless remains an open problem within
Despite global participation, Queer in AI s structure and operational
 design can discourage participation for many queer scientists.
 First, participation in a volunteer-run community not only
requires organizers to have income that allows them to perform
free labor but also have access to computers, internet, and otherresources required to even connect with Queer in AI. Second, while
Queer in AI strives to be intersectional, it severely lacks access to
queer networks in countries from the Global South. It originated
and primarily operated within a Western context during its initial
years, which led to the inadvertent creation of barriers that limit
its outreach. For example, because Queer in AI organizers are best
connected with US and European institutions, its events are often
co-located at conferences attended mainly by scientists residing in
the Global North. Further, its meetings often occur at times best
aligned with European and American time zones, at the expense
of much of Asia. Finally, all Queer in AI activities require English
While recent community and focused outreach efforts have reduced
 some of these barriers, significant work lies ahead in establishing
 truly global ways of participation, especially for countries
where queerness is criminalized. Third, participation in Queer in
AI exerts a toll on mental health and exhaustion of its organizers
(cf. Figure A16). This is partly due to Queer in AI s lack of formal
structure, instead relying on individuals self-coordinating on initiatives
 of their choice. While efficient, this approach can make joining
and keeping track of ongoing efforts challenging for newcomers
and neurodivergent members of the community. Past organizers
have also shared anecdotes of experiencing exhaustion, fatigue, and
anxiety due to a lack of accommodation of different working styles
and falling behind on personal schedules while undertaking operational
 work for Queer in AI (cf. Figure A16). This disproportionately
impacts disabled and neurodivergent members and is compounded
for intersecting marginalized identities.
Even after years of critical reflection and significant investment
of volunteer time, money, and other resources, Queer in AI is still
inaccessible to many. While accessibility to everyone should always
be the goal, in practice, no single community or participatory initiative
 will be able to include everyone in that community. Therefore,
participatory researchers aspiring to broad inclusion should consider
 the pluralities of communities and participatory initiatives
with radically different structures.
Funding and payments are where Queer in AI struggles most to
meet its commitments to decentralization, intersectionality, and
community leadership. Queer in AI relies on sponsorships, donations,
 and contributions from its parent organization oSTEM to fund
its activities. In 2022, Queer in AI expenses (rounded to the closest
integer) totaled US$100,658  the graduate application fee scholarship
 program ( 4.1) spent $40,435  two DEIA contractors were paid
a total of $33,220  speaker honoraria totaled $14,500  $6,941 went
to travel grants, room and board, and conference registration fees 
emergency microgrants for queer people totaled $5,000. Income
comprised $78,000 in corporate sponsorship, $13,711 in donations,
and $5,000 in grant revenue (cf. Appendix  B.9 provides income
and expenses for previous years.).
Queer in AI s reliance on corporate sponsorship may call into
question its independence and community-lead ideal. Corporate
sponsors receive access to opt-in resume books, short speaking
opportunities, and event recruiting booths. A large part of Queer
1891Queer In AI  A Case Study in Community-Led Participatory AI FAccT  23, June 12 15, 2023, Chicago, IL, USA
in AI s funding still comes from big tech corporations that are complicit
 in oppression and genocide globally, such as the policing of
Palestinians. Queer in AI has nonetheless dropped and turned down
many sponsors for ethics concerns, including a mutual decision
with Black in AI in 2021 to drop Google [ 65], costing $20,000 in
lost sponsorship per year. While Queer in AI has been growing
donations, many in the Queer in AI community are students or
early in their careers with very limited capacity to give. Opportunities
 for grants are limited, as many scientific funding bodies
such as the US s NSF exclude queer people from many of their D&I
Queer in AI sends honoraria, scholarships, and travel grants to
people in many different countries, primarily through PayPal and
wires. Payment disbursal in Queer in AI is highly centralized  for
reasons of security oSTEM only allows one Queer in AI organizer
to send PayPal payments. All wires and credit card payments must
be sent by the oSTEM CEO. Additionally, payments strain Queer in
AI s intersectional values. PayPal does not work well in China, India,
 many countries in Africa, and some countries in South America,
forcing reliance on slower and more administratively difficult wire
transfers. Moreover, U.S. law requires people receiving honoraria
and other types of payments to pay US taxes above a certain threshold,
 which requires a lengthy registration process or significant fees
and overhead from Queer in AI. Payments also frequently trigger
spurious fraud alerts and investigations, which require even more
time from and stress on organizers.
In summary, marginalization prefigures Queer in AI s funding
options, legal and security concerns exert a strong centralizing pressure
 on financial administration, and the financial system regards
many payments, especially to non-Western countries and those
making them, with suspicion by default.
Participatory methods have the potential to address issues of power
and inclusion in AI, but their benefits and challenges in practice
are still unclear because few organizations have deeply engaged
with them. In this paper we studied Queer in AI as a case study
of a grassroots participatory AI organization. We explored how
they designed their organization to enable participation, and how
initiatives addressing intersectional marginalization arose from and
were continuously refined by this participation. We theorized how
Queer in AI s numerous socials, workshops, and other events have
contributed to a culture of participation in AI by bringing queer
people into AI conferences and research and industry settings and
resisting predatory inclusion. We hope this case study will inform
theoretical study and practical design of participatory initiatives. In
particular, we encourage consideration of Queer in AI s reinforcing
principles of decentralization, community leadership, and focus on
intersectionality, and urge care for mitigating the ways hierarchy,
inaccessability, and funding can subvert participatory methods.
6.1 Future Directions
Queer in AI will continue to grapple with the tensions and alleviate
the challenges addressed in  5. To dismantle hierarchies among
organizers created by knowledge, experienced Queer in AI organizers
 will host structured trainings to onboard new organizersonto finance & sponsorships and workshops. Queer in AI additionally
 plans to supplement its 2023 community survey with community
 interviews about accessibility, towards gleaning actionable
insights about mitigating barriers to participation. Furthermore,
Queer in AI s organizers will work with its community to refine its
sponsorship policies and identify less precarious mechanisms for
transferring funds. All of these activities are motivated and will be
guided by our core principles of decentralization, intersectionality,
and centering community. Queer in AI will further communicate
its activities and their implications for equity and inclusivity via
accessible media, e.g., blog posts, zines.
This work would not have been possible without the activism and
organizing efforts of the Queer in AI community. We would also
like to thank Katta Spiel and Os Keyes for their insightful feedback
on the earlier versions of the paper.
[1]2015. Some African Countries Are Trying to Use Science to
Make Homophobic Laws, Now African Scientists are Pushing Back.
https //www.smithsonianmag.com/smart-news/africans-scientists-speak-outagainst-homophobic-laws-180955579/
[2]2020. A constant uneasy state  Trans people in STEM in India. https //
thelifeofscience.com/2020/11/09/transgender-people-in-science/
[3]2022. Brazil LGBTQ activists, HIV/AIDS service providers fear Bolsonaro reelection.
 https //www.washingtonblade.com/2022/05/19/brazil-lgbtq-activistshiv-aids-service-providers-fear-bolsonaro-reelection/
[4]Blaise Ag√ºera y Arcas, Margaret Mitchell, and Alexander Todorov. 2017. Physiognomy s
 New Clothes. https //medium.com/@blaisea/physiognomys-newclothes-f2d4b59fdd6a
[5]ACL Anthology. (n.d.). Requesting Corrections. https //aclanthology.org/info/
corrections/ [Accessed Feb 2023].
[6]arXiv. 2021. arXiv Proceedings  Name Change Policy. https //blog.arxiv.org/
2021/03/11/update-name-change-policy, Name Change Policy blog.
[7]Alison Barclay and Melissa Russell. 2017. A guide to LGBTIQ-inclusive data
collection. https //meridianact.org.au. https //meridianact.org.au/wp-content/
uploads/LGBTIQ-Inclusive-Data-Collection-a-Guide.pdf
[8]Emily M Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret
Shmitchell. 2021. On the Dangers of Stochastic Parrots  Can Language Models Be
Too Big . In Proceedings of the 2021 ACM Conference on Fairness, Accountability,
and Transparency . 610 623.
[9]Abeba Birhane, William Isaac, Vinodkumar Prabhakaran, Mark Diaz,
Madeleine Clare Elish, Iason Gabriel, and Shakir Mohamed. 2022. Power to the
People  Opportunities and Challenges for Participatory AI. In Equity and Access
in Algorithms, Mechanisms, and Optimization (Arlington, VA, USA) (EAAMO  22) .
Association for Computing Machinery, New York, NY, USA, Article 6, 8 pages.
https //doi.org/10.1145/3551624.3555290
[10] Abeba Birhane, Vinay Uday Prabhu, and Emmanuel Kahembwe. 2021. Multimodal
 datasets  misogyny, pornography, and malignant stereotypes. arXiv
(2021). https //arxiv.org/abs/2110.01963
[11] Black in AI. 2020. Academic Program. https //blackinai.github.io/#/programs/
[12] Black in AI (n.d.). https //blackinai.github.io
[13] Su Lin Blodgett, Solon Barocas, Hal Daum√© III, and Hanna Wallach. 2020. Language
 (Technology) is Power  A Critical Survey of  Bias  in NLP. In Proceedings
 of the 58th Annual Meeting of the Association for Computational Linguistics.
 Association for Computational Linguistics, Online, 5454 5476. https 
//doi.org/10.18653/v1/2020.acl-main.485
[14] ACM Publications Board. 2019. ACM Publications Policy on Author Name
Changes. https //www.acm.org/publications/policies/author-name-changes
[15] Melisa Bok. 2022. Comment on issue  Transphobic name and email policy. https 
//github.com/openreview/openreview/issues/28#issuecomment-1124245541
[16] Tolga Bolukbasi, Kai-Wei Chang, James Y. Zou, Venkatesh Saligrama, and
Adam Tauman Kalai. 2016. Man is to Computer Programmer as Woman is
to Homemaker  Debiasing Word Embeddings. Advances in Neural Information
Processing Systems 29 (2016).
[17] Yang Trista Cao and Hal Daum√© III. 2020. Toward Gender-Inclusive Coreference
Resolution. In Proceedings of the 58th Annual Meeting of the Association for
1892FAccT  23, June 12 15, 2023, Chicago, IL, USA Organizers of Queer in AI, et al.
Computational Linguistics . Association for Computational Linguistics, Online,
4568 4595. https //doi.org/10.18653/v1/2020.acl-main.418
[18] Logan S Casey, Sari L Reisner, Mary G Findling, Robert J Blendon, John M
Benson, Justin M Sayde, and Carolyn Miller. 2019. Discrimination in the United
States  Experiences of lesbian, gay, bisexual, transgender, and queer Americans.
Health services research 54 (2019), 1454 1466.
[19] EA Cech and TJ Waidzunas. 2021. Systemic inequalities for LGBTQ professionals
in STEM. Science advances 7, 3 (2021), eabe0933.
[20] Erin A. Cech and Michelle Pham. 2017. Queer in STEM Organizations  Workplace
 Disadvantages for LGBT Employees in STEM Related Federal Agencies.
The Social Sciences 6 (2017), 12.
[21] Erin A. Cech and Michelle V. Pham. 2017. Queer in STEM Organizations  Workplace
 Disadvantages for LGBT Employees in STEM Related Federal Agencies.
Social Sciences 6, 1 (2017). https //doi.org/10.3390/socsci6010012
[22] Pia Ceres. 2022. Kids are back in classrooms and laptops are still spying on
them. Wired (Aug 2022). https //www.wired.com/story/student-monitoringsoftware-privacy-in-schools/
[23] Soon Kyu Choi, Shahrzad Divsalar, Jennifer Fl√≥rez-Donado, Krystal Kittle,
 Andy Lin, Ilan H. Meyer, and Prince Torres-Salazar. 2019. STRESS,
HEALTH, AND WELL-BEING OF LGBT PEOPLE IN COLOMBIA. https 
//www.ohchr.org/sites/default/files/Documents/Issues/SexualOrientation/
IESOGI/Academics/1912_Colombia_Report_English_FINAL.pdf
[24] Camille Cobb, Ted McCarthy, Annuska Perkins, Ankitha Bharadwaj, Jared
Comis, Brian Do, and Kate Starbird. 2014. Designing for the deluge  understanding
 & supporting the distributed, collaborative work of crisis volunteers. In
Proceedings of the 17th ACM conference on Computer supported cooperative work
& social computing . 888 899.
[25] Patricia Hill Collins. 2019. Intersectionality as critical social theory . Duke
[26] Patricia Hill Collins and Sirma Bilge. 2020. Intersectionality . John Wiley & Sons.
[27] Susan E Collins, Seema L Clifasefi, Joey Stanton, Kee JE Straits, Eleanor GilKashiwabara,
 Patricia Rodriguez Espinosa, Andel V Nicasio, Michele P Andrasik,
Starlyn M Hawes, Kimberly A Miller, et al .2018. Community-based participatory
research (CBPR)  Towards equitable involvement of community in psychology
research. American Psychologist 73, 7 (2018), 884.
[28] Bill Cooke and Uma Kothari. 2001. Participation . Zed Books, London, England.
[29] Sasha Costanza-Chock. 2018. Design justice  Towards an intersectional feminist
framework for design theory and practice. Proceedings of the Design Research
[30] Jakub Dalek, Nica Dumlao, Miles Kenyon, Irene Poetranto, Adam Senft, Caroline
Wesley, Arturo Filast√≤, Maria Xynou, and Amie Bishop. 2021. No Access  LGBTIQ
Website Censorship in Six Countries. (2021). https //citizenlab.ca/2021/08/noaccess-lgbtiq-website-censorship-in-six-countries/
[31] Deep Learning Indaba 2017. https //deeplearningindaba.com/2021/
[32] Sunipa Dev, Masoud Monajatipoor, Anaelia Ovalle, Arjun Subramonian, Jeff
Phillips, and Kai-Wei Chang. 2021. Harms of Gender Exclusivity and Challenges
 in Non-Binary Representation in Language Technologies. In Proceedings
of the 2021 Conference on Empirical Methods in Natural Language Processing .
Association for Computational Linguistics, Online and Punta Cana, Dominican
Republic, 1968 1994. https //doi.org/10.18653/v1/2021.emnlp-main.150
[33] Michael A DeVito, Ashley Marie Walker, and Jeremy Birnholtz. 2018.  Too Gay
for Facebook   Presenting LGBTQ  Identity Throughout the Personal Social
Media Ecosystem. Proceedings of the ACM on Human-Computer Interaction 2,
[34] Michael A DeVito, Ashley Marie Walker, Caitlin Lustig, Amy J Ko, Katta Spiel,
Alex A Ahmed, Kimberley Allison, Morgan Scheuerman, Briana Dym, Jed R
Brubaker, et al .2020. Queer in HCI  Supporting LGBTQIA  Researchers and
Research Across Domains. In Extended Abstracts of the 2020 CHI Conference on
Human Factors in Computing Systems . 1 4.
[35] Catherine D ignazio and Lauren F Klein. 2020. Data feminism . MIT press.
[36] Diversity in AI (n.d.). http //www.diverseinai.org
[37] Jesse Dodge, Maarten Sap, Ana Marasoviƒá, William Agnew, Gabriel Ilharco, Dirk
Groeneveld, Margaret Mitchell, and Matt Gardner. 2021. Documenting Large
Webtext Corpora  A Case Study on the Colossal Clean Crawled Corpus. arXiv
preprint arXiv 2104.08758 (Nov. 2021), 1286 1305. https //doi.org/10.18653/v1/
[38] Jack Drescher. 2015. Out of DSM  Depathologizing homosexuality. Behavioral
sciences 5, 4 (2015), 565 575.
[39] Ashe Dryden. 2013. CODES OF CONDUCT 101   FAQ. Link.
[40] Ashe Dryden. 2013. Increasing Diversity at Your Conference. Link.
[41] Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard S.
Zemel. 2012. Fairness through awareness. In Proceedings of the 3rd Innovations
in Theoretical Computer Science Conference . https //doi.org/10.1145/2090236.
[42] Russell Rowe Dynes. 1970. Organized behavior in disaster . Heath Lexington
[43] Val Elefante. 2021. Lips. Queer in AI Workshop at International Conference on
Machine Learning 2021 (2021). https //sites.google.com/view/queer-in-ai/icml-2021#h.lx7wo16mt2ax
[44] ELLIS. 2022. ELLIS PhD Program  Call for applications 2022. https //ellis.eu/
news/ellis-phd-program-call-for-applications-2022
[45] Myra Marx Ferree. 2016. The discursive politics of feminist intersectionality. In
Framing Intersectionality . Routledge, 55 65.
[46] Michelle Fine and Mar√≠a Elena Torre. 2006. Intimate details  Participatory action
research in prison. Action Research 4, 3 (2006), 253 269.
[47] Aoife Finn, Peter-Lucas Jones, Keoni Mahelona, Suzanne Duncan, and Gianna
Leoni. 2022. Developing a Part-Of-Speech tagger for te reo M  aori. In Proceedings
of the Fifth Workshop on the Use of Computational Methods in the Study of
Endangered Languages . 93 98.
[48] Luciano Floridi. 2019. Establishing the rules for building trustworthy AI. Nature
Machine Intelligence 1, 6 (2019), 261 262.
[49] Association for Computational Linguistics. (n.d.). https //www.aclweb.org/
[50] Jon Freeman. 2023. Letter to the NSF Director. https //static1.squarespace.
com/static/545d3fabe4b0811b5cc48193/t/63c867aefb89f3761070a5a3/
1674078140137/Letter to NSF Director - LGBTQ%2B Data_redacted.pdf
[51] Jonathan B. Freeman. 2020. Measuring and Resolving LGBTQ Disparities in
STEM. Policy Insights from the Behavioral and Brain Sciences 7 (2020), 141   148.
[52] Paolo Gaudiano. 2021. Exposure doesn t pay  Why tech conferences should
compensate their speakers. https //www.forbes.com/sites/paologaudiano/2021/
06/07/how-to-make-conference-speaker-fees-more-inclusive-and-equitable/.
https //www.forbes.com/sites/paologaudiano/2021/06/07/how-to-makeconference-speaker-fees-more-inclusive-and-equitable/
[53] Timnit Gebru and Emily Denton. 2021. Beyond Fairness. https //neurips.cc/
virtual/2021/tutorial/21889
[54] Christine Geeng, Mike Harris, Elissa Redmiles, and Franziska Roesner. 2021.
Queer Security Advice in the US. (2021).
[55] A Gomes, D Antonialli, and T Dias-Oliva. 2019. Drag queens and artificial
intelligence. Should computers decide what is toxic on the internet. Internet
Lab blog (2019). https //internetlab.org.br/en/news/drag-queens-and-artificialintelligence-should-computers-decide-what-is-toxic-on-the-internet/
[56] Mary L Gray and Siddharth Suri. 2019. Ghost work  How to stop Silicon Valley
from building a new global underclass . Eamon Dolan Books.
[57] LW Green, MA George, et al .2003. Appendix C  Guidelines for participatory
research in health promotion. In Community-based participatory research for
health , M. Minkler and N. Wallerstein (Eds.). San Francisco, CA, Jossey-Bass.
[58] Christina E. Gringeri, St√©phanie Wahab, and Ben Anderson-Nathe. 2010. What
Makes it Feminist   Mapping the Landscape of Feminist Social Work Research.
 Affilia 25, 4 (2010), 390 405. https //doi.org/10.1177/0886109910384072
arXiv https //doi.org/10.1177/0886109910384072
[59] Kevin Guyan. 2022. Fixing the Wrong Problems  Queer Communities and the
False Promise of Unbiased and Equal Data Systems. European Data Protection
Law Review 8, 4 (2022). https //doi.org/10.21552/edpl/2022/4/5
[60] Karen Hacker and J. Glover Taylor. 2011. Community-Engaged Research
101. https //catalyst.harvard.edu/publications-documents/communityengaged-research-101-2/
[61] Oliver Haug. 2021. TikTokers Are Using Grindr to Out LGBTQ  Olympians,
Potentially Endangering Their Lives. Them (2021). https //www.them.us/story/
tiktokers-use-grindr-out-lgbtq-olympians/
[62] IEEE. (n.d.). IEEE Author Name Change Policy. https //conferences.
ieeeauthorcenter.ieee.org/author-ethics/guidelines-and-policies/ieee-authorname-change-policy/
 [Accessed Feb 2023].
[63] DisAbility in AI. (n.d.). https //elesa.github.io/ability_in_AI
[64] Indigenous in AI (n.d.). https //indigenousinai.org/
[65] Khari Johnson. 2021. Black and Queer AI Groups Say They ll Spurn Google
Funding. Wired (2021). https //www.wired.com/story/black-queer-ai-groupsspurn-google-funding/
[66] Khari Johnson. 2022. How Wrongful Arrests Based on AI Derailed 3 Men s Lives.
Wired (2022). https //www.wired.com/story/wrongful-arrests-ai-derailed-3mens-lives/
[67] John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov,
Olaf Ronneberger, Kathryn Tunyasuvunakool, Russ Bates, Augustin ≈Ω√≠dek, Anna
Potapenko, Alex Bridgland, Clemens Meyer, Simon A A Kohl, Andrew J Ballard,
 Andrew Cowie, Bernardino Romera-Paredes, Stanislav Nikolov, Rishub
Jain, Jonas Adler, Trevor Back, Stig Petersen, David Reiman, Ellen Clancy,
Michal Zielinski, Martin Steinegger, Michalina Pacholska, Tamas Berghammer,
 Sebastian Bodenstein, David Silver, Oriol Vinyals, Andrew W Senior, Koray
Kavukcuoglu, Pushmeet Kohli, and Demis Hassabis. 2021. Highly accurate
protein structure prediction with AlphaFold. Nature 596, 7873 (2021), 583 589.
https //doi.org/10.1038/s41586-021-03819-2
[68] Pratyusha Kalluri. 2020. Don t ask if artificial intelligence is good or fair, ask
how it shifts power. Nature 583, 169 (2020).
[69] Michael Katell, Meg Young, Dharma Dailey, Bernease Herman, Vivian Guetler,
Aaron Tam, Corinne Bintz, Daniella Raz, and PM Krafft. 2020. Toward situated
interventions for algorithmic equity  lessons from the field. In Proceedings of
the 2020 conference on fairness, accountability, and transparency . 45 55.
1893Queer In AI  A Case Study in Community-Led Participatory AI FAccT  23, June 12 15, 2023, Chicago, IL, USA
[70] Os Keyes. 2018. The misgendering machines  Trans/HCI implications of automatic
 gender recognition. Proceedings of the ACM on human-computer interaction
2, CSCW (2018), 1 22. https //doi.org/10.1145/3274357
[71] Os Keyes. 2019. Counting the Countless  Why data science is a profound threat
for queer people. Real Life 2 (2019).
[72] Os Keyes, Zo√´ Hitzig, and Mwenza Blell. 2021. Truth from the machine  artificial
intelligence and the materialization of identity. Interdisciplinary Science Reviews
46 (2021), 158   175.
[73] Khipu. (n.d.). https //khipu.ai/committee-2023/
[74] Andrey Kormilitzin, Nenad Tomasev, Kevin R McKee, and Dan W Joyce. 2023. A
participatory initiative to include LGBT  voices in AI for mental health. Nature
Medicine (2023), 1 2.
[75] Gary A Kreps and Susan Lovegren Bosworth. 1994. Organizing, role enactment,
and disaster  A structural theory . University of Delaware Press.
[76] Katie Langin. 2023. NSF still won t track sexual orientation among scientific
workforce, prompting frustration. https //www.science.org/content/article/nsfstill-won-t-track-sexual-orientation-among-scientific-workforce-prompting
[77] LatinX in AI (n.d.). https //www.latinxinai.org
[78] Neil Lawrence. 2021. Comment on pull request  Fix author name. https 
//github.com/mlresearch/v119/pull/4#issuecomment-760081621
[79] Jason Edward Lewis, Angie Abdilla, Noelani Arista, Kaipulaumakaniolono Baker,
Scott Benesiinaabandan, Michelle Brown, Melanie Cheung, Meredith Coleman,
Ashley Cordes, Joel Davison, et al .2020. Indigenous protocol and artificial
intelligence position paper. (2020).
[80] Yanan Long. 2021. Automatic Gender Recognition  Perspectives from Phenomenological
 Hermeneutics. Queer in AI Workshop at International Conference
 on Machine Learning 2021 (2021). https //sites.google.com/view/queer-inai/icml-2021#h.lx7wo16mt2ax
[81] Christina Lu, Jackie Kay, and Kevin McKee. 2022. Subverting machines, fluctuating
 identities  Re-learning human categorization. In 2022 ACM Conference on
Fairness, Accountability, and Transparency . 1005 1015.
[82] Sarah Maiter, Laura Simich, Nora Jacobson, and Julie Wise. 2008. Reciprocity 
An ethic for community-based participatory action research. Action research 6,
[83] Miranda Marquit. 2018. Survey  60% of LGBTQ Student Borrowers Regret
Taking Out Student Loans. (2018). https //www.lendingtree.com/student/lgbtqstudent-borrowers-regret-loans-survey/
[84] Masakhane (n.d.). https //www.masakhane.io
[85] Lyndsey McMillon-Brown. 2021. Implementing diversity, equity and inclusion
efforts at conferences. Nature Energy 6, 11 (2021), 1000 1002.
[86] Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram
Galstyan. 2021. A Survey on Bias and Fairness in Machine Learning. ACM
Comput. Surv. 54, 6, Article 115 (jul 2021), 35 pages. https //doi.org/10.1145/
[87] Doug Meyer. 2015. Violence against queer people  Race, class, gender, and the
persistence of anti-LGBT discrimination . Rutgers University Press.
[88] Muslims in ML. (n.d.). http //www.musiml.org/
[89] Name Change Policy Working Group (n.d.). Name Change Policy Working
Group. https //ncpwg.org/
[90] NeurIPS. (n.d.). NeurIPS Proceedings  Name Change Policy. https //papers.nips.
cc/,  Name Change Policy  link in footer [Accessed Feb 2023].
[91] North Africans in ML. (n.d.). https //sites.google.com/view/northafricansinml
[92] Molly Olmstead. 2021. A Prominent Priest Was Outed for Using Grindr. Experts
Say It s a Warning Sign. Slate (2021). https //slate.com/technology/2021/07/
catholic-priest-grindr-data-privacy.html
[93] ORCID (n.d.). Open Researcher and Contributor ID (ORCID). https //orcid.org/
[94] Matt Payton. 2021. Egyptian police  are using Grindr to find and arrest LGBT
people . The Independent (2021). https //www.independent.co.uk/news/world/
africa/egyptian-police-grindr-dating-app-arrest-lgbt-gay-antigay-lesbianhomophobia-a7211881.html
[95] Billy Perrigo. 2023. OpenAI Used Kenyan Workers on Less Than $2 Per Hour
to Make ChatGPT Less Toxic. Time (2023). https //time.com/6247678/openaichatgpt-kenya-workers/
[96] Anthony T Pinter, Morgan Klaus Scheuerman, and Jed R Brubaker. 2021. Entering
 Doors, Evading Traps  Benefits and Risks of Visibility During Transgender
Coming Outs. Proceedings of the ACM on Human-Computer Interaction 4, CSCW3
[97] Anastasia Powell, Adrian J Scott, and Nicola Henry. 2020. Digital harassment
and abuse  Experiences of sexuality and gender minority adults. European
journal of criminology 17, 2 (2020), 199 223.
[98] ACL Pubcheck. (n.d.). https //github.com/acl-org/aclpubcheck [Accessed Feb
[99] Queer in AI at NeurIPS 2021. http //queerinai.org/neurips-2021
[100] Queer in AI Organizers. 2019. Code of Conduct. https //sites.google.com/view/
queer-in-ai/code-of-conduct.
[101] Organizers of QueerInAI, A Pranav, MaryLena Bleile, Arjun Subramonian, Luca
Soldaini, Danica J. Sutherland, Sabine Weber, and Pan Xu. 2021. How to MakeVirtual Conferences Queer-Friendly  A Guide. In Proceedings of the 2021 Workshop
 on Widening NLP . Conference on Empirical Methods in Natural Language
Processing, Punta Cana, Dominican Republic. queerinai.org/diversity-guide
[102] Suman Ravuri, Karel Lenc, Matthew Willson, Dmitry Kangin, Remi Lam, Piotr
Mirowski, Megan Fitzsimons, Maria Athanassiadou, Sheleem Kashem, Sam
Madge, et al .2021. Skilful precipitation nowcasting using deep generative
models of radar. Nature 597, 7878 (2021), 672 677.
[103] Eva Reid. 2021. How To Make Conference Speaker Fees More Inclusive And
Equitable. hhttps //technical.ly/2021/07/22/conferences-pay-speakers//. https 
//technical.ly/2021/07/22/conferences-pay-speakers/
[104] Christina R. Richey, Katharine M N Lee, Erica M. Rodgers, and Kathryn B. H.
Clancy. 2019. Gender and sexual minorities in astronomy and planetary science
 face increased risks of harassment and assault. Bulletin of the American
Astronomical Society 51 (2019), 0206.
[105] Nancy Russell, Susan Igras, Nalin Johri, Henrietta Kuoh, Melinda Pavin, and
Jane Wickstrom. 2008. ACQUIRE Project Working Paper. https //pdf.usaid.
gov/pdf_docs/Pnadm497.pdf
[106] Morgan Klaus Scheuerman, Aaron Jiang, Katta Spiel, and Jed R. Brubaker. 2021.
Revisiting Gendered Web Forms  An Evaluation of Gender Inputs with (Non)Binary
 People. In Proceedings of the 2021 CHI Conference on Human Factors in
Computing Systems (Yokohama, Japan) (CHI  21) . Association for Computing
Machinery, New York, NY, USA, Article 400, 18 pages. https //doi.org/10.1145/
[107] Morgan Klaus Scheuerman, Madeleine Pape, and Alex Hanna. 2021. Autoessentialization 
 Gender in automated facial analysis as extended colonial project.
Big Data & Society 8, 2 (2021), 20539517211053712.
[108] Morgan Klaus Scheuerman, Jacob M Paul, and Jed R Brubaker. 2019. How
computers see gender  An evaluation of gender classification in commercial
facial analysis services. Proceedings of the ACM on Human-Computer Interaction
3, CSCW (2019), 1 33.
[109] Natalie Schluter. 2018. The glass ceiling in NLP. In Proceedings of the 2018
Conference on Empirical Methods in Natural Language Processing . 2793 2798.
[110] Sarah Schulman. 2021. Let the Record Show  A Political History of ACT UP New
York, 1987-1993 . Farrar, Straus and Giroux.
[111] Tom Simonite. 2021. AI and the List of Dirty, Naughty, Obscene, and Otherwise
Bad Words. Wired (2021). https //www.wired.com/story/ai-list-dirty-naughtyobscene-bad-words/
[112] Mona Sloane, Emanuel Moss, Olaitan Awomolo, and Laura Forlano. 2022. Participation
 Is Not a Design Fix for Machine Learning. In Equity and Access in
Algorithms, Mechanisms, and Optimization (Arlington, VA, USA) (EAAMO  22) .
Association for Computing Machinery, New York, NY, USA, Article 1, 6 pages.
https //doi.org/10.1145/3551624.3555285
[113] Shakira Smith, Oliver L Haimson, Claire Fitzsimmons, and Nikki Echarte
Brown. 2021. Censorship of Marginalized Communities on Instagram. Salty
(2021). https //saltyworld.net/exclusive-report-censorship-of-marginalizedcommunities-on-instagram-2021-pdf-download/
[114] Dean Spade. 2020. Mutual aid  Building solidarity during this crisis (and the next) .
[115] Robyn Speer. 2021. Google Scholar deadnames trans authors and obstructs
 their name change. Link. https //docs.google.com/document/d/
1st05rXL1wcBBdgcMVqgN0X3L-6HGqORGfgnHMfXHKvE
[116] Robyn Speer. 2021. Google Scholar has failed us. (2021). https //scholar.hasfailed.
[117] Kate Starbird and Leysia Palen. 2011. "Voluntweeters" self-organizing by digital
volunteers in times of crisis. In Proceedings of the SIGCHI conference on human
factors in computing systems . 1071 1080.
[118] Luke Stark and Jevan Hutson. 2021. Physiognomic Artificial Intelligence. Available
 at SSRN 3927300 32, 4 (2021), 922.
[119] Harini Suresh, Rajiv Movva, Amelia Lee Dogan, Rahul Bhargava, Isadora Cruxen,
Angeles Martinez Cuba, Guilia Taurino, Wonyoung So, and Catherine D Ignazio.
2022. Towards Intersectional Feminist and Participatory ML  A Case Study
in Supporting Feminicide Counterdata Collection. In 2022 ACM Conference on
Fairness, Accountability, and Transparency (Seoul, Republic of Korea) (FAccT  22) .
Association for Computing Machinery, New York, NY, USA, 667 678. https 
//doi.org/10.1145/3531146.3533132
[120] Danica J. Sutherland. 2022. Name Change Policies  A Brief (Personal) Tour.
Queer in AI workshop, NeurIPS 2022  https //djsutherland.ml/slides/qai-namechange.
[121] Rajesh Tandon. 1988. Social transformation and participatory research. Convergence
[122] Theresa Jean Tanenbaum, Irving Rettig, H Michael Schwartz, BM Watson,
Teddy G Goetz, Katta Spiel, and Mike Hill. 2021. A vision for a more transinclusive
 publishing world  guest article. Committee on Publication Ethics. https 
//publicationethics.org/news/vision-more-trans-inclusive-publishing-world.
[123] NAACL DEI Team. (n.d.). NAACL Citation Name Change Procedure. https 
//2021.naacl.org/blog/name-change-procedure/ [Accessed Feb 2023].
[124] Nenad Tomasev, Kevin R McKee, Jackie Kay, and Shakir Mohamed. 2021. Fairness
for Unobserved Characteristics  Insights from Technological Impacts on Queer
1894FAccT  23, June 12 15, 2023, Chicago, IL, USA Organizers of Queer in AI, et al.
Communities. arXiv preprint arXiv 2102.04257 (2021). https //doi.org/10.1145/
[125] Paige Yes Treebridge. 2021. Crowdsourcing a Corpus of Dogwhistle Transphobia.
Queer in AI Workshop at International Conference on Machine Learning 2021
(2021). https //sites.google.com/view/queer-in-ai/icml-2021#h.lx7wo16mt2ax
[126] Fangjing Tu. 2022. What can we learn from longitudinal studies
on the impacts of college internships  https //ccwt.wisc.edu/wpcontent/uploads/2022/04/Final_CCWT_report_LR-What-can-we-learn-
from-longitudinal-studies-on-the-impacts-of-college-internships.pdf
[127] Ayesha IT Tulloch. 2020. Improving sex and gender identity equity and inclusion
at conservation and ecology conferences. Nature Ecology & Evolution 4, 10 (2020),
[128] Jessica Vamathevan, Dominic Clark, Paul Czodrowski, Ian Dunham, Edgardo
Ferran, George Lee, Bin Li, Anant Madabhushi, Parantu Shah, Michaela Spitzer,
et al.2019. Applications of machine learning in drug discovery and development.
Nature Reviews Drug discovery 18, 6 (2019), 463 477.[129] Lindsay Weinberg. 2022. Rethinking Fairness  An Interdisciplinary Survey of
Critiques of Hegemonic ML Fairness Approaches. Journal of Artificial Intelligence
Research 74 (2022), 75 109.
[130] Widening NLP (n.d.). http //www.winlp.org
[131] Bianca DM Wilson, Soon Kyu Choi, Gary W Harper, Marguerita Lightfoot,
Stephen Russell, and Ilan H Meyer. 2020. Homelessness among LGBT adults in
the US. https //williamsinstitute.law.ucla.edu/publications/lgbt-homelessnessus/
[132] Women in Machine Learning. 2021. Code of Conduct. https //wimlworkshop.
[133] Women in Machine Learning (n.d.). https //wimlworkshop.org
[134] Aman Yadav, Christopher D Seals, Cristina M Soto Sullivan, Michael Lachney,
Quintana Clark, Kathy G Dixon, and Mark JT Smith. 2020. The forgotten scholar 
underrepresented minority postdoc experiences in STEM fields. Educational
Studies 56, 2 (2020), 160 185.