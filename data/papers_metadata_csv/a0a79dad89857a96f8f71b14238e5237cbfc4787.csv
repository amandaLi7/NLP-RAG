Question,Answer,Notes
What is the author ID of Eric P. Xing?,143977260,##Title: Judging LLM-as-a-judge with MT-Bench and Chatbot Arena
What is the H-index of Eric P. Xing?,103,##Title: Judging LLM-as-a-judge with MT-Bench and Chatbot Arena
What is the semantic scholar author name of Eric P. Xing?,E. Xing,##Title: Judging LLM-as-a-judge with MT-Bench and Chatbot Arena
What is the semantic scholar author name of Eric P. Xing?,https://www.semanticscholar.org/author/143977260,##Title: Judging LLM-as-a-judge with MT-Bench and Chatbot Arena
What is the affiliation of Eric P. Xing?,"LTI (CMU), No other affiliations",##Title: Judging LLM-as-a-judge with MT-Bench and Chatbot Arena
What is the paper ID of the paper Judging LLM-as-a-judge with MT-Bench and Chatbot Arena?,a0a79dad89857a96f8f71b14238e5237cbfc4787,##Title: Judging LLM-as-a-judge with MT-Bench and Chatbot Arena
What are the external IDs of the paper Judging LLM-as-a-judge with MT-Bench and Chatbot Arena?,"{'DBLP': 'journals/corr/abs-2306-05685', 'ArXiv': '2306.05685', 'DOI': '10.48550/arXiv.2306.05685', 'CorpusId': 259129398}",##Title: Judging LLM-as-a-judge with MT-Bench and Chatbot Arena
What is the URL of the paper Judging LLM-as-a-judge with MT-Bench and Chatbot Arena?,https://www.semanticscholar.org/paper/a0a79dad89857a96f8f71b14238e5237cbfc4787,##Title: Judging LLM-as-a-judge with MT-Bench and Chatbot Arena
What is the abstract of the paper 'Judging LLM-as-a-judge with MT-Bench and Chatbot Arena'?,"Evaluating large language model (LLM) based chat assistants is challenging due to their broad capabilities and the inadequacy of existing benchmarks in measuring human preferences. To address this, we explore using strong LLMs as judges to evaluate these models on more open-ended questions. We examine the usage and limitations of LLM-as-a-judge, including position, verbosity, and self-enhancement biases, as well as limited reasoning ability, and propose solutions to mitigate some of them. We then verify the agreement between LLM judges and human preferences by introducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80% agreement, the same level of agreement between humans. Hence, LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain. Additionally, we show our benchmark and traditional benchmarks complement each other by evaluating several variants of LLaMA and Vicuna. The MT-bench questions, 3K expert votes, and 30K conversations with human preferences are publicly available at https://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge.",##Title: Judging LLM-as-a-judge with MT-Bench and Chatbot Arena
In which venue was the paper 'Judging LLM-as-a-judge with MT-Bench and Chatbot Arena' published?,arXiv.org,##Title: Judging LLM-as-a-judge with MT-Bench and Chatbot Arena
In what year was the paper 'Judging LLM-as-a-judge with MT-Bench and Chatbot Arena' published?,2023,##Title: Judging LLM-as-a-judge with MT-Bench and Chatbot Arena
How many references are in the paper 'Judging LLM-as-a-judge with MT-Bench and Chatbot Arena'?,59,##Title: Judging LLM-as-a-judge with MT-Bench and Chatbot Arena
How many citations does the paper 'Judging LLM-as-a-judge with MT-Bench and Chatbot Arena' have?,690,##Title: Judging LLM-as-a-judge with MT-Bench and Chatbot Arena
What is the citation count of 'Judging LLM-as-a-judge with MT-Bench and Chatbot Arena' have?,690,##Title: Judging LLM-as-a-judge with MT-Bench and Chatbot Arena
How many influential citations does the paper 'Judging LLM-as-a-judge with MT-Bench and Chatbot Arena' have?,126,##Title: Judging LLM-as-a-judge with MT-Bench and Chatbot Arena
Is the paper 'Judging LLM-as-a-judge with MT-Bench and Chatbot Arena' open access?,Yes,##Title: Judging LLM-as-a-judge with MT-Bench and Chatbot Arena
What is the open access PDF URL of the paper titled 'Judging LLM-as-a-judge with MT-Bench and Chatbot Arena'?,https://arxiv.org/pdf/2306.05685,##Title: Judging LLM-as-a-judge with MT-Bench and Chatbot Arena
What are the fields of study for the paper 'Judging LLM-as-a-judge with MT-Bench and Chatbot Arena'?,Computer Science,##Title: Judging LLM-as-a-judge with MT-Bench and Chatbot Arena
What is the journal name for the paper 'Judging LLM-as-a-judge with MT-Bench and Chatbot Arena'?,"ArXiv, volume: abs/2306.05685; ArXiv",##Title: Judging LLM-as-a-judge with MT-Bench and Chatbot Arena
Who are the authors of the paper 'Judging LLM-as-a-judge with MT-Bench and Chatbot Arena'?,"Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, E. Xing, Haotong Zhang, Joseph Gonzalez, I. Stoica",##Title: Judging LLM-as-a-judge with MT-Bench and Chatbot Arena
Who is the first author of the paper 'Judging LLM-as-a-judge with MT-Bench and Chatbot Arena'?,Lianmin Zheng,##Title: Judging LLM-as-a-judge with MT-Bench and Chatbot Arena
What is the TLDR summary of the paper 'Judging LLM-as-a-judge with MT-Bench and Chatbot Arena'?,"The results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80% agreement, the same level of agreement between humans, and LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain.",##Title: Judging LLM-as-a-judge with MT-Bench and Chatbot Arena
