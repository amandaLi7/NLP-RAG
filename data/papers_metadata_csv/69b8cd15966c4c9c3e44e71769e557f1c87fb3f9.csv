Question,Answer,Notes
What is the author ID of Yonatan Bisk?,3312309,##Title: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception
What is the H-index of Yonatan Bisk?,33,##Title: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception
What is the semantic scholar author name of Yonatan Bisk?,Yonatan Bisk,##Title: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception
What is the semantic scholar author name of Yonatan Bisk?,https://www.semanticscholar.org/author/3312309,##Title: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception
What are affiliation of Yonatan Bisk?,Carnegie Mellon University,##Title: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception
What is the paper ID of the paper MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception?,69b8cd15966c4c9c3e44e71769e557f1c87fb3f9,##Title: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception
What are the external IDs of the paper MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception?,"{'DBLP': 'journals/corr/abs-2309-08508', 'ArXiv': '2309.08508', 'DOI': '10.48550/arXiv.2309.08508', 'CorpusId': 262012665}",##Title: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception
What is the URL of the paper MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception?,https://www.semanticscholar.org/paper/69b8cd15966c4c9c3e44e71769e557f1c87fb3f9,##Title: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception
What is the abstract of the paper 'MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception'?,"A holistic understanding of object properties across diverse sensory modalities (e.g., visual, audio, and haptic) is essential for tasks ranging from object categorization to complex manipulation. Drawing inspiration from cognitive science studies that emphasize the significance of multi-sensory integration in human perception, we introduce MOSAIC (Multi-modal Object property learning with Self-Attention and Integrated Comprehension), a novel framework designed to facilitate the learning of unified multi-sensory object property representations. While it is undeniable that visual information plays a prominent role, we acknowledge that many fundamental object properties extend beyond the visual domain to encompass attributes like texture, mass distribution, or sounds, which significantly influence how we interact with objects. In MOSAIC, we leverage this profound insight by distilling knowledge from the extensive pre-trained Contrastive Language-Image Pre-training (CLIP) model, aligning these representations not only across vision but also haptic and auditory sensory modalities. Through extensive experiments on a dataset where a humanoid robot interacts with 100 objects across 10 exploratory behaviors, we demonstrate the versatility of MOSAIC in two task families: object categorization and object-fetching tasks. Our results underscore the efficacy of MOSAIC's unified representations, showing competitive performance in category recognition through a simple linear probe setup and excelling in the fetch object task under zero-shot transfer conditions. This work pioneers the application of CLIP-based sensory grounding in robotics, promising a significant leap in multi-sensory perception capabilities for autonomous systems. We have released the code, datasets, and additional results: https://github.com/gtatiya/MOSAIC.",##Title: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception
In which venue was the paper 'MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception' published?,arXiv.org,##Title: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception
In what year was the paper 'MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception' published?,2023,##Title: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception
How many references are in the paper 'MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception'?,35,##Title: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception
How many citations does the paper 'MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception' have?,1,##Title: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception
What is the citation count of 'MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception' have?,1,##Title: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception
How many influential citations does the paper 'MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception' have?,0,##Title: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception
Is the paper 'MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception' open access?,Yes,##Title: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception
What is the open access PDF URL of the paper titled 'MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception'?,https://arxiv.org/pdf/2309.08508,##Title: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception
What are the fields of study for the paper 'MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception'?,Computer Science,##Title: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception
What is the journal name for the paper 'MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception'?,"ArXiv, volume: abs/2309.08508; ArXiv",##Title: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception
Who are the authors of the paper 'MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception'?,"Gyan Tatiya, Jonathan M Francis, Ho-Hsiang Wu, Yonatan Bisk, J. Sinapov",##Title: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception
Who is the first author of the paper 'MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception'?,Gyan Tatiya,##Title: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception
What is the TLDR summary of the paper 'MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception'?,"This work pioneers the application of CLIP-based sensory grounding in robotics, promising a significant leap in multi-sensory perception capabilities for autonomous systems.",##Title: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception
