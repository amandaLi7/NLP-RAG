Question,Answer,Notes
What is the author ID of Shinji Watanabe?,1746678,##Title: Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing
What is the H-index of Shinji Watanabe?,67,##Title: Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing
What is the semantic scholar author name of Shinji Watanabe?,Shinji Watanabe,##Title: Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing
What is the semantic scholar author name of Shinji Watanabe?,https://www.semanticscholar.org/author/1746678,##Title: Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing
What is the affiliation of Shinji Watanabe?,"LTI (CMU), No other affiliations",##Title: Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing
What is the paper ID of the paper Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing?,d8728d62b238b09630309c1df723036db84bac10,##Title: Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing
What are the external IDs of the paper Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing?,"{'DBLP': 'journals/corr/abs-2309-15826', 'ArXiv': '2309.15826', 'DOI': '10.48550/arXiv.2309.15826', 'CorpusId': 263152659}",##Title: Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing
What is the URL of the paper Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing?,https://www.semanticscholar.org/paper/d8728d62b238b09630309c1df723036db84bac10,##Title: Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing
What is the abstract of the paper 'Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing'?,"Recent works in end-to-end speech-to-text translation (ST) have proposed multi-tasking methods with soft parameter sharing which leverage machine translation (MT) data via secondary encoders that map text inputs to an eventual cross-modal representation. In this work, we instead propose a ST/MT multi-tasking framework with hard parameter sharing in which all model parameters are shared cross-modally. Our method reduces the speech-text modality gap via a pre-processing stage which converts speech and text inputs into two discrete token sequences of similar length -- this allows models to indiscriminately process both modalities simply using a joint vocabulary. With experiments on MuST-C, we demonstrate that our multi-tasking framework improves attentional encoder-decoder, Connectionist Temporal Classification (CTC), transducer, and joint CTC/attention models by an average of +0.5 BLEU without any external MT data. Further, we show that this framework incorporates external MT data, yielding +0.8 BLEU, and also improves transfer learning from pre-trained textual models, yielding +1.8 BLEU.",##Title: Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing
In which venue was the paper 'Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing' published?,arXiv.org,##Title: Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing
In what year was the paper 'Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing' published?,2023,##Title: Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing
How many references are in the paper 'Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing'?,55,##Title: Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing
How many citations does the paper 'Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing' have?,0,##Title: Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing
What is the citation count of 'Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing' have?,0,##Title: Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing
How many influential citations does the paper 'Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing' have?,0,##Title: Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing
Is the paper 'Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing' open access?,Yes,##Title: Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing
What is the open access PDF URL of the paper titled 'Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing'?,https://arxiv.org/pdf/2309.15826,##Title: Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing
What are the fields of study for the paper 'Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing'?,"Computer Science, Engineering",##Title: Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing
What is the journal name for the paper 'Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing'?,"ArXiv, volume: abs/2309.15826; ArXiv",##Title: Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing
Who are the authors of the paper 'Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing'?,"Brian Yan, Xuankai Chang, Antonios Anastasopoulos, Yuya Fujita, Shinji Watanabe",##Title: Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing
Who is the first author of the paper 'Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing'?,Brian Yan,##Title: Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing
What is the TLDR summary of the paper 'Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing'?,This work proposes a ST/MT multi-tasking framework with hard parameter sharing in which all model parameters are shared cross-modally and reduces the speech-text modality gap via a pre-processing stage which converts speech and text inputs into two discrete token sequences of similar length.,##Title: Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing
