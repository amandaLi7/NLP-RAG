Question,Answer,Notes
What is the author ID of Louis-Philippe Morency?,49933077,##Title: MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning
What is the H-index of Louis-Philippe Morency?,79,##Title: MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning
What is the semantic scholar author name of Louis-Philippe Morency?,Louis-Philippe Morency,##Title: MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning
What is the semantic scholar url of Louis-Philippe Morency?,https://www.semanticscholar.org/author/49933077,##Title: MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning
What is the affiliation of Louis-Philippe Morency?,"LTI (CMU), No other affiliations",##Title: MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning
What is the paper ID of the paper MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning?,40fb36ee67fdde99b196b4d1772de114aa821698,##Title: MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning
What are the external IDs of the paper MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning?,"{'ArXiv': '2306.16413', 'DBLP': 'journals/corr/abs-2306-16413', 'DOI': '10.48550/arXiv.2306.16413', 'CorpusId': 259274645}",##Title: MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning
What is the URL of the paper MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning?,https://www.semanticscholar.org/paper/40fb36ee67fdde99b196b4d1772de114aa821698,##Title: MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning
What is the abstract of the paper 'MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning'?,"Learning multimodal representations involves integrating information from multiple heterogeneous sources of data. In order to accelerate progress towards understudied modalities and tasks while ensuring real-world robustness, we release MultiZoo, a public toolkit consisting of standardized implementations of>20 core multimodal algorithms and MultiBench, a large-scale benchmark spanning 15 datasets, 10 modalities, 20 prediction tasks, and 6 research areas. Together, these provide an automated end-to-end machine learning pipeline that simplifies and standardizes data loading, experimental setup, and model evaluation. To enable holistic evaluation, we offer a comprehensive methodology to assess (1) generalization, (2) time and space complexity, and (3) modality robustness. MultiBench paves the way towards a better understanding of the capabilities and limitations of multimodal models, while ensuring ease of use, accessibility, and reproducibility. Our toolkits are publicly available, will be regularly updated, and welcome inputs from the community.",##Title: MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning
In which venue was the paper 'MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning' published?,arXiv.org,##Title: MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning
In what year was the paper 'MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning' published?,2023,##Title: MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning
How many references are in the paper 'MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning'?,48,##Title: MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning
How many citations does the paper 'MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning' have?,2,##Title: MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning
What is the citation count of 'MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning' have?,2,##Title: MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning
How many influential citations does the paper 'MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning' have?,0,##Title: MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning
Is the paper 'MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning' open access?,Yes,##Title: MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning
What is the open access PDF URL of the paper titled 'MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning'?,http://arxiv.org/pdf/2306.16413,##Title: MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning
What are the fields of study for the paper 'MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning'?,Computer Science,##Title: MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning
What is the journal name for the paper 'MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning'?,"ArXiv, volume: abs/2306.16413; ArXiv",##Title: MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning
Who are the authors of the paper 'MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning'?,"P. Liang, Yiwei Lyu, Xiang Fan, Arav Agarwal, Yun Cheng, Louis-Philippe Morency, R. Salakhutdinov",##Title: MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning
Who is the first author of the paper 'MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning'?,P. Liang,##Title: MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning
What is the TLDR summary of the paper 'MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning'?,"MultiZoo is released, a public toolkit consisting of standardized implementations of>20 core multimodal algorithms and MultiBench, a large-scale benchmark spanning 15 datasets, 10 modalities, 20 prediction tasks, and 6 research areas that provide an automated end-to-end machine learning pipeline that simplifies and standardizes data loading, experimental setup, and model evaluation.",##Title: MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning
