Question,Answer,Notes
What is the author ID of Shinji Watanabe?,1746678,##Title: I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition
What is the H-index of Shinji Watanabe?,67,##Title: I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition
What is the semantic scholar author name of Shinji Watanabe?,Shinji Watanabe,##Title: I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition
What is the semantic scholar author name of Shinji Watanabe?,https://www.semanticscholar.org/author/1746678,##Title: I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition
What is the affiliation of Shinji Watanabe?,"LTI (CMU), No other affiliations",##Title: I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition
What is the paper ID of the paper I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition?,48c6318dbcf9908cabe0023b8817566f34d0b466,##Title: I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition
What are the external IDs of the paper I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition?,"{'DBLP': 'journals/corr/abs-2303-07624', 'ArXiv': '2303.07624', 'DOI': '10.1109/ICASSP49357.2023.10096662', 'CorpusId': 257505392}",##Title: I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition
What is the URL of the paper I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition?,https://www.semanticscholar.org/paper/48c6318dbcf9908cabe0023b8817566f34d0b466,##Title: I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition
What is the abstract of the paper 'I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition'?,"Transformer-based end-to-end speech recognition has achieved great success. However, the large footprint and computational overhead make it difficult to deploy these models in some real-world applications. Model compression techniques can reduce the model size and speed up inference, but the compressed model has a fixed architecture which might be suboptimal. We propose a novel Transformer encoder with Input-Dependent Dynamic Depth (I3D) to achieve strong performance-efficiency trade-offs. With a similar number of layers at inference time, I3D-based models outperform the vanilla Transformer and the static pruned model via iterative layer pruning. We also present interesting analysis on the gate probabilities and the input-dependency, which helps us better understand deep encoders.",##Title: I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition
In which venue was the paper 'I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition' published?,"IEEE International Conference on Acoustics, Speech, and Signal Processing",##Title: I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition
In what year was the paper 'I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition' published?,2023,##Title: I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition
How many references are in the paper 'I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition'?,39,##Title: I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition
How many citations does the paper 'I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition' have?,8,##Title: I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition
What is the citation count of 'I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition' have?,8,##Title: I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition
How many influential citations does the paper 'I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition' have?,0,##Title: I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition
Is the paper 'I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition' open access?,Yes,##Title: I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition
What is the open access PDF URL of the paper titled 'I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition'?,https://arxiv.org/pdf/2303.07624,##Title: I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition
What are the fields of study for the paper 'I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition'?,"Computer Science, Engineering",##Title: I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition
What is the journal name for the paper 'I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition'?,"ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages: 1-5; ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",##Title: I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition
Who are the authors of the paper 'I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition'?,"Yifan Peng, Jaesong Lee, Shinji Watanabe",##Title: I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition
Who is the first author of the paper 'I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition'?,Yifan Peng,##Title: I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition
What is the TLDR summary of the paper 'I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition'?,"A novel Transformer encoder with Input-Dependent Dynamic Depth (I3D) to achieve strong performance-efficiency trade-offs and interesting analysis on the gate probabilities and the input-dependency, which helps to better understand deep encoders.",##Title: I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition
