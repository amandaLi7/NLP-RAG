Question,Answer,Notes
What is the author ID of Graham Neubig?,1700325,##Title: CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code
What is the H-index of Graham Neubig?,75,##Title: CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code
What is the semantic scholar author name of Graham Neubig?,Graham Neubig,##Title: CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code
What is the semantic scholar url of Graham Neubig?,https://www.semanticscholar.org/author/1700325,##Title: CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code
What is the affiliation of Graham Neubig?,"LTI (CMU), No other affiliations",##Title: CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code
What is the paper ID of the paper CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code?,31366ff634fc905affd78dbd8ddc9a872c006a87,##Title: CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code
What are the external IDs of the paper CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code?,"{'DBLP': 'journals/corr/abs-2302-05527', 'ArXiv': '2302.05527', 'DOI': '10.48550/arXiv.2302.05527', 'CorpusId': 256827797}",##Title: CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code
What is the URL of the paper CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code?,https://www.semanticscholar.org/paper/31366ff634fc905affd78dbd8ddc9a872c006a87,##Title: CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code
What is the abstract of the paper 'CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code'?,"Since the rise of neural natural-language-to-code models (NL->Code) that can generate long expressions and statements rather than a single next-token, one of the major problems has been reliably evaluating their generated output. In this paper, we propose CodeBERTScore: an evaluation metric for code generation, which builds on BERTScore (Zhang et al., 2020). Instead of encoding only the generated tokens as in BERTScore, CodeBERTScore also encodes the natural language input preceding the generated code, thus modeling the consistency between the generated code and its given natural language context as well. We perform an extensive evaluation of CodeBERTScore across four programming languages. We find that CodeBERTScore achieves a higher correlation with human preference and with functional correctness than all existing metrics. That is, generated code that receives a higher score by CodeBERTScore is more likely to be preferred by humans, as well as to function correctly when executed. We release five language-specific pretrained models to use with our publicly available code. Our language-specific models have been downloaded more than 1,000,000 times from the Huggingface Hub. Our code and data are available at https://github.com/neulab/code-bert-score",##Title: CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code
In which venue was the paper 'CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code' published?,Conference on Empirical Methods in Natural Language Processing,##Title: CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code
In what year was the paper 'CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code' published?,2023,##Title: CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code
How many references are in the paper 'CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code'?,43,##Title: CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code
How many citations does the paper 'CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code' have?,25,##Title: CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code
What is the citation count of 'CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code' have?,25,##Title: CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code
How many influential citations does the paper 'CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code' have?,5,##Title: CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code
Is the paper 'CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code' open access?,Yes,##Title: CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code
What is the open access PDF URL of the paper titled 'CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code'?,http://arxiv.org/pdf/2302.05527,##Title: CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code
What are the fields of study for the paper 'CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code'?,Computer Science,##Title: CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code
What is the journal name for the paper 'CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code'?,"Conference on Empirical Methods in Natural Language Processing, pages: 13921-13937; Conference on Empirical Methods in Natural Language Processing",##Title: CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code
Who are the authors of the paper 'CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code'?,"Shuyan Zhou, Uri Alon, Sumit Agarwal, Graham Neubig",##Title: CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code
Who is the first author of the paper 'CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code'?,Shuyan Zhou,##Title: CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code
What is the TLDR summary of the paper 'CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code'?,"It is found that generated code that receives a higher score by CodeBERTScore is more likely to be preferred by humans, as well as to function correctly when executed, than all existing metrics.",##Title: CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code
