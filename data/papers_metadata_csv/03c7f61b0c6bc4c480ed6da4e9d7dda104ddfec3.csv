Question,Answer,Notes
What is the author ID of Graham Neubig?,1700325,##Title: Cross-Modal Fine-Tuning: Align then Refine
What is the H-index of Graham Neubig?,75,##Title: Cross-Modal Fine-Tuning: Align then Refine
What is the semantic scholar author name of Graham Neubig?,Graham Neubig,##Title: Cross-Modal Fine-Tuning: Align then Refine
What is the semantic scholar url of Graham Neubig?,https://www.semanticscholar.org/author/1700325,##Title: Cross-Modal Fine-Tuning: Align then Refine
What is the affiliation of Graham Neubig?,"LTI (CMU), No other affiliations",##Title: Cross-Modal Fine-Tuning: Align then Refine
What is the paper ID of the paper Cross-Modal Fine-Tuning: Align then Refine?,03c7f61b0c6bc4c480ed6da4e9d7dda104ddfec3,##Title: Cross-Modal Fine-Tuning: Align then Refine
What are the external IDs of the paper Cross-Modal Fine-Tuning: Align then Refine?,"{'DBLP': 'journals/corr/abs-2302-05738', 'ArXiv': '2302.05738', 'DOI': '10.48550/arXiv.2302.05738', 'CorpusId': 256827706}",##Title: Cross-Modal Fine-Tuning: Align then Refine
What is the URL of the paper Cross-Modal Fine-Tuning: Align then Refine?,https://www.semanticscholar.org/paper/03c7f61b0c6bc4c480ed6da4e9d7dda104ddfec3,##Title: Cross-Modal Fine-Tuning: Align then Refine
What is the abstract of the paper 'Cross-Modal Fine-Tuning: Align then Refine'?,"Fine-tuning large-scale pretrained models has led to tremendous progress in well-studied modalities such as vision and NLP. However, similar gains have not been observed in many other modalities due to a lack of relevant pretrained models. In this work, we propose ORCA, a general cross-modal fine-tuning framework that extends the applicability of a single large-scale pretrained model to diverse modalities. ORCA adapts to a target task via an align-then-refine workflow: given the target input, ORCA first learns an embedding network that aligns the embedded feature distribution with the pretraining modality. The pretrained model is then fine-tuned on the embedded data to exploit the knowledge shared across modalities. Through extensive experiments, we show that ORCA obtains state-of-the-art results on 3 benchmarks containing over 60 datasets from 12 modalities, outperforming a wide range of hand-designed, AutoML, general-purpose, and task-specific methods. We highlight the importance of data alignment via a series of ablation studies and demonstrate ORCA's utility in data-limited regimes.",##Title: Cross-Modal Fine-Tuning: Align then Refine
In which venue was the paper 'Cross-Modal Fine-Tuning: Align then Refine' published?,International Conference on Machine Learning,##Title: Cross-Modal Fine-Tuning: Align then Refine
In what year was the paper 'Cross-Modal Fine-Tuning: Align then Refine' published?,2023,##Title: Cross-Modal Fine-Tuning: Align then Refine
How many references are in the paper 'Cross-Modal Fine-Tuning: Align then Refine'?,84,##Title: Cross-Modal Fine-Tuning: Align then Refine
How many citations does the paper 'Cross-Modal Fine-Tuning: Align then Refine' have?,7,##Title: Cross-Modal Fine-Tuning: Align then Refine
What is the citation count of 'Cross-Modal Fine-Tuning: Align then Refine' have?,7,##Title: Cross-Modal Fine-Tuning: Align then Refine
How many influential citations does the paper 'Cross-Modal Fine-Tuning: Align then Refine' have?,0,##Title: Cross-Modal Fine-Tuning: Align then Refine
Is the paper 'Cross-Modal Fine-Tuning: Align then Refine' open access?,Yes,##Title: Cross-Modal Fine-Tuning: Align then Refine
What is the open access PDF URL of the paper titled 'Cross-Modal Fine-Tuning: Align then Refine'?,http://arxiv.org/pdf/2302.05738,##Title: Cross-Modal Fine-Tuning: Align then Refine
What are the fields of study for the paper 'Cross-Modal Fine-Tuning: Align then Refine'?,Computer Science,##Title: Cross-Modal Fine-Tuning: Align then Refine
What is the journal name for the paper 'Cross-Modal Fine-Tuning: Align then Refine'?,"International Conference on Machine Learning, pages: 31030-31056; International Conference on Machine Learning",##Title: Cross-Modal Fine-Tuning: Align then Refine
Who are the authors of the paper 'Cross-Modal Fine-Tuning: Align then Refine'?,"Junhong Shen, Liam Li, L. Dery, Corey Staten, M. Khodak, Graham Neubig, Ameet Talwalkar",##Title: Cross-Modal Fine-Tuning: Align then Refine
Who is the first author of the paper 'Cross-Modal Fine-Tuning: Align then Refine'?,Junhong Shen,##Title: Cross-Modal Fine-Tuning: Align then Refine
What is the TLDR summary of the paper 'Cross-Modal Fine-Tuning: Align then Refine'?,"This work proposes ORCA, a general cross-modal fine-tuning framework that extends the applicability of a single large-scale pretrained model to diverse modalities and highlights the importance of data alignment via a series of ablation studies and demonstrates ORCA's utility in data-limited regimes.",##Title: Cross-Modal Fine-Tuning: Align then Refine
