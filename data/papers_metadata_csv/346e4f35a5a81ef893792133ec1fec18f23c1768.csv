Question,Answer,Notes
What is the author ID of Yulia Tsvetkov?,2073587169,##Title: Examining risks of racial biases in NLP tools for child protective services
What is the H-index of Yulia Tsvetkov?,17,##Title: Examining risks of racial biases in NLP tools for child protective services
What is the semantic scholar author name of Yulia Tsvetkov?,Yulia Tsvetkov,##Title: Examining risks of racial biases in NLP tools for child protective services
What is the semantic scholar url of Yulia Tsvetkov?,https://www.semanticscholar.org/author/2073587169,##Title: Examining risks of racial biases in NLP tools for child protective services
What is the affiliation of Yulia Tsvetkov?,"LTI (CMU), No other affiliations",##Title: Examining risks of racial biases in NLP tools for child protective services
What is the paper ID of the paper Examining risks of racial biases in NLP tools for child protective services?,346e4f35a5a81ef893792133ec1fec18f23c1768,##Title: Examining risks of racial biases in NLP tools for child protective services
What are the external IDs of the paper Examining risks of racial biases in NLP tools for child protective services?,"{'DBLP': 'conf/fat/FieldCGCPST23', 'ArXiv': '2305.19409', 'DOI': '10.1145/3593013.3594094', 'CorpusId': 258987867}",##Title: Examining risks of racial biases in NLP tools for child protective services
What is the URL of the paper Examining risks of racial biases in NLP tools for child protective services?,https://www.semanticscholar.org/paper/346e4f35a5a81ef893792133ec1fec18f23c1768,##Title: Examining risks of racial biases in NLP tools for child protective services
What is the abstract of the paper 'Examining risks of racial biases in NLP tools for child protective services'?,"Although much literature has established the presence of demographic bias in natural language processing (NLP) models, most work relies on curated bias metrics that may not be reflective of real-world applications. At the same time, practitioners are increasingly using algorithmic tools in high-stakes settings, with particular recent interest in NLP. In this work, we focus on one such setting: child protective services (CPS). CPS workers often write copious free-form text notes about families they are working with, and CPS agencies are actively seeking to deploy NLP models to leverage these data. Given well-established racial bias in this setting, we investigate possible ways deployed NLP is liable to increase racial disparities. We specifically examine word statistics within notes and algorithmic fairness in risk prediction, coreference resolution, and named entity recognition (NER). We document consistent algorithmic unfairness in NER models, possible algorithmic unfairness in coreference resolution models, and little evidence of exacerbated racial bias in risk prediction. While there is existing pronounced criticism of risk prediction, our results expose previously undocumented risks of racial bias in realistic information extraction systems, highlighting potential concerns in deploying them, even though they may appear more benign. Our work serves as a rare realistic examination of NLP algorithmic fairness in a potential deployed setting and a timely investigation of a specific risk associated with deploying NLP in CPS settings.",##Title: Examining risks of racial biases in NLP tools for child protective services
In which venue was the paper 'Examining risks of racial biases in NLP tools for child protective services' published?,"Conference on Fairness, Accountability and Transparency",##Title: Examining risks of racial biases in NLP tools for child protective services
In what year was the paper 'Examining risks of racial biases in NLP tools for child protective services' published?,2023,##Title: Examining risks of racial biases in NLP tools for child protective services
How many references are in the paper 'Examining risks of racial biases in NLP tools for child protective services'?,68,##Title: Examining risks of racial biases in NLP tools for child protective services
How many citations does the paper 'Examining risks of racial biases in NLP tools for child protective services' have?,2,##Title: Examining risks of racial biases in NLP tools for child protective services
What is the citation count of 'Examining risks of racial biases in NLP tools for child protective services' have?,2,##Title: Examining risks of racial biases in NLP tools for child protective services
How many influential citations does the paper 'Examining risks of racial biases in NLP tools for child protective services' have?,0,##Title: Examining risks of racial biases in NLP tools for child protective services
Is the paper 'Examining risks of racial biases in NLP tools for child protective services' open access?,Yes,##Title: Examining risks of racial biases in NLP tools for child protective services
What is the open access PDF URL of the paper titled 'Examining risks of racial biases in NLP tools for child protective services'?,https://dl.acm.org/doi/pdf/10.1145/3593013.3594094,##Title: Examining risks of racial biases in NLP tools for child protective services
What are the fields of study for the paper 'Examining risks of racial biases in NLP tools for child protective services'?,Computer Science,##Title: Examining risks of racial biases in NLP tools for child protective services
What is the journal name for the paper 'Examining risks of racial biases in NLP tools for child protective services'?,"Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency",##Title: Examining risks of racial biases in NLP tools for child protective services
Who are the authors of the paper 'Examining risks of racial biases in NLP tools for child protective services'?,"Anjalie Field, Amanda Coston, Nupoor Gandhi, A. Chouldechova, Emily Putnam-Hornstein, David Steier, Yulia Tsvetkov",##Title: Examining risks of racial biases in NLP tools for child protective services
Who is the first author of the paper 'Examining risks of racial biases in NLP tools for child protective services'?,Anjalie Field,##Title: Examining risks of racial biases in NLP tools for child protective services
What is the TLDR summary of the paper 'Examining risks of racial biases in NLP tools for child protective services'?,"This work investigates possible ways deployed NLP is liable to increase racial disparities and examines word statistics within notes and algorithmic fairness in risk prediction, coreference resolution, and named entity recognition (NER).",##Title: Examining risks of racial biases in NLP tools for child protective services
