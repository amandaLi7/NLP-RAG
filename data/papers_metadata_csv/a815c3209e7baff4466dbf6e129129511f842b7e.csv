Question,Answer,Notes
What is the author ID of Emma Strubell?,2268272,##Title: Making Scalable Meta Learning Practical
What is the H-index of Emma Strubell?,17,##Title: Making Scalable Meta Learning Practical
What is the semantic scholar author name of Emma Strubell?,Emma Strubell,##Title: Making Scalable Meta Learning Practical
What is the semantic scholar author name of Emma Strubell?,https://www.semanticscholar.org/author/2268272,##Title: Making Scalable Meta Learning Practical
What is the affiliation of Emma Strubell?,"LTI (CMU), No other affiliations",##Title: Making Scalable Meta Learning Practical
What is the paper ID of the paper Making Scalable Meta Learning Practical?,a815c3209e7baff4466dbf6e129129511f842b7e,##Title: Making Scalable Meta Learning Practical
What are the external IDs of the paper Making Scalable Meta Learning Practical?,"{'ArXiv': '2310.05674', 'DBLP': 'journals/corr/abs-2310-05674', 'DOI': '10.48550/arXiv.2310.05674', 'CorpusId': 263830616}",##Title: Making Scalable Meta Learning Practical
What is the URL of the paper Making Scalable Meta Learning Practical?,https://www.semanticscholar.org/paper/a815c3209e7baff4466dbf6e129129511f842b7e,##Title: Making Scalable Meta Learning Practical
What is the abstract of the paper 'Making Scalable Meta Learning Practical'?,"Despite its flexibility to learn diverse inductive biases in machine learning programs, meta learning (i.e., learning to learn) has long been recognized to suffer from poor scalability due to its tremendous compute/memory costs, training instability, and a lack of efficient distributed training support. In this work, we focus on making scalable meta learning practical by introducing SAMA, which combines advances in both implicit differentiation algorithms and systems. Specifically, SAMA is designed to flexibly support a broad range of adaptive optimizers in the base level of meta learning programs, while reducing computational burden by avoiding explicit computation of second-order gradient information, and exploiting efficient distributed training techniques implemented for first-order gradients. Evaluated on multiple large-scale meta learning benchmarks, SAMA showcases up to 1.7/4.8x increase in throughput and 2.0/3.8x decrease in memory consumption respectively on single-/multi-GPU setups compared to other baseline meta learning algorithms. Furthermore, we show that SAMA-based data optimization leads to consistent improvements in text classification accuracy with BERT and RoBERTa large language models, and achieves state-of-the-art results in both small- and large-scale data pruning on image classification tasks, demonstrating the practical applicability of scalable meta learning across language and vision domains.",##Title: Making Scalable Meta Learning Practical
In which venue was the paper 'Making Scalable Meta Learning Practical' published?,arXiv.org,##Title: Making Scalable Meta Learning Practical
In what year was the paper 'Making Scalable Meta Learning Practical' published?,2023,##Title: Making Scalable Meta Learning Practical
How many references are in the paper 'Making Scalable Meta Learning Practical'?,72,##Title: Making Scalable Meta Learning Practical
How many citations does the paper 'Making Scalable Meta Learning Practical' have?,1,##Title: Making Scalable Meta Learning Practical
What is the citation count of 'Making Scalable Meta Learning Practical' have?,1,##Title: Making Scalable Meta Learning Practical
How many influential citations does the paper 'Making Scalable Meta Learning Practical' have?,0,##Title: Making Scalable Meta Learning Practical
Is the paper 'Making Scalable Meta Learning Practical' open access?,Yes,##Title: Making Scalable Meta Learning Practical
What is the open access PDF URL of the paper titled 'Making Scalable Meta Learning Practical'?,https://arxiv.org/pdf/2310.05674,##Title: Making Scalable Meta Learning Practical
What are the fields of study for the paper 'Making Scalable Meta Learning Practical'?,Computer Science,##Title: Making Scalable Meta Learning Practical
What is the journal name for the paper 'Making Scalable Meta Learning Practical'?,"ArXiv, volume: abs/2310.05674; ArXiv",##Title: Making Scalable Meta Learning Practical
Who are the authors of the paper 'Making Scalable Meta Learning Practical'?,"Sang Keun Choe, Sanket Vaibhav Mehta, Hwijeen Ahn, W. Neiswanger, Pengtao Xie, Emma Strubell, Eric P. Xing",##Title: Making Scalable Meta Learning Practical
Who is the first author of the paper 'Making Scalable Meta Learning Practical'?,Sang Keun Choe,##Title: Making Scalable Meta Learning Practical
What is the TLDR summary of the paper 'Making Scalable Meta Learning Practical'?,"SAMA is designed to flexibly support a broad range of adaptive optimizers in the base level of meta learning programs, while reducing computational burden by avoiding explicit computation of second-order gradient information, and exploiting efficient distributed training techniques implemented for first-order gradients.",##Title: Making Scalable Meta Learning Practical
