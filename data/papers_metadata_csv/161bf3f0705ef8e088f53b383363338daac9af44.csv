Question,Answer,Notes
What is the name of this paper?,Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings,"##Author: Alexander Rudnicky, ##Title: Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings"
What is the author ID of Alexander Rudnicky?,3156164,"##Author: Alexander Rudnicky, ##Title: Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings"
What is the H-index of Alexander Rudnicky?,8,"##Author: Alexander Rudnicky, ##Title: Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings"
What is the semantic scholar author name of Alexander Rudnicky?,A. Rudnicky,"##Author: Alexander Rudnicky, ##Title: Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings"
What is the semantic scholar author name of Alexander Rudnicky?,https://www.semanticscholar.org/author/3156164,"##Author: Alexander Rudnicky, ##Title: Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings"
What is the affiliation of Alexander Rudnicky?,"LTI (CMU), No other affiliations on Semantic Scholar","##Author: Alexander Rudnicky, ##Title: Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings"
What is the paper ID of the paper Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings?,161bf3f0705ef8e088f53b383363338daac9af44,"##Author: Alexander Rudnicky, ##Title: Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings"
What are the external IDs of the paper Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings?,"{'ArXiv': '2305.13571', 'DBLP': 'journals/corr/abs-2305-13571', 'ACL': '2023.acl-short.102', 'DOI': '10.48550/arXiv.2305.13571', 'CorpusId': 258840844}","##Author: Alexander Rudnicky, ##Title: Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings"
What is the URL of the paper Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings?,https://www.semanticscholar.org/paper/161bf3f0705ef8e088f53b383363338daac9af44,"##Author: Alexander Rudnicky, ##Title: Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings"
What is the abstract of the paper 'Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings'?,"The use of positional embeddings in transformer language models is widely accepted. However, recent research has called into question the necessity of such embeddings. We further extend this inquiry by demonstrating that a randomly initialized and frozen transformer language model, devoid of positional embeddings, inherently encodes strong positional information through the shrinkage of self-attention variance. To quantify this variance, we derive the underlying distribution of each step within a transformer layer. Through empirical validation using a fully pretrained model, we show that the variance shrinkage effect still persists after extensive gradient updates. Our findings serve to justify the decision to discard positional embeddings and thus facilitate more efficient pretraining of transformer language models.","##Author: Alexander Rudnicky, ##Title: Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings"
In which venue was the paper 'Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings' published?,Annual Meeting of the Association for Computational Linguistics,"##Author: Alexander Rudnicky, ##Title: Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings"
In what year was the paper 'Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings' published?,2023,"##Author: Alexander Rudnicky, ##Title: Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings"
How many references are in the paper 'Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings'?,23,"##Author: Alexander Rudnicky, ##Title: Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings"
How many citations does the paper 'Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings' have?,1,"##Author: Alexander Rudnicky, ##Title: Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings"
What is the citation count of 'Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings' have?,1,"##Author: Alexander Rudnicky, ##Title: Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings"
How many influential citations does the paper 'Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings' have?,0,"##Author: Alexander Rudnicky, ##Title: Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings"
Is the paper 'Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings' open access?,Yes,"##Author: Alexander Rudnicky, ##Title: Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings"
What is the open access PDF URL of the paper titled 'Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings'?,http://arxiv.org/pdf/2305.13571,"##Author: Alexander Rudnicky, ##Title: Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings"
What are the fields of study for the paper titled 'Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings'?,Computer Science,"##Author: Alexander Rudnicky, ##Title: Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings"
What is the journal name for the paper titled 'Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings'?,"Annual Meeting of the Association for Computational Linguistics, pages: 1183-1193; Annual Meeting of the Association for Computational Linguistics","##Author: Alexander Rudnicky, ##Title: Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings"
Who are the authors of the paper 'Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings'?,"Ta-Chung Chi, Ting-Han Fan, Li-Wei Chen, A. Rudnicky, P. Ramadge","##Author: Alexander Rudnicky, ##Title: Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings"
What is the TLDR summary of the paper 'Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings'?,"This work demonstrates that a randomly initialized and frozen transformer language model, devoid of positional embeddings, inherently encodes strong positional information through the shrinkage of self-attention variance, and derives the underlying distribution of each step within a transformer layer.","##Author: Alexander Rudnicky, ##Title: Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings"
