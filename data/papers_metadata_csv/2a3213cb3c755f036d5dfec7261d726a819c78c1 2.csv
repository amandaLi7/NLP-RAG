Question,Answer,Notes
What is the name of this paper?,Muse: Text-To-Image Generation via Masked Generative Transformers,"##Author: Lu Jiang, ##Title: Muse: Text-To-Image Generation via Masked Generative Transformers"
What is the author ID of Lu Jiang?,39978626,"##Author: Lu Jiang, ##Title: Muse: Text-To-Image Generation via Masked Generative Transformers"
What is the H-index of Lu Jiang?,41,"##Author: Lu Jiang, ##Title: Muse: Text-To-Image Generation via Masked Generative Transformers"
What is the semantic scholar author name of Lu Jiang?,Lu Jiang,"##Author: Lu Jiang, ##Title: Muse: Text-To-Image Generation via Masked Generative Transformers"
What is the semantic scholar author name of Lu Jiang?,https://www.semanticscholar.org/author/39978626,"##Author: Lu Jiang, ##Title: Muse: Text-To-Image Generation via Masked Generative Transformers"
What is the affiliation of Lu Jiang?,Google Research,"##Author: Lu Jiang, ##Title: Muse: Text-To-Image Generation via Masked Generative Transformers"
What is the paper ID of the paper Muse: Text-To-Image Generation via Masked Generative Transformers?,2a3213cb3c755f036d5dfec7261d726a819c78c1,"##Author: Lu Jiang, ##Title: Muse: Text-To-Image Generation via Masked Generative Transformers"
What are the external IDs of the paper Muse: Text-To-Image Generation via Masked Generative Transformers?,"{'DBLP': 'conf/icml/ChangZBML00MFRL23', 'ArXiv': '2301.00704', 'DOI': '10.48550/arXiv.2301.00704', 'CorpusId': 255372955}","##Author: Lu Jiang, ##Title: Muse: Text-To-Image Generation via Masked Generative Transformers"
What is the URL of the paper Muse: Text-To-Image Generation via Masked Generative Transformers?,https://www.semanticscholar.org/paper/2a3213cb3c755f036d5dfec7261d726a819c78c1,"##Author: Lu Jiang, ##Title: Muse: Text-To-Image Generation via Masked Generative Transformers"
What is the abstract of the paper 'Muse: Text-To-Image Generation via Masked Generative Transformers'?,"We present Muse, a text-to-image Transformer model that achieves state-of-the-art image generation performance while being significantly more efficient than diffusion or autoregressive models. Muse is trained on a masked modeling task in discrete token space: given the text embedding extracted from a pre-trained large language model (LLM), Muse is trained to predict randomly masked image tokens. Compared to pixel-space diffusion models, such as Imagen and DALL-E 2, Muse is significantly more efficient due to the use of discrete tokens and requiring fewer sampling iterations; compared to autoregressive models, such as Parti, Muse is more efficient due to the use of parallel decoding. The use of a pre-trained LLM enables fine-grained language understanding, translating to high-fidelity image generation and the understanding of visual concepts such as objects, their spatial relationships, pose, cardinality etc. Our 900M parameter model achieves a new SOTA on CC3M, with an FID score of 6.06. The Muse 3B parameter model achieves an FID of 7.88 on zero-shot COCO evaluation, along with a CLIP score of 0.32. Muse also directly enables a number of image editing applications without the need to fine-tune or invert the model: inpainting, outpainting, and mask-free editing. More results are available at https://muse-model.github.io","##Author: Lu Jiang, ##Title: Muse: Text-To-Image Generation via Masked Generative Transformers"
In which venue was the paper 'Muse: Text-To-Image Generation via Masked Generative Transformers' published?,International Conference on Machine Learning,"##Author: Lu Jiang, ##Title: Muse: Text-To-Image Generation via Masked Generative Transformers"
In what year was the paper 'Muse: Text-To-Image Generation via Masked Generative Transformers' published?,2023,"##Author: Lu Jiang, ##Title: Muse: Text-To-Image Generation via Masked Generative Transformers"
How many references are in the paper 'Muse: Text-To-Image Generation via Masked Generative Transformers'?,87,"##Author: Lu Jiang, ##Title: Muse: Text-To-Image Generation via Masked Generative Transformers"
How many citations does the paper 'Muse: Text-To-Image Generation via Masked Generative Transformers' have?,235,"##Author: Lu Jiang, ##Title: Muse: Text-To-Image Generation via Masked Generative Transformers"
What is the citation count of 'Muse: Text-To-Image Generation via Masked Generative Transformers' have?,235,"##Author: Lu Jiang, ##Title: Muse: Text-To-Image Generation via Masked Generative Transformers"
How many influential citations does the paper 'Muse: Text-To-Image Generation via Masked Generative Transformers' have?,17,"##Author: Lu Jiang, ##Title: Muse: Text-To-Image Generation via Masked Generative Transformers"
Is the paper 'Muse: Text-To-Image Generation via Masked Generative Transformers' open access?,Yes,"##Author: Lu Jiang, ##Title: Muse: Text-To-Image Generation via Masked Generative Transformers"
What is the open access PDF URL of the paper titled 'Muse: Text-To-Image Generation via Masked Generative Transformers'?,http://arxiv.org/pdf/2301.00704,"##Author: Lu Jiang, ##Title: Muse: Text-To-Image Generation via Masked Generative Transformers"
What are the fields of study for the paper titled 'Muse: Text-To-Image Generation via Masked Generative Transformers'?,Computer Science,"##Author: Lu Jiang, ##Title: Muse: Text-To-Image Generation via Masked Generative Transformers"
What is the journal name for the paper titled 'Muse: Text-To-Image Generation via Masked Generative Transformers'?,"ArXiv, volume: abs/2301.00704; ArXiv","##Author: Lu Jiang, ##Title: Muse: Text-To-Image Generation via Masked Generative Transformers"
Who are the authors of the paper 'Muse: Text-To-Image Generation via Masked Generative Transformers'?,"Huiwen Chang, Han Zhang, Jarred Barber, AJ Maschinot, Jose Lezama, Lu Jiang, Ming Yang, K. Murphy, W. Freeman, Michael Rubinstein, Yuanzhen Li, Dilip Krishnan","##Author: Lu Jiang, ##Title: Muse: Text-To-Image Generation via Masked Generative Transformers"
What is the TLDR summary of the paper 'Muse: Text-To-Image Generation via Masked Generative Transformers'?,,"##Author: Lu Jiang, ##Title: Muse: Text-To-Image Generation via Masked Generative Transformers"
