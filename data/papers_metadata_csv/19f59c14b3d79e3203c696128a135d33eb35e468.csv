Question,Answer,Notes
What is the author ID of Daniel Fried?,47070750,##Title: Pragmatic Inference with a CLIP Listener for Contrastive Captioning
What is the H-index of Daniel Fried?,26,##Title: Pragmatic Inference with a CLIP Listener for Contrastive Captioning
What is the semantic scholar author name of Daniel Fried?,Daniel Fried,##Title: Pragmatic Inference with a CLIP Listener for Contrastive Captioning
What is the semantic scholar author name of Daniel Fried?,https://www.semanticscholar.org/author/47070750,##Title: Pragmatic Inference with a CLIP Listener for Contrastive Captioning
What are affiliation of Daniel Fried?,Carnegie Mellon University,##Title: Pragmatic Inference with a CLIP Listener for Contrastive Captioning
What is the paper ID of the paper Pragmatic Inference with a CLIP Listener for Contrastive Captioning?,19f59c14b3d79e3203c696128a135d33eb35e468,##Title: Pragmatic Inference with a CLIP Listener for Contrastive Captioning
What are the external IDs of the paper Pragmatic Inference with a CLIP Listener for Contrastive Captioning?,"{'ArXiv': '2306.08818', 'DBLP': 'conf/acl/OuKF23', 'DOI': '10.48550/arXiv.2306.08818', 'CorpusId': 259164492}",##Title: Pragmatic Inference with a CLIP Listener for Contrastive Captioning
What is the URL of the paper Pragmatic Inference with a CLIP Listener for Contrastive Captioning?,https://www.semanticscholar.org/paper/19f59c14b3d79e3203c696128a135d33eb35e468,##Title: Pragmatic Inference with a CLIP Listener for Contrastive Captioning
What is the abstract of the paper 'Pragmatic Inference with a CLIP Listener for Contrastive Captioning'?,"We propose a simple yet effective and robust method for contrastive captioning: generating discriminative captions that distinguish target images from very similar alternative distractor images. Our approach is built on a pragmatic inference procedure that formulates captioning as a reference game between a speaker, which produces possible captions describing the target, and a listener, which selects the target given the caption. Unlike previous methods that derive both speaker and listener distributions from a single captioning model, we leverage an off-the-shelf CLIP model to parameterize the listener. Compared with captioner-only pragmatic models, our method benefits from rich vision language alignment representations from CLIP when reasoning over distractors. Like previous methods for discriminative captioning, our method uses a hyperparameter to control the tradeoff between the informativity (how likely captions are to allow a human listener to discriminate the target image) and the fluency of the captions. However, we find that our method is substantially more robust to the value of this hyperparameter than past methods, which allows us to automatically optimize the captions for informativity - outperforming past methods for discriminative captioning by 11% to 15% accuracy in human evaluations",##Title: Pragmatic Inference with a CLIP Listener for Contrastive Captioning
In which venue was the paper 'Pragmatic Inference with a CLIP Listener for Contrastive Captioning' published?,Annual Meeting of the Association for Computational Linguistics,##Title: Pragmatic Inference with a CLIP Listener for Contrastive Captioning
In what year was the paper 'Pragmatic Inference with a CLIP Listener for Contrastive Captioning' published?,2023,##Title: Pragmatic Inference with a CLIP Listener for Contrastive Captioning
How many references are in the paper 'Pragmatic Inference with a CLIP Listener for Contrastive Captioning'?,39,##Title: Pragmatic Inference with a CLIP Listener for Contrastive Captioning
How many citations does the paper 'Pragmatic Inference with a CLIP Listener for Contrastive Captioning' have?,1,##Title: Pragmatic Inference with a CLIP Listener for Contrastive Captioning
What is the citation count of 'Pragmatic Inference with a CLIP Listener for Contrastive Captioning' have?,1,##Title: Pragmatic Inference with a CLIP Listener for Contrastive Captioning
How many influential citations does the paper 'Pragmatic Inference with a CLIP Listener for Contrastive Captioning' have?,0,##Title: Pragmatic Inference with a CLIP Listener for Contrastive Captioning
Is the paper 'Pragmatic Inference with a CLIP Listener for Contrastive Captioning' open access?,Yes,##Title: Pragmatic Inference with a CLIP Listener for Contrastive Captioning
What is the open access PDF URL of the paper titled 'Pragmatic Inference with a CLIP Listener for Contrastive Captioning'?,http://arxiv.org/pdf/2306.08818,##Title: Pragmatic Inference with a CLIP Listener for Contrastive Captioning
What are the fields of study for the paper 'Pragmatic Inference with a CLIP Listener for Contrastive Captioning'?,Computer Science,##Title: Pragmatic Inference with a CLIP Listener for Contrastive Captioning
What is the journal name for the paper 'Pragmatic Inference with a CLIP Listener for Contrastive Captioning'?,"ArXiv, volume: abs/2306.08818; ArXiv",##Title: Pragmatic Inference with a CLIP Listener for Contrastive Captioning
Who are the authors of the paper 'Pragmatic Inference with a CLIP Listener for Contrastive Captioning'?,"Jiefu Ou, Benno Krojer, Daniel Fried",##Title: Pragmatic Inference with a CLIP Listener for Contrastive Captioning
Who is the first author of the paper 'Pragmatic Inference with a CLIP Listener for Contrastive Captioning'?,Jiefu Ou,##Title: Pragmatic Inference with a CLIP Listener for Contrastive Captioning
What is the TLDR summary of the paper 'Pragmatic Inference with a CLIP Listener for Contrastive Captioning'?,This work proposes a simple yet effective and robust method for contrastive captioning: generating discriminative captions that distinguish target images from very similar alternative distractor images by leveraging an off-the-shelf CLIP model to parameterize the listener.,##Title: Pragmatic Inference with a CLIP Listener for Contrastive Captioning
