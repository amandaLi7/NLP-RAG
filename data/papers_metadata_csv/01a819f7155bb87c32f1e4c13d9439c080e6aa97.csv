Question,Answer,Notes
What is the author ID of Shinji Watanabe?,1746678,##Title: Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning
What is the H-index of Shinji Watanabe?,67,##Title: Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning
What is the semantic scholar author name of Shinji Watanabe?,Shinji Watanabe,##Title: Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning
What is the semantic scholar author name of Shinji Watanabe?,https://www.semanticscholar.org/author/1746678,##Title: Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning
What is the affiliation of Shinji Watanabe?,"LTI (CMU), No other affiliations",##Title: Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning
What is the paper ID of the paper Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning?,01a819f7155bb87c32f1e4c13d9439c080e6aa97,##Title: Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning
What are the external IDs of the paper Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning?,"{'DBLP': 'journals/corr/abs-2309-15317', 'ArXiv': '2309.15317', 'DOI': '10.1109/ASRU57964.2023.10389735', 'CorpusId': 262935178}",##Title: Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning
What is the URL of the paper Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning?,https://www.semanticscholar.org/paper/01a819f7155bb87c32f1e4c13d9439c080e6aa97,##Title: Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning
What is the abstract of the paper 'Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning'?,"Multilingual self-supervised learning (SSL) has often lagged behind state-of-the-art (SOTA) methods due to the expenses and complexity required to handle many languages. This further harms the reproducibility of SSL, which is already limited to few research groups due to its resource usage. We show that more powerful techniques can actually lead to more efficient pre-training, opening SSL to more research groups. We propose WavLabLM, which extends WavLM’s joint prediction and denoising to 40k hours of data across 136 languages. To build WavLabLM, we devise a novel multi-stage pre-training method, designed to address the language imbalance of multilingual data. WavLabLM achieves comparable performance to XLS-R on ML-SUPERB with less than $10 \%$ of the training data, making SSL realizable with academic compute. We show that further efficiency can be achieved with a vanilla HuBERT Base model, which can maintain $94 \%$ of XLS-R’s performance with only $3 \%$ of the data, 4 GPUs, and limited trials. We open-source all code and models in ESPnet.",##Title: Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning
In which venue was the paper 'Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning' published?,Automatic Speech Recognition & Understanding,##Title: Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning
In what year was the paper 'Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning' published?,2023,##Title: Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning
How many references are in the paper 'Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning'?,50,##Title: Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning
How many citations does the paper 'Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning' have?,2,##Title: Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning
What is the citation count of 'Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning' have?,2,##Title: Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning
How many influential citations does the paper 'Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning' have?,0,##Title: Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning
Is the paper 'Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning' open access?,Yes,##Title: Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning
What is the open access PDF URL of the paper titled 'Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning'?,https://arxiv.org/pdf/2309.15317,##Title: Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning
What are the fields of study for the paper 'Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning'?,"Computer Science, Engineering",##Title: Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning
What is the journal name for the paper 'Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning'?,"2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU), pages: 1-8; 2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)",##Title: Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning
Who are the authors of the paper 'Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning'?,"William Chen, Jiatong Shi, Brian Yan, Dan Berrebbi, Wangyou Zhang, Yifan Peng, Xuankai Chang, Soumi Maiti, Shinji Watanabe",##Title: Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning
Who is the first author of the paper 'Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning'?,William Chen,##Title: Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning
What is the TLDR summary of the paper 'Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning'?,"This work proposes WavLabLM, which extends WavLM’s joint prediction and denoising to 40k hours of data across 136 languages, and devise a novel multi-stage pre-training method, designed to address the language imbalance of multilingual data.",##Title: Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning
