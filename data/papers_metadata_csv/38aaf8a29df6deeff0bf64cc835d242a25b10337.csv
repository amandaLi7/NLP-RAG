Question,Answer,Notes
What is the author ID of Chenyan Xiong?,2139787803,##Title: Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers
What is the H-index of Chenyan Xiong?,7,##Title: Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers
What is the semantic scholar author name of Chenyan Xiong?,Chenyan Xiong,##Title: Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers
What is the semantic scholar author name of Chenyan Xiong?,https://www.semanticscholar.org/author/2139787803,##Title: Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers
What is the affiliation of Chenyan Xiong?,"LTI (CMU), No other affiliations",##Title: Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers
What is the paper ID of the paper Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers?,38aaf8a29df6deeff0bf64cc835d242a25b10337,##Title: Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers
What are the external IDs of the paper Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers?,"{'ArXiv': '2305.12567', 'DBLP': 'journals/corr/abs-2305-12567', 'ACL': '2023.acl-long.724', 'DOI': '10.18653/v1/2023.acl-long.724', 'CorpusId': 258833130}",##Title: Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers
What is the URL of the paper Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers?,https://www.semanticscholar.org/paper/38aaf8a29df6deeff0bf64cc835d242a25b10337,##Title: Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers
What is the abstract of the paper 'Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers'?,"This paper explores the effectiveness of model-generated signals in improving zero-shot generalization of text-to-text Transformers such as T5. We study various designs to pretrain T5 using an auxiliary model to construct more challenging token replacements for the main model to denoise. Key aspects under study include the decoding target, the location of the RTD head, and the masking pattern. Based on these studies, we develop a new model, METRO-T0, which is pretrained using the redesigned ELECTRA-Style pretraining strategies and then prompt-finetuned on a mixture of NLP tasks. METRO-T0 outperforms all similar-sized baselines on prompted NLP benchmarks, such as _T0 Eval_ and MMLU, and rivals the state-of-the-art T0-11B model with only **8%** of its parameters. Our analysis on modelâ€™s neural activation and parameter sensitivity reveals that the effectiveness of METRO-T0 stems from more balanced contribution of parameters and better utilization of their capacity. The code and model checkpoints are available at [https://github.com/gonglinyuan/metro_t0](https://github.com/gonglinyuan/metro_t0).",##Title: Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers
In which venue was the paper 'Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers' published?,Annual Meeting of the Association for Computational Linguistics,##Title: Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers
In what year was the paper 'Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers' published?,2023,##Title: Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers
How many references are in the paper 'Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers'?,32,##Title: Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers
How many citations does the paper 'Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers' have?,0,##Title: Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers
What is the citation count of 'Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers' have?,0,##Title: Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers
How many influential citations does the paper 'Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers' have?,0,##Title: Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers
Is the paper 'Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers' open access?,Yes,##Title: Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers
What is the open access PDF URL of the paper titled 'Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers'?,https://aclanthology.org/2023.acl-long.724.pdf,##Title: Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers
What are the fields of study for the paper 'Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers'?,Computer Science,##Title: Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers
What is the journal name for the paper 'Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers'?,"Annual Meeting of the Association for Computational Linguistics, pages: 12933-12950; Annual Meeting of the Association for Computational Linguistics",##Title: Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers
Who are the authors of the paper 'Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers'?,"Linyuan Gong, Chenyan Xiong, Xiaodong Liu, Payal Bajaj, Yiqing Xie, Alvin Cheung, Jianfeng Gao, Xia Song",##Title: Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers
Who is the first author of the paper 'Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers'?,Linyuan Gong,##Title: Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers
What is the TLDR summary of the paper 'Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers'?,"A new model, METRO-T0 is developed, which is pretrained using the redesigned ELECTRA-Style pretraining strategies and then prompt-finetuned on a mixture of NLP tasks and rivals the state-of-the-art T0-11B model with only **8%** of its parameters.",##Title: Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers
