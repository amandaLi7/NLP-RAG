Question,Answer,Notes
What is the author ID of Louis-Philippe Morency?,49933077,##Title: Understanding Masked Autoencoders via Hierarchical Latent Variable Models
What is the H-index of Louis-Philippe Morency?,79,##Title: Understanding Masked Autoencoders via Hierarchical Latent Variable Models
What is the semantic scholar author name of Louis-Philippe Morency?,Louis-Philippe Morency,##Title: Understanding Masked Autoencoders via Hierarchical Latent Variable Models
What is the semantic scholar author name of Louis-Philippe Morency?,https://www.semanticscholar.org/author/49933077,##Title: Understanding Masked Autoencoders via Hierarchical Latent Variable Models
What is the affiliation of Louis-Philippe Morency?,"LTI (CMU), No other affiliations",##Title: Understanding Masked Autoencoders via Hierarchical Latent Variable Models
What is the paper ID of the paper Understanding Masked Autoencoders via Hierarchical Latent Variable Models?,dcb4f2b9b0e6da0d629878d1ad0469aee3df2020,##Title: Understanding Masked Autoencoders via Hierarchical Latent Variable Models
What are the external IDs of the paper Understanding Masked Autoencoders via Hierarchical Latent Variable Models?,"{'DBLP': 'journals/corr/abs-2306-04898', 'ArXiv': '2306.04898', 'DOI': '10.1109/CVPR52729.2023.00765', 'CorpusId': 259108864}",##Title: Understanding Masked Autoencoders via Hierarchical Latent Variable Models
What is the URL of the paper Understanding Masked Autoencoders via Hierarchical Latent Variable Models?,https://www.semanticscholar.org/paper/dcb4f2b9b0e6da0d629878d1ad0469aee3df2020,##Title: Understanding Masked Autoencoders via Hierarchical Latent Variable Models
What is the abstract of the paper 'Understanding Masked Autoencoders via Hierarchical Latent Variable Models'?,"Masked autoencoder (MAE), a simple and effective self-supervised learning framework based on the reconstruction of masked image regions, has recently achieved prominent success in a variety of vision tasks. Despite the emergence of intriguing empirical observations on MAE, a theoretically principled understanding is still lacking. In this work, we formally characterize and justify existing empirical in-sights and provide theoretical guarantees of MAE. We formulate the underlying data-generating process as a hierarchical latent variable model, and show that under reasonable assumptions, MAE provably identifies a set of latent variables in the hierarchical model, explaining why MAE can extract high-level information from pixels. Further, we show how key hyperparameters in MAE (the masking ratio and the patch size) determine which true latent variables to be recovered, therefore influencing the level of semantic information in the representation. Specifically, extremely large or small masking ratios inevitably lead to low-level representations. Our theory offers coherent explanations of existing empirical observations and provides insights for potential empirical improvements and fundamental limitations of the masked-reconstruction paradigm. We conduct extensive experiments to validate our theoretical insights.",##Title: Understanding Masked Autoencoders via Hierarchical Latent Variable Models
In which venue was the paper 'Understanding Masked Autoencoders via Hierarchical Latent Variable Models' published?,Computer Vision and Pattern Recognition,##Title: Understanding Masked Autoencoders via Hierarchical Latent Variable Models
In what year was the paper 'Understanding Masked Autoencoders via Hierarchical Latent Variable Models' published?,2023,##Title: Understanding Masked Autoencoders via Hierarchical Latent Variable Models
How many references are in the paper 'Understanding Masked Autoencoders via Hierarchical Latent Variable Models'?,74,##Title: Understanding Masked Autoencoders via Hierarchical Latent Variable Models
How many citations does the paper 'Understanding Masked Autoencoders via Hierarchical Latent Variable Models' have?,8,##Title: Understanding Masked Autoencoders via Hierarchical Latent Variable Models
What is the citation count of 'Understanding Masked Autoencoders via Hierarchical Latent Variable Models' have?,8,##Title: Understanding Masked Autoencoders via Hierarchical Latent Variable Models
How many influential citations does the paper 'Understanding Masked Autoencoders via Hierarchical Latent Variable Models' have?,0,##Title: Understanding Masked Autoencoders via Hierarchical Latent Variable Models
Is the paper 'Understanding Masked Autoencoders via Hierarchical Latent Variable Models' open access?,Yes,##Title: Understanding Masked Autoencoders via Hierarchical Latent Variable Models
What is the open access PDF URL of the paper titled 'Understanding Masked Autoencoders via Hierarchical Latent Variable Models'?,https://arxiv.org/pdf/2306.04898,##Title: Understanding Masked Autoencoders via Hierarchical Latent Variable Models
What are the fields of study for the paper 'Understanding Masked Autoencoders via Hierarchical Latent Variable Models'?,Computer Science,##Title: Understanding Masked Autoencoders via Hierarchical Latent Variable Models
What is the journal name for the paper 'Understanding Masked Autoencoders via Hierarchical Latent Variable Models'?,"2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages: 7918-7928; 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",##Title: Understanding Masked Autoencoders via Hierarchical Latent Variable Models
Who are the authors of the paper 'Understanding Masked Autoencoders via Hierarchical Latent Variable Models'?,"Lingjing Kong, Martin Q. Ma, Guan-Hong Chen, E. Xing, Yuejie Chi, Louis-Philippe Morency, Kun Zhang",##Title: Understanding Masked Autoencoders via Hierarchical Latent Variable Models
Who is the first author of the paper 'Understanding Masked Autoencoders via Hierarchical Latent Variable Models'?,Lingjing Kong,##Title: Understanding Masked Autoencoders via Hierarchical Latent Variable Models
What is the TLDR summary of the paper 'Understanding Masked Autoencoders via Hierarchical Latent Variable Models'?,"This work formally characterize and justify existing empirical in-sights and provide theoretical guarantees of MAE, and formulate the underlying data-generating process as a hierarchical latent variable model, and shows that under reasonable assumptions, MAE provably identifies a set of latent variables in the hierarchical model.",##Title: Understanding Masked Autoencoders via Hierarchical Latent Variable Models
