profName,authorId,authorName,authorUrl,authorHIndex,authorAffiliations,authorPaperCount,authorCitationCount,paperId,externalIds,url,title,abstract,venue,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,openAccessPdf,fieldsOfStudy,journal,authors,tldr
Alexander Hauptmann,145788702,A. Hauptmann,https://www.semanticscholar.org/author/145788702,27,[],59,2295,2107b867cb8f8afa30a9a940288d7c8b657f8aa5,"{'ACL': '2023.acl-short.127', 'DBLP': 'conf/acl/WenH23', 'DOI': '10.18653/v1/2023.acl-short.127', 'CorpusId': 259370856}",https://www.semanticscholar.org/paper/2107b867cb8f8afa30a9a940288d7c8b657f8aa5,Zero-Shot and Few-Shot Stance Detection on Varied Topics via Conditional Generation,"Zero-shot and few-shot stance detection identify the polarity of text with regard to a certain target when we have only limited or no training resources for the target. Previous work generally formulates the problem into a classification setting, ignoring the potential use of label text. In this paper, we instead utilize a conditional generation framework and formulate the problem as denoising from partially-filled templates, which can better utilize the semantics among input, label, and target texts. We further propose to jointly train an auxiliary task, target prediction, and to incorporate manually constructed incorrect samples with unlikelihood training to improve the representations for both target and label texts. We also verify the effectiveness of target-related Wikipedia knowledge with the generation framework. Experiments show that our proposed method significantly outperforms several strong baselines on VAST, and achieves new state-of-the-art performance.",Annual Meeting of the Association for Computational Linguistics,2023,31,2,0,True,"{'url': 'https://aclanthology.org/2023.acl-short.127.pdf', 'status': None}",['Computer Science'],{'pages': '1491-1499'},"[{'authorId': '4428136', 'name': 'Haoyang Wen'}, {'authorId': '145788702', 'name': 'A. Hauptmann'}]","This paper utilizes a conditional generation framework and formulates the zero-shot and few-shot stance detection problem as denoising from partially-filled templates, which can better utilize the semantics among input, label, and target texts."
Alexander Hauptmann,145788702,A. Hauptmann,https://www.semanticscholar.org/author/145788702,27,[],59,2295,376f494126d1ea4f571ea0263c43ac2b6331800a,"{'ArXiv': '2306.17842', 'DBLP': 'journals/corr/abs-2306-17842', 'DOI': '10.48550/arXiv.2306.17842', 'CorpusId': 259308960}",https://www.semanticscholar.org/paper/376f494126d1ea4f571ea0263c43ac2b6331800a,SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs,"In this work, we introduce Semantic Pyramid AutoEncoder (SPAE) for enabling frozen LLMs to perform both understanding and generation tasks involving non-linguistic modalities such as images or videos. SPAE converts between raw pixels and interpretable lexical tokens (or words) extracted from the LLM's vocabulary. The resulting tokens capture both the semantic meaning and the fine-grained details needed for visual reconstruction, effectively translating the visual content into a language comprehensible to the LLM, and empowering it to perform a wide array of multimodal tasks. Our approach is validated through in-context learning experiments with frozen PaLM 2 and GPT 3.5 on a diverse set of image understanding and generation tasks. Our method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.",arXiv.org,2023,52,9,1,True,"{'url': 'http://arxiv.org/pdf/2306.17842', 'status': None}",['Computer Science'],"{'volume': 'abs/2306.17842', 'name': 'ArXiv'}","[{'authorId': '8547960', 'name': 'Lijun Yu'}, {'authorId': '2109716647', 'name': 'Yong Cheng'}, {'authorId': '1390877035', 'name': 'Zhiruo Wang'}, {'authorId': '2107989922', 'name': 'Vivek Kumar'}, {'authorId': '3153147', 'name': 'Wolfgang Macherey'}, {'authorId': '2145438541', 'name': 'Yanping Huang'}, {'authorId': '144711958', 'name': 'David A. Ross'}, {'authorId': '145955800', 'name': 'Irfan Essa'}, {'authorId': '3312309', 'name': 'Yonatan Bisk'}, {'authorId': '152790163', 'name': 'Ming Yang'}, {'authorId': '1702318', 'name': 'K. Murphy'}, {'authorId': '145788702', 'name': 'A. Hauptmann'}, {'authorId': '39978626', 'name': 'Lu Jiang'}]","This method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%."
Alexander Hauptmann,145788702,A. Hauptmann,https://www.semanticscholar.org/author/145788702,27,[],59,2295,405e3910e06c9efe7e660b8697bcb4bab4e92f48,"{'DBLP': 'journals/corr/abs-2303-18177', 'ArXiv': '2303.18177', 'DOI': '10.1109/CVPR52729.2023.00153', 'CorpusId': 257900902}",https://www.semanticscholar.org/paper/405e3910e06c9efe7e660b8697bcb4bab4e92f48,STMT: A Spatial-Temporal Mesh Transformer for MoCap-Based Action Recognition,"We study the problem of human action recognition using motion capture (MoCap) sequences. Unlike existing techniques that take multiple manual steps to derive standard-ized skeleton representations as model input, we propose a novel Spatial-Temporal Mesh Transformer (STMT) to directly model the mesh sequences. The model uses a hierarchical transformer with intra-frame off-set attention and inter-frame self-attention. The attention mechanism allows the model to freely attend between any two vertex patches to learn nonlocal relationships in the spatial-temporal domain. Masked vertex modeling and future frame prediction are used as two self-supervised tasks to fully activate the bi-directional and auto-regressive attention in our hierarchical transformer. The proposed method achieves state-of-the-art performance compared to skeleton-based and point-cloud-based models on common MoCap benchmarks. Code is available at https://github.com/zgzxy001/STMT.",Computer Vision and Pattern Recognition,2023,69,4,0,True,"{'url': 'https://arxiv.org/pdf/2303.18177', 'status': None}",['Computer Science'],"{'pages': '1526-1536', 'name': '2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)'}","[{'authorId': '2197848856', 'name': 'Xiaoyu Zhu'}, {'authorId': '2319973', 'name': 'Po-Yao (Bernie) Huang'}, {'authorId': '118150711', 'name': 'Junwei Liang'}, {'authorId': '2147315384', 'name': 'Celso M. de Melo'}, {'authorId': '145788702', 'name': 'A. Hauptmann'}]",A novel Spatial-Temporal Mesh Transformer (STMT) is proposed to directly model the mesh sequences using motion capture sequences to achieve state-of-the-art performance compared to skeleton-based and point-cloud-based models on common MoCap benchmarks.
Alexander Hauptmann,145788702,A. Hauptmann,https://www.semanticscholar.org/author/145788702,27,[],59,2295,8ccda6de0223bcd897d5dc0efc8f33222a899d0d,"{'ArXiv': '2306.08937', 'DBLP': 'conf/emnlp/YuMSCHD023', 'DOI': '10.18653/v1/2023.emnlp-industry.66', 'CorpusId': 259165255}",https://www.semanticscholar.org/paper/8ccda6de0223bcd897d5dc0efc8f33222a899d0d,DocumentNet: Bridging the Data Gap in Document Pre-training,"Document understanding tasks, in particular, Visually-rich Document Entity Retrieval (VDER), have gained significant attention in recent years thanks to their broad applications in enterprise AI. However, publicly available data have been scarce for these tasks due to strict privacy constraints and high annotation costs. To make things worse, the non-overlapping entity spaces from different datasets hinder the knowledge transfer between document types. In this paper, we propose a method to collect massive-scale and weakly labeled data from the web to benefit the training of VDER models. The collected dataset, named DocumentNet, does not depend on specific document types or entity sets, making it universally applicable to all VDER tasks. The current DocumentNet consists of 30M documents spanning nearly 400 document types organized in a four-level ontology. Experiments on a set of broadly adopted VDER tasks show significant improvements when DocumentNet is incorporated into the pre-training for both classic and few-shot learning settings. With the recent emergence of large language models (LLMs), DocumentNet provides a large data source to extend their multi-modal capabilities for VDER.",Conference on Empirical Methods in Natural Language Processing,2023,43,1,0,True,"{'url': 'https://aclanthology.org/2023.emnlp-industry.66.pdf', 'status': None}",['Computer Science'],{'pages': '707-722'},"[{'authorId': '8547960', 'name': 'Lijun Yu'}, {'authorId': '2220100953', 'name': 'Jin Miao'}, {'authorId': '2112561470', 'name': 'Xiaoyu Sun'}, {'authorId': '2108327780', 'name': 'Jiayi Chen'}, {'authorId': '145788702', 'name': 'A. Hauptmann'}, {'authorId': '2791430', 'name': 'H. Dai'}, {'authorId': '2149192376', 'name': 'Wei Wei'}]","This paper proposes a method to collect massive-scale and weakly labeled data from the web to benefit the training of VDER models, and provides a large data source to extend their multi-modal capabilities for VDER."
Alon Lavie,1784914,A. Lavie,https://www.semanticscholar.org/author/1784914,47,[],213,14491,10127fa44054eb985ede206113b96aac3a96fd80,"{'DBLP': 'conf/acl/ReiGTCLM23', 'ACL': '2023.acl-short.94', 'ArXiv': '2305.11806', 'DOI': '10.48550/arXiv.2305.11806', 'CorpusId': 258822885}",https://www.semanticscholar.org/paper/10127fa44054eb985ede206113b96aac3a96fd80,The Inside Story: Towards Better Understanding of Machine Translation Neural Evaluation Metrics,"Neural metrics for machine translation evaluation, such as COMET, exhibit significant improvements in their correlation with human judgments, as compared to traditional metrics based on lexical overlap, such as BLEU. Yet, neural metrics are, to a great extent, “black boxes” returning a single sentence-level score without transparency about the decision-making process. In this work, we develop and compare several neural explainability methods and demonstrate their effectiveness for interpreting state-of-the-art fine-tuned neural metrics. Our study reveals that these metrics leverage token-level information that can be directly attributed to translation errors, as assessed through comparison of token-level neural saliency maps with Multidimensional Quality Metrics (MQM) annotations and with synthetically-generated critical translation errors. To ease future research, we release our code at: https://github.com/Unbabel/COMET/tree/explainable-metrics",Annual Meeting of the Association for Computational Linguistics,2023,52,8,1,True,"{'url': 'http://arxiv.org/pdf/2305.11806', 'status': None}",['Computer Science'],{'pages': '1089-1105'},"[{'authorId': '15631652', 'name': 'Ricardo Rei'}, {'authorId': '144726818', 'name': 'Nuno M. Guerreiro'}, {'authorId': '145188499', 'name': 'Marcos Vinícius Treviso'}, {'authorId': '147294938', 'name': 'Luísa Coheur'}, {'authorId': '1784914', 'name': 'A. Lavie'}, {'authorId': '2069905347', 'name': 'André Martins'}]","This study reveals that neural explainability metrics leverage token-level information that can be directly attributed to translation errors, as assessed through comparison of token- level neural saliency maps with Multidimensional Quality Metrics annotations and with synthetically-generated critical translation errors."
Alon Lavie,1784914,A. Lavie,https://www.semanticscholar.org/author/1784914,47,[],213,14491,5579d38636b898c6a67ad67a16a80dd83be0f8d4,"{'DBLP': 'journals/corr/abs-2308-16795', 'DOI': '10.48550/arXiv.2308.16795', 'CorpusId': 265476314}",https://www.semanticscholar.org/paper/5579d38636b898c6a67ad67a16a80dd83be0f8d4,Towards Multilingual Automatic Dialogue Evaluation,,arXiv.org,2023,0,0,0,True,"{'url': 'https://arxiv.org/pdf/2308.16795', 'status': None}",['Computer Science'],"{'volume': 'abs/2308.16795', 'name': 'ArXiv'}","[{'authorId': '2007581062', 'name': 'John Mendonça'}, {'authorId': '1784914', 'name': 'A. Lavie'}, {'authorId': '2268558660', 'name': 'Isabel Trancoso'}]",TLDR not found
Alon Lavie,1784914,A. Lavie,https://www.semanticscholar.org/author/1784914,47,[],213,14491,5c920b2326282d93ad2ac3d1cb8f746bd7ab6f50,"{'ACL': '2023.wmt-1.51', 'DBLP': 'conf/wmt/FreitagMLARTKBD23', 'DOI': '10.18653/v1/2023.wmt-1.51', 'CorpusId': 265607943}",https://www.semanticscholar.org/paper/5c920b2326282d93ad2ac3d1cb8f746bd7ab6f50,Results of WMT23 Metrics Shared Task: Metrics Might Be Guilty but References Are Not Innocent,"This paper presents the results of the WMT23 Metrics Shared Task. Participants submitting automatic MT evaluation metrics were asked to score the outputs of the translation systems competing in the WMT23 News Translation Task. All metrics were evaluated on how well they correlate with human ratings at the system and segment level. Similar to last year, we acquired our own human ratings based on expert-based human evaluation via Multidimensional Quality Metrics (MQM). Following last year’s success, we also included a challenge set subtask, where participants had to create contrastive test suites for evaluating metrics’ ability to capture and penalise specific types of translation errors. Furthermore, we improved our meta-evaluation procedure by considering fewer tasks and calculating a global score by weighted averaging across the various tasks. We present an extensive analysis on how well metrics perform on three language pairs: Chinese-English, Hebrew-English on the sentence-level and English-German on the paragraph-level. The results strongly confirm the results reported last year, that neural-based metrics are significantly better than non-neural metrics in their levels of correlation with human judgments. Further, we investigate the impact of bad reference translations on the correlations of metrics with human judgment. We present a novel approach for generating synthetic reference translations based on the collection of MT system outputs and their corresponding MQM ratings, which has the potential to mitigate bad reference issues we observed this year for some language pairs. Finally, we also study the connections between the magnitude of metric differences and their expected significance in human evaluation, which should help the community to better understand and adopt new metrics.",Conference on Machine Translation,2023,0,8,1,True,"{'url': 'https://aclanthology.org/2023.wmt-1.51.pdf', 'status': None}",['Computer Science'],{'pages': '578-628'},"[{'authorId': '2247094600', 'name': 'Markus Freitag'}, {'authorId': '2615454', 'name': 'Nitika Mathur'}, {'authorId': '2269458984', 'name': 'Chi-kiu Lo'}, {'authorId': '2837687', 'name': 'Eleftherios Avramidis'}, {'authorId': '2269461024', 'name': 'Ricardo Rei'}, {'authorId': '137174569', 'name': 'Brian Thompson'}, {'authorId': '3452584', 'name': 'Tom Kocmi'}, {'authorId': '2269457763', 'name': 'Frederic Blain'}, {'authorId': '2258954267', 'name': 'Daniel Deutsch'}, {'authorId': '2269462160', 'name': 'Craig Stewart'}, {'authorId': '36259430', 'name': 'Chrysoula Zerva'}, {'authorId': '2269457734', 'name': 'Sheila Castilho'}, {'authorId': '1784914', 'name': 'A. Lavie'}, {'authorId': '2149559186', 'name': 'George F. Foster'}]","A novel approach for generating synthetic reference translations based on the collection of MT system outputs and their corresponding MQM ratings, which has the potential to mitigate bad reference issues the authors observed this year for some language pairs are presented."
Alon Lavie,1784914,A. Lavie,https://www.semanticscholar.org/author/1784914,47,[],213,14491,9364720b2ab9ac67bc08e2b0b49aadded3d4e2e5,"{'ArXiv': '2304.14553', 'DBLP': 'journals/corr/abs-2304-14553', 'DOI': '10.48550/arXiv.2304.14553', 'CorpusId': 258418023}",https://www.semanticscholar.org/paper/9364720b2ab9ac67bc08e2b0b49aadded3d4e2e5,Appropriateness is all you need!,"The strive to make AI applications""safe""has led to the development of safety-measures as the main or even sole normative requirement of their permissible use. Similar can be attested to the latest version of chatbots, such as chatGPT. In this view, if they are""safe"", they are supposed to be permissible to deploy. This approach, which we call""safety-normativity"", is rather limited in solving the emerging issues that chatGPT and other chatbots have caused thus far. In answering this limitation, in this paper we argue for limiting chatbots in the range of topics they can chat about according to the normative concept of appropriateness. We argue that rather than looking for""safety""in a chatbot's utterances to determine what they may and may not say, we ought to assess those utterances according to three forms of appropriateness: technical-discursive, social, and moral. We then spell out what requirements for chatbots follow from these forms of appropriateness to avoid the limits of previous accounts: positionality, acceptability, and value alignment (PAVA). With these in mind, we may be able to determine what a chatbot may and may not say. Lastly, one initial suggestion is to use challenge sets, specifically designed for appropriateness, as a validation method.",arXiv.org,2023,61,1,0,True,"{'url': 'http://arxiv.org/pdf/2304.14553', 'status': None}",['Computer Science'],"{'volume': 'abs/2304.14553', 'name': 'ArXiv'}","[{'authorId': '1729525678', 'name': 'Hendrik Kempt'}, {'authorId': '1784914', 'name': 'A. Lavie'}, {'authorId': '1855863', 'name': 'S. Nagel'}]","This paper argues for limiting chatbots in the range of topics they can chat about according to the normative concept of appropriateness, and spells out what requirements for chatbots follow from these forms of Appropriateness to avoid the limits of previous accounts."
Alon Lavie,1784914,A. Lavie,https://www.semanticscholar.org/author/1784914,47,[],213,14491,9e8f125ef479af7e95ee5b8949b24e750c7df367,"{'DBLP': 'conf/sigdial/MendoncaLT23', 'ACL': '2023.sigdial-1.11', 'ArXiv': '2308.16795', 'DOI': '10.18653/v1/2023.sigdial-1.11', 'CorpusId': 261394693}",https://www.semanticscholar.org/paper/9e8f125ef479af7e95ee5b8949b24e750c7df367,Towards Multilingual Automatic Open-Domain Dialogue Evaluation,"The main limiting factor in the development of robust multilingual open-domain dialogue evaluation metrics is the lack of multilingual data and the limited availability of open-sourced multilingual dialogue systems. In this work, we propose a workaround for this lack of data by leveraging a strong multilingual pretrained encoder-based Language Model and augmenting existing English dialogue data using Machine Translation. We empirically show that the naive approach of finetuning a pretrained multilingual encoder model with translated data is insufficient to outperform the strong baseline of finetuning a multilingual model with only source data. Instead, the best approach consists in the careful curation of translated data using MT Quality Estimation metrics, excluding low quality translations that hinder its performance.",SIGDIAL Conferences,2023,35,0,0,True,"{'url': 'https://aclanthology.org/2023.sigdial-1.11.pdf', 'status': None}",['Computer Science'],{'pages': '130-141'},"[{'authorId': '2007581062', 'name': 'John Mendonça'}, {'authorId': '1784914', 'name': 'A. Lavie'}, {'authorId': '1691021', 'name': 'I. Trancoso'}]",It is empirically show that the naive approach of finetuning a pretrained multilingual encoder model with translated data is insufficient to outperform the strong baseline of finETuning a multilingual model with only source data.
Alon Lavie,1784914,A. Lavie,https://www.semanticscholar.org/author/1784914,47,[],213,14491,bcefc74b20649fd41ea05d87a3fa512d2559fc8d,"{'ACL': '2023.dstc-1.16', 'DBLP': 'journals/corr/abs-2308-16797', 'ArXiv': '2308.16797', 'DOI': '10.48550/arXiv.2308.16797', 'CorpusId': 261395306}",https://www.semanticscholar.org/paper/bcefc74b20649fd41ea05d87a3fa512d2559fc8d,Simple LLM Prompting is State-of-the-Art for Robust and Multilingual Dialogue Evaluation,"Despite significant research effort in the development of automatic dialogue evaluation metrics, little thought is given to evaluating dialogues other than in English. At the same time, ensuring metrics are invariant to semantically similar responses is also an overlooked topic. In order to achieve the desired properties of robustness and multilinguality for dialogue evaluation metrics, we propose a novel framework that takes advantage of the strengths of current evaluation models with the newly-established paradigm of prompting Large Language Models (LLMs). Empirical results show our framework achieves state of the art results in terms of mean Spearman correlation scores across several benchmarks and ranks first place on both the Robust and Multilingual tasks of the DSTC11 Track 4 “Automatic Evaluation Metrics for Open-Domain Dialogue Systems”, proving the evaluation capabilities of prompted LLMs.",DSTC,2023,45,4,0,True,"{'url': 'https://arxiv.org/pdf/2308.16797', 'status': None}",['Computer Science'],"{'volume': 'abs/2308.16797', 'name': 'ArXiv'}","[{'authorId': '8026343', 'name': 'J. Mendoncca'}, {'authorId': '2058093218', 'name': 'Patrícia Pereira'}, {'authorId': '123739597', 'name': 'Joao Paulo Carvalho'}, {'authorId': '1784914', 'name': 'A. Lavie'}, {'authorId': '1691021', 'name': 'I. Trancoso'}]",A novel framework that takes advantage of the strengths of current evaluation models with the newly-established paradigm of prompting Large Language Models (LLMs) to achieve the desired properties of robustness and multilinguality for dialogue evaluation metrics.
Alexander Rudnicky,3156164,A. Rudnicky,https://www.semanticscholar.org/author/3156164,8,[],16,309,161bf3f0705ef8e088f53b383363338daac9af44,"{'ArXiv': '2305.13571', 'DBLP': 'journals/corr/abs-2305-13571', 'ACL': '2023.acl-short.102', 'DOI': '10.48550/arXiv.2305.13571', 'CorpusId': 258840844}",https://www.semanticscholar.org/paper/161bf3f0705ef8e088f53b383363338daac9af44,Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings,"The use of positional embeddings in transformer language models is widely accepted. However, recent research has called into question the necessity of such embeddings. We further extend this inquiry by demonstrating that a randomly initialized and frozen transformer language model, devoid of positional embeddings, inherently encodes strong positional information through the shrinkage of self-attention variance. To quantify this variance, we derive the underlying distribution of each step within a transformer layer. Through empirical validation using a fully pretrained model, we show that the variance shrinkage effect still persists after extensive gradient updates. Our findings serve to justify the decision to discard positional embeddings and thus facilitate more efficient pretraining of transformer language models.",Annual Meeting of the Association for Computational Linguistics,2023,23,1,0,True,"{'url': 'http://arxiv.org/pdf/2305.13571', 'status': None}",['Computer Science'],{'pages': '1183-1193'},"[{'authorId': '27531332', 'name': 'Ta-Chung Chi'}, {'authorId': '32037089', 'name': 'Ting-Han Fan'}, {'authorId': '2119257114', 'name': 'Li-Wei Chen'}, {'authorId': '3156164', 'name': 'A. Rudnicky'}, {'authorId': '1693135', 'name': 'P. Ramadge'}]","This work demonstrates that a randomly initialized and frozen transformer language model, devoid of positional embeddings, inherently encodes strong positional information through the shrinkage of self-attention variance, and derives the underlying distribution of each step within a transformer layer."
Alexander Rudnicky,3156164,A. Rudnicky,https://www.semanticscholar.org/author/3156164,8,[],16,309,465ec2212d865e875e64638b3dd1ecaac21c5ddd,"{'DBLP': 'conf/emnlp/ChiFRR23', 'ArXiv': '2305.03796', 'DOI': '10.48550/arXiv.2305.03796', 'CorpusId': 258557586}",https://www.semanticscholar.org/paper/465ec2212d865e875e64638b3dd1ecaac21c5ddd,Transformer Working Memory Enables Regular Language Reasoning and Natural Language Length Extrapolation,"Unlike recurrent models, conventional wisdom has it that Transformers cannot perfectly model regular languages. Inspired by the notion of working memory, we propose a new Transformer variant named RegularGPT. With its novel combination of Weight-Sharing, Adaptive-Depth, and Sliding-Dilated-Attention, RegularGPT constructs working memory along the depth dimension, thereby enabling efficient and successful modeling of regular languages such as PARITY. We further test RegularGPT on the task of natural language length extrapolation and surprisingly find that it rediscovers the local windowed attention effect deemed necessary in prior work for length extrapolation.",Conference on Empirical Methods in Natural Language Processing,2023,47,4,0,True,"{'url': 'http://arxiv.org/pdf/2305.03796', 'status': None}",['Computer Science'],{'pages': '5972-5984'},"[{'authorId': '27531332', 'name': 'Ta-Chung Chi'}, {'authorId': '32037089', 'name': 'Ting-Han Fan'}, {'authorId': '3156164', 'name': 'A. Rudnicky'}, {'authorId': '1693135', 'name': 'P. Ramadge'}]","Inspired by the notion of working memory, a new Transformer variant named RegularGPT is proposed, which constructs working memory along the depth dimension, thereby enabling efficient and successful modeling of regular languages such as PARITY."
Alexander Waibel,1724972,A. Waibel,https://www.semanticscholar.org/author/1724972,80,[],719,27573,100eb82862a66e264686d015934c97c54bdadb4f,"{'DBLP': 'conf/icassp/NguyenPW23', 'DOI': '10.1109/ICASSP49357.2023.10096431', 'CorpusId': 258544929}",https://www.semanticscholar.org/paper/100eb82862a66e264686d015934c97c54bdadb4f,SYNTACC : Synthesizing Multi-Accent Speech By Weight Factorization,"Conventional multi-speaker text-to-speech synthesis (TTS) is known to be capable of synthesizing speech for multiple voices, yet it cannot generate speech in different accents. This limitation has motivated us to develop SYNTACC (Synthesizing speech with accents) which adapts conventional multi-speaker TTS to produce multi-accent speech. Our method uses the YourTTS model and involves a novel multi-accent training mechanism. The method works by decomposing each weight matrix into a shared component and an accent-dependent component, with the former being initialized by the pretrained multi-speaker TTS model and the latter being factorized into vectors using rank-1 matrices to reduce the number of training parameters per accent. This weight factorization method proves to be effective in fine-tuning the SYNTACC on multi-accent data sets in a low-resource condition. Our SYNTACC model eventually allows speech synthesis in not only different voices but also in different accents.","IEEE International Conference on Acoustics, Speech, and Signal Processing",2023,14,0,0,True,,['Computer Science'],"{'pages': '1-5', 'name': 'ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)'}","[{'authorId': '1706931907', 'name': 'Tuan-Nam Nguyen'}, {'authorId': '50214018', 'name': 'Ngoc-Quan Pham'}, {'authorId': '1724972', 'name': 'A. Waibel'}]","The SYNTACC model eventually allows speech synthesis in not only different voices but also in different accents, and the weight factorization method proves to be effective in fine-tuning the SYNT ACC on multi-accent data sets in a low-resource condition."
Alexander Waibel,1724972,A. Waibel,https://www.semanticscholar.org/author/1724972,80,[],719,27573,610d9958390ab83515d0d81e19f8e5264faf8e9b,"{'ACL': '2023.iwslt-1.6', 'DBLP': 'conf/iwslt/LiuNKUPNDMWN23', 'ArXiv': '2306.05320', 'DOI': '10.48550/arXiv.2306.05320', 'CorpusId': 259108961}",https://www.semanticscholar.org/paper/610d9958390ab83515d0d81e19f8e5264faf8e9b,KIT’s Multilingual Speech Translation System for IWSLT 2023,"Many existing speech translation benchmarks focus on native-English speech in high-quality recording conditions, which often do not match the conditions in real-life use-cases. In this paper, we describe our speech translation system for the multilingual track of IWSLT 2023, which focuses on the translation of scientific conference talks. The test condition features accented input speech and terminology-dense contents. The tasks requires translation into 10 languages of varying amounts of resources. In absence of training data from the target domain, we use a retrieval-based approach (kNN-MT) for effective adaptation (+0.8 BLEU for speech translation). We also use adapters to easily integrate incremental training data from data augmentation, and show that it matches the performance of re-training. We observe that cascaded systems are more easily adaptable towards specific target domains, due to their separate modules. Our cascaded speech system outperforms its end-to-end counterpart on scientific talk translation, although their performance remains similar on TED talks.",International Workshop on Spoken Language Translation,2023,41,2,0,True,"{'url': 'https://arxiv.org/pdf/2306.05320', 'status': None}",['Computer Science'],"{'volume': 'abs/2306.05320', 'name': 'ArXiv'}","[{'authorId': '1609468282', 'name': 'Danni Liu'}, {'authorId': '2165093057', 'name': 'T. Nguyen'}, {'authorId': '2061139721', 'name': 'Sai Koneru'}, {'authorId': '2186875551', 'name': 'Enes Yavuz Ugan'}, {'authorId': '50214018', 'name': 'Ngoc-Quan Pham'}, {'authorId': '1706931907', 'name': 'Tuan-Nam Nguyen'}, {'authorId': '2067507367', 'name': 'Tu Anh Dinh'}, {'authorId': '2052542025', 'name': 'Carlos Mullov'}, {'authorId': '1724972', 'name': 'A. Waibel'}, {'authorId': '2920247', 'name': 'J. Niehues'}]","This paper describes the speech translation system for the multilingual track of IWSLT 2023, which focuses on the translation of scientific conference talks, and observes that cascaded systems are more easily adaptable towards specific target domains, due to their separate modules."
Alexander Waibel,1724972,A. Waibel,https://www.semanticscholar.org/author/1724972,80,[],719,27573,7e13fcb7b7bae202fb9087e87abaa71a4b19a3e3,"{'ArXiv': '2308.11380', 'DBLP': 'journals/corr/abs-2308-11380', 'DOI': '10.48550/arXiv.2308.11380', 'CorpusId': 261064761}",https://www.semanticscholar.org/paper/7e13fcb7b7bae202fb9087e87abaa71a4b19a3e3,Convoifilter: A case study of doing cocktail party speech recognition,"This paper presents an end-to-end model designed to improve automatic speech recognition (ASR) for a particular speaker in a crowded, noisy environment. The model utilizes a single-channel speech enhancement module that isolates the speaker's voice from background noise (ConVoiFilter) and an ASR module. The model can decrease ASR's word error rate (WER) from 80% to 26.4% through this approach. Typically, these two components are adjusted independently due to variations in data requirements. However, speech enhancement can create anomalies that decrease ASR efficiency. By implementing a joint fine-tuning strategy, the model can reduce the WER from 26.4% in separate tuning to 14.5% in joint tuning. We openly share our pre-trained model to foster further research hf.co/nguyenvulebinh/voice-filter.",arXiv.org,2023,22,0,0,True,"{'url': 'https://arxiv.org/pdf/2308.11380', 'status': None}","['Computer Science', 'Engineering']","{'volume': 'abs/2308.11380', 'name': 'ArXiv'}","[{'authorId': '2165093057', 'name': 'T. Nguyen'}, {'authorId': '1724972', 'name': 'A. Waibel'}]","An end-to-end model designed to improve automatic speech recognition for a particular speaker in a crowded, noisy environment that utilizes a single-channel speech enhancement module that isolates the speaker's voice from background noise and an ASR module."
Alexander Waibel,1724972,A. Waibel,https://www.semanticscholar.org/author/1724972,80,[],719,27573,d24d60719e90e69749a75c160cb760d1d9fca44a,"{'ArXiv': '2309.11379', 'DBLP': 'journals/corr/abs-2309-11379', 'DOI': '10.21437/Interspeech.2023-2225', 'CorpusId': 260917017}",https://www.semanticscholar.org/paper/d24d60719e90e69749a75c160cb760d1d9fca44a,Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff,"Blockwise self-attentional encoder models have recently emerged as one promising end-to-end approach to simultaneous speech translation. These models employ a blockwise beam search with hypothesis reliability scoring to determine when to wait for more input speech before translating further. However, this method maintains multiple hypotheses until the entire speech input is consumed -- this scheme cannot directly show a single \textit{incremental} translation to users. Further, this method lacks mechanisms for \textit{controlling} the quality vs. latency tradeoff. We propose a modified incremental blockwise beam search incorporating local agreement or hold-$n$ policies for quality-latency control. We apply our framework to models trained for online or offline translation and demonstrate that both types can be effectively used in online mode. Experimental results on MuST-C show 0.6-3.6 BLEU improvement without changing latency or 0.8-1.4 s latency improvement without changing quality.",Interspeech,2023,39,4,1,True,"{'url': 'https://arxiv.org/pdf/2309.11379', 'status': None}","['Computer Science', 'Engineering']","{'volume': 'abs/2309.11379', 'name': 'ArXiv'}","[{'authorId': '2066246895', 'name': 'Peter Polák'}, {'authorId': '2087059555', 'name': 'Brian Yan'}, {'authorId': '2187876006', 'name': 'Shinji Watanabe'}, {'authorId': '1724972', 'name': 'A. Waibel'}, {'authorId': '143832874', 'name': 'Ondrej Bojar'}]",A modified incremental blockwise beam search incorporating local agreement or hold-$n$ policies for quality-latency control is proposed and applied to models trained for online or offline translation and it is demonstrated that both types can be effectively used in online mode.
Alexander Waibel,1724972,A. Waibel,https://www.semanticscholar.org/author/1724972,80,[],719,27573,f524f119afc13cc07ca15998c10b9509e9e9b0b5,"{'DBLP': 'conf/emnlp/HuberDMPNRCULLK23', 'ArXiv': '2308.03415', 'DOI': '10.48550/arXiv.2308.03415', 'CorpusId': 260681330}",https://www.semanticscholar.org/paper/f524f119afc13cc07ca15998c10b9509e9e9b0b5,End-to-End Evaluation for Low-Latency Simultaneous Speech Translation,"The challenge of low-latency speech translation has recently draw significant interest in the research community as shown by several publications and shared tasks. Therefore, it is essential to evaluate these different approaches in realistic scenarios. However, currently only specific aspects of the systems are evaluated and often it is not possible to compare different approaches. In this work, we propose the first framework to perform and evaluate the various aspects of low-latency speech translation under realistic conditions. The evaluation is carried out in an end-to-end fashion. This includes the segmentation of the audio as well as the run-time of the different components. Secondly, we compare different approaches to low-latency speech translation using this framework. We evaluate models with the option to revise the output as well as methods with fixed output. Furthermore, we directly compare state-of-the-art cascaded as well as end-to-end systems. Finally, the framework allows to automatically evaluate the translation quality as well as latency and also provides a web interface to show the low-latency model outputs to the user.",Conference on Empirical Methods in Natural Language Processing,2023,26,0,0,True,"{'url': 'https://arxiv.org/pdf/2308.03415', 'status': None}",['Computer Science'],{'pages': '12-20'},"[{'authorId': '2016060548', 'name': 'Christian Huber'}, {'authorId': '2067507367', 'name': 'Tu Anh Dinh'}, {'authorId': '2052542025', 'name': 'Carlos Mullov'}, {'authorId': '50214018', 'name': 'Ngoc-Quan Pham'}, {'authorId': '2165093057', 'name': 'T. Nguyen'}, {'authorId': '2083829072', 'name': 'Fabian Retkowski'}, {'authorId': '40901832', 'name': 'Stefan Constantin'}, {'authorId': '2186875551', 'name': 'Enes Yavuz Ugan'}, {'authorId': '1609468282', 'name': 'Danni Liu'}, {'authorId': '2190433826', 'name': 'Zhaolin Li'}, {'authorId': '2061139721', 'name': 'Sai Koneru'}, {'authorId': '2920247', 'name': 'J. Niehues'}, {'authorId': '1724972', 'name': 'A. Waibel'}]",This work proposes the first framework to perform and evaluate the various aspects of low-latency speech translation under realistic conditions and directly compares state-of-the-art cascaded as well as end-to-end systems.
Alexander Waibel,1724972,A. Waibel,https://www.semanticscholar.org/author/1724972,80,[],719,27573,f7e995c3cae465963ecaa8c9b4ce8b9b4323a71b,"{'ACL': '2023.iwslt-1.1', 'DBLP': 'conf/iwslt/AgrawalABBBCCCC23', 'DOI': '10.18653/v1/2023.iwslt-1.1', 'CorpusId': 259376816}",https://www.semanticscholar.org/paper/f7e995c3cae465963ecaa8c9b4ce8b9b4323a71b,FINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN,"This paper reports on the shared tasks organized by the 20th IWSLT Conference. The shared tasks address 9 scientific challenges in spoken language translation: simultaneous and offline translation, automatic subtitling and dubbing, speech-to-speech translation, multilingual, dialect and low-resource speech translation, and formality control. The shared tasks attracted a total of 38 submissions by 31 teams. The growing interest towards spoken language translation is also witnessed by the constantly increasing number of shared task organizers and contributors to the overview paper, almost evenly distributed across industry and academia.",International Workshop on Spoken Language Translation,2023,156,22,0,True,"{'url': 'https://aclanthology.org/2023.iwslt-1.1.pdf', 'status': None}",['Computer Science'],{'pages': '1-61'},"[{'authorId': '5112699', 'name': 'Sweta Agrawal'}, {'authorId': '49513989', 'name': 'Antonios Anastasopoulos'}, {'authorId': '2486762', 'name': 'L. Bentivogli'}, {'authorId': '143832874', 'name': 'Ondrej Bojar'}, {'authorId': '2870709', 'name': 'Claudia Borg'}, {'authorId': '2954727', 'name': 'Marine Carpuat'}, {'authorId': '2145191465', 'name': 'Roldano Cattoni'}, {'authorId': '2134567113', 'name': 'Mauro Cettolo'}, {'authorId': '46221498', 'name': 'Mingda Chen'}, {'authorId': '2144302389', 'name': 'William Chen'}, {'authorId': '1678451', 'name': 'K. Choukri'}, {'authorId': '3379701', 'name': 'Alexandra Chronopoulou'}, {'authorId': '3456678', 'name': 'Anna Currey'}, {'authorId': '72836788', 'name': 'T. Declerck'}, {'authorId': '48965598', 'name': 'Qianqian Dong'}, {'authorId': '1800354', 'name': 'Kevin Duh'}, {'authorId': '1736665', 'name': 'Y. Estève'}, {'authorId': '102811815', 'name': 'Marcello Federico'}, {'authorId': '2029654236', 'name': 'Souhir Gahbiche'}, {'authorId': '2259100', 'name': 'B. Haddow'}, {'authorId': '2064231695', 'name': 'B. Hsu'}, {'authorId': '2221319128', 'name': 'Phu Mon Htut'}, {'authorId': '49276525', 'name': 'H. Inaguma'}, {'authorId': '2157427038', 'name': 'Dávid Javorský'}, {'authorId': '144955737', 'name': 'J. Judge'}, {'authorId': '2059098838', 'name': 'Yasumasa Kano'}, {'authorId': '3023507', 'name': 'Tom Ko'}, {'authorId': '2107940335', 'name': 'Rishu Kumar'}, {'authorId': '50492525', 'name': 'Peng Li'}, {'authorId': '40765198', 'name': 'Xutai Ma'}, {'authorId': '2067519818', 'name': 'Prashant Mathur'}, {'authorId': '2987437', 'name': 'E. Matusov'}, {'authorId': '145324163', 'name': 'Paul McNamee'}, {'authorId': '2221319413', 'name': 'John P. McCrae'}, {'authorId': '38730896', 'name': 'Kenton Murray'}, {'authorId': '3456844', 'name': 'Maria Nadejde'}, {'authorId': '2148246160', 'name': 'Satoshi Nakamura'}, {'authorId': '2138026', 'name': 'Matteo Negri'}, {'authorId': '8308431', 'name': 'H. Nguyen'}, {'authorId': '2920247', 'name': 'J. Niehues'}, {'authorId': '145523874', 'name': 'Xing Niu'}, {'authorId': '2221318257', 'name': 'Atul Kr. Ojha'}, {'authorId': '2172668258', 'name': 'John E. Ortega'}, {'authorId': '66380217', 'name': 'Proyag Pal'}, {'authorId': '145503806', 'name': 'J. Pino'}, {'authorId': '35100952', 'name': 'Lonneke van der Plas'}, {'authorId': '2066246895', 'name': 'Peter Polák'}, {'authorId': '2165226832', 'name': 'Elijah Matthew Rippeth'}, {'authorId': '3448427', 'name': 'Elizabeth Salesky'}, {'authorId': '1485531923', 'name': 'Jiatong Shi'}, {'authorId': '3011998', 'name': 'Matthias Sperber'}, {'authorId': '11126660', 'name': 'Sebastian Stüker'}, {'authorId': '1790811', 'name': 'Katsuhito Sudoh'}, {'authorId': '2119309046', 'name': 'Yun Tang'}, {'authorId': '137174569', 'name': 'Brian Thompson'}, {'authorId': '2748455', 'name': 'Ke M. Tran'}, {'authorId': '145862931', 'name': 'M. Turchi'}, {'authorId': '1724972', 'name': 'A. Waibel'}, {'authorId': '50468534', 'name': 'Mingxuan Wang'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '1729345257', 'name': 'Rodolfo Zevallos'}]",
Alexander Waibel,2064429921,A. Waibel,https://www.semanticscholar.org/author/2064429921,6,[],18,69,aab2ed83bc3739a20e90ae1d97dcf45f3bc8e508,"{'DBLP': 'conf/icassp/NguyenNNDLW23', 'DOI': '10.1109/ICASSP49357.2023.10094599', 'CorpusId': 258531035}",https://www.semanticscholar.org/paper/aab2ed83bc3739a20e90ae1d97dcf45f3bc8e508,"AdapITN: A Fast, Reliable, and Dynamic Adaptive Inverse Text Normalization","Inverse text normalization (ITN) is the task that transforms text in spoken-form into written-form. While automatic speech recognition (ASR) produces text in spoken-form, human and natural language understanding systems prefer to consume text in written-form. ITN generally deals with semiotic phrases (e.g., numbers, date, time). However, lack of studies to deal with phonetization phrases, which is ASR’s output when it handles unseen data (e.g., foreign-named entities, domain names), although these exist in the same form in the spoken-form text. The reason is that phonetization phrases are infinite patterns and language-dependent. In this study, we introduce a novel end2end model that can handle both semiotic phrases (SEP) and phonetization phrases (PHP), named AdapITN. We call it ""Adap"" because it allows for handling unseen PHP. The model performs only when necessary by providing a mechanism to narrow normalized regions and external query knowledge, reducing the runtime significantly.","IEEE International Conference on Acoustics, Speech, and Signal Processing",2023,22,1,0,True,,['Computer Science'],"{'pages': '1-5', 'name': 'ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)'}","[{'authorId': '2165093057', 'name': 'T. Nguyen'}, {'authorId': '2216415969', 'name': 'Le Duc Minh Nhat'}, {'authorId': '2057071045', 'name': 'Quang Minh Nguyen'}, {'authorId': '2527751', 'name': 'Quoc Truong Do'}, {'authorId': '1983382', 'name': 'C. Luong'}, {'authorId': '2064429921', 'name': 'A. Waibel'}]","A novel end2end model that can handle both semiotic phrases (SEP) and phonetization phrases (PHP), named AdapITN is introduced, named ""Adap"" because it allows for handling unseen PHP."
Alexander Waibel,2064429921,A. Waibel,https://www.semanticscholar.org/author/2064429921,6,[],18,69,f3e237e794bc4cd8df7f3e31d0caa2f7ee8cd06b,"{'ArXiv': '2305.03873', 'ACL': '2023.loresmt-1.1', 'DBLP': 'journals/corr/abs-2305-03873', 'DOI': '10.48550/arXiv.2305.03873', 'CorpusId': 258486942}",https://www.semanticscholar.org/paper/f3e237e794bc4cd8df7f3e31d0caa2f7ee8cd06b,"Train Global, Tailor Local: Minimalist Multilingual Translation into Endangered Languages","In many humanitarian scenarios, translation into severely low resource languages often does not require a universal translation engine, but a dedicated text-specific translation engine. For example, healthcare records, hygienic procedures, government communication, emergency procedures and religious texts are all limited texts. While generic translation engines for all languages do not exist, translation of multilingually known limited texts into new, endangered languages may be possible and reduce human translation effort. We attempt to leverage translation resources from rich resource languages to efficiently produce best possible translation quality for well known texts, which is available in multiple languages, in a new, severely low resource language. We examine two approaches: 1.) best selection of seed sentences to jump start translations in a new language in view of best generalization to the remainder of a larger targeted text(s), and 2.) we adapt large general multilingual translation engines from many other languages to focus on a specific text in a new, unknown language. We find that adapting large pretrained multilingual models to the domain/text first and then to the severely low resource language works best. If we also select a best set of seed sentences, we can improve average chrF performance on new test languages from a baseline of 21.9 to 50.7, while reducing the number of seed sentences to only ∼1,000 in the new, unknown language.",LORESMT,2023,82,0,0,True,"{'url': 'http://arxiv.org/pdf/2305.03873', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.03873', 'name': 'ArXiv'}","[{'authorId': '144812501', 'name': 'Zhong Zhou'}, {'authorId': '2920247', 'name': 'J. Niehues'}, {'authorId': '2064429921', 'name': 'A. Waibel'}]","This work examines two approaches to best selection of seed sentences to jump start translations in a new language in view of best generalization to the remainder of a larger targeted text(s), and it finds that adapting large pretrained multilingual models to the domain/text first and then to the severely low resource language works best."
Alexander Waibel,2064429921,A. Waibel,https://www.semanticscholar.org/author/2064429921,6,[],18,69,f547c7ec86cbc0989e87f0e23f7e0b2cfc5259c3,"{'ACL': '2023.iwslt-1.37', 'DBLP': 'conf/iwslt/PolakLPNWB23', 'DOI': '10.18653/v1/2023.iwslt-1.37', 'CorpusId': 259376517}",https://www.semanticscholar.org/paper/f547c7ec86cbc0989e87f0e23f7e0b2cfc5259c3,Towards Efficient Simultaneous Speech Translation: CUNI-KIT System for Simultaneous Track at IWSLT 2023,"In this paper, we describe our submission to the Simultaneous Track at IWSLT 2023. This year, we continue with the successful setup from the last year, however, we adopt the latest methods that further improve the translation quality. Additionally, we propose a novel online policy for attentional encoder-decoder models. The policy prevents the model to generate translation beyond the current speech input by using an auxiliary CTC output layer. We show that the proposed simultaneous policy can be applied to both streaming blockwise models and offline encoder-decoder models. We observe significant improvements in quality (up to 1.1 BLEU) and the computational footprint (up to 45% relative RTF).",International Workshop on Spoken Language Translation,2023,32,5,1,True,"{'url': 'https://aclanthology.org/2023.iwslt-1.37.pdf', 'status': None}",['Computer Science'],{'pages': '389-396'},"[{'authorId': '2066246895', 'name': 'Peter Polák'}, {'authorId': '1609468282', 'name': 'Danni Liu'}, {'authorId': '50214018', 'name': 'Ngoc-Quan Pham'}, {'authorId': '2920247', 'name': 'J. Niehues'}, {'authorId': '2064429921', 'name': 'A. Waibel'}, {'authorId': '143832874', 'name': 'Ondrej Bojar'}]","This year's submission to the Simultaneous Track at IWSLT 2023 is described, and a novel online policy for attentional encoder-decoder models is proposed that prevents the model to generate translation beyond the current speech input by using an auxiliary CTC output layer."
Alexander Hauptmann,7661726,Alexander Hauptmann,https://www.semanticscholar.org/author/7661726,81,[],543,25325,72cce47fd053bf916314d89a8174726c58c05e02,"{'DBLP': 'conf/acl/WenXHH23', 'DOI': '10.18653/v1/2023.findings-acl.198', 'CorpusId': 259859135}",https://www.semanticscholar.org/paper/72cce47fd053bf916314d89a8174726c58c05e02,Towards Open-Domain Twitter User Profile Inference,",",Annual Meeting of the Association for Computational Linguistics,2023,61,0,0,True,"{'url': 'https://aclanthology.org/2023.findings-acl.198.pdf', 'status': None}",['Computer Science'],{'pages': '3172-3188'},"[{'authorId': '4428136', 'name': 'Haoyang Wen'}, {'authorId': '123034558', 'name': 'Zhenxin Xiao'}, {'authorId': '144547315', 'name': 'E. Hovy'}, {'authorId': '7661726', 'name': 'Alexander Hauptmann'}]",
Alexander Rudnicky,1783635,Alexander I. Rudnicky,https://www.semanticscholar.org/author/1783635,42,[],264,7639,06a8f2e3c4266196b008851f1ec7ef9f340809da,"{'DBLP': 'journals/corr/abs-2309-07412', 'ArXiv': '2309.07412', 'DOI': '10.48550/arXiv.2309.07412', 'CorpusId': 261823538}",https://www.semanticscholar.org/paper/06a8f2e3c4266196b008851f1ec7ef9f340809da,Advancing Regular Language Reasoning in Linear Recurrent Neural Networks,"In recent studies, linear recurrent neural networks (LRNNs) have achieved Transformer-level performance in natural language modeling and long-range modeling while offering rapid parallel training and constant inference costs. With the resurged interest in LRNNs, we study whether they can learn the hidden rules in training sequences, such as the grammatical structures of regular language. We theoretically analyze some existing LRNNs and discover their limitations on regular language. Motivated by the analysis, we propose a new LRNN equipped with a block-diagonal and input-dependent transition matrix. Experiments suggest that the proposed model is the only LRNN that can perform length extrapolation on regular language tasks such as Sum, Even Pair, and Modular Arithmetic.",arXiv.org,2023,22,0,0,True,"{'url': 'https://arxiv.org/pdf/2309.07412', 'status': None}",['Computer Science'],"{'volume': 'abs/2309.07412', 'name': 'ArXiv'}","[{'authorId': '32037089', 'name': 'Ting-Han Fan'}, {'authorId': '27531332', 'name': 'Ta-Chung Chi'}, {'authorId': '1783635', 'name': 'Alexander I. Rudnicky'}]","This work theoretically analyze some existing LRNNs and proposes a new LRNN equipped with a block-diagonal and input-dependent transition matrix that is the only LRNN that can perform length extrapolation on regular language tasks such as Sum, Even Pair, and Modular Arithmetic."
Alexander Rudnicky,1783635,Alexander I. Rudnicky,https://www.semanticscholar.org/author/1783635,42,[],264,7639,2670612b5e11297cd9b98f4d7ff796725f77fe35,"{'DBLP': 'conf/sigdial/ChiR22', 'ArXiv': '2306.15103', 'ACL': '2022.sigdial-1.32', 'DOI': '10.48550/arXiv.2306.15103', 'CorpusId': 252847494}",https://www.semanticscholar.org/paper/2670612b5e11297cd9b98f4d7ff796725f77fe35,Structured Dialogue Discourse Parsing,"Dialogue discourse parsing aims to uncover the internal structure of a multi-participant conversation by finding all the discourse links and corresponding relations. Previous work either treats this task as a series of independent multiple-choice problems, in which the link existence and relations are decoded separately, or the encoding is restricted to only local interaction, ignoring the holistic structural information. In contrast, we propose a principled method that improves upon previous work from two perspectives: encoding and decoding. From the encoding side, we perform structured encoding on the adjacency matrix followed by the matrix-tree learning algorithm, where all discourse links and relations in the dialogue are jointly optimized based on latent tree-level distribution. From the decoding side, we perform structured inference using the modified Chiu-Liu-Edmonds algorithm, which explicitly generates the labeled multi-root non-projective spanning tree that best captures the discourse structure. In addition, unlike in previous work, we do not rely on hand-crafted features; this improves the model’s robustness. Experiments show that our method achieves new state-of-the-art, surpassing the previous model by 2.3 on STAC and 1.5 on Molweni (F1 scores).",SIGDIAL Conferences,2023,64,4,1,True,"{'url': 'http://arxiv.org/pdf/2306.15103', 'status': None}",['Computer Science'],"{'volume': 'abs/2306.15103', 'name': 'ArXiv'}","[{'authorId': '27531332', 'name': 'Ta-Chung Chi'}, {'authorId': '1783635', 'name': 'Alexander I. Rudnicky'}]","This work proposes a principled method that improves upon previous work from two perspectives: encoding and decoding and achieves new state-of-the-art results, surpassing the previous model by 2.3 on STAC and 1.5 on Molweni (F1 scores)."
Alexander Rudnicky,1783635,Alexander I. Rudnicky,https://www.semanticscholar.org/author/1783635,42,[],264,7639,4b8d3ede673ddeab9dfb5184da6b748d7a526754,"{'DBLP': 'conf/aaai/Chen0R23', 'ArXiv': '2302.04215', 'DOI': '10.48550/arXiv.2302.04215', 'CorpusId': 256662411}",https://www.semanticscholar.org/paper/4b8d3ede673ddeab9dfb5184da6b748d7a526754,A Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech,"Recent Text-to-Speech (TTS) systems trained on reading or acted corpora have achieved near human-level naturalness. The diversity of human speech, however, often goes beyond the coverage of these corpora. We believe the ability to handle such diversity is crucial for AI systems to achieve human-level communication. Our work explores the use of more abundant real-world data for building speech synthesizers. We train TTS systems using real-world speech from YouTube and podcasts. We observe the mismatch between training and inference alignments in mel-spectrogram based autoregressive models, leading to unintelligible synthesis, and demonstrate that learned discrete codes within multiple code groups effectively resolves this issue. We introduce our MQTTS system whose architecture is designed for multiple code generation and monotonic alignment, along with the use of a clean silence prompt to improve synthesis quality. We conduct ablation analyses to identify the efficacy of our methods. We show that MQTTS outperforms existing TTS systems in several objective and subjective measures.",AAAI Conference on Artificial Intelligence,2023,40,16,3,True,"{'url': 'http://arxiv.org/pdf/2302.04215', 'status': None}","['Computer Science', 'Engineering']","{'volume': 'abs/2302.04215', 'name': 'ArXiv'}","[{'authorId': '2119257114', 'name': 'Li-Wei Chen'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '1783635', 'name': 'Alexander I. Rudnicky'}]","This work introduces the MQTTS system, a Text-to-Speech system whose architecture is designed for multiple code generation and monotonic alignment, along with the use of a clean silence prompt to improve synthesis quality, and shows that MqTTS outperforms existing TTS systems in several objective and subjective measures."
Alexander Rudnicky,1783635,Alexander I. Rudnicky,https://www.semanticscholar.org/author/1783635,42,[],264,7639,9799c17fd287bb9e8d231fe032c6dbf9c0c9d675,"{'ArXiv': '2306.12794', 'DBLP': 'journals/corr/abs-2306-12794', 'ACL': '2023.dstc-1.28', 'DOI': '10.48550/arXiv.2306.12794', 'CorpusId': 259224700}",https://www.semanticscholar.org/paper/9799c17fd287bb9e8d231fe032c6dbf9c0c9d675,"Overview of Robust and Multilingual Automatic Evaluation Metrics

for Open-Domain Dialogue Systems at DSTC 11 Track 4","The advent and fast development of neural networks have revolutionized the research on dialogue systems and subsequently have triggered various challenges regarding their automatic evaluation. Automatic evaluation of open-domain dialogue systems as an open challenge has been the center of the attention of many researchers. Despite the consistent efforts to improve automatic metrics’ correlations with human evaluation, there have been very few attempts to assess their robustness over multiple domains and dimensions. Also, their focus is mainly on the English language. All of these challenges prompt the development of automatic evaluation metrics that are reliable in various domains, dimensions, and languages. This track in the 11th Dialogue System Technology Challenge (DSTC11) is part of the ongoing effort to promote robust and multilingual automatic evaluation metrics. This article describes the datasets and baselines provided to participants and discusses the submission and result details of the two proposed subtasks.",DSTC,2023,71,3,0,True,"{'url': 'https://arxiv.org/pdf/2306.12794', 'status': None}",['Computer Science'],"{'volume': 'abs/2306.12794', 'name': 'ArXiv'}","[{'authorId': '2220406508', 'name': ""Mario Rodr'iguez-Cantelar""}, {'authorId': '2111574800', 'name': 'Chen Zhang'}, {'authorId': '1672552269', 'name': 'Chengguang Tang'}, {'authorId': '2026468506', 'name': 'Ke Shi'}, {'authorId': '3022427', 'name': 'Sarik Ghazarian'}, {'authorId': '2662374', 'name': 'João Sedoc'}, {'authorId': '1405511901', 'name': 'L. F. D’Haro'}, {'authorId': '1783635', 'name': 'Alexander I. Rudnicky'}]","The datasets and baselines provided to participants are described and the submission and result details of the two proposed subtasks are discussed, which promote robust and multilingual automatic evaluation metrics."
Alexander Rudnicky,1783635,Alexander I. Rudnicky,https://www.semanticscholar.org/author/1783635,42,[],264,7639,f743324682d5d50db9b114fa60b908f09c10c9a0,"{'DBLP': 'conf/sigir/TavaresSRM23', 'DOI': '10.1145/3539618.3592010', 'CorpusId': 259949703}",https://www.semanticscholar.org/paper/f743324682d5d50db9b114fa60b908f09c10c9a0,Learning to Ask Questions for Zero-shot Dialogue State Tracking,"We present a method for performing zero-shot Dialogue State Tracking (DST) by casting the task as a learning-to-ask-questions framework. The framework learns to pair the best question generation (QG) strategy with in-domain question answering (QA) methods to extract slot values from a dialogue without any human intervention. A novel self-supervised QA pretraining step using in-domain data is essential to learn the structure without requiring any slot-filling annotations. Moreover, we show that QG methods need to be aligned with the same grammatical person used in the dialogue. Empirical evaluation on the MultiWOZ 2.1 dataset demonstrates that our approach, when used alongside robust QA models, outperforms existing zero-shot methods in the challenging task of zero-shot cross domain adaptation-given a comparable amount of domain knowledge during data creation. Finally, we analyze the impact of the types of questions used, and demonstrate that the algorithmic approach outperforms template-based question generation.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2023,28,1,0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/3539618.3592010', 'status': None}",['Computer Science'],{'name': 'Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval'},"[{'authorId': '2187308615', 'name': 'Diogo Tavares'}, {'authorId': '3442611', 'name': 'David Semedo'}, {'authorId': '1783635', 'name': 'Alexander I. Rudnicky'}, {'authorId': '2190828088', 'name': 'João Magalhães'}]",This work presents a method for performing zero-shot Dialogue State Tracking by casting the task as a learning-to-ask-questions framework that outperforms template-based question generation and shows that QG methods need to be aligned with the same grammatical person used in the dialogue.
Brian MacWhinney,2414040,B. MacWhinney,https://www.semanticscholar.org/author/2414040,75,[],432,27192,02a626bd8538ecb675bd2bcd8f5985274e965d00,"{'DOI': '10.1044/2022_persp-22-00156', 'CorpusId': 256655709, 'PubMed': '37229359'}",https://www.semanticscholar.org/paper/02a626bd8538ecb675bd2bcd8f5985274e965d00,Assessment and Therapy Goal Planning Using Free Computerized Language Analysis Software.,"Background
We discuss a free software system (Computerized Language Analysis [CLAN]) that can enable fast, thorough, and informative language sample analysis (LSA).


Method
We describe methods for eliciting, transcribing, analyzing, and interpreting language samples. Using a hypothetical child speaker, we illustrate use KidEval to generate a diagnostic report.


Results
Given LSA results suggestive of expressive language delay, we analyze further using CLAN's Developmental Sentence Score and Index of Productive Syntax routines, and outline the child's use of Brown's morphemes.


Discussion
This tutorial provides an introduction to the use of free CLAN software. We discuss how LSA results can be used to structure therapy goals that address specific aspects of grammatical structure that the child may not yet demonstrate in their spoken language. Finally, we provide answers to common questions, including user support.",Perspectives of the ASHA Special Interest Groups,2023,10,1,0,True,,['Medicine'],"{'volume': '8 1', 'pages': '\n          19-31\n        ', 'name': 'Perspectives of the ASHA special interest groups'}","[{'authorId': '30403011', 'name': 'N. Ratner'}, {'authorId': '2414040', 'name': 'B. MacWhinney'}]",This tutorial provides an introduction to the use of free CLAN software and discusses how LSA results can be used to structure therapy goals that address specific aspects of grammatical structure that the child may not yet demonstrate in their spoken language.
Brian MacWhinney,2414040,B. MacWhinney,https://www.semanticscholar.org/author/2414040,75,[],432,27192,0773228ecc4c1f2d729c0ae5764c77c1c9bb9573,"{'PubMedCentral': '10555460', 'DOI': '10.1044/2023_JSLHR-22-00642', 'CorpusId': 259232740, 'PubMed': '37348510'}",https://www.semanticscholar.org/paper/0773228ecc4c1f2d729c0ae5764c77c1c9bb9573,Automation of Language Sample Analysis,"Purpose: A major barrier to the wider use of language sample analysis (LSA) is the fact that transcription is very time intensive. Methods that can reduce the required time and effort could help in promoting the use of LSA for clinical practice and research. Method: This article describes an automated pipeline, called Batchalign, that takes raw audio and creates full transcripts in Codes for the Human Analysis of Talk (CHAT) transcription format, complete with utterance- and word-level time alignments and morphosyntactic analysis. The pipeline only requires major human intervention for final checking. It combines a series of existing tools with additional novel reformatting processes. The steps in the pipeline are (a) automatic speech recognition, (b) utterance tokenization, (c) automatic corrections, (d) speaker ID assignment, (e) forced alignment, (f) user adjustments, and (g) automatic morphosyntactic and profiling analyses. Results: For work with recordings from adults with language disorders, six major results were obtained: (a) The word error rate was between 2.4% for controls and 3.4% for patients, (b) utterance tokenization accuracy was at the level reported for speakers without language disorders, (c) word-level diarization accuracy was at 93% for control participants and 83% for participants with language disorders, (d) utterance-level diarization accuracy based on word-level diarization was high, (e) adherence to CHAT format was fully accurate, and (f) human transcriber time was reduced by up to 75%. Conclusion: The pipeline dramatically shortens the time gap between data collection and data analysis and provides an output superior to that typically generated by human transcribers.","Journal of Speech, Language and Hearing Research",2023,70,0,0,True,,['Medicine'],"{'volume': '66', 'pages': '2421 - 2433', 'name': 'Journal of Speech, Language, and Hearing Research : JSLHR'}","[{'authorId': '2110153362', 'name': 'Houjun Liu'}, {'authorId': '2414040', 'name': 'B. MacWhinney'}, {'authorId': '50098578', 'name': 'Davida Fromm'}, {'authorId': '50857375', 'name': 'Alyssa M. Lanzi'}]","An automated pipeline that takes raw audio and creates full transcripts in Codes for the Human Analysis of Talk (CHAT) transcription format, complete with utterance- and word-level time alignments and morphosyntactic analysis, provides an output superior to that typically generated by human transcribers."
Brian MacWhinney,2414040,B. MacWhinney,https://www.semanticscholar.org/author/2414040,75,[],432,27192,283dbaa4da4beafa5e5719095bcc88e63d17815e,"{'DBLP': 'journals/sle/ZhangM23', 'DOI': '10.1186/s40561-023-00223-3', 'CorpusId': 255624882}",https://www.semanticscholar.org/paper/283dbaa4da4beafa5e5719095bcc88e63d17815e,The role of novelty stimuli in second language acquisition: evidence from the optimized training by the Pinyin Tutor at TalkBank,,Smart Learning Environments,2023,69,4,0,True,"{'url': 'https://slejournal.springeropen.com/counter/pdf/10.1186/s40561-023-00223-3', 'status': None}",['Computer Science'],"{'volume': '10', 'pages': '1-19', 'name': 'Smart Learning Environments'}","[{'authorId': '46868808', 'name': 'Yanhui Zhang'}, {'authorId': '2414040', 'name': 'B. MacWhinney'}]",TLDR not found
Brian MacWhinney,2414040,B. MacWhinney,https://www.semanticscholar.org/author/2414040,75,[],432,27192,3859f18277f0c5876a53411b07f80d65254c52e5,"{'DOI': '10.1186/s40468-023-00232-6', 'CorpusId': 259950664}",https://www.semanticscholar.org/paper/3859f18277f0c5876a53411b07f80d65254c52e5,Using diagnostic feedback to enhance the development of phonetic knowledge of an L2: a CALL design based on the unified competition model and the implementation with the Pinyin Tutor,,Language Testing in Asia,2023,68,0,0,True,"{'url': 'https://languagetestingasia.springeropen.com/counter/pdf/10.1186/s40468-023-00232-6', 'status': None}",,"{'volume': '13', 'pages': '1-22', 'name': 'Language Testing in Asia'}","[{'authorId': '46868808', 'name': 'Yanhui Zhang'}, {'authorId': '2414040', 'name': 'B. MacWhinney'}]",The findings demonstrated that the repeated feedback-embedded training with the Pinyin Tutor significantly boosted the learners’ proficiency in all aspects of PinyIn knowledge for second language (L2) learners of Chinese whose first language backgrounds were varied and whose initial proficiencies in Chinese were elementary.
Brian MacWhinney,2414040,B. MacWhinney,https://www.semanticscholar.org/author/2414040,75,[],432,27192,4d35540aaf993c8fa7e1fa5fc6a990f1eb830263,"{'DBLP': 'journals/corr/abs-2305-13331', 'ArXiv': '2305.13331', 'DOI': '10.48550/arXiv.2305.13331', 'CorpusId': 258841801}",https://www.semanticscholar.org/paper/4d35540aaf993c8fa7e1fa5fc6a990f1eb830263,A New Benchmark of Aphasia Speech Recognition and Detection Based on E-Branchformer and Multi-task Learning,"Aphasia is a language disorder that affects the speaking ability of millions of patients. This paper presents a new benchmark for Aphasia speech recognition and detection tasks using state-of-the-art speech recognition techniques with the AphsiaBank dataset. Specifically, we introduce two multi-task learning methods based on the CTC/Attention architecture to perform both tasks simultaneously. Our system achieves state-of-the-art speaker-level detection accuracy (97.3%), and a relative WER reduction of 11% for moderate Aphasia patients. In addition, we demonstrate the generalizability of our approach by applying it to another disordered speech database, the DementiaBank Pitt corpus. We will make our all-in-one recipes and pre-trained model publicly available to facilitate reproducibility. Our standardized data preprocessing pipeline and open-source recipes enable researchers to compare results directly, promoting progress in disordered speech processing.",Interspeech,2023,44,1,0,True,"{'url': 'http://arxiv.org/pdf/2305.13331', 'status': None}","['Engineering', 'Computer Science']","{'volume': 'abs/2305.13331', 'name': 'ArXiv'}","[{'authorId': '1677684712', 'name': 'Jiyang Tang'}, {'authorId': '2144302389', 'name': 'William Chen'}, {'authorId': '8776560', 'name': 'Xuankai Chang'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '2414040', 'name': 'B. MacWhinney'}]",A new benchmark for Aphasia speech recognition and detection tasks using state-of-the-art speech recognition techniques with the AphsiaBank dataset is presented and two multi-task learning methods based on the CTC/Attention architecture are introduced to perform both tasks simultaneously.
Brian MacWhinney,2414040,B. MacWhinney,https://www.semanticscholar.org/author/2414040,75,[],432,27192,52b48ab5d7d87642395818bea1ff804ff6dd0bd3,"{'DOI': '10.1044/2023_AJSLP-22-00385', 'CorpusId': 260114227, 'PubMed': '37486768'}",https://www.semanticscholar.org/paper/52b48ab5d7d87642395818bea1ff804ff6dd0bd3,Collaborative Commentary for Understanding Communication Disorders.,"PURPOSE
The goal of the Collaborative Commentary (CC) system is to make the TalkBank adult clinical databases-including AphasiaBank, DementiaBank, RHDBank, and TBIBank-open to commentary and analysis from the full community of researchers, instructors, students, and clinicians.


METHOD
CC allows a group leader to establish a commentary group and invite colleagues or students to join as members of the group. Members can then browse through the transcript database using the TalkBank Browser. When they wish to insert a comment, they click on the utterance line number or drag the cursor across a range of utterances and a window opens to receive the comment. The comment can include open text along with codes selected from a predefined set of codes created by that commentary group.


RESULTS
CC was released for public use in August 2022. It is being used currently in five research projects and eight classes. An important feature of CC is its ability to evaluate the reliability of coding systems and to sharpen analytic categories. By familiarizing instructors and researchers with the capabilities of CC, we expect to see an increasing usage of CC for a variety of clinical and research applications.


CONCLUSIONS
CC can contribute to a better understanding of connected speech features in aphasia, dementia, right hemisphere disorder, and traumatic brain injury. CC represents an extreme innovation not only for the study of adult neurogenic communication disorders but also for the study of spoken language generally.",American Journal of Speech-Language Pathology,2023,17,0,0,True,,['Medicine'],"{'pages': '\n          1-9\n        ', 'name': 'American journal of speech-language pathology'}","[{'authorId': '2414040', 'name': 'B. MacWhinney'}, {'authorId': '50098578', 'name': 'Davida Fromm'}]","CC can contribute to a better understanding of connected speech features in aphasia, dementia, right hemisphere disorder, and traumatic brain injury and is being used currently in five research projects and eight classes."
Brian MacWhinney,2414040,B. MacWhinney,https://www.semanticscholar.org/author/2414040,75,[],432,27192,cf152ac1b3c9daea5b48f858acc13193a83df185,"{'DOI': '10.1002/alz.073058', 'CorpusId': 266541840}",https://www.semanticscholar.org/paper/cf152ac1b3c9daea5b48f858acc13193a83df185,Establishing the DementiaBank Delaware Corpus: An Online Multimedia Database for the Study of Language and Cognition in Dementia,"To better understand the progressive decline of language abilities in aging and dementia, we expanded the quality and quantity of resources in DementiaBank — an open‐access database of multimedia spoken language interactions for the study of speech and language abilities across the progression of dementia. This work builds from the success of the TalkBank Project with regard to data sharing, transcription, analysis, and web delivery. Specifically, this work collected connected speech and language data to develop the new “Delaware corpus” and to share resources for future analyses.",Alzheimer's &amp; Dementia,2023,0,0,0,True,"{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/alz.073058', 'status': None}",,"{'volume': '19', 'name': ""Alzheimer's & Dementia""}","[{'authorId': '50857375', 'name': 'Alyssa M. Lanzi'}, {'authorId': '2276357670', 'name': 'Anna K Saylor'}, {'authorId': '50098578', 'name': 'Davida Fromm'}, {'authorId': '2414040', 'name': 'B. MacWhinney'}, {'authorId': '2276404308', 'name': 'Matthew L Cohen'}]",This work collected connected speech and language data to develop the new “Delaware corpus” and to share resources for future analyses to better understand the progressive decline of language abilities in aging and dementia.
Brian MacWhinney,2414040,B. MacWhinney,https://www.semanticscholar.org/author/2414040,75,[],432,27192,d898963243ad4b177b799f197a7732395e165cf6,"{'ArXiv': '2308.07933', 'DBLP': 'journals/corr/abs-2308-07933', 'DOI': '10.48550/arXiv.2308.07933', 'CorpusId': 260926499}",https://www.semanticscholar.org/paper/d898963243ad4b177b799f197a7732395e165cf6,Evaluating Picture Description Speech for Dementia Detection using Image-text Alignment,"Using picture description speech for dementia detection has been studied for 30 years. Despite the long history, previous models focus on identifying the differences in speech patterns between healthy subjects and patients with dementia but do not utilize the picture information directly. In this paper, we propose the first dementia detection models that take both the picture and the description texts as inputs and incorporate knowledge from large pre-trained image-text alignment models. We observe the difference between dementia and healthy samples in terms of the text's relevance to the picture and the focused area of the picture. We thus consider such a difference could be used to enhance dementia detection accuracy. Specifically, we use the text's relevance to the picture to rank and filter the sentences of the samples. We also identified focused areas of the picture as topics and categorized the sentences according to the focused areas. We propose three advanced models that pre-processed the samples based on their relevance to the picture, sub-image, and focused areas. The evaluation results show that our advanced models, with knowledge of the picture and large image-text alignment models, achieve state-of-the-art performance with the best detection accuracy at 83.44%, which is higher than the text-only baseline model at 79.91%. Lastly, we visualize the sample and picture results to explain the advantages of our models.",arXiv.org,2023,46,0,0,True,"{'url': 'https://arxiv.org/pdf/2308.07933', 'status': None}",['Computer Science'],"{'volume': 'abs/2308.07933', 'name': 'ArXiv'}","[{'authorId': '50877340', 'name': 'Youxiang Zhu'}, {'authorId': '2218105515', 'name': 'Nan Lin'}, {'authorId': '2153398177', 'name': 'Xiaohui Liang'}, {'authorId': '4989016', 'name': 'J. Batsis'}, {'authorId': '5989787', 'name': 'R. Roth'}, {'authorId': '2414040', 'name': 'B. MacWhinney'}]",The first dementia detection models that take both the picture and the description texts as inputs and incorporate knowledge from large pre-trained image-text alignment models are proposed and achieve state-of-the-art performance.
Brian MacWhinney,2414040,B. MacWhinney,https://www.semanticscholar.org/author/2414040,75,[],432,27192,f1ebdd8c99aa33284e3604c28b72efa9dc46047c,"{'DBLP': 'conf/icassp/LuzHFLKM23', 'ArXiv': '2301.05562', 'DOI': '10.1109/ICASSP49357.2023.10433923', 'CorpusId': 255825778}",https://www.semanticscholar.org/paper/f1ebdd8c99aa33284e3604c28b72efa9dc46047c,Multilingual Alzheimer’s Dementia Recognition through Spontaneous Speech: A Signal Processing Grand Challenge,"This Signal Processing Grand Challenge (SPGC) targets a difficult automatic prediction problem of societal and medical relevance, namely, the detection of Alzheimer’s Dementia (AD). Participants were invited to employ signal processing and machine learning methods to create predictive models based on spontaneous speech data. The Challenge has been designed to assess the extent to which predictive models built based on speech in one language (English) generalise to another language (Greek). To the best of our knowledge no work has investigated acoustic features of the speech signal in multilingual AD detection. Our baseline system used conventional machine learning algorithms with Active Data Representation of acoustic features, achieving accuracy of 73.91% on AD detection, and 4.95 root mean squared error on cognitive score prediction.","IEEE International Conference on Acoustics, Speech, and Signal Processing",2023,6,9,2,True,"{'url': 'https://arxiv.org/pdf/2301.05562', 'status': None}","['Computer Science', 'Engineering']","{'pages': '1-2', 'name': 'ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)'}","[{'authorId': '2098485248', 'name': 'S. Luz'}, {'authorId': '2203130', 'name': 'F. Haider'}, {'authorId': '50098578', 'name': 'Davida Fromm'}, {'authorId': '1883451', 'name': 'Ioulietta Lazarou'}, {'authorId': '1715604', 'name': 'Y. Kompatsiaris'}, {'authorId': '2414040', 'name': 'B. MacWhinney'}]","This Signal Processing Grand Challenge (SPGC) targets a difficult automatic prediction problem of societal and medical relevance, namely, the detection of Alzheimer’s Dementia, and aims to assess the extent to which predictive models built based on speech in one language generalise to another language."
Brian MacWhinney,2414040,B. MacWhinney,https://www.semanticscholar.org/author/2414040,75,[],432,27192,f7254ae607056ba5522c10dbcf21b394967b6d42,"{'PubMedCentral': '10171844', 'DOI': '10.1044/2022_AJSLP-22-00281', 'CorpusId': 256899351, 'PubMed': '36791255'}",https://www.semanticscholar.org/paper/f7254ae607056ba5522c10dbcf21b394967b6d42,"DementiaBank: Theoretical Rationale, Protocol, and Illustrative Analyses","Purpose: Dementia from Alzheimer's disease (AD) is characterized primarily by a significant decline in memory abilities; however, language abilities are also commonly affected and may precede the decline of other cognitive abilities. To study the progression of language, there is a need for open-access databases that can be used to build algorithms to produce translational models sensitive enough to detect early declines in language abilities. DementiaBank is an open-access repository of transcribed video/audio data from communicative interactions from people with dementia, mild cognitive impairment (MCI), and controls. The aims of this tutorial are to (a) describe the newly established standardized DementiaBank discourse protocol, (b) describe the Delaware corpus data, and (c) provide examples of automated linguistic analyses that can be conducted with the Delaware corpus data and describe additional DementiaBank resources. Method: The DementiaBank discourse protocol elicits four types of discourse: picture description, story narrative, procedural, and personal narrative. The Delaware corpus currently includes data from 20 neurotypical adults and 33 adults with MCI from possible AD who completed the DementiaBank discourse protocol and a cognitive–linguistic battery. Language samples were video- and audio-recorded, transcribed, coded, and uploaded to DementiaBank. The protocol materials and transcription programs can be accessed for free via the DementiaBank website. Results: Illustrative analyses show the potential of the Delaware corpus data to help understand discourse metrics at the individual and group levels. In addition, they highlight analyses that could be used across TalkBank's other clinical banks (e.g., AphasiaBank). Information is also included on manual and automatic speech recognition transcription methods. Conclusions: DementiaBank is a shared online database that can facilitate research efforts to address the gaps in knowledge about language changes associated with MCI and dementia from AD. Identifying early language markers could lead to improved assessment and treatment approaches for adults at risk for dementia.",American Journal of Speech-Language Pathology,2023,82,8,0,True,,['Medicine'],"{'volume': '32', 'pages': '426 - 438', 'name': 'American Journal of Speech-Language Pathology'}","[{'authorId': '50857375', 'name': 'Alyssa M. Lanzi'}, {'authorId': '122005633', 'name': 'Anna K Saylor'}, {'authorId': '50098578', 'name': 'Davida Fromm'}, {'authorId': '2110153362', 'name': 'Houjun Liu'}, {'authorId': '2414040', 'name': 'B. MacWhinney'}, {'authorId': '21792117', 'name': 'Matthew L. Cohen'}]",DementiaBank is a shared online database that can facilitate research efforts to address the gaps in knowledge about language changes associated with MCI and dementia from AD and is shown to have potential to help understand discourse metrics at the individual and group levels.
Bhiksha Raj,1681921,B. Raj,https://www.semanticscholar.org/author/1681921,54,[],404,14485,078f86c6a691806cc71bbef1e734f75690db0ffc,"{'DBLP': 'journals/corr/abs-2304-02135', 'ArXiv': '2304.02135', 'DOI': '10.1109/CVPR52729.2023.01914', 'CorpusId': 257952618}",https://www.semanticscholar.org/paper/078f86c6a691806cc71bbef1e734f75690db0ffc,FREDOM: Fairness Domain Adaptation Approach to Semantic Scene Understanding,"Although Domain Adaptation in Semantic Scene Segmentation has shown impressive improvement in recent years, the fairness concerns in the domain adaptation have yet to be well defined and addressed. In addition, fairness is one of the most critical aspects when deploying the segmentation models into human-related real-world applications, e.g., autonomous driving, as any unfair predictions could influence human safety. In this paper, we propose a novel Fairness Domain Adaptation (FREDOM) approach to semantic scene segmentation. In particular, from the proposed formulated fairness objective, a new adaptation framework will be introduced based on the fair treatment of class distributions. Moreover, to generally model the context of structural dependency, a new conditional structural constraint is introduced to impose the consistency of predicted segmentation. Thanks to the proposed Conditional Structure Network, the self-attention mechanism has sufficiently modeled the structural information of segmentation. Through the ablation studies, the proposed method has shown the performance improvement of the segmentation models and promoted fairness in the model predictions. The experimental results on the two standard benchmarks, i.e., SYNTHIA $\rightarrow$ Cityscapes and GTA5 $\rightarrow$ Cityscapes, have shown that our method achieved State-of-the-Art (SOTA) performance11The implementation of FREDOM is available at https://github.com/uark-cviu/FREDOM",Computer Vision and Pattern Recognition,2023,55,8,0,True,"{'url': 'https://arxiv.org/pdf/2304.02135', 'status': None}",['Computer Science'],"{'pages': '19988-19997', 'name': '2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)'}","[{'authorId': '35659935', 'name': 'Thanh-Dat Truong'}, {'authorId': '144556913', 'name': 'Ngan T. H. Le'}, {'authorId': '1681921', 'name': 'B. Raj'}, {'authorId': '145863239', 'name': 'J. Cothren'}, {'authorId': '1769788', 'name': 'Khoa Luu'}]","This paper proposes a novel Fairness Domain Adaptation (FREDOM) approach to semantic scene segmentation, where a new adaptation framework will be introduced based on the fair treatment of class distributions to generally model the context of structural dependency."
Bhiksha Raj,1681921,B. Raj,https://www.semanticscholar.org/author/1681921,54,[],404,14485,0a8d38686b18f28aae1222529e6b9e8a60cab1c2,"{'DBLP': 'journals/corr/abs-2306-09613', 'ArXiv': '2306.09613', 'DOI': '10.48550/arXiv.2306.09613', 'CorpusId': 259187821}",https://www.semanticscholar.org/paper/0a8d38686b18f28aae1222529e6b9e8a60cab1c2,UTOPIA: Unconstrained Tracking Objects without Preliminary Examination via Cross-Domain Adaptation,"Multiple Object Tracking (MOT) aims to find bounding boxes and identities of targeted objects in consecutive video frames. While fully-supervised MOT methods have achieved high accuracy on existing datasets, they cannot generalize well on a newly obtained dataset or a new unseen domain. In this work, we first address the MOT problem from the cross-domain point of view, imitating the process of new data acquisition in practice. Then, a new cross-domain MOT adaptation from existing datasets is proposed without any pre-defined human knowledge in understanding and modeling objects. It can also learn and update itself from the target data feedback. The intensive experiments are designed on four challenging settings, including MOTSynth to MOT17, MOT17 to MOT20, MOT17 to VisDrone, and MOT17 to DanceTrack. We then prove the adaptability of the proposed self-supervised learning strategy. The experiments also show superior performance on tracking metrics MOTA and IDF1, compared to fully supervised, unsupervised, and self-supervised state-of-the-art methods.",arXiv.org,2023,62,1,0,True,"{'url': 'http://arxiv.org/pdf/2306.09613', 'status': None}",['Computer Science'],"{'volume': 'abs/2306.09613', 'name': 'ArXiv'}","[{'authorId': '2468571', 'name': 'Pha Nguyen'}, {'authorId': '2687827', 'name': 'Kha Gia Quach'}, {'authorId': '1701970', 'name': 'J. Gauch'}, {'authorId': '1740261', 'name': 'S. Khan'}, {'authorId': '1681921', 'name': 'B. Raj'}, {'authorId': '1769788', 'name': 'Khoa Luu'}]","A new cross-domain MOT adaptation from existing datasets is proposed without any pre-defined human knowledge in understanding and modeling objects, and it can also learn and update itself from the target data feedback."
Bhiksha Raj,1681921,B. Raj,https://www.semanticscholar.org/author/1681921,54,[],404,14485,100da279ee981960884a12dfc5a0697c24ed315a,"{'DBLP': 'journals/corr/abs-2301-10921', 'ArXiv': '2301.10921', 'DOI': '10.48550/arXiv.2301.10921', 'CorpusId': 256274785}",https://www.semanticscholar.org/paper/100da279ee981960884a12dfc5a0697c24ed315a,SoftMatch: Addressing the Quantity-Quality Trade-off in Semi-supervised Learning,"The critical challenge of Semi-Supervised Learning (SSL) is how to effectively leverage the limited labeled data and massive unlabeled data to improve the model's generalization performance. In this paper, we first revisit the popular pseudo-labeling methods via a unified sample weighting formulation and demonstrate the inherent quantity-quality trade-off problem of pseudo-labeling with thresholding, which may prohibit learning. To this end, we propose SoftMatch to overcome the trade-off by maintaining both high quantity and high quality of pseudo-labels during training, effectively exploiting the unlabeled data. We derive a truncated Gaussian function to weight samples based on their confidence, which can be viewed as a soft version of the confidence threshold. We further enhance the utilization of weakly-learned classes by proposing a uniform alignment approach. In experiments, SoftMatch shows substantial improvements across a wide variety of benchmarks, including image, text, and imbalanced classification.",International Conference on Learning Representations,2023,54,31,2,True,"{'url': 'http://arxiv.org/pdf/2301.10921', 'status': None}",['Computer Science'],"{'volume': 'abs/2301.10921', 'name': 'ArXiv'}","[{'authorId': '2051536212', 'name': 'Hao Chen'}, {'authorId': '26151496', 'name': 'R. Tao'}, {'authorId': '144356331', 'name': 'Yue Fan'}, {'authorId': '2108024273', 'name': 'Yidong Wang'}, {'authorId': '1519290245', 'name': 'Jindong Wang'}, {'authorId': '48920094', 'name': 'B. Schiele'}, {'authorId': '1576441343', 'name': 'Xingxu Xie'}, {'authorId': '1681921', 'name': 'B. Raj'}, {'authorId': '1794486', 'name': 'M. Savvides'}]","This paper revisits the popular pseudo-labeling methods via a unified sample weighting formulation and demonstrates the inherent quantity-quality trade-off problem of pseudo-labels with thresholding, which may prohibit learning."
Bhiksha Raj,1681921,B. Raj,https://www.semanticscholar.org/author/1681921,54,[],404,14485,11c50900f50036fb3247be7c83849a8774a4ba60,"{'ArXiv': '2308.03956', 'DBLP': 'journals/corr/abs-2308-03956', 'DOI': '10.48550/arXiv.2308.03956', 'CorpusId': 260704305}",https://www.semanticscholar.org/paper/11c50900f50036fb3247be7c83849a8774a4ba60,Fixed Inter-Neuron Covariability Induces Adversarial Robustness,"The vulnerability to adversarial perturbations is a major flaw of Deep Neural Networks (DNNs) that raises question about their reliability when in real-world scenarios. On the other hand, human perception, which DNNs are supposed to emulate, is highly robust to such perturbations, indicating that there may be certain features of the human perception that make it robust but are not represented in the current class of DNNs. One such feature is that the activity of biological neurons is correlated and the structure of this correlation tends to be rather rigid over long spans of times, even if it hampers performance and learning. We hypothesize that integrating such constraints on the activations of a DNN would improve its adversarial robustness, and, to test this hypothesis, we have developed the Self-Consistent Activation (SCA) layer, which comprises of neurons whose activations are consistent with each other, as they conform to a fixed, but learned, covariability pattern. When evaluated on image and sound recognition tasks, the models with a SCA layer achieved high accuracy, and exhibited significantly greater robustness than multi-layer perceptron models to state-of-the-art Auto-PGD adversarial attacks \textit{without being trained on adversarially perturbed data",arXiv.org,2023,33,0,0,True,"{'url': 'https://arxiv.org/pdf/2308.03956', 'status': None}",['Computer Science'],"{'volume': 'abs/2308.03956', 'name': 'ArXiv'}","[{'authorId': '145897481', 'name': 'Muhammad A Shah'}, {'authorId': '1681921', 'name': 'B. Raj'}]","The SCA layer is developed, which comprises of neurons whose activations are consistent with each other, as they conform to a fixed, but learned, covariability pattern, and exhibited significantly greater robustness than multi-layer perceptron models to state-of-the-art Auto-PGD adversarial attacks."
Bhiksha Raj,1681921,B. Raj,https://www.semanticscholar.org/author/1681921,54,[],404,14485,22c9eb4868c5cabb26d132e0a160b9a093579f08,"{'DBLP': 'journals/aim/GodeBRY23', 'DOI': '10.1002/aaai.12104', 'CorpusId': 260728762}",https://www.semanticscholar.org/paper/22c9eb4868c5cabb26d132e0a160b9a093579f08,Understanding political polarization using language models: A dataset and method,"Our paper aims to analyze political polarization in US political system using language models, and thereby help candidates make an informed decision. The availability of this information will help voters understand their candidates' views on the economy, healthcare, education, and other social issues. Our main contributions are a dataset extracted from Wikipedia that spans the past 120 years and a language model‐based method that helps analyze how polarized a candidate is. Our data are divided into two parts, background information and political information about a candidate, since our hypothesis is that the political views of a candidate should be based on reason and be independent of factors such as birthplace, alma mater, and so forth. We further split this data into four phases chronologically, to help understand if and how the polarization amongst candidates changes. This data has been cleaned to remove biases. To understand the polarization, we begin by showing results from some classical language models in Word2Vec and Doc2Vec. And then use more powerful techniques like the Longformer, a transformer‐based encoder, to assimilate more information and find the nearest neighbors of each candidate based on their political view and their background. The code and data for the project will be available here: “https://github.com/samirangode/Understanding_Polarization”",The AI Magazine,2023,7,0,0,True,"{'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/aaai.12104', 'status': None}",['Computer Science'],"{'volume': '44', 'pages': '248-254', 'name': 'AI Mag.'}","[{'authorId': '2199184565', 'name': 'Samiran Gode'}, {'authorId': '2199182939', 'name': 'Supreeth Bare'}, {'authorId': '1681921', 'name': 'B. Raj'}, {'authorId': '1576015238', 'name': 'H. Yoo'}]",The main contributions are a dataset extracted from Wikipedia that spans the past 120 years and a language model‐based method that helps analyze how polarized a candidate is.
Bhiksha Raj,1681921,B. Raj,https://www.semanticscholar.org/author/1681921,54,[],404,14485,35a8802facb4441787017ac5c630a8fa0f2413bd,"{'PubMedCentral': '10339019', 'DOI': '10.1016/j.heliyon.2023.e17865', 'CorpusId': 259764473, 'PubMed': '37456023'}",https://www.semanticscholar.org/paper/35a8802facb4441787017ac5c630a8fa0f2413bd,"Prolonged school closure during the pandemic time in successive waves of COVID-19- vulnerability of children to sexual abuses – A case study in Tamil Nadu, India",,Heliyon,2023,43,0,0,True,"{'url': 'http://www.cell.com/article/S2405844023050739/pdf', 'status': None}",['Medicine'],"{'volume': '9', 'name': 'Heliyon'}","[{'authorId': '2142828053', 'name': 'Kandaswamy Paramasivan'}, {'authorId': '1681921', 'name': 'B. Raj'}, {'authorId': '2222824729', 'name': 'Nandan Sudarasanam'}, {'authorId': '2102113776', 'name': 'R. Subburaj'}]","Considering that the median delay in filing CSA complaints was above 30 days in the mild and post-intervention periods, the upsurge of cases in the more relaxed phases indicates increased occurrences of CSA during strict lockdowns."
Bhiksha Raj,1681921,B. Raj,https://www.semanticscholar.org/author/1681921,54,[],404,14485,3bd320ddb25886417ae90011b00f13f5d558097b,"{'ArXiv': '2307.08217', 'DBLP': 'journals/corr/abs-2307-08217', 'DOI': '10.48550/arXiv.2307.08217', 'CorpusId': 259936797}",https://www.semanticscholar.org/paper/3bd320ddb25886417ae90011b00f13f5d558097b,BASS: Block-wise Adaptation for Speech Summarization,"End-to-end speech summarization has been shown to improve performance over cascade baselines. However, such models are difficult to train on very large inputs (dozens of minutes or hours) owing to compute restrictions and are hence trained with truncated model inputs. Truncation leads to poorer models, and a solution to this problem rests in block-wise modeling, i.e., processing a portion of the input frames at a time. In this paper, we develop a method that allows one to train summarization models on very long sequences in an incremental manner. Speech summarization is realized as a streaming process, where hypothesis summaries are updated every block based on new acoustic information. We devise and test strategies to pass semantic context across the blocks. Experiments on the How2 dataset demonstrate that the proposed block-wise training method improves by 3 points absolute on ROUGE-L over a truncated input baseline.",Interspeech,2023,28,1,0,True,"{'url': 'https://arxiv.org/pdf/2307.08217', 'status': None}","['Computer Science', 'Engineering']","{'volume': 'abs/2307.08217', 'name': 'ArXiv'}","[{'authorId': '145521253', 'name': 'Roshan Sharma'}, {'authorId': '2163585699', 'name': 'Kenneth Zheng'}, {'authorId': '72401599', 'name': 'Siddhant Arora'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '153915824', 'name': 'Rita Singh'}, {'authorId': '1681921', 'name': 'B. Raj'}]",This paper develops a method that allows one to train summarization models on very long sequences in an incremental manner and devise and test strategies to pass semantic context across the blocks.
Bhiksha Raj,1681921,B. Raj,https://www.semanticscholar.org/author/1681921,54,[],404,14485,4e6a004e4f9a3b489004a2efb5b25b0bcd0f48b5,"{'DBLP': 'journals/corr/abs-2301-00891', 'ArXiv': '2301.00891', 'DOI': '10.48550/arXiv.2301.00891', 'CorpusId': 255393829}",https://www.semanticscholar.org/paper/4e6a004e4f9a3b489004a2efb5b25b0bcd0f48b5,Understanding Political Polarisation using Language Models: A dataset and method,"Our paper aims to analyze political polarization in US political system using Language Models, and thereby help candidates make an informed decision. The availability of this information will help voters understand their candidates views on the economy, healthcare, education and other social issues. Our main contributions are a dataset extracted from Wikipedia that spans the past 120 years and a Language model based method that helps analyze how polarized a candidate is. Our data is divided into 2 parts, background information and political information about a candidate, since our hypothesis is that the political views of a candidate should be based on reason and be independent of factors such as birthplace, alma mater, etc. We further split this data into 4 phases chronologically, to help understand if and how the polarization amongst candidates changes. This data has been cleaned to remove biases. To understand the polarization we begin by showing results from some classical language models in Word2Vec and Doc2Vec. And then use more powerful techniques like the Longformer, a transformer based encoder, to assimilate more information and find the nearest neighbors of each candidate based on their political view and their background.",arXiv.org,2023,20,0,0,True,"{'url': 'http://arxiv.org/pdf/2301.00891', 'status': None}",['Computer Science'],"{'volume': 'abs/2301.00891', 'name': 'ArXiv'}","[{'authorId': '2199184565', 'name': 'Samiran Gode'}, {'authorId': '2199182939', 'name': 'Supreeth Bare'}, {'authorId': '1681921', 'name': 'B. Raj'}, {'authorId': '1576015238', 'name': 'H. Yoo'}]",A dataset extracted from Wikipedia that spans the past 120 years and a Language model based method that helps analyze how polarized a candidate is are used to understand the polarization.
Bhiksha Raj,1681921,B. Raj,https://www.semanticscholar.org/author/1681921,54,[],404,14485,593a603354c09d151440ae044de1d80324a2ab01,"{'DBLP': 'conf/icassp/ShahTCZGR23', 'DOI': '10.1109/icassp49357.2023.10097025', 'CorpusId': 258540002}",https://www.semanticscholar.org/paper/593a603354c09d151440ae044de1d80324a2ab01,An Approach to Ontological Learning from Weak Labels,"Ontologies encompass a formal representation of knowledge through the definition of concepts or properties of a domain, and the relationships between those concepts. In this work, we seek to investigate whether using this ontological information will improve learning from weakly labeled data, which are easier to collect since it requires only the presence or absence of an event to be known. We use the AudioSet ontology and dataset, which contains audio clips weakly labeled with the ontology concepts and the ontology providing the ""Is A"" relations between the concepts. We first re-implemented the model proposed by [1] with modifications to fit the multi-label scenario and then expand on that idea by using a Graph Convolutional Network (GCN) to model the ontology information to learn the concepts. We find that the baseline Twin Neural Network (TNN) does not perform better by incorporating ontology information in the weak and multi-label scenario, but that the GCN does capture the ontology knowledge better for weak, multi-labeled data. We also investigate how different modules can tolerate noises introduced from weak labels and better incorporate ontology information. Our best TNN-GCN model achieves mAP=0.45 and AUC=0.87 for lower-level concepts and mAP=0.72 and AUC=0.86 for higher-level concepts, which is an improvement over the baseline TNN but about the same as our models that do not use ontology information.","IEEE International Conference on Acoustics, Speech, and Signal Processing",2023,8,0,0,True,,['Computer Science'],"{'pages': '1-5', 'name': 'ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)'}","[{'authorId': '31017418', 'name': 'Ankit Shah'}, {'authorId': '2157796077', 'name': 'Larry Tang'}, {'authorId': '2216451398', 'name': 'Po Hao Chou'}, {'authorId': '2158586492', 'name': 'Yilun Zheng'}, {'authorId': '2157426412', 'name': 'Ziqian Ge'}, {'authorId': '1681921', 'name': 'B. Raj'}]",This work re-implements the model proposed by [1] with modifications to fit the multi-label scenario and expands on that idea by using a Graph Convolutional Network (GCN) to model the ontology information to learn the concepts.
Bhiksha Raj,1681921,B. Raj,https://www.semanticscholar.org/author/1681921,54,[],404,14485,5a3307b2e64bbcaff1202e261b8a83f7d03418a8,"{'ArXiv': '2307.13948', 'DBLP': 'journals/corr/abs-2307-13948', 'DOI': '10.1145/3581783.3611779', 'CorpusId': 260165102}",https://www.semanticscholar.org/paper/5a3307b2e64bbcaff1202e261b8a83f7d03418a8,Rethinking Voice-Face Correlation: A Geometry View,"Previous works on voice-face matching and voice-guided face synthesis demonstrate strong correlations between voice and face, but mainly rely on coarse semantic cues such as gender, age, and emotion. In this paper, we aim to investigate the capability of reconstructing the 3D facial shape from voice from a geometry perspective without any semantic information. We propose a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable facial AMs from the voice and uses them to guide 3D face reconstruction. By leveraging AMs as a proxy to link the voice and face geometry, we can eliminate the influence of unpredictable AMs and make the face geometry tractable. Our approach is evaluated on our proposed dataset with ground-truth 3D face scans and corresponding voice recordings, and we find significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium. Our work offers a new perspective on voice-face correlation and can serve as a good empirical study for anthropometry science.",ACM Multimedia,2023,56,1,0,True,"{'url': 'https://arxiv.org/pdf/2307.13948', 'status': None}","['Computer Science', 'Engineering']",{'name': 'Proceedings of the 31st ACM International Conference on Multimedia'},"[{'authorId': '2108280244', 'name': 'Xiang Li'}, {'authorId': '145357606', 'name': 'Yandong Wen'}, {'authorId': '72966973', 'name': 'Muqiao Yang'}, {'authorId': '2110107884', 'name': 'Jinglu Wang'}, {'authorId': '153915824', 'name': 'Rita Singh'}, {'authorId': '1681921', 'name': 'B. Raj'}]","This work proposes a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable facial AMs from the voice and uses them to guide 3D face reconstruction and finds significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium."
Bhiksha Raj,1681921,B. Raj,https://www.semanticscholar.org/author/1681921,54,[],404,14485,611f9ee6eef0936462cd78f371798d0699951c59,"{'ArXiv': '2302.08095', 'DBLP': 'conf/icassp/YangKBZHKWR23', 'DOI': '10.1109/ICASSP49357.2023.10096807', 'CorpusId': 256900649}",https://www.semanticscholar.org/paper/611f9ee6eef0936462cd78f371798d0699951c59,Paaploss: A Phonetic-Aligned Acoustic Parameter Loss for Speech Enhancement,"Despite rapid advancement in recent years, current speech enhancement models often produce speech that differs in perceptual quality from real clean speech. We propose a learning objective that formalizes differences in perceptual quality, by using domain knowledge of acoustic-phonetics. We identify temporal acoustic parameters – such as spectral tilt, spectral flux, shimmer, etc. – that are non-differentiable, and we develop a neural network estimator that can accurately predict their time-series values across an utterance. We also model phoneme-specific weights for each feature, as the acoustic parameters are known to show different behavior in different phonemes. We can add this criterion as an auxiliary loss to any model that produces speech, to optimize speech outputs to match the values of clean speech in these features. Experimentally we show that it improves speech enhancement workflows in both time-domain and time-frequency domain, as measured by standard evaluation metrics. We also provide an analysis of phoneme-dependent improvement on acoustic parameters, demonstrating the additional interpretability that our method provides. This analysis can suggest which features are currently the bottleneck for improvement.","IEEE International Conference on Acoustics, Speech, and Signal Processing",2023,38,3,0,True,"{'url': 'https://arxiv.org/pdf/2302.08095', 'status': None}","['Computer Science', 'Engineering']","{'pages': '1-5', 'name': 'ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)'}","[{'authorId': '72966973', 'name': 'Muqiao Yang'}, {'authorId': '2174668832', 'name': 'Joseph Konan'}, {'authorId': '2174668503', 'name': 'David Bick'}, {'authorId': '2111187803', 'name': 'YUNYANG ZENG'}, {'authorId': '2206298901', 'name': 'Shuo Han'}, {'authorId': '47311290', 'name': 'Anurag Kumar'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '1681921', 'name': 'B. Raj'}]","A learning objective is proposed that formalizes differences in perceptual quality, by using domain knowledge of acoustic-phonetics, and a neural network estimator is developed that can accurately predict their time-series values across an utterance."
Bhiksha Raj,1681921,B. Raj,https://www.semanticscholar.org/author/1681921,54,[],404,14485,7333be530df311b3148e9857ce9f481975cf0a9b,"{'ArXiv': '2303.09048', 'DBLP': 'journals/corr/abs-2303-09048', 'DOI': '10.48550/arXiv.2303.09048', 'CorpusId': 257557465}",https://www.semanticscholar.org/paper/7333be530df311b3148e9857ce9f481975cf0a9b,"Improving Perceptual Quality, Intelligibility, and Acoustics on VoIP Platforms","In this paper, we present a method for fine-tuning models trained on the Deep Noise Suppression (DNS) 2020 Challenge to improve their performance on Voice over Internet Protocol (VoIP) applications. Our approach involves adapting the DNS 2020 models to the specific acoustic characteristics of VoIP communications, which includes distortion and artifacts caused by compression, transmission, and platform-specific processing. To this end, we propose a multi-task learning framework for VoIP-DNS that jointly optimizes noise suppression and VoIP-specific acoustics for speech enhancement. We evaluate our approach on a diverse VoIP scenarios and show that it outperforms both industry performance and state-of-the-art methods for speech enhancement on VoIP applications. Our results demonstrate the potential of models trained on DNS-2020 to be improved and tailored to different VoIP platforms using VoIP-DNS, whose findings have important applications in areas such as speech recognition, voice assistants, and telecommunication.",arXiv.org,2023,11,2,0,True,"{'url': 'http://arxiv.org/pdf/2303.09048', 'status': None}","['Computer Science', 'Engineering']","{'volume': 'abs/2303.09048', 'name': 'ArXiv'}","[{'authorId': '2174668832', 'name': 'Joseph Konan'}, {'authorId': '1649727619', 'name': 'Ojas Bhargave'}, {'authorId': '2202224349', 'name': 'Shikhar Agnihotri'}, {'authorId': '2110019379', 'name': 'Hojeong Lee'}, {'authorId': '31017418', 'name': 'Ankit Shah'}, {'authorId': '2206298901', 'name': 'Shuo Han'}, {'authorId': '2111187803', 'name': 'YUNYANG ZENG'}, {'authorId': '2202226132', 'name': 'Amanda Shu'}, {'authorId': '2143857486', 'name': 'Haohui Liu'}, {'authorId': '8776560', 'name': 'Xuankai Chang'}, {'authorId': '1500657253', 'name': 'Hamza Khalid'}, {'authorId': '2031482648', 'name': 'Minseon Gwak'}, {'authorId': '2204265592', 'name': 'Kawon Lee'}, {'authorId': '2145949834', 'name': 'Minjeong Kim'}, {'authorId': '1681921', 'name': 'B. Raj'}]",A multi-task learning framework forVoIP-DNS that jointly optimizes noise suppression and VoIP-specific acoustics for speech enhancement and outperforms both industry performance and state-of-the-art methods for speech Enhancement on VoIP applications is proposed.
Bhiksha Raj,1681921,B. Raj,https://www.semanticscholar.org/author/1681921,54,[],404,14485,740488982dee323d559f2dae70b1f4b3aa5f7171,"{'ArXiv': '2303.03591', 'DBLP': 'journals/corr/abs-2303-03591', 'DOI': '10.48550/arXiv.2303.03591', 'CorpusId': 257378346}",https://www.semanticscholar.org/paper/740488982dee323d559f2dae70b1f4b3aa5f7171,Approach to Learning Generalized Audio Representation Through Batch Embedding Covariance Regularization and Constant-Q Transforms,"General-purpose embedding is highly desirable for few-shot even zero-shot learning in many application scenarios, including audio tasks. In order to understand representations better, we conducted a thorough error analysis and visualization of HEAR 2021 submission results. Inspired by the analysis, this work experiments with different front-end audio preprocessing methods, including Constant-Q Transform (CQT) and Short-time Fourier transform (STFT), and proposes a Batch Embedding Covariance Regularization (BECR) term to uncover a more holistic simulation of the frequency information received by the human auditory system. We tested the models on the suite of HEAR 2021 tasks, which encompass a broad category of tasks. Preliminary results show (1) the proposed BECR can incur a more dispersed embedding on the test set, (2) BECR improves the PaSST model without extra computation complexity, and (3) STFT preprocessing outperforms CQT in all tasks we tested. Github:https://github.com/ankitshah009/general_audio_embedding_hear_2021",arXiv.org,2023,12,0,0,True,"{'url': 'http://arxiv.org/pdf/2303.03591', 'status': None}","['Computer Science', 'Engineering']","{'volume': 'abs/2303.03591', 'name': 'ArXiv'}","[{'authorId': '31017418', 'name': 'Ankit Shah'}, {'authorId': '2108757768', 'name': 'Shuyi Chen'}, {'authorId': '2210856438', 'name': 'Kejun Zhou'}, {'authorId': '1681412', 'name': 'Yue Chen'}, {'authorId': '1681921', 'name': 'B. Raj'}]","Experiments with different front-end audio preprocessing methods are experiments, and a Batch Embedding Covariance Regularization (BECR) term is proposed to uncover a more holistic simulation of the frequency information received by the human auditory system."
Bhiksha Raj,1681921,B. Raj,https://www.semanticscholar.org/author/1681921,54,[],404,14485,74664618ad3b44eb191ba96fdff5b93f27a29ced,"{'ArXiv': '2308.00854', 'DBLP': 'journals/corr/abs-2308-00854', 'DOI': '10.48550/arXiv.2308.00854', 'CorpusId': 260379047}",https://www.semanticscholar.org/paper/74664618ad3b44eb191ba96fdff5b93f27a29ced,Training on Foveated Images Improves Robustness to Adversarial Attacks,"Deep neural networks (DNNs) have been shown to be vulnerable to adversarial attacks -- subtle, perceptually indistinguishable perturbations of inputs that change the response of the model. In the context of vision, we hypothesize that an important contributor to the robustness of human visual perception is constant exposure to low-fidelity visual stimuli in our peripheral vision. To investigate this hypothesis, we develop \RBlur, an image transform that simulates the loss in fidelity of peripheral vision by blurring the image and reducing its color saturation based on the distance from a given fixation point. We show that compared to DNNs trained on the original images, DNNs trained on images transformed by \RBlur are substantially more robust to adversarial attacks, as well as other, non-adversarial, corruptions, achieving up to 25\% higher accuracy on perturbed data.",arXiv.org,2023,52,0,0,True,"{'url': 'https://arxiv.org/pdf/2308.00854', 'status': None}",['Computer Science'],"{'volume': 'abs/2308.00854', 'name': 'ArXiv'}","[{'authorId': '145897481', 'name': 'Muhammad A Shah'}, {'authorId': '1681921', 'name': 'B. Raj'}]","DNNs trained on images transformed by \RBlur are substantially more robust to adversarial attacks, as well as other, non-adversarial, corruptions, achieving up to 25\% higher accuracy on perturbed data."
Bhiksha Raj,1681921,B. Raj,https://www.semanticscholar.org/author/1681921,54,[],404,14485,8665c864d71df1e918d2010778fc06712f4e5550,"{'ArXiv': '2305.12715', 'DBLP': 'journals/corr/abs-2305-12715', 'DOI': '10.48550/arXiv.2305.12715', 'CorpusId': 258832327}",https://www.semanticscholar.org/paper/8665c864d71df1e918d2010778fc06712f4e5550,Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations,"Learning with reduced labeling standards, such as noisy label, partial label, and multiple label candidates, which we generically refer to as \textit{imprecise} labels, is a commonplace challenge in machine learning tasks. Previous methods tend to propose specific designs for every emerging imprecise label configuration, which is usually unsustainable when multiple configurations of imprecision coexist. In this paper, we introduce imprecise label learning (ILL), a framework for the unification of learning with various imprecise label configurations. ILL leverages expectation-maximization (EM) for modeling the imprecise label information, treating the precise labels as latent variables.Instead of approximating the correct labels for training, it considers the entire distribution of all possible labeling entailed by the imprecise information. We demonstrate that ILL can seamlessly adapt to partial label learning, semi-supervised learning, noisy label learning, and, more importantly, a mixture of these settings. Notably, ILL surpasses the existing specified techniques for handling imprecise labels, marking the first unified framework with robust and effective performance across various challenging settings. We hope our work will inspire further research on this topic, unleashing the full potential of ILL in wider scenarios where precise labels are expensive and complicated to obtain.",arXiv.org,2023,136,3,0,True,"{'url': 'https://arxiv.org/pdf/2305.12715', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.12715', 'name': 'ArXiv'}","[{'authorId': '2051536212', 'name': 'Hao Chen'}, {'authorId': '47287745', 'name': 'Ankit Shah'}, {'authorId': '1519290245', 'name': 'Jindong Wang'}, {'authorId': '26151496', 'name': 'R. Tao'}, {'authorId': '2108024273', 'name': 'Yidong Wang'}, {'authorId': '1576441343', 'name': 'Xingxu Xie'}, {'authorId': '67154907', 'name': 'Masashi Sugiyama'}, {'authorId': '153915824', 'name': 'Rita Singh'}, {'authorId': '1681921', 'name': 'B. Raj'}]","Imprecise label learning (ILL) is introduced, a framework for the unification of learning with various imprecise label configurations, marking the first unified framework with robust and effective performance across various challenging settings."
Bhiksha Raj,1681921,B. Raj,https://www.semanticscholar.org/author/1681921,54,[],404,14485,a6e3a10a6286967413e3406374bbeea533640030,"{'ArXiv': '2307.13953', 'DBLP': 'journals/corr/abs-2307-13953', 'DOI': '10.48550/arXiv.2307.13953', 'CorpusId': 260164956}",https://www.semanticscholar.org/paper/a6e3a10a6286967413e3406374bbeea533640030,The Hidden Dance of Phonemes and Visage: Unveiling the Enigmatic Link between Phonemes and Facial Features,"This work unveils the enigmatic link between phonemes and facial features. Traditional studies on voice-face correlations typically involve using a long period of voice input, including generating face images from voices and reconstructing 3D face meshes from voices. However, in situations like voice-based crimes, the available voice evidence may be short and limited. Additionally, from a physiological perspective, each segment of speech -- phoneme -- corresponds to different types of airflow and movements in the face. Therefore, it is advantageous to discover the hidden link between phonemes and face attributes. In this paper, we propose an analysis pipeline to help us explore the voice-face relationship in a fine-grained manner, i.e., phonemes v.s. facial anthropometric measurements (AM). We build an estimator for each phoneme-AM pair and evaluate the correlation through hypothesis testing. Our results indicate that AMs are more predictable from vowels compared to consonants, particularly with plosives. Additionally, we observe that if a specific AM exhibits more movement during phoneme pronunciation, it is more predictable. Our findings support those in physiology regarding correlation and lay the groundwork for future research on speech-face multimodal learning.",Interspeech,2023,29,2,0,True,"{'url': 'https://arxiv.org/pdf/2307.13953', 'status': None}","['Computer Science', 'Engineering']","{'volume': 'abs/2307.13953', 'name': 'ArXiv'}","[{'authorId': '2125181846', 'name': 'Liao Qu'}, {'authorId': '1818224862', 'name': 'X. Zou'}, {'authorId': '2108280244', 'name': 'Xiang Li'}, {'authorId': '145357606', 'name': 'Yandong Wen'}, {'authorId': '153915824', 'name': 'Rita Singh'}, {'authorId': '1681921', 'name': 'B. Raj'}]","This work proposes an analysis pipeline to help explore the voice-face relationship in a fine-grained manner, i.s. phonemes v. facial anthropometric measurements (AM), and indicates that AMs are more predictable from vowels compared to consonants, particularly with plosives."
Bhiksha Raj,1681921,B. Raj,https://www.semanticscholar.org/author/1681921,54,[],404,14485,ac856b6b7b3f32fb34320b7170526d3ab15ba5f3,"{'DBLP': 'journals/corr/abs-2305-15700', 'ArXiv': '2305.15700', 'DOI': '10.48550/arXiv.2305.15700', 'CorpusId': 258887971}",https://www.semanticscholar.org/paper/ac856b6b7b3f32fb34320b7170526d3ab15ba5f3,Fairness Continual Learning Approach to Semantic Scene Understanding in Open-World Environments,"Continual semantic segmentation aims to learn new classes while maintaining the information from the previous classes. Although prior studies have shown impressive progress in recent years, the fairness concern in the continual semantic segmentation needs to be better addressed. Meanwhile, fairness is one of the most vital factors in deploying the deep learning model, especially in human-related or safety applications. In this paper, we present a novel Fairness Continual Learning approach to the semantic segmentation problem. In particular, under the fairness objective, a new fairness continual learning framework is proposed based on class distributions. Then, a novel Prototypical Contrastive Clustering loss is proposed to address the significant challenges in continual learning, i.e., catastrophic forgetting and background shift. Our proposed loss has also been proven as a novel, generalized learning paradigm of knowledge distillation commonly used in continual learning. Moreover, the proposed Conditional Structural Consistency loss further regularized the structural constraint of the predicted segmentation. Our proposed approach has achieved State-of-the-Art performance on three standard scene understanding benchmarks, i.e., ADE20K, Cityscapes, and Pascal VOC, and promoted the fairness of the segmentation model.",arXiv.org,2023,52,2,0,True,"{'url': 'https://arxiv.org/pdf/2305.15700', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.15700', 'name': 'ArXiv'}","[{'authorId': '35659935', 'name': 'Thanh-Dat Truong'}, {'authorId': None, 'name': 'Hoang-Quan Nguyen'}, {'authorId': '1681921', 'name': 'B. Raj'}, {'authorId': '1769788', 'name': 'Khoa Luu'}]","A novel Fairness Continual Learning approach to the semantic segmentation problem is presented, in particular, a new fairness continual learning framework is proposed based on class distributions and a novel Prototypical Contrastive Clustering loss is proposed to address the significant challenges in continual learning."
Bhiksha Raj,1681921,B. Raj,https://www.semanticscholar.org/author/1681921,54,[],404,14485,dc157eba8bdb4cfe6ee65566d8295939ac5b4b37,"{'ArXiv': '2305.19406', 'DBLP': 'journals/corr/abs-2305-19406', 'DOI': '10.48550/arXiv.2305.19406', 'CorpusId': 258987438}",https://www.semanticscholar.org/paper/dc157eba8bdb4cfe6ee65566d8295939ac5b4b37,PaintSeg: Training-free Segmentation via Painting,"The paper introduces PaintSeg, a new unsupervised method for segmenting objects without any training. We propose an adversarial masked contrastive painting (AMCP) process, which creates a contrast between the original image and a painted image in which a masked area is painted using off-the-shelf generative models. During the painting process, inpainting and outpainting are alternated, with the former masking the foreground and filling in the background, and the latter masking the background while recovering the missing part of the foreground object. Inpainting and outpainting, also referred to as I-step and O-step, allow our method to gradually advance the target segmentation mask toward the ground truth without supervision or training. PaintSeg can be configured to work with a variety of prompts, e.g. coarse masks, boxes, scribbles, and points. Our experimental results demonstrate that PaintSeg outperforms existing approaches in coarse mask-prompt, box-prompt, and point-prompt segmentation tasks, providing a training-free solution suitable for unsupervised segmentation.",arXiv.org,2023,70,2,1,True,"{'url': 'http://arxiv.org/pdf/2305.19406', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.19406', 'name': 'ArXiv'}","[{'authorId': '2108280244', 'name': 'Xiang Li'}, {'authorId': '1955556', 'name': 'Chung-Ching Lin'}, {'authorId': '2109306087', 'name': 'Yinpeng Chen'}, {'authorId': '2145253136', 'name': 'Zicheng Liu'}, {'authorId': '2110107884', 'name': 'Jinglu Wang'}, {'authorId': '1681921', 'name': 'B. Raj'}]","An adversarial masked contrastive painting process, which creates a contrast between the original image and a painted image in which a masked area is painted using off-the-shelf generative models, providing a training-free solution suitable for unsupervised segmentation."
Bhiksha Raj,1681921,B. Raj,https://www.semanticscholar.org/author/1681921,54,[],404,14485,e146e5221c124d93f69516c5ae7e1b7b1822848e,"{'DBLP': 'journals/corr/abs-2302-08088', 'ArXiv': '2302.08088', 'DOI': '10.1109/ICASSP49357.2023.10094773', 'CorpusId': 256900782}",https://www.semanticscholar.org/paper/e146e5221c124d93f69516c5ae7e1b7b1822848e,TAPLoss: A Temporal Acoustic Parameter Loss for Speech Enhancement,"Speech enhancement models have greatly progressed in recent years, but still show limits in perceptual quality of their speech outputs. We propose an objective for perceptual quality based on temporal acoustic parameters. These are fundamental speech features that play an essential role in various applications, including speaker recognition and paralinguistic analysis. We provide a differentiable estimator for four categories of low-level acoustic descriptors involving: frequency-related parameters, energy or amplitude-related parameters, spectral balance parameters, and temporal features. Un-like prior work that looks at aggregated acoustic parameters or a few categories of acoustic parameters, our temporal acoustic parameter (TAP) loss enables auxiliary optimization and improvement of many fine-grained speech characteristics in enhancement workflows. We show that adding TAPLoss as an auxiliary objective in speech enhancement produces speech with improved perceptual quality and intelligibility. We use data from the Deep Noise Suppression 2020 Challenge to demonstrate that both time-domain models and time-frequency domain models can benefit from our method.","IEEE International Conference on Acoustics, Speech, and Signal Processing",2023,35,7,0,True,"{'url': 'https://arxiv.org/pdf/2302.08088', 'status': None}","['Computer Science', 'Engineering']","{'pages': '1-5', 'name': 'ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)'}","[{'authorId': '2111187803', 'name': 'YUNYANG ZENG'}, {'authorId': '2174668832', 'name': 'Joseph Konan'}, {'authorId': '2206298901', 'name': 'Shuo Han'}, {'authorId': '2174668503', 'name': 'David Bick'}, {'authorId': '72966973', 'name': 'Muqiao Yang'}, {'authorId': '47311290', 'name': 'Anurag Kumar'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '1681921', 'name': 'B. Raj'}]",This work shows that adding TAPLoss as an auxiliary objective in speech enhancement produces speech with improved perceptual quality and intelligibility and uses data from the Deep Noise Suppression 2020 Challenge to demonstrate that both time-domain models and time-frequency domain models can benefit from the method.
Bhiksha Raj,1681921,B. Raj,https://www.semanticscholar.org/author/1681921,54,[],404,14485,feecd2cfb7871a818ba514e8b4b3f9da482f17bc,"{'DBLP': 'journals/corr/abs-2302-09719', 'ArXiv': '2302.09719', 'DOI': '10.48550/arXiv.2302.09719', 'CorpusId': 257039066}",https://www.semanticscholar.org/paper/feecd2cfb7871a818ba514e8b4b3f9da482f17bc,Synergy between human and machine approaches to sound/scene recognition and processing: An overview of ICASSP special session,"Machine Listening, as usually formalized, attempts to perform a task that is, from our perspective, fundamentally human-performable, and performed by humans. Current automated models of Machine Listening vary from purely data-driven approaches to approaches imitating human systems. In recent years, the most promising approaches have been hybrid in that they have used data-driven approaches informed by models of the perceptual, cognitive, and semantic processes of the human system. Not only does the guidance provided by models of human perception and domain knowledge enable better, and more generalizable Machine Listening, in the converse, the lessons learned from these models may be used to verify or improve our models of human perception themselves. This paper summarizes advances in the development of such hybrid approaches, ranging from Machine Listening models that are informed by models of peripheral (human) auditory processes, to those that employ or derive semantic information encoded in relations between sounds. The research described herein was presented in a special session on""Synergy between human and machine approaches to sound/scene recognition and processing""at the 2023 ICASSP meeting.",arXiv.org,2023,15,8,0,True,"{'url': 'http://arxiv.org/pdf/2302.09719', 'status': None}","['Computer Science', 'Engineering']","{'volume': 'abs/2302.09719', 'name': 'ArXiv'}","[{'authorId': '38655601', 'name': 'L. Heller'}, {'authorId': '2532460', 'name': 'Benjamin Elizalde'}, {'authorId': '1681921', 'name': 'B. Raj'}, {'authorId': '67345939', 'name': 'Soham Deshmukh'}]","Advances in the development of hybrid approaches to Machine Listening models that are informed by models of peripheral (human) auditory processes, to those that employ or derive semantic information encoded in relations between sounds are summarized."
Carolyn Rose,35959897,C. Rosé,https://www.semanticscholar.org/author/35959897,54,[],441,11882,06dc7b3d8cbc40fb4e39b42de1bc664deaacca74,"{'DOI': '10.1080/17439884.2023.2189735', 'CorpusId': 257522345}",https://www.semanticscholar.org/paper/06dc7b3d8cbc40fb4e39b42de1bc664deaacca74,High school students’ data modeling practices and processes: from modeling unstructured data to evaluating automated decisions,"ABSTRACT It’s critical to foster artificial intelligence (AI) literacy for high school students, the first generation to grow up surrounded by AI, to understand working mechanism of data-driven AI technologies and critically evaluate automated decisions from predictive models. While efforts have been made to engage youth in understanding AI through developing machine learning models, few provided in-depth insights into the nuanced learning processes. In this study, we examined high school students’ data modeling practices and processes. Twenty-eight students developed machine learning models with text data for classifying negative and positive reviews of ice cream stores. We identified nine data modeling practices that describe students’ processes of model exploration, development, and testing and two themes about evaluating automated decisions from data technologies. The results provide implications for designing accessible data modeling experiences for students to understand data justice as well as the role and responsibility of data modelers in creating AI technologies.",Journal of Educational Media,2023,54,2,0,True,"{'url': 'https://www.tandfonline.com/doi/pdf/10.1080/17439884.2023.2189735?needAccess=true&role=button', 'status': None}",,"{'volume': '48', 'pages': '350 - 368', 'name': 'Learning, Media and Technology'}","[{'authorId': '2119329460', 'name': 'Shiyan Jiang'}, {'authorId': '46666192', 'name': 'Hengtao Tang'}, {'authorId': '48481506', 'name': 'Can Tatar'}, {'authorId': '35959897', 'name': 'C. Rosé'}, {'authorId': '2063179110', 'name': 'J. Chao'}]",It’s critical to foster artificial intelligence literacy for high school students to understand working mechanism of data-driven AI technologies and critically evaluate automated decisions from predictive models.
Carolyn Rose,35959897,C. Rosé,https://www.semanticscholar.org/author/35959897,54,[],441,11882,0c0d8ea1c1745e7b56bc3b1513a715ae3df30c44,"{'DBLP': 'conf/acl/GururajaDLR23', 'ACL': '2023.acl-long.414', 'ArXiv': '2307.03823', 'DOI': '10.48550/arXiv.2307.03823', 'CorpusId': 259370581}",https://www.semanticscholar.org/paper/0c0d8ea1c1745e7b56bc3b1513a715ae3df30c44,Linguistic representations for fewer-shot relation extraction across domains,"Recent work has demonstrated the positive impact of incorporating linguistic representations as additional context and scaffolds on the in-domain performance of several NLP tasks. We extend this work by exploring the impact of linguistic representations on cross-domain performance in a few-shot transfer setting. An important question is whether linguistic representations enhance generalizability by providing features that function as cross-domain pivots. We focus on the task of relation extraction on three datasets of procedural text in two domains, cooking and materials science. Our approach augments a popular transformer-based architecture by alternately incorporating syntactic and semantic graphs constructed by freely available off-the-shelf tools. We examine their utility for enhancing generalization, and investigate whether earlier findings, e.g. that semantic representations can be more helpful than syntactic ones, extend to relation extraction in multiple domains. We find that while the inclusion of these graphs results in significantly higher performance in few-shot transfer, both types of graph exhibit roughly equivalent utility.",Annual Meeting of the Association for Computational Linguistics,2023,36,1,0,True,"{'url': 'https://arxiv.org/pdf/2307.03823', 'status': None}",['Computer Science'],"{'volume': 'abs/2307.03823', 'name': 'ArXiv'}","[{'authorId': '2165225404', 'name': 'Sireesh Gururaja'}, {'authorId': '36662010', 'name': 'Ritam Dutt'}, {'authorId': '2853287', 'name': 'Ting-gen Liao'}, {'authorId': '35959897', 'name': 'C. Rosé'}]","This work explores the impact of linguistic representations on cross-domain performance in a few-shot transfer setting, and investigates whether earlier findings, e.g. that semantic representations can be more helpful than syntactic ones, extend to relation extraction in multiple domains."
Carolyn Rose,35959897,C. Rosé,https://www.semanticscholar.org/author/35959897,54,[],441,11882,117e1323677cb5d78ece0fd07b5cfa81618f4866,"{'DBLP': 'conf/acl/NourbakhshSR23', 'ACL': '2023.acl-long.834', 'DOI': '10.18653/v1/2023.acl-long.834', 'CorpusId': 259370632}",https://www.semanticscholar.org/paper/117e1323677cb5d78ece0fd07b5cfa81618f4866,Using counterfactual contrast to improve compositional generalization for multi-step quantitative reasoning,"In quantitative question answering, compositional generalization is one of the main challenges of state of the art models, especially when longer sequences of reasoning steps are required. In this paper we propose CounterComp, a method that uses counterfactual scenarios to generate samples with compositional contrast. Instead of a data augmentation approach, CounterComp is based on metric learning, which allows for direct sampling from the training set and circumvents the need for additional human labels. Our proposed auxiliary metric learning loss improves the performance of three state of the art models on four recently released datasets. We also show how the approach can improve OOD performance on unseen domains, as well as unseen compositions. Lastly, we demonstrate how the method can lead to better compositional attention patterns during training.",Annual Meeting of the Association for Computational Linguistics,2023,30,0,0,True,"{'url': 'https://aclanthology.org/2023.acl-long.834.pdf', 'status': None}",['Computer Science'],{'pages': '14930-14943'},"[{'authorId': '2144369', 'name': 'Armineh Nourbakhsh'}, {'authorId': '36532736', 'name': 'Sameena Shah'}, {'authorId': '35959897', 'name': 'C. Rosé'}]","This paper proposes CounterComp, a method that uses counterfactual scenarios to generate samples with compositional contrast based on metric learning, which allows for direct sampling from the training set and circumvents the need for additional human labels."
Carolyn Rose,35959897,C. Rosé,https://www.semanticscholar.org/author/35959897,54,[],441,11882,15d85036b15388bcb0199c83c01ba833e6095a31,"{'DBLP': 'conf/bea/FiaccoAR23', 'ACL': '2023.bea-1.20', 'DOI': '10.18653/v1/2023.bea-1.20', 'CorpusId': 259376635}",https://www.semanticscholar.org/paper/15d85036b15388bcb0199c83c01ba833e6095a31,Towards Extracting and Understanding the Implicit Rubrics of Transformer Based Automatic Essay Scoring Models,"By aligning the functional components derived from the activations of transformer models trained for AES with external knowledge such as human-understandable feature groups, the proposed method improves the interpretability of a Longformer Automatic Essay Scoring (AES) system and provides tools for performing such analyses on further neural AES systems. The analysis focuses on models trained to score essays based on organization, main idea, support, and language. The findings provide insights into the models’ decision-making processes, biases, and limitations, contributing to the development of more transparent and reliable AES systems.",Workshop on Innovative Use of NLP for Building Educational Applications,2023,33,0,0,True,"{'url': 'https://aclanthology.org/2023.bea-1.20.pdf', 'status': None}",['Computer Science'],{'pages': '232-241'},"[{'authorId': '50842746', 'name': 'James Fiacco'}, {'authorId': '2060195323', 'name': 'David Adamson'}, {'authorId': '35959897', 'name': 'C. Rosé'}]",The proposed method improves the interpretability of a Longformer Automatic Essay Scoring (AES) system and provides tools for performing such analyses on further neural AES systems.
Carolyn Rose,35959897,C. Rosé,https://www.semanticscholar.org/author/35959897,54,[],441,11882,27ca2d927421035e10b48c96a96db32224f1f8e6,"{'DBLP': 'conf/aaai/ChaoEJRFTFW23', 'DOI': '10.1609/aaai.v37i13.26899', 'CorpusId': 259760182}",https://www.semanticscholar.org/paper/27ca2d927421035e10b48c96a96db32224f1f8e6,Exploring Artificial Intelligence in English Language Arts with StoryQ,"Exploring Artificial Intelligence (AI) in English Language Arts (ELA) with StoryQ is a 10-hour curriculum module designed for high school ELA classes. The module introduces students to fundamental AI concepts and essential machine learning workflow using StoryQ, a web-based GUI environment for Grades 6-12 learners. In this module, students work with unstructured text data and learn to train, test, and improve text classification models such as intent recognition, clickbait filter, and sentiment analysis. As they interact with machine-learning language models deeply, students also gain a nuanced understanding of language and how to wield it, not just as a data structure, but as a tool in our human-human encounters as well. The current version contains eight lessons, all delivered through a full-featured online learning and teaching platform. Computers and Internet access are required to implement the module. The module was piloted in an ELA class in the Spring of 2022, and the student learning outcomes were positive. The module is currently undergoing revision and will be further tested and improved in Fall 2022.",AAAI Conference on Artificial Intelligence,2023,6,0,0,True,"{'url': 'https://ojs.aaai.org/index.php/AAAI/article/download/26899/26671', 'status': None}",['Computer Science'],{'pages': '15999-16003'},"[{'authorId': '2063179110', 'name': 'J. Chao'}, {'authorId': '2190602482', 'name': 'Rebecca Ellis'}, {'authorId': '2119329460', 'name': 'Shiyan Jiang'}, {'authorId': '35959897', 'name': 'C. Rosé'}, {'authorId': '3160261', 'name': 'W. Finzer'}, {'authorId': '48481506', 'name': 'Can Tatar'}, {'authorId': '50842746', 'name': 'James Fiacco'}, {'authorId': '2053547445', 'name': 'Kenia Wiedemann'}]",
Chenyan Xiong,144628574,Chenyan Xiong,https://www.semanticscholar.org/author/144628574,35,[],94,5048,159100c8323fc558e4073a3a006f3f243aca3a60,"{'DBLP': 'journals/corr/abs-2308-14029', 'ArXiv': '2308.14029', 'DOI': '10.1145/3583780.3615077', 'CorpusId': 261243943}",https://www.semanticscholar.org/paper/159100c8323fc558e4073a3a006f3f243aca3a60,Text Matching Improves Sequential Recommendation by Reducing Popularity Biases,"This paper proposes Text mAtching based SequenTial rEcommenda-tion model (TASTE), which maps items and users in an embedding space and recommends items by matching their text representations. TASTE verbalizes items and user-item interactions using identifiers and attributes of items. To better characterize user behaviors, TASTE additionally proposes an attention sparsity method, which enables TASTE to model longer user-item interactions by reducing the self-attention computations during encoding. Our experiments show that TASTE outperforms the state-of-the-art methods on widely used sequential recommendation datasets. TASTE alleviates the cold start problem by representing long-tail items using full-text modeling and bringing the benefits of pretrained language models to recommendation systems. Our further analyses illustrate that TASTE significantly improves the recommendation accuracy by reducing the popularity bias of previous item id based recommendation models and returning more appropriate and text-relevant items to satisfy users. All codes are available at https://github.com/OpenMatch/TASTE.",International Conference on Information and Knowledge Management,2023,74,3,0,True,"{'url': 'https://arxiv.org/pdf/2308.14029', 'status': None}",['Computer Science'],{'name': 'Proceedings of the 32nd ACM International Conference on Information and Knowledge Management'},"[{'authorId': '49047064', 'name': 'Zhenghao Liu'}, {'authorId': '2124028252', 'name': 'Senkun Mei'}, {'authorId': '144628574', 'name': 'Chenyan Xiong'}, {'authorId': '2164732511', 'name': 'Xiaohua Li'}, {'authorId': '12493038', 'name': 'Shi Yu'}, {'authorId': '2109232579', 'name': 'Zhiyuan Liu'}, {'authorId': '144955064', 'name': 'Yu Gu'}, {'authorId': '2110954235', 'name': 'Ge Yu'}]",
Chenyan Xiong,144628574,Chenyan Xiong,https://www.semanticscholar.org/author/144628574,35,[],94,5048,275da3802142fc42f6fab2ce2104223b2e0ef40d,"{'ArXiv': '2305.14685', 'DBLP': 'journals/corr/abs-2305-14685', 'DOI': '10.48550/arXiv.2305.14685', 'CorpusId': 258865599}",https://www.semanticscholar.org/paper/275da3802142fc42f6fab2ce2104223b2e0ef40d,Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval,"Common IR pipelines are typically cascade systems that may involve multiple rankers and/or fusion models to integrate different information step-by-step. In this paper, we propose a novel re-ranker named Fusion-in-T5 (FiT5), which integrates document text information, retrieval features, and global document information into a single unified model using templated-based input and global attention. Experiments on passage ranking benchmarks MS MARCO and TREC DL show that FiT5 significantly improves ranking performance over prior pipelines. Analyses find that through global attention, FiT5 is able to jointly utilize the ranking features via gradually attending to related documents, and thus improve the detection of subtle nuances between them. Our code will be open-sourced.",arXiv.org,2023,28,2,0,True,"{'url': 'http://arxiv.org/pdf/2305.14685', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.14685', 'name': 'ArXiv'}","[{'authorId': '150311558', 'name': 'S. Yu'}, {'authorId': '151462763', 'name': 'Cheng-Chung Fan'}, {'authorId': '144628574', 'name': 'Chenyan Xiong'}, {'authorId': '2152284449', 'name': 'David Jin'}, {'authorId': '2109232579', 'name': 'Zhiyuan Liu'}, {'authorId': '2218865926', 'name': 'Zhenghao Liu Tsinghua University'}, {'authorId': '1387888436', 'name': 'Huazhong University of Science'}, {'authorId': '2069450537', 'name': 'Technology'}, {'authorId': '68973648', 'name': 'Microsoft Research'}, {'authorId': '51432736', 'name': 'M. I. O. Technology'}, {'authorId': '102720314', 'name': 'N. University'}]","A novel re-ranker named Fusion-in-T5 (FiT5), which integrates document text information, retrieval features, and global document information into a single unified model using templated-based input and global attention, is proposed."
Chenyan Xiong,144628574,Chenyan Xiong,https://www.semanticscholar.org/author/144628574,35,[],94,5048,cdfd0926ad26c3c95a02db2ae891b7d4a457429c,"{'DBLP': 'conf/sigir/YuLX023', 'DOI': '10.1145/3539618.3591813', 'CorpusId': 259949845}",https://www.semanticscholar.org/paper/cdfd0926ad26c3c95a02db2ae891b7d4a457429c,OpenMatch-v2: An All-in-one Multi-Modality PLM-based Information Retrieval Toolkit,"Pre-trained language models (PLMs) have emerged as the foundation of the most advanced Information Retrieval (IR) models. Powered by PLMs, the latest IR research has proposed novel models, new domain adaptation algorithms as well as enlarged datasets. In this paper, we present a Python-based IR toolkit OpenMatch-v2. As a full upgrade of OpenMatch proposed in 2021, OpenMatch-v2 incorporates the most recent advancements of PLM-based IR research, providing support for new, cross-modality models and enhanced domain adaptation techniques with a streamlined, optimized infrastructure. The code of OpenMatch is publicly available at https://github.com/OpenMatch/OpenMatch.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2023,42,6,0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/3539618.3591813', 'status': None}",['Computer Science'],{'name': 'Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval'},"[{'authorId': '12493038', 'name': 'Shi Yu'}, {'authorId': '49047064', 'name': 'Zhenghao Liu'}, {'authorId': '144628574', 'name': 'Chenyan Xiong'}, {'authorId': '2109232579', 'name': 'Zhiyuan Liu'}]","As a full upgrade of OpenMatch proposed in 2021, OpenMatch-v2 incorporates the most recent advancements of PLM-based IR research, providing support for new, cross-modality models and enhanced domain adaptation techniques with a streamlined, optimized infrastructure."
Chenyan Xiong,2139787803,Chenyan Xiong,https://www.semanticscholar.org/author/2139787803,7,[],22,222,105759bdb5e3bddc1d3244df2eff2d5c997a1d84,"{'DBLP': 'journals/corr/abs-2307-00342', 'ArXiv': '2307.00342', 'DOI': '10.1162/tacl_a_00597', 'CorpusId': 259316561}",https://www.semanticscholar.org/paper/105759bdb5e3bddc1d3244df2eff2d5c997a1d84,Improving Multitask Retrieval by Promoting Task Specialization,"Abstract In multitask retrieval, a single retriever is trained to retrieve relevant contexts for multiple tasks. Despite its practical appeal, naive multitask retrieval lags behind task-specific retrieval, in which a separate retriever is trained for each task. We show that it is possible to train a multitask retriever that outperforms task-specific retrievers by promoting task specialization. The main ingredients are: (1) a better choice of pretrained model—one that is explicitly optimized for multitasking—along with compatible prompting, and (2) a novel adaptive learning method that encourages each parameter to specialize in a particular task. The resulting multitask retriever is highly performant on the KILT benchmark. Upon analysis, we find that the model indeed learns parameters that are more task-specialized compared to naive multitasking without prompting or adaptive learning.1",Transactions of the Association for Computational Linguistics,2023,36,0,0,True,"{'url': 'https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl_a_00597/2159628/tacl_a_00597.pdf', 'status': None}",['Computer Science'],"{'volume': '11', 'pages': '1201-1212', 'name': 'Transactions of the Association for Computational Linguistics'}","[{'authorId': '2107940644', 'name': 'Wenzheng Zhang'}, {'authorId': '2139787803', 'name': 'Chenyan Xiong'}, {'authorId': '1714215', 'name': 'K. Stratos'}, {'authorId': '2734525', 'name': 'Arnold Overwijk'}]","It is shown that it is possible to train a multitask retriever that outperforms task-specific retrievers by promoting task specialization, and the model indeed learns parameters that are more task-specialized compared to naive multitasking without prompting or adaptive learning."
Chenyan Xiong,2139787803,Chenyan Xiong,https://www.semanticscholar.org/author/2139787803,7,[],22,222,1fe3a802efdc4f1a3e5c8187547f38a3ec65750b,"{'DBLP': 'journals/corr/abs-2305-05834', 'ArXiv': '2305.05834', 'DOI': '10.1145/3539618.3592080', 'CorpusId': 258588167}",https://www.semanticscholar.org/paper/1fe3a802efdc4f1a3e5c8187547f38a3ec65750b,Unsupervised Dense Retrieval Training with Web Anchors,"In this work, we present an unsupervised retrieval method with contrastive learning on web anchors. The anchor text describes the content that is referenced from the linked page. This shows similarities to search queries that aim to retrieve pertinent information from relevant documents. Based on their commonalities, we train an unsupervised dense retriever, Anchor-DR, with a contrastive learning task that matches the anchor text and the linked document. To filter out uninformative anchors (such as ""homepage"" or other functional anchors), we present a novel filtering technique to only select anchors that contain similar types of information as search queries. Experiments show that Anchor-DR outperforms state-of-the-art methods on unsupervised dense retrieval by a large margin (e.g., by 5.3% NDCG@10 on MSMARCO). The gain of our method is especially significant for search and question answering tasks. Our analysis further reveals that the pattern of anchor-document pairs is similar to that of search query-document pairs. Code available at https://github.com/Veronicium/AnchorDR.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2023,32,2,0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/3539618.3592080', 'status': None}",['Computer Science'],{'name': 'Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval'},"[{'authorId': '1892794261', 'name': 'Yiqing Xie'}, {'authorId': '2111312954', 'name': 'X. Liu'}, {'authorId': '2139787803', 'name': 'Chenyan Xiong'}]","This work trains an unsupervised dense retriever, Anchor-DR, with a contrastive learning task that matches the anchor text and the linked document, and presents a novel filtering technique to only select anchors that contain similar types of information as search queries."
Chenyan Xiong,2139787803,Chenyan Xiong,https://www.semanticscholar.org/author/2139787803,7,[],22,222,24811cadf16519910f643b6084107164e6ca4219,"{'DBLP': 'conf/acl/YuXY023', 'ACL': '2023.acl-long.136', 'ArXiv': '2305.17331', 'DOI': '10.48550/arXiv.2305.17331', 'CorpusId': 258960666}",https://www.semanticscholar.org/paper/24811cadf16519910f643b6084107164e6ca4219,Augmentation-Adapted Retriever Improves Generalization of Language Models as Generic Plug-In,"Retrieval augmentation can aid language models (LMs) in knowledge-intensive tasks by supplying them with external information. Prior works on retrieval augmentation usually jointly fine-tune the retriever and the LM, making them closely coupled. In this paper, we explore the scheme of generic retrieval plug-in: the retriever is to assist target LMs that may not be known beforehand or are unable to be fine-tuned together. To retrieve useful documents for unseen target LMs, we propose augmentation-adapted retriever (AAR), which learns LM’s preferences obtained from a known source LM. Experiments on the MMLU and PopQA datasets demonstrate that our AAR trained with a small source LM is able to significantly improve the zero-shot generalization of larger target LMs ranging from 250M Flan-T5 to 175B InstructGPT. Further analysis indicates that the preferences of different LMs overlap, enabling AAR trained with a single source LM to serve as a generic plug-in for various target LMs. Our code is open-sourced at https://github.com/OpenMatch/Augmentation-Adapted-Retriever.",Annual Meeting of the Association for Computational Linguistics,2023,52,9,1,True,"{'url': 'http://arxiv.org/pdf/2305.17331', 'status': None}",['Computer Science'],{'pages': '2421-2436'},"[{'authorId': '103985655', 'name': 'Zichun Yu'}, {'authorId': '2139787803', 'name': 'Chenyan Xiong'}, {'authorId': '150311558', 'name': 'S. Yu'}, {'authorId': '2109232579', 'name': 'Zhiyuan Liu'}]","This paper proposes augmentation-adapted retriever (AAR), which learns LM’s preferences obtained from a known source LM to assist target LMs that may not be known beforehand or are unable to be fine-tuned together in a generic retrieval plug-in."
Chenyan Xiong,2139787803,Chenyan Xiong,https://www.semanticscholar.org/author/2139787803,7,[],22,222,38aaf8a29df6deeff0bf64cc835d242a25b10337,"{'ArXiv': '2305.12567', 'DBLP': 'journals/corr/abs-2305-12567', 'ACL': '2023.acl-long.724', 'DOI': '10.18653/v1/2023.acl-long.724', 'CorpusId': 258833130}",https://www.semanticscholar.org/paper/38aaf8a29df6deeff0bf64cc835d242a25b10337,Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers,"This paper explores the effectiveness of model-generated signals in improving zero-shot generalization of text-to-text Transformers such as T5. We study various designs to pretrain T5 using an auxiliary model to construct more challenging token replacements for the main model to denoise. Key aspects under study include the decoding target, the location of the RTD head, and the masking pattern. Based on these studies, we develop a new model, METRO-T0, which is pretrained using the redesigned ELECTRA-Style pretraining strategies and then prompt-finetuned on a mixture of NLP tasks. METRO-T0 outperforms all similar-sized baselines on prompted NLP benchmarks, such as _T0 Eval_ and MMLU, and rivals the state-of-the-art T0-11B model with only **8%** of its parameters. Our analysis on model’s neural activation and parameter sensitivity reveals that the effectiveness of METRO-T0 stems from more balanced contribution of parameters and better utilization of their capacity. The code and model checkpoints are available at [https://github.com/gonglinyuan/metro_t0](https://github.com/gonglinyuan/metro_t0).",Annual Meeting of the Association for Computational Linguistics,2023,32,0,0,True,"{'url': 'https://aclanthology.org/2023.acl-long.724.pdf', 'status': None}",['Computer Science'],{'pages': '12933-12950'},"[{'authorId': '32816503', 'name': 'Linyuan Gong'}, {'authorId': '2139787803', 'name': 'Chenyan Xiong'}, {'authorId': '46522098', 'name': 'Xiaodong Liu'}, {'authorId': '34765717', 'name': 'Payal Bajaj'}, {'authorId': '1892794261', 'name': 'Yiqing Xie'}, {'authorId': '2172244319', 'name': 'Alvin Cheung'}, {'authorId': '48441311', 'name': 'Jianfeng Gao'}, {'authorId': '50706785', 'name': 'Xia Song'}]","A new model, METRO-T0 is developed, which is pretrained using the redesigned ELECTRA-Style pretraining strategies and then prompt-finetuned on a mixture of NLP tasks and rivals the state-of-the-art T0-11B model with only **8%** of its parameters."
Chenyan Xiong,2139787803,Chenyan Xiong,https://www.semanticscholar.org/author/2139787803,7,[],22,222,a57b90cfc2eab46b773e65240d4ff910f05f989e,"{'DBLP': 'conf/acl/LiLXY00023', 'ArXiv': '2305.19912', 'DOI': '10.48550/arXiv.2305.19912', 'CorpusId': 258987900}",https://www.semanticscholar.org/paper/a57b90cfc2eab46b773e65240d4ff910f05f989e,Structure-Aware Language Model Pretraining Improves Dense Retrieval on Structured Data,"This paper presents Structure Aware Dense Retrieval (SANTA) model, which encodes user queries and structured data in one universal embedding space for retrieving structured data. SANTA proposes two pretraining methods to make language models structure-aware and learn effective representations for structured data: 1) Structured Data Alignment, which utilizes the natural alignment relations between structured data and unstructured data for structure-aware pretraining. It contrastively trains language models to represent multi-modal text data and teaches models to distinguish matched structured data for unstructured texts. 2) Masked Entity Prediction, which designs an entity-oriented mask strategy and asks language models to fill in the masked entities. Our experiments show that SANTA achieves state-of-the-art on code search and product search and conducts convincing results in the zero-shot setting. SANTA learns tailored representations for multi-modal text data by aligning structured and unstructured data pairs and capturing structural semantics by masking and predicting entities in the structured data. All codes are available at https://github.com/OpenMatch/OpenMatch.",Annual Meeting of the Association for Computational Linguistics,2023,46,1,1,True,"{'url': 'http://arxiv.org/pdf/2305.19912', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.19912', 'name': 'ArXiv'}","[{'authorId': '2109419838', 'name': 'Xinze Li'}, {'authorId': '49047064', 'name': 'Zhenghao Liu'}, {'authorId': '2139787803', 'name': 'Chenyan Xiong'}, {'authorId': '12493038', 'name': 'Shi Yu'}, {'authorId': '144955064', 'name': 'Yu Gu'}, {'authorId': '2109232579', 'name': 'Zhiyuan Liu'}, {'authorId': '2110954235', 'name': 'Ge Yu'}]",
Chenyan Xiong,2139787803,Chenyan Xiong,https://www.semanticscholar.org/author/2139787803,7,[],22,222,b9e8b62bcc019f47a0a015568f70039b3b7c1196,"{'ArXiv': '2310.05155', 'DBLP': 'journals/corr/abs-2310-05155', 'DOI': '10.48550/arXiv.2310.05155', 'CorpusId': 263829000}",https://www.semanticscholar.org/paper/b9e8b62bcc019f47a0a015568f70039b3b7c1196,Toolink: Linking Toolkit Creation and Using through Chain-of-Solving on Open-Source Model,"Large Language Models (LLMs) have demonstrated remarkable progress in utilizing tools, but their closed-source nature and high inference costs pose limitations on their adaptability, necessitating a valid method that leverages smaller, open-sourced models. In this paper, we introduce Toolink, a comprehensive framework that performs task-solving by first creating a toolkit and then integrating the planning and calling of tools through a chain-of-solving (CoS) approach. We first validate the efficacy of Toolink in harnessing the model's creativity and CoS ability on ChatGPT. Subsequently, we curate CoS-GPT, a chain-of-solving dataset designed for tool-using, and finetune the LLaMA-7B model. It results in LLaMA-CoS, a powerful open-source model with advanced tool-planning and tool-calling capabilities. Evaluation on diverse tasks from BIG-bench demonstrates its CoS ability matches that of ChatGPT while its performance surpasses the chain-of-thought approach. Further studies highlight the generalization of LLaMA-CoS to unseen tasks and showcase its capability in using toolkits not explicitly tailored for the target task, affirming its robustness in real-world scenarios. All codes and data are released.",arXiv.org,2023,39,3,0,True,"{'url': 'https://arxiv.org/pdf/2310.05155', 'status': None}",['Computer Science'],"{'volume': 'abs/2310.05155', 'name': 'ArXiv'}","[{'authorId': '2214580084', 'name': 'Cheng Qian'}, {'authorId': '2139787803', 'name': 'Chenyan Xiong'}, {'authorId': '49047064', 'name': 'Zhenghao Liu'}, {'authorId': '2109232579', 'name': 'Zhiyuan Liu'}]","This paper introduces Toolink, a comprehensive framework that performs task-solving by first creating a toolkit and then integrating the planning and calling of tools through a chain-of-s solving (CoS) approach, and results in LLaMA-CoS, a powerful open-source model with advanced tool-planning and tool-calling capabilities."
Chenyan Xiong,2139787803,Chenyan Xiong,https://www.semanticscholar.org/author/2139787803,7,[],22,222,e0401ca2d4fd6d0ed55130a4a24b33ed90111479,"{'DBLP': 'conf/emnlp/GeXRO0023', 'ArXiv': '2302.03754', 'DOI': '10.48550/arXiv.2302.03754', 'CorpusId': 256662717}",https://www.semanticscholar.org/paper/e0401ca2d4fd6d0ed55130a4a24b33ed90111479,Augmenting Zero-Shot Dense Retrievers with Plug-in Mixture-of-Memories,"In this paper we improve the zero-shot generalization ability of language models via Mixture-Of-Memory Augmentation (MoMA), a mechanism that retrieves augmentation documents from multiple information corpora (""external memories""), with the option to""plug in""new memory at inference time. We develop a joint learning mechanism that trains the augmentation component with latent labels derived from the end retrieval task, paired with hard negatives from the memory mixture. We instantiate the model in a zero-shot dense retrieval setting by augmenting a strong T5-based retriever with MoMA. Our model, MoMA, obtains strong zero-shot retrieval accuracy on the eighteen tasks included in the standard BEIR benchmark. It outperforms systems that seek generalization from increased model parameters and computation steps. Our analysis further illustrates the necessity of augmenting with mixture-of-memory for robust generalization, the benefits of augmentation learning, and how MoMA utilizes the plug-in memory at inference time without changing its parameters. We plan to open source our code.",Conference on Empirical Methods in Natural Language Processing,2023,72,4,0,True,"{'url': 'http://arxiv.org/pdf/2302.03754', 'status': None}",['Computer Science'],"{'volume': 'abs/2302.03754', 'name': 'ArXiv'}","[{'authorId': '148048326', 'name': 'Suyu Ge'}, {'authorId': '2139787803', 'name': 'Chenyan Xiong'}, {'authorId': '41016119', 'name': 'Corby Rosset'}, {'authorId': '2734525', 'name': 'Arnold Overwijk'}, {'authorId': '2111759643', 'name': 'Jiawei Han'}, {'authorId': '144609235', 'name': 'Paul N. Bennett'}]",
Daniel Fried,47070750,Daniel Fried,https://www.semanticscholar.org/author/47070750,26,['Carnegie Mellon University'],50,2668,19f59c14b3d79e3203c696128a135d33eb35e468,"{'ArXiv': '2306.08818', 'DBLP': 'conf/acl/OuKF23', 'DOI': '10.48550/arXiv.2306.08818', 'CorpusId': 259164492}",https://www.semanticscholar.org/paper/19f59c14b3d79e3203c696128a135d33eb35e468,Pragmatic Inference with a CLIP Listener for Contrastive Captioning,"We propose a simple yet effective and robust method for contrastive captioning: generating discriminative captions that distinguish target images from very similar alternative distractor images. Our approach is built on a pragmatic inference procedure that formulates captioning as a reference game between a speaker, which produces possible captions describing the target, and a listener, which selects the target given the caption. Unlike previous methods that derive both speaker and listener distributions from a single captioning model, we leverage an off-the-shelf CLIP model to parameterize the listener. Compared with captioner-only pragmatic models, our method benefits from rich vision language alignment representations from CLIP when reasoning over distractors. Like previous methods for discriminative captioning, our method uses a hyperparameter to control the tradeoff between the informativity (how likely captions are to allow a human listener to discriminate the target image) and the fluency of the captions. However, we find that our method is substantially more robust to the value of this hyperparameter than past methods, which allows us to automatically optimize the captions for informativity - outperforming past methods for discriminative captioning by 11% to 15% accuracy in human evaluations",Annual Meeting of the Association for Computational Linguistics,2023,39,1,0,True,"{'url': 'http://arxiv.org/pdf/2306.08818', 'status': None}",['Computer Science'],"{'volume': 'abs/2306.08818', 'name': 'ArXiv'}","[{'authorId': '1657712151', 'name': 'Jiefu Ou'}, {'authorId': '1994697809', 'name': 'Benno Krojer'}, {'authorId': '47070750', 'name': 'Daniel Fried'}]",This work proposes a simple yet effective and robust method for contrastive captioning: generating discriminative captions that distinguish target images from very similar alternative distractor images by leveraging an off-the-shelf CLIP model to parameterize the listener.
Daniel Fried,47070750,Daniel Fried,https://www.semanticscholar.org/author/47070750,26,['Carnegie Mellon University'],50,2668,1bf21dabbdfc81fd4f9e92b1201ecce744cabb6a,"{'ArXiv': '2301.03988', 'DBLP': 'journals/corr/abs-2301-03988', 'DOI': '10.48550/arXiv.2301.03988', 'CorpusId': 255570209}",https://www.semanticscholar.org/paper/1bf21dabbdfc81fd4f9e92b1201ecce744cabb6a,SantaCoder: don't reach for the stars!,"The BigCode project is an open-scientific collaboration working on the responsible development of large language models for code. This tech report describes the progress of the collaboration until December 2022, outlining the current state of the Personally Identifiable Information (PII) redaction pipeline, the experiments conducted to de-risk the model architecture, and the experiments investigating better preprocessing methods for the training data. We train 1.1B parameter models on the Java, JavaScript, and Python subsets of The Stack and evaluate them on the MultiPL-E text-to-code benchmark. We find that more aggressive filtering of near-duplicates can further boost performance and, surprisingly, that selecting files from repositories with 5+ GitHub stars deteriorates performance significantly. Our best model outperforms previous open-source multilingual code generation models (InCoder-6.7B and CodeGen-Multi-2.7B) in both left-to-right generation and infilling on the Java, JavaScript, and Python portions of MultiPL-E, despite being a substantially smaller model. All models are released under an OpenRAIL license at https://hf.co/bigcode.",arXiv.org,2023,47,83,11,True,"{'url': 'http://arxiv.org/pdf/2301.03988', 'status': None}",['Computer Science'],"{'volume': 'abs/2301.03988', 'name': 'ArXiv'}","[{'authorId': '2190281230', 'name': 'Loubna Ben Allal'}, {'authorId': '144235909', 'name': 'Raymond Li'}, {'authorId': '2192609008', 'name': 'Denis Kocetkov'}, {'authorId': '35966970', 'name': 'Chenghao Mou'}, {'authorId': '2003696840', 'name': 'Christopher Akiki'}, {'authorId': '2005399190', 'name': 'Carlos Muñoz Ferrandis'}, {'authorId': '2037383772', 'name': 'Niklas Muennighoff'}, {'authorId': '1381446720', 'name': 'Mayank Mishra'}, {'authorId': '2060030895', 'name': 'A. Gu'}, {'authorId': '1879591269', 'name': 'Manan Dey'}, {'authorId': '2160540450', 'name': 'Logesh Kumar Umapathi'}, {'authorId': '144901955', 'name': 'Carolyn Jane Anderson'}, {'authorId': '2181729017', 'name': 'Yangtian Zi'}, {'authorId': '92537065', 'name': 'J. Poirier'}, {'authorId': '2184031883', 'name': 'Hailey Schoelkopf'}, {'authorId': '144215206', 'name': 'S. Troshin'}, {'authorId': '133810684', 'name': 'Dmitry Abulkhanov'}, {'authorId': '2027442879', 'name': 'M. Romero'}, {'authorId': '12342993', 'name': 'M. Lappert'}, {'authorId': '2067891070', 'name': 'F. Toni'}, {'authorId': '2199839668', 'name': ""Bernardo Garc'ia del R'io""}, {'authorId': '1409707585', 'name': 'Qian Liu'}, {'authorId': '2795685', 'name': 'Shamik Bose'}, {'authorId': '34518411', 'name': 'Urvashi Bhattacharyya'}, {'authorId': '2080123731', 'name': 'Terry Yue Zhuo'}, {'authorId': '52141399', 'name': 'I. Yu'}, {'authorId': '2176184659', 'name': 'Paulo Villegas'}, {'authorId': '145302471', 'name': 'Marco Zocca'}, {'authorId': '51145342', 'name': 'Sourab Mangrulkar'}, {'authorId': '2532989', 'name': 'D. Lansky'}, {'authorId': '2168170616', 'name': 'Huu Nguyen'}, {'authorId': '2075459', 'name': 'Danish Contractor'}, {'authorId': '147381819', 'name': 'Luisa Villa'}, {'authorId': '2133337166', 'name': 'Jia Li'}, {'authorId': '3335364', 'name': 'Dzmitry Bahdanau'}, {'authorId': '2262249', 'name': 'Yacine Jernite'}, {'authorId': '7367259', 'name': 'S. Hughes'}, {'authorId': '47070750', 'name': 'Daniel Fried'}, {'authorId': '2100712', 'name': 'Arjun Guha'}, {'authorId': '153559313', 'name': 'Harm de Vries'}, {'authorId': '51128119', 'name': 'Leandro von Werra'}]","The current state of the Personally Identifiable Information (PII) redaction pipeline is outlined, the experiments conducted to de-risk the model architecture, and the experiments investigating better preprocessing methods for the training data are outlined."
Daniel Fried,47070750,Daniel Fried,https://www.semanticscholar.org/author/47070750,26,['Carnegie Mellon University'],50,2668,2b2d9ee18507aa89a7f1ecba0bf68844c7d9aa75,"{'DBLP': 'journals/corr/abs-2301-13823', 'DOI': '10.48550/arXiv.2301.13823', 'CorpusId': 256416164}",https://www.semanticscholar.org/paper/2b2d9ee18507aa89a7f1ecba0bf68844c7d9aa75,Grounding Language Models to Images for Multimodal Generation,"We propose an efﬁcient method to ground pre-trained text-only language models to the visual domain, enabling them to process and generate arbitrarily interleaved image-and-text data. Our method leverages the abilities of language models learnt from large scale text-only pretraining, such as in-context learning and free-form text generation. We keep the language model frozen, and ﬁnetune input and output linear layers to enable cross-modality interactions. This allows our model to process arbitrarily interleaved image-and-text inputs, and generate free-form text interleaved with retrieved images. We achieve strong zero-shot performance on grounded tasks such as contextual image retrieval and multimodal dialogue, and showcase compelling interactive abilities. Our approach works with any off-the-shelf language model and paves the way towards an ef-fective, general solution for leveraging pretrained language models in visually grounded settings.",arXiv.org,2023,55,60,5,True,"{'url': 'http://arxiv.org/pdf/2301.13823', 'status': None}",['Computer Science'],"{'volume': 'abs/2301.13823', 'name': 'ArXiv'}","[{'authorId': '23978705', 'name': 'Jing Yu Koh'}, {'authorId': '145124475', 'name': 'R. Salakhutdinov'}, {'authorId': '47070750', 'name': 'Daniel Fried'}]","An ef-fective, general solution for leveraging pretrained language models in visually grounded settings, enabling them to process and generate arbitrarily interleaved image-and-text data."
Daniel Fried,47070750,Daniel Fried,https://www.semanticscholar.org/author/47070750,26,['Carnegie Mellon University'],50,2668,3e4085e5869f1b7959707a1e1d7d273b6057eb4e,"{'DBLP': 'journals/corr/abs-2305-06161', 'ArXiv': '2305.06161', 'DOI': '10.48550/arXiv.2305.06161', 'CorpusId': 258588247}",https://www.semanticscholar.org/paper/3e4085e5869f1b7959707a1e1d7d273b6057eb4e,StarCoder: may the source be with you!,"The BigCode community, an open-scientific collaboration working on the responsible development of Large Language Models for Code (Code LLMs), introduces StarCoder and StarCoderBase: 15.5B parameter models with 8K context length, infilling capabilities and fast large-batch inference enabled by multi-query attention. StarCoderBase is trained on 1 trillion tokens sourced from The Stack, a large collection of permissively licensed GitHub repositories with inspection tools and an opt-out process. We fine-tuned StarCoderBase on 35B Python tokens, resulting in the creation of StarCoder. We perform the most comprehensive evaluation of Code LLMs to date and show that StarCoderBase outperforms every open Code LLM that supports multiple programming languages and matches or outperforms the OpenAI code-cushman-001 model. Furthermore, StarCoder outperforms every model that is fine-tuned on Python, can be prompted to achieve 40\% pass@1 on HumanEval, and still retains its performance on other programming languages. We take several important steps towards a safe open-access model release, including an improved PII redaction pipeline and a novel attribution tracing tool, and make the StarCoder models publicly available under a more commercially viable version of the Open Responsible AI Model license.",arXiv.org,2023,113,217,29,True,"{'url': 'http://arxiv.org/pdf/2305.06161', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.06161', 'name': 'ArXiv'}","[{'authorId': '2116277958', 'name': 'Raymond Li'}, {'authorId': '2190281230', 'name': 'Loubna Ben Allal'}, {'authorId': '2181729017', 'name': 'Yangtian Zi'}, {'authorId': '2037383772', 'name': 'Niklas Muennighoff'}, {'authorId': '2192609008', 'name': 'Denis Kocetkov'}, {'authorId': '35966970', 'name': 'Chenghao Mou'}, {'authorId': '82893387', 'name': 'Marc Marone'}, {'authorId': '2003696840', 'name': 'Christopher Akiki'}, {'authorId': '2133337166', 'name': 'Jia Li'}, {'authorId': '2164872258', 'name': 'Jenny Chim'}, {'authorId': '1409707585', 'name': 'Qian Liu'}, {'authorId': '23913513', 'name': 'Evgenii Zheltonozhskii'}, {'authorId': '2080123731', 'name': 'Terry Yue Zhuo'}, {'authorId': '2135734748', 'name': 'Thomas Wang'}, {'authorId': '90133940', 'name': 'Olivier Dehaene'}, {'authorId': '2216716007', 'name': 'Mishig Davaadorj'}, {'authorId': '1404999623', 'name': 'J. Lamy-Poirier'}, {'authorId': '2165647953', 'name': 'João Monteiro'}, {'authorId': '2001138860', 'name': 'Oleh Shliazhko'}, {'authorId': '51921879', 'name': 'Nicolas Gontier'}, {'authorId': '150247363', 'name': 'Nicholas Meade'}, {'authorId': '2216716005', 'name': 'Armel Zebaze'}, {'authorId': '39043661', 'name': 'Ming-Ho Yee'}, {'authorId': '2160540450', 'name': 'Logesh Kumar Umapathi'}, {'authorId': '144549416', 'name': 'Jian Zhu'}, {'authorId': '2098806399', 'name': 'Benjamin Lipkin'}, {'authorId': '2025767395', 'name': 'Muhtasham Oblokulov'}, {'authorId': '1390877035', 'name': 'Zhiruo Wang'}, {'authorId': '144725573', 'name': 'Rudra Murthy'}, {'authorId': '2074988455', 'name': 'J. Stillerman'}, {'authorId': '80836534', 'name': 'S. Patel'}, {'authorId': '133810684', 'name': 'Dmitry Abulkhanov'}, {'authorId': '145302471', 'name': 'Marco Zocca'}, {'authorId': '1879591269', 'name': 'Manan Dey'}, {'authorId': '72871419', 'name': 'Zhihan Zhang'}, {'authorId': '1992948200', 'name': 'N. Fahmy'}, {'authorId': '34518411', 'name': 'Urvashi Bhattacharyya'}, {'authorId': '38767143', 'name': 'W. Yu'}, {'authorId': '2216707828', 'name': 'Swayam Singh'}, {'authorId': '2165225321', 'name': 'Sasha Luccioni'}, {'authorId': '2176184659', 'name': 'Paulo Villegas'}, {'authorId': '2216716363', 'name': 'M. Kunakov'}, {'authorId': '2096007', 'name': 'Fedor Zhdanov'}, {'authorId': '2068219897', 'name': 'Manuel Romero'}, {'authorId': '2216871008', 'name': 'Tony Lee'}, {'authorId': '2151790441', 'name': 'Nadav Timor'}, {'authorId': '2202586855', 'name': 'Jennifer Ding'}, {'authorId': '2216724826', 'name': 'Claire Schlesinger'}, {'authorId': '2184031883', 'name': 'Hailey Schoelkopf'}, {'authorId': '29968727', 'name': 'Jana Ebert'}, {'authorId': '24593911', 'name': 'Tri Dao'}, {'authorId': '1381446720', 'name': 'Mayank Mishra'}, {'authorId': '2060030895', 'name': 'A. Gu'}, {'authorId': '2216708905', 'name': 'Jennifer Robinson'}, {'authorId': '144901955', 'name': 'Carolyn Jane Anderson'}, {'authorId': '1398683279', 'name': 'Brendan Dolan-Gavitt'}, {'authorId': '2075459', 'name': 'Danish Contractor'}, {'authorId': '145732771', 'name': 'Siva Reddy'}, {'authorId': '47070750', 'name': 'Daniel Fried'}, {'authorId': '3335364', 'name': 'Dzmitry Bahdanau'}, {'authorId': '2262249', 'name': 'Yacine Jernite'}, {'authorId': '2005399190', 'name': 'Carlos Muñoz Ferrandis'}, {'authorId': '2054162307', 'name': 'Sean M. Hughes'}, {'authorId': '50335211', 'name': 'Thomas Wolf'}, {'authorId': '2100712', 'name': 'Arjun Guha'}, {'authorId': '51128119', 'name': 'Leandro von Werra'}, {'authorId': '153559313', 'name': 'Harm de Vries'}]",This work performs the most comprehensive evaluation of Code LLMs to date and shows that StarCoderBase outperforms every open Code LLM that supports multiple programming languages and matches or outperforms the OpenAI code-cushman-001 model.
Daniel Fried,47070750,Daniel Fried,https://www.semanticscholar.org/author/47070750,26,['Carnegie Mellon University'],50,2668,6fb5c0eff3696ef252aca9638e10176ecce7cecb,"{'ArXiv': '2305.17216', 'DBLP': 'journals/corr/abs-2305-17216', 'DOI': '10.48550/arXiv.2305.17216', 'CorpusId': 258959284}",https://www.semanticscholar.org/paper/6fb5c0eff3696ef252aca9638e10176ecce7cecb,Generating Images with Multimodal Language Models,"We propose a method to fuse frozen text-only large language models (LLMs) with pre-trained image encoder and decoder models, by mapping between their embedding spaces. Our model demonstrates a wide suite of multimodal capabilities: image retrieval, novel image generation, and multimodal dialogue. Ours is the first approach capable of conditioning on arbitrarily interleaved image and text inputs to generate coherent image (and text) outputs. To achieve strong performance on image generation, we propose an efficient mapping network to ground the LLM to an off-the-shelf text-to-image generation model. This mapping network translates hidden representations of text into the embedding space of the visual models, enabling us to leverage the strong text representations of the LLM for visual outputs. Our approach outperforms baseline generation models on tasks with longer and more complex language. In addition to novel image generation, our model is also capable of image retrieval from a prespecified dataset, and decides whether to retrieve or generate at inference time. This is done with a learnt decision module which conditions on the hidden representations of the LLM. Our model exhibits a wider range of capabilities compared to prior multimodal language models. It can process image-and-text inputs, and produce retrieved images, generated images, and generated text -- outperforming non-LLM based generation models across several text-to-image tasks that measure context dependence.",arXiv.org,2023,73,63,11,True,"{'url': 'https://arxiv.org/pdf/2305.17216', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.17216', 'name': 'ArXiv'}","[{'authorId': '23978705', 'name': 'Jing Yu Koh'}, {'authorId': '47070750', 'name': 'Daniel Fried'}, {'authorId': '145124475', 'name': 'R. Salakhutdinov'}]","This work proposes a method to fuse frozen text-only large language models (LLMs) with pre-trained image encoder and decoder models, by mapping between their embedding spaces, and exhibits a wider range of capabilities compared to prior multimodal language models."
Daniel Fried,47070750,Daniel Fried,https://www.semanticscholar.org/author/47070750,26,['Carnegie Mellon University'],50,2668,e41482f4ee984f17382f6cdd900df094d928be06,"{'ArXiv': '2307.13854', 'DBLP': 'journals/corr/abs-2307-13854', 'DOI': '10.48550/arXiv.2307.13854', 'CorpusId': 260164780}",https://www.semanticscholar.org/paper/e41482f4ee984f17382f6cdd900df094d928be06,WebArena: A Realistic Web Environment for Building Autonomous Agents,"With advances in generative AI, there is now potential for autonomous agents to manage daily tasks via natural language commands. However, current agents are primarily created and tested in simplified synthetic environments, leading to a disconnect with real-world scenarios. In this paper, we build an environment for language-guided agents that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on the web, and create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our environment is enriched with tools (e.g., a map) and external knowledge bases (e.g., user manuals) to encourage human-like task-solving. Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and designed to emulate tasks that humans routinely perform on the internet. We experiment with several baseline agents, integrating recent techniques such as reasoning before acting. The results demonstrate that solving complex tasks is challenging: our best GPT-4-based agent only achieves an end-to-end task success rate of 14.41%, significantly lower than the human performance of 78.24%. These results highlight the need for further development of robust agents, that current state-of-the-art large language models are far from perfect performance in these real-life tasks, and that WebArena can be used to measure such progress.",arXiv.org,2023,63,60,7,True,"{'url': 'https://arxiv.org/pdf/2307.13854', 'status': None}",['Computer Science'],"{'volume': 'abs/2307.13854', 'name': 'ArXiv'}","[{'authorId': '2149163534', 'name': 'Shuyan Zhou'}, {'authorId': '40027632', 'name': 'Frank F. Xu'}, {'authorId': '2115313911', 'name': 'Hao Zhu'}, {'authorId': '144101734', 'name': 'Xuhui Zhou'}, {'authorId': '145250604', 'name': 'Robert Lo'}, {'authorId': '66820957', 'name': 'Abishek Sridhar'}, {'authorId': '144691454', 'name': 'Xianyi Cheng'}, {'authorId': '3312309', 'name': 'Yonatan Bisk'}, {'authorId': '47070750', 'name': 'Daniel Fried'}, {'authorId': '47051926', 'name': 'Uri Alon'}, {'authorId': '1700325', 'name': 'Graham Neubig'}]","This paper builds an environment for language-guided agents that is highly realistic and reproducible, and creates an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management."
Daphne Ippolito,7975935,Daphne Ippolito,https://www.semanticscholar.org/author/7975935,25,[],44,6460,03fb535de5cfcf435705a079334ac60f501226ab,"{'DBLP': 'journals/corr/abs-2309-04858', 'ACL': '2023.inlg-main.28', 'ArXiv': '2309.04858', 'DOI': '10.48550/arXiv.2309.04858', 'CorpusId': 261681722}",https://www.semanticscholar.org/paper/03fb535de5cfcf435705a079334ac60f501226ab,Reverse-Engineering Decoding Strategies Given Blackbox Access to a Language Generation System,"Neural language models are increasingly deployed into APIs and websites that allow a user to pass in a prompt and receive generated text. Many of these systems do not reveal generation parameters. In this paper, we present methods to reverse-engineer the decoding method used to generate text (i.e., top-_k_ or nucleus sampling). Our ability to discover which decoding strategy was used has implications for detecting generated text. Additionally, the process of discovering the decoding strategy can reveal biases caused by selecting decoding settings which severely truncate a model’s predicted distributions. We perform our attack on several families of open-source language models, as well as on production systems (e.g., ChatGPT).",International Conference on Natural Language Generation,2023,15,3,0,True,"{'url': 'https://arxiv.org/pdf/2309.04858', 'status': None}",['Computer Science'],{'pages': '396-406'},"[{'authorId': '7975935', 'name': 'Daphne Ippolito'}, {'authorId': '2483738', 'name': 'Nicholas Carlini'}, {'authorId': '3844009', 'name': 'Katherine Lee'}, {'authorId': '3490923', 'name': 'Milad Nasr'}, {'authorId': '2239157286', 'name': 'Yun William Yu'}]","Methods to reverse-engineer the decoding method used to generate text (i.e., top-_k_ or nucleus sampling) are presented, which has implications for detecting generated text."
Daphne Ippolito,7975935,Daphne Ippolito,https://www.semanticscholar.org/author/7975935,25,[],44,6460,1567bcac0ab09269c9d0ff33c9a406132417fab9,"{'ArXiv': '2305.13169', 'DBLP': 'journals/corr/abs-2305-13169', 'DOI': '10.48550/arXiv.2305.13169', 'CorpusId': 258832491}",https://www.semanticscholar.org/paper/1567bcac0ab09269c9d0ff33c9a406132417fab9,"A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity","Pretraining is the preliminary and fundamental step in developing capable language models (LM). Despite this, pretraining data design is critically under-documented and often guided by empirically unsupported intuitions. To address this, we pretrain 28 1.5B parameter decoder-only models, training on data curated (1) at different times, (2) with varying toxicity and quality filters, and (3) with different domain compositions. First, we quantify the effect of pretraining data age. A temporal shift between evaluation data and pretraining data leads to performance degradation, which is not overcome by finetuning. Second, we explore the effect of quality and toxicity filters, showing a trade-off between performance on standard benchmarks and risk of toxic generations. Our findings indicate there does not exist a one-size-fits-all solution to filtering training data. We also find that the effects of different types of filtering are not predictable from text domain characteristics. Lastly, we empirically validate that the inclusion of heterogeneous data sources, like books and web, is broadly beneficial and warrants greater prioritization. These findings constitute the largest set of experiments to validate, quantify, and expose many undocumented intuitions about text pretraining, which we hope will help support more informed data-centric decisions in LM development.",arXiv.org,2023,118,32,1,True,"{'url': 'http://arxiv.org/pdf/2305.13169', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.13169', 'name': 'ArXiv'}","[{'authorId': '29909347', 'name': 'S. Longpre'}, {'authorId': '32918271', 'name': 'Gregory Yauney'}, {'authorId': '49849144', 'name': 'Emily Reif'}, {'authorId': '3844009', 'name': 'Katherine Lee'}, {'authorId': '145625142', 'name': 'Adam Roberts'}, {'authorId': '2368067', 'name': 'Barret Zoph'}, {'authorId': '65855107', 'name': 'Denny Zhou'}, {'authorId': '119640649', 'name': 'Jason Wei'}, {'authorId': '2148473059', 'name': 'Kevin Robinson'}, {'authorId': '38917723', 'name': 'David M. Mimno'}, {'authorId': '7975935', 'name': 'Daphne Ippolito'}]","These findings constitute the largest set of experiments to validate, quantify, and expose many undocumented intuitions about text pretraining, which are hoped to help support more informed data-centric decisions in LM development."
Daphne Ippolito,7975935,Daphne Ippolito,https://www.semanticscholar.org/author/7975935,25,[],44,6460,2e965b5d97c2d6fb4af284307735be39283792ba,"{'DBLP': 'conf/uss/CarliniHNJSTBIW23', 'ArXiv': '2301.13188', 'DOI': '10.48550/arXiv.2301.13188', 'CorpusId': 256389993}",https://www.semanticscholar.org/paper/2e965b5d97c2d6fb4af284307735be39283792ba,Extracting Training Data from Diffusion Models,"Image diffusion models such as DALL-E 2, Imagen, and Stable Diffusion have attracted significant attention due to their ability to generate high-quality synthetic images. In this work, we show that diffusion models memorize individual images from their training data and emit them at generation time. With a generate-and-filter pipeline, we extract over a thousand training examples from state-of-the-art models, ranging from photographs of individual people to trademarked company logos. We also train hundreds of diffusion models in various settings to analyze how different modeling and data decisions affect privacy. Overall, our results show that diffusion models are much less private than prior generative models such as GANs, and that mitigating these vulnerabilities may require new advances in privacy-preserving training.",USENIX Security Symposium,2023,78,222,24,True,"{'url': 'http://arxiv.org/pdf/2301.13188', 'status': None}",['Computer Science'],"{'volume': 'abs/2301.13188', 'name': 'ArXiv'}","[{'authorId': '2483738', 'name': 'Nicholas Carlini'}, {'authorId': '9200194', 'name': 'Jamie Hayes'}, {'authorId': '3490923', 'name': 'Milad Nasr'}, {'authorId': '40844378', 'name': 'Matthew Jagielski'}, {'authorId': '3482535', 'name': 'Vikash Sehwag'}, {'authorId': '2444919', 'name': 'Florian Tramèr'}, {'authorId': '1718064', 'name': 'B. Balle'}, {'authorId': '7975935', 'name': 'Daphne Ippolito'}, {'authorId': '145217343', 'name': 'Eric Wallace'}]","The results show that diffusion models are much less private than prior generative models such as GANs, and that mitigating these vulnerabilities may require new advances in privacy-preserving training."
Daphne Ippolito,7975935,Daphne Ippolito,https://www.semanticscholar.org/author/7975935,25,[],44,6460,8724579d3f126e753a0451d98ff57b165f722e72,"{'ArXiv': '2306.15447', 'DBLP': 'journals/corr/abs-2306-15447', 'DOI': '10.48550/arXiv.2306.15447', 'CorpusId': 259262181}",https://www.semanticscholar.org/paper/8724579d3f126e753a0451d98ff57b165f722e72,Are aligned neural networks adversarially aligned?,"Large language models are now tuned to align with the goals of their creators, namely to be""helpful and harmless.""These models should respond helpfully to user questions, but refuse to answer requests that could cause harm. However, adversarial users can construct inputs which circumvent attempts at alignment. In this work, we study to what extent these models remain aligned, even when interacting with an adversarial user who constructs worst-case inputs (adversarial examples). These inputs are designed to cause the model to emit harmful content that would otherwise be prohibited. We show that existing NLP-based optimization attacks are insufficiently powerful to reliably attack aligned text models: even when current NLP-based attacks fail, we can find adversarial inputs with brute force. As a result, the failure of current attacks should not be seen as proof that aligned text models remain aligned under adversarial inputs. However the recent trend in large-scale ML models is multimodal models that allow users to provide images that influence the text that is generated. We show these models can be easily attacked, i.e., induced to perform arbitrary un-aligned behavior through adversarial perturbation of the input image. We conjecture that improved NLP attacks may demonstrate this same level of adversarial control over text-only models.",arXiv.org,2023,53,67,8,True,"{'url': 'http://arxiv.org/pdf/2306.15447', 'status': None}",['Computer Science'],"{'volume': 'abs/2306.15447', 'name': 'ArXiv'}","[{'authorId': '2483738', 'name': 'Nicholas Carlini'}, {'authorId': '3490923', 'name': 'Milad Nasr'}, {'authorId': '1415982317', 'name': 'Christopher A. Choquette-Choo'}, {'authorId': '40844378', 'name': 'Matthew Jagielski'}, {'authorId': '8687620', 'name': 'Irena Gao'}, {'authorId': '2135149490', 'name': 'Anas Awadalla'}, {'authorId': '2572525', 'name': 'Pang Wei Koh'}, {'authorId': '7975935', 'name': 'Daphne Ippolito'}, {'authorId': '3844009', 'name': 'Katherine Lee'}, {'authorId': '2444919', 'name': 'Florian Tramèr'}, {'authorId': '152772922', 'name': 'Ludwig Schmidt'}]","It is shown that existing NLP-based optimization attacks are insufficiently powerful to reliably attack aligned text models, and conjecture that improved NLP attacks may demonstrate this same level of adversarial control over text-only models."
David R Mortensen,3407646,David R. Mortensen,https://www.semanticscholar.org/author/3407646,15,['Carnegie Mellon University'],75,1049,11a571eaab42a6ffb1d938635a093315e392756d,"{'DBLP': 'journals/corr/abs-2309-07423', 'ArXiv': '2309.07423', 'ACL': '2023.wmt-1.40', 'DOI': '10.48550/arXiv.2309.07423', 'CorpusId': 261824661}",https://www.semanticscholar.org/paper/11a571eaab42a6ffb1d938635a093315e392756d,ChatGPT MT: Competitive for High- (but Not Low-) Resource Languages,"Large language models (LLMs) implicitly learn to perform a range of language tasks, including machine translation (MT). Previous studies explore aspects of LLMs’ MT capabilities. However, there exist a wide variety of languages for which recent LLM MT performance has never before been evaluated. Without published experimental evidence on the matter, it is difficult for speakers of the world’s diverse languages to know how and whether they can use LLMs for their languages. We present the first experimental evidence for an expansive set of 204 languages, along with MT cost analysis, using the FLORES-200 benchmark. Trends reveal that GPT models approach or exceed traditional MT model performance for some high-resource languages (HRLs) but consistently lag for low-resource languages (LRLs), under-performing traditional MT for 84.1% of languages we covered. Our analysis reveals that a language’s resource level is the most important feature in determining ChatGPT’s relative ability to translate it, and suggests that ChatGPT is especially disadvantaged for LRLs and African languages.",Conference on Machine Translation,2023,24,1,0,True,"{'url': 'https://arxiv.org/pdf/2309.07423', 'status': None}",['Computer Science'],"{'volume': 'abs/2309.07423', 'name': 'ArXiv'}","[{'authorId': '2240569372', 'name': 'Nathaniel R. Robinson'}, {'authorId': '1988654955', 'name': 'Perez Ogayo'}, {'authorId': '3407646', 'name': 'David R. Mortensen'}, {'authorId': '1700325', 'name': 'Graham Neubig'}]","This work presents the first experimental evidence for an expansive set of 204 languages, along with MT cost analysis, using the FLORES-200 benchmark, and reveals that a language’s resource level is the most important feature in determining ChatGPT's relative ability to translate it, and suggests thatChatGPT is especially disadvantaged for LRLs and African languages."
David R Mortensen,3407646,David R. Mortensen,https://www.semanticscholar.org/author/3407646,15,['Carnegie Mellon University'],75,1049,17fbffb05fa14e21d1c506fd5f0f568b955fe983,"{'DBLP': 'conf/emnlp/Ahia0GKMST23', 'ArXiv': '2305.13707', 'DOI': '10.48550/arXiv.2305.13707', 'CorpusId': 258841465}",https://www.semanticscholar.org/paper/17fbffb05fa14e21d1c506fd5f0f568b955fe983,Do All Languages Cost the Same? Tokenization in the Era of Commercial Language Models,"Language models have graduated from being research prototypes to commercialized products offered as web APIs, and recent works have highlighted the multilingual capabilities of these products. The API vendors charge their users based on usage, more specifically on the number of ``tokens'' processed or generated by the underlying language models. What constitutes a token, however, is training data and model dependent with a large variance in the number of tokens required to convey the same information in different languages. In this work, we analyze the effect of this non-uniformity on the fairness of an API's pricing policy across languages. We conduct a systematic analysis of the cost and utility of OpenAI's language model API on multilingual benchmarks in 22 typologically diverse languages. We show evidence that speakers of a large number of the supported languages are overcharged while obtaining poorer results. These speakers tend to also come from regions where the APIs are less affordable to begin with. Through these analyses, we aim to increase transparency around language model APIs' pricing policies and encourage the vendors to make them more equitable.",Conference on Empirical Methods in Natural Language Processing,2023,82,11,2,True,"{'url': 'http://arxiv.org/pdf/2305.13707', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.13707', 'name': 'ArXiv'}","[{'authorId': '1452686038', 'name': 'Orevaoghene Ahia'}, {'authorId': '51467955', 'name': 'Sachin Kumar'}, {'authorId': '1821892', 'name': 'Hila Gonen'}, {'authorId': '11348687', 'name': 'Jungo Kasai'}, {'authorId': '3407646', 'name': 'David R. Mortensen'}, {'authorId': '144365875', 'name': 'Noah A. Smith'}, {'authorId': '2073587169', 'name': 'Yulia Tsvetkov'}]",This work conducts a systematic analysis of the cost and utility of OpenAI's language model API on multilingual benchmarks in 22 typologically diverse languages and shows evidence that speakers of a large number of the supported languages are overcharged while obtaining poorer results.
David R Mortensen,3407646,David R. Mortensen,https://www.semanticscholar.org/author/3407646,15,['Carnegie Mellon University'],75,1049,659be1ff350634f50cc066d258ee6a45e697e552,"{'DBLP': 'conf/sigmorphon/HeTR0MNL23', 'ACL': '2023.sigmorphon-1.22', 'DOI': '10.18653/v1/2023.sigmorphon-1.22', 'CorpusId': 259833803}",https://www.semanticscholar.org/paper/659be1ff350634f50cc066d258ee6a45e697e552,SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing,"In our submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), we explore approaches to data augmentation and modeling across seven low-resource languages. For data augmentation, we explore two approaches: creating artificial data from the provided training data and utilizing existing IGT resources in other languages. On the modeling side, we test an enhanced version of the provided token classification baseline as well as a pretrained multilingual seq2seq model. Additionally, we apply post-correction using a dictionary for Gitksan, the language with the smallest amount of data. We find that our token classification models are the best performing, with the highest word-level accuracy for Arapaho and highest morpheme-level accuracy for Gitksan out of all submissions. We also show that data augmentation is an effective strategy, though applying artificial data pretraining has very different effects across both models tested.",Special Interest Group on Computational Morphology and Phonology Workshop,2023,18,2,0,True,"{'url': 'https://aclanthology.org/2023.sigmorphon-1.22.pdf', 'status': None}",['Computer Science'],{'pages': '209-216'},"[{'authorId': '2107034039', 'name': 'Taiqi He'}, {'authorId': '2219036626', 'name': 'Lindia Tjuatja'}, {'authorId': '2067645226', 'name': 'Nathaniel R. Robinson'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '3407646', 'name': 'David R. Mortensen'}, {'authorId': '1700325', 'name': 'Graham Neubig'}, {'authorId': '145585627', 'name': 'L. Levin'}]","In this submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), approaches to data augmentation and modeling across seven low-resource languages are explored and token classification models are found to be the best performing."
David R Mortensen,3407646,David R. Mortensen,https://www.semanticscholar.org/author/3407646,15,['Carnegie Mellon University'],75,1049,7a08051aac75a809737096e39820bf836908d4e1,"{'ACL': '2023.cxgsnlp-1.10', 'ArXiv': '2302.02178', 'DBLP': 'journals/corr/abs-2302-02178', 'DOI': '10.48550/arXiv.2302.02178', 'CorpusId': 256615802}",https://www.semanticscholar.org/paper/7a08051aac75a809737096e39820bf836908d4e1,Construction Grammar Provides Unique Insight into Neural Language Models,"Construction Grammar (CxG) has recently been used as the basis for probing studies that have investigated the performance of large pretrained language models (PLMs) with respect to the structure and meaning of constructions. In this position paper, we make suggestions for the continuation and augmentation of this line of research. We look at probing methodology that was not designed with CxG in mind, as well as probing methodology that was designed for specific constructions. We analyse selected previous work in detail, and provide our view of the most important challenges and research questions that this promising new field faces.",CXGSNLP,2023,42,7,0,True,"{'url': 'http://arxiv.org/pdf/2302.02178', 'status': None}",['Computer Science'],"{'volume': 'abs/2302.02178', 'name': 'ArXiv'}","[{'authorId': '31832571', 'name': 'Leonie Weissweiler'}, {'authorId': '2107034039', 'name': 'Taiqi He'}, {'authorId': '32498559', 'name': 'Naoki Otani'}, {'authorId': '3407646', 'name': 'David R. Mortensen'}, {'authorId': '145585627', 'name': 'L. Levin'}, {'authorId': '144418438', 'name': 'Hinrich Schütze'}]","The view of the most important challenges and research questions that this promising new field of research faces is provided, and an analysis of selected previous work in detail is provided."
David R Mortensen,3407646,David R. Mortensen,https://www.semanticscholar.org/author/3407646,15,['Carnegie Mellon University'],75,1049,bf42c0462d1415cdde877c90d58da11545407b8a,"{'ACL': '2023.sigmorphon-1.7', 'DBLP': 'conf/sigmorphon/MortensenGHRATL23', 'DOI': '10.18653/v1/2023.sigmorphon-1.7', 'CorpusId': 259833816}",https://www.semanticscholar.org/paper/bf42c0462d1415cdde877c90d58da11545407b8a,"Generalized Glossing Guidelines: An Explicit, Human- and Machine-Readable, Item-and-Process Convention for Morphological Annotation","Interlinear glossing provides a vital type of morphosyntactic annotation, both for linguists and language revitalists, and numerous conventions exist for representing it formally and computationally. Some of these formats are human readable; others are machine readable. Some are easy to edit with general-purpose tools. Few represent non-concatentative processes like infixation, reduplication, mutation, truncation, and tonal overwriting in a consistent and formally rigorous way (on par with affixation). We propose an annotation conventionâ€”Generalized Glossing Guidelines (GGG) that combines all of these positive properties using an Item-and-Process (IP) framework. We describe the format, demonstrate its linguistic adequacy, and compare it with two other interlinear glossed text annotation schemes.",Special Interest Group on Computational Morphology and Phonology Workshop,2023,19,0,0,True,"{'url': 'https://aclanthology.org/2023.sigmorphon-1.7.pdf', 'status': None}",['Computer Science'],{'pages': '58-67'},"[{'authorId': '3407646', 'name': 'David R. Mortensen'}, {'authorId': '2223096956', 'name': 'Ela Gulsen'}, {'authorId': '2107034039', 'name': 'Taiqi He'}, {'authorId': '2067645226', 'name': 'Nathaniel R. Robinson'}, {'authorId': '1798729', 'name': 'Jonathan D. Amith'}, {'authorId': '2219036626', 'name': 'Lindia Tjuatja'}, {'authorId': '145585627', 'name': 'L. Levin'}]","An annotation convention is proposed that combines all of these positive properties using an Item-and-Process (IP) framework, and its linguistic adequacy is demonstrated, and it is compared with two other interlinear glossed text annotation schemes."
David R Mortensen,3407646,David R. Mortensen,https://www.semanticscholar.org/author/3407646,15,['Carnegie Mellon University'],75,1049,c5c6d006e399386c99068daba138021a62d6cc17,"{'DBLP': 'conf/acl/KimCCM23', 'ACL': '2023.acl-short.3', 'ArXiv': '2307.01896', 'DOI': '10.48550/arXiv.2307.01896', 'CorpusId': 259342672}",https://www.semanticscholar.org/paper/c5c6d006e399386c99068daba138021a62d6cc17,Transformed Protoform Reconstruction,"Protoform reconstruction is the task of inferring what morphemes or words appeared like in the ancestral languages of a set of daughter languages. Meloni et al (2021) achieved the state-of-the-art on Latin protoform reconstruction with an RNN-based encoder-decoder with attention model. We update their model with the state-of-the-art seq2seq model: the Transformer. Our model outperforms their model on a suite of different metrics on two different datasets: their Romance data of 8,000 cognates spanning 5 languages and a Chinese dataset (Hou 2004) of 800+ cognates spanning 39 varieties. We also probe our model for potential phylogenetic signal contained in the model. Our code is publicly available at https://github.com/cmu-llab/acl-2023.",Annual Meeting of the Association for Computational Linguistics,2023,36,1,0,True,"{'url': 'https://arxiv.org/pdf/2307.01896', 'status': None}",['Computer Science'],{'pages': '24-38'},"[{'authorId': '2221149804', 'name': 'Young Min Kim'}, {'authorId': '2187555978', 'name': 'Kalvin Chang'}, {'authorId': '31248497', 'name': 'Chenxuan Cui'}, {'authorId': '3407646', 'name': 'David R. Mortensen'}]","The Meloni et al (2021) model is updated with the state-of-the-art seq2seq model: the Transformer, which outperforms their model on a suite of different metrics on two different datasets: their Romance data of 8,000 cognate spanning 5 languages and a Chinese dataset (Hou 2004) of 800+ cognates spanning 39 varieties."
David R Mortensen,3407646,David R. Mortensen,https://www.semanticscholar.org/author/3407646,15,['Carnegie Mellon University'],75,1049,db14d05b18ec852f8afcd6d2d10bbd9eeaef8325,"{'DBLP': 'journals/corr/abs-2304-02541', 'ArXiv': '2304.02541', 'DOI': '10.48550/arXiv.2304.02541', 'CorpusId': 257952358}",https://www.semanticscholar.org/paper/db14d05b18ec852f8afcd6d2d10bbd9eeaef8325,PWESuite: Phonetic Word Embeddings and Tasks They Facilitate,"Mapping words into a fixed-dimensional vector space is the backbone of modern NLP. While most word embedding methods successfully encode semantic information, they overlook phonetic information that is crucial for many tasks. We develop three methods that use articulatory features to build phonetically informed word embeddings. To address the inconsistent evaluation of existing phonetic word embedding methods, we also contribute a task suite to fairly evaluate past, current, and future methods. We evaluate both (1) intrinsic aspects of phonetic word embeddings, such as word retrieval and correlation with sound similarity, and (2) extrinsic performance on tasks such as rhyme and cognate detection and sound analogies. We hope our task suite will promote reproducibility and inspire future phonetic embedding research.",arXiv.org,2023,71,0,0,True,"{'url': 'http://arxiv.org/pdf/2304.02541', 'status': None}",['Computer Science'],"{'volume': 'abs/2304.02541', 'name': 'ArXiv'}","[{'authorId': '1429837660', 'name': 'Vilém Zouhar'}, {'authorId': '2187555978', 'name': 'Kalvin Chang'}, {'authorId': '31248497', 'name': 'Chenxuan Cui'}, {'authorId': '2190909003', 'name': 'Nathaniel Carlson'}, {'authorId': '2067645226', 'name': 'Nathaniel R. Robinson'}, {'authorId': '2790926', 'name': 'Mrinmaya Sachan'}, {'authorId': '3407646', 'name': 'David R. Mortensen'}]","Three methods that use articulatory features to build phonetically informed word embeddings are developed that address the inconsistent evaluation of existing phonetic word embedding methods and contribute a task suite to fairly evaluate past, current, and future methods."
Eric P. Xing,143977260,E. Xing,https://www.semanticscholar.org/author/143977260,103,[],631,46108,075b751201f549daeba9840f78768f4ceb507e17,"{'DBLP': 'journals/corr/abs-2306-07916', 'ArXiv': '2306.07916', 'DOI': '10.48550/arXiv.2306.07916', 'CorpusId': 259144964}",https://www.semanticscholar.org/paper/075b751201f549daeba9840f78768f4ceb507e17,Identification of Nonlinear Latent Hierarchical Models,"Identifying latent variables and causal structures from observational data is essential to many real-world applications involving biological data, medical data, and unstructured data such as images and languages. However, this task can be highly challenging, especially when observed variables are generated by causally related latent variables and the relationships are nonlinear. In this work, we investigate the identification problem for nonlinear latent hierarchical causal models in which observed variables are generated by a set of causally related latent variables, and some latent variables may not have observed children. We show that the identifiability of causal structures and latent variables (up to invertible transformations) can be achieved under mild assumptions: on causal structures, we allow for multiple paths between any pair of variables in the graph, which relaxes latent tree assumptions in prior work; on structural functions, we permit general nonlinearity and multi-dimensional continuous variables, alleviating existing work's parametric assumptions. Specifically, we first develop an identification criterion in the form of novel identifiability guarantees for an elementary latent variable model. Leveraging this criterion, we show that both causal structures and latent variables of the hierarchical model can be identified asymptotically by explicitly constructing an estimation procedure. To the best of our knowledge, our work is the first to establish identifiability guarantees for both causal structures and latent variables in nonlinear latent hierarchical models.",arXiv.org,2023,47,5,0,True,"{'url': 'http://arxiv.org/pdf/2306.07916', 'status': None}","['Computer Science', 'Mathematics']","{'volume': 'abs/2306.07916', 'name': 'ArXiv'}","[{'authorId': '2069275317', 'name': 'Lingjing Kong'}, {'authorId': '1938684', 'name': 'Biwei Huang'}, {'authorId': '47060248', 'name': 'Feng Xie'}, {'authorId': '143977260', 'name': 'E. Xing'}, {'authorId': '1784472', 'name': 'Yuejie Chi'}, {'authorId': '2119016656', 'name': 'Kun Zhang'}]",This work develops an identification criterion in the form of novel identifiability guarantees for an elementary latent variable model and shows that both causal structures and latent variables of the hierarchical model can be identified asymptotically by explicitly constructing an estimation procedure.
Eric P. Xing,143977260,E. Xing,https://www.semanticscholar.org/author/143977260,103,[],631,46108,8cc1cd002bfc36a8cba8bcbe63d32eacc656097f,"{'DBLP': 'conf/cvpr/LiuZCZYELX23', 'ArXiv': '2303.10598', 'DOI': '10.1109/CVPR52729.2023.00806', 'CorpusId': 257632294}",https://www.semanticscholar.org/paper/8cc1cd002bfc36a8cba8bcbe63d32eacc656097f,StyleRF: Zero-Shot 3D Style Transfer of Neural Radiance Fields,"3D style transfer aims to render stylized novel views of a 3D scene with multiview consistency. However, most existing work suffers from a three-way dilemma over accurate geometry reconstruction, high-quality stylization, and being generalizable to arbitrary new styles. We propose StyleRF (Style Radiance Fields), an innovative 3D style transfer technique that resolves the three-way dilemma by performing style transformation within the feature space of a radiance field. StyleRF employs an explicit grid of high-level features to represent 3D scenes, with which highfidelity geometry can be reliably restored via volume rendering. In addition, it transforms the grid features according to the reference style which directly leads to high-quality zero-shot style transfer. StyleRF consists of two innovative designs. The first is sampling-invariant content transformation that makes the transformation invariant to the holistic statistics of the sampled 3D points and accordingly ensures multi-view consistency. The second is deferred style transformation of 2D feature maps which is equivalent to the transformation of 3D points but greatly reduces memory footprint without degrading multi-view consistency. Extensive experiments show that StyleRF achieves superior 3D stylization quality with precise geometry reconstruction and it can generalize to various new styles in a zero-shot manner. Project website: https://kunhao-liu.github.io/StyleRF/",Computer Vision and Pattern Recognition,2023,74,12,3,True,"{'url': 'https://arxiv.org/pdf/2303.10598', 'status': None}",['Computer Science'],"{'pages': '8338-8348', 'name': '2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)'}","[{'authorId': '2212199002', 'name': 'Kunhao Liu'}, {'authorId': '51111483', 'name': 'Fangneng Zhan'}, {'authorId': '2109275146', 'name': 'Yiwen Chen'}, {'authorId': '2121386031', 'name': 'Jiahui Zhang'}, {'authorId': '101206696', 'name': 'Yingchen Yu'}, {'authorId': '30889568', 'name': 'Abdulmotaleb El Saddik'}, {'authorId': '1771189', 'name': 'Shijian Lu'}, {'authorId': '143977260', 'name': 'E. Xing'}]","StyleRF (Style Radiance Fields), an innovative 3D style transfer technique that resolves the three-way dilemma by performing style transformation within the feature space of a radiance field, achieves superior 3D stylization quality with precise geometry reconstruction and it can generalize to various new styles in a zero-shot manner."
Eric P. Xing,143977260,E. Xing,https://www.semanticscholar.org/author/143977260,103,[],631,46108,a0a79dad89857a96f8f71b14238e5237cbfc4787,"{'DBLP': 'journals/corr/abs-2306-05685', 'ArXiv': '2306.05685', 'DOI': '10.48550/arXiv.2306.05685', 'CorpusId': 259129398}",https://www.semanticscholar.org/paper/a0a79dad89857a96f8f71b14238e5237cbfc4787,Judging LLM-as-a-judge with MT-Bench and Chatbot Arena,"Evaluating large language model (LLM) based chat assistants is challenging due to their broad capabilities and the inadequacy of existing benchmarks in measuring human preferences. To address this, we explore using strong LLMs as judges to evaluate these models on more open-ended questions. We examine the usage and limitations of LLM-as-a-judge, including position, verbosity, and self-enhancement biases, as well as limited reasoning ability, and propose solutions to mitigate some of them. We then verify the agreement between LLM judges and human preferences by introducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80% agreement, the same level of agreement between humans. Hence, LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain. Additionally, we show our benchmark and traditional benchmarks complement each other by evaluating several variants of LLaMA and Vicuna. The MT-bench questions, 3K expert votes, and 30K conversations with human preferences are publicly available at https://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge.",arXiv.org,2023,59,690,126,True,"{'url': 'https://arxiv.org/pdf/2306.05685', 'status': None}",['Computer Science'],"{'volume': 'abs/2306.05685', 'name': 'ArXiv'}","[{'authorId': '2149970173', 'name': 'Lianmin Zheng'}, {'authorId': '2537924', 'name': 'Wei-Lin Chiang'}, {'authorId': '2209360681', 'name': 'Ying Sheng'}, {'authorId': '92721493', 'name': 'Siyuan Zhuang'}, {'authorId': '1390573666', 'name': 'Zhanghao Wu'}, {'authorId': '2152482391', 'name': 'Yonghao Zhuang'}, {'authorId': '143872641', 'name': 'Zi Lin'}, {'authorId': '2141335450', 'name': 'Zhuohan Li'}, {'authorId': '2117961435', 'name': 'Dacheng Li'}, {'authorId': '143977260', 'name': 'E. Xing'}, {'authorId': '145140331', 'name': 'Haotong Zhang'}, {'authorId': '144307989', 'name': 'Joseph Gonzalez'}, {'authorId': '2055174324', 'name': 'I. Stoica'}]","The results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80% agreement, the same level of agreement between humans, and LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain."
Eric P. Xing,143977260,E. Xing,https://www.semanticscholar.org/author/143977260,103,[],631,46108,dcb4f2b9b0e6da0d629878d1ad0469aee3df2020,"{'DBLP': 'journals/corr/abs-2306-04898', 'ArXiv': '2306.04898', 'DOI': '10.1109/CVPR52729.2023.00765', 'CorpusId': 259108864}",https://www.semanticscholar.org/paper/dcb4f2b9b0e6da0d629878d1ad0469aee3df2020,Understanding Masked Autoencoders via Hierarchical Latent Variable Models,"Masked autoencoder (MAE), a simple and effective self-supervised learning framework based on the reconstruction of masked image regions, has recently achieved prominent success in a variety of vision tasks. Despite the emergence of intriguing empirical observations on MAE, a theoretically principled understanding is still lacking. In this work, we formally characterize and justify existing empirical in-sights and provide theoretical guarantees of MAE. We formulate the underlying data-generating process as a hierarchical latent variable model, and show that under reasonable assumptions, MAE provably identifies a set of latent variables in the hierarchical model, explaining why MAE can extract high-level information from pixels. Further, we show how key hyperparameters in MAE (the masking ratio and the patch size) determine which true latent variables to be recovered, therefore influencing the level of semantic information in the representation. Specifically, extremely large or small masking ratios inevitably lead to low-level representations. Our theory offers coherent explanations of existing empirical observations and provides insights for potential empirical improvements and fundamental limitations of the masked-reconstruction paradigm. We conduct extensive experiments to validate our theoretical insights.",Computer Vision and Pattern Recognition,2023,74,8,0,True,"{'url': 'https://arxiv.org/pdf/2306.04898', 'status': None}",['Computer Science'],"{'pages': '7918-7928', 'name': '2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)'}","[{'authorId': '2069275317', 'name': 'Lingjing Kong'}, {'authorId': '1384374825', 'name': 'Martin Q. Ma'}, {'authorId': '2155315836', 'name': 'Guan-Hong Chen'}, {'authorId': '143977260', 'name': 'E. Xing'}, {'authorId': '1784472', 'name': 'Yuejie Chi'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}, {'authorId': '2175349484', 'name': 'Kun Zhang'}]","This work formally characterize and justify existing empirical in-sights and provide theoretical guarantees of MAE, and formulate the underlying data-generating process as a hierarchical latent variable model, and shows that under reasonable assumptions, MAE provably identifies a set of latent variables in the hierarchical model."
Emma Strubell,2268272,Emma Strubell,https://www.semanticscholar.org/author/2268272,17,[],62,4143,1433b8d43d446fcc7f3e1370b22f744a4dd7c8e4,"{'DBLP': 'conf/emnlp/GururajaBNWS23', 'ArXiv': '2310.07715', 'DOI': '10.48550/arXiv.2310.07715', 'CorpusId': 263834772}",https://www.semanticscholar.org/paper/1433b8d43d446fcc7f3e1370b22f744a4dd7c8e4,"To Build Our Future, We Must Know Our Past: Contextualizing Paradigm Shifts in Natural Language Processing","NLP is in a period of disruptive change that is impacting our methodologies, funding sources, and public perception. In this work, we seek to understand how to shape our future by better understanding our past. We study factors that shape NLP as a field, including culture, incentives, and infrastructure by conducting long-form interviews with 26 NLP researchers of varying seniority, research area, institution, and social identity. Our interviewees identify cyclical patterns in the field, as well as new shifts without historical parallel, including changes in benchmark culture and software infrastructure. We complement this discussion with quantitative analysis of citation, authorship, and language use in the ACL Anthology over time. We conclude by discussing shared visions, concerns, and hopes for the future of NLP. We hope that this study of our field's past and present can prompt informed discussion of our community's implicit norms and more deliberate action to consciously shape the future.",Conference on Empirical Methods in Natural Language Processing,2023,43,0,0,True,"{'url': 'https://arxiv.org/pdf/2310.07715', 'status': None}",['Computer Science'],{'pages': '13310-13325'},"[{'authorId': '2165225404', 'name': 'Sireesh Gururaja'}, {'authorId': '2138301112', 'name': 'Amanda Bertsch'}, {'authorId': '2166313248', 'name': 'Clara Na'}, {'authorId': '35529938', 'name': 'D. Widder'}, {'authorId': '2268272', 'name': 'Emma Strubell'}]","This work conducts long-form interviews with 26 NLP researchers of varying seniority, research area, institution, and social identity to study factors that shape NLP as a field, including culture, incentives, and infrastructure."
Emma Strubell,2268272,Emma Strubell,https://www.semanticscholar.org/author/2268272,17,[],62,4143,45e50baac4d341f0cf1a40af096bfa9c3f555235,"{'ArXiv': '2312.05662', 'DBLP': 'journals/corr/abs-2312-05662', 'DOI': '10.18653/v1/2023.emnlp-main.161', 'CorpusId': 266163873}",https://www.semanticscholar.org/paper/45e50baac4d341f0cf1a40af096bfa9c3f555235,Understanding the Effect of Model Compression on Social Bias in Large Language Models,"Large Language Models (LLMs) trained with self-supervision on vast corpora of web text fit to the social biases of that text. Without intervention, these social biases persist in the model's predictions in downstream tasks, leading to representational harm. Many strategies have been proposed to mitigate the effects of inappropriate social biases learned during pretraining. Simultaneously, methods for model compression have become increasingly popular to reduce the computational burden of LLMs. Despite the popularity and need for both approaches, little work has been done to explore the interplay between these two. We perform a carefully controlled study of the impact of model compression via quantization and knowledge distillation on measures of social bias in LLMs. Longer pretraining and larger models led to higher social bias, and quantization showed a regularizer effect with its best trade-off around 20% of the original pretraining time.",Conference on Empirical Methods in Natural Language Processing,2023,37,2,0,True,"{'url': 'https://aclanthology.org/2023.emnlp-main.161.pdf', 'status': None}",['Computer Science'],"{'volume': 'abs/2312.05662', 'name': 'ArXiv'}","[{'authorId': '2273536347', 'name': 'Gustavo Gonçalves'}, {'authorId': '2268272', 'name': 'Emma Strubell'}]","A carefully controlled study of the impact of model compression via quantization and knowledge distillation on measures of social bias in LLMs finds that longer pretraining and larger models led to higher social bias, and quantization showed a regularizer effect with its best trade-off around 20% of the original pretraining time."
Emma Strubell,2268272,Emma Strubell,https://www.semanticscholar.org/author/2268272,17,[],62,4143,667ba2e8f1933b6c32e9672012526904b4c5dc31,"{'DBLP': 'journals/corr/abs-2306-16900', 'ArXiv': '2306.16900', 'DOI': '10.48550/arXiv.2306.16900', 'CorpusId': 259287420}",https://www.semanticscholar.org/paper/667ba2e8f1933b6c32e9672012526904b4c5dc31,Surveying (Dis)Parities and Concerns of Compute Hungry NLP Research,"Many recent improvements in NLP stem from the development and use of large pre-trained language models (PLMs) with billions of parameters. Large model sizes makes computational cost one of the main limiting factors for training and evaluating such models; and has raised severe concerns about the sustainability, reproducibility, and inclusiveness for researching PLMs. These concerns are often based on personal experiences and observations. However, there had not been any large-scale surveys that investigate them. In this work, we provide a first attempt to quantify these concerns regarding three topics, namely, environmental impact, equity, and impact on peer reviewing. By conducting a survey with 312 participants from the NLP community, we capture existing (dis)parities between different and within groups with respect to seniority, academia, and industry; and their impact on the peer reviewing process. For each topic, we provide an analysis and devise recommendations to mitigate found disparities, some of which already successfully implemented. Finally, we discuss additional concerns raised by many participants in free-text responses.",arXiv.org,2023,21,2,0,True,"{'url': 'http://arxiv.org/pdf/2306.16900', 'status': None}",['Computer Science'],"{'volume': 'abs/2306.16900', 'name': 'ArXiv'}","[{'authorId': '2108605329', 'name': 'Ji-Ung Lee'}, {'authorId': '1389023854', 'name': 'Haritz Puerto'}, {'authorId': '51436004', 'name': 'Betty van Aken'}, {'authorId': '3043844', 'name': 'Yuki Arase'}, {'authorId': '39774809', 'name': 'J. Forde'}, {'authorId': '113320522', 'name': 'Leon Derczynski'}, {'authorId': '1404060894', 'name': ""Andreas Ruckl'e""}, {'authorId': '69033154', 'name': 'Iryna Gurevych'}, {'authorId': '4671928', 'name': 'Roy Schwartz'}, {'authorId': '2268272', 'name': 'Emma Strubell'}, {'authorId': '34176020', 'name': 'Jesse Dodge'}]","This work captures existing (dis)parities between different and within groups with respect to seniority, academia, and industry; and their impact on the peer reviewing process; and provides an analysis and devise recommendations to mitigate found disparities."
Emma Strubell,2268272,Emma Strubell,https://www.semanticscholar.org/author/2268272,17,[],62,4143,71debf888acd57bb1baa4c146f31e58c66ea51af,"{'ACL': '2023.sustainlp-1.10', 'DBLP': 'conf/sustainlp/ZhangSH23', 'DOI': '10.18653/v1/2023.sustainlp-1.10', 'CorpusId': 259833786}",https://www.semanticscholar.org/paper/71debf888acd57bb1baa4c146f31e58c66ea51af,On the Interactions of Structural Constraints and Data Resources for Structured Prediction,"In this work, we provide an analysis on the interactions of the effectiveness of decoding with structural constraints and the amount of available training data for structured prediction tasks in NLP. Our exploration adopts a simple protocol that enforces constraints upon constraint-agnostic local models at testing time. With evaluations on three typical structured prediction tasks (named entity recognition, dependency parsing, and event argument extraction), we find that models trained with less data predict outputs with more structural violations in greedy decoding mode. Incorporating constraints provides consistent performance improvements and such benefits are larger in lower resource scenarios. Moreover, there are similar patterns with regard to the model sizes and more efficient models tend to enjoy more benefits. Finally, we also investigate settings with genre transfer and discover patterns that are related to domain discrepancies.",SUSTAINLP,2023,50,0,0,True,"{'url': 'https://aclanthology.org/2023.sustainlp-1.10.pdf', 'status': None}",['Computer Science'],{'pages': '147-157'},"[{'authorId': '1929423', 'name': 'Zhisong Zhang'}, {'authorId': '2268272', 'name': 'Emma Strubell'}, {'authorId': '144547315', 'name': 'E. Hovy'}]",An analysis on the interactions of the effectiveness of decoding with structural constraints and the amount of available training data for structured prediction tasks in NLP finds that models trained with less data predict outputs with more structural violations in greedy decoding mode.
Emma Strubell,2268272,Emma Strubell,https://www.semanticscholar.org/author/2268272,17,[],62,4143,84d20ad9f42d80dfd5130a6362d5422be8a6bdc3,"{'ArXiv': '2307.09701', 'DBLP': 'journals/corr/abs-2307-09701', 'DOI': '10.48550/arXiv.2307.09701', 'CorpusId': 259982429}",https://www.semanticscholar.org/paper/84d20ad9f42d80dfd5130a6362d5422be8a6bdc3,Efficiency Pentathlon: A Standardized Arena for Efficiency Evaluation,"Rising computational demands of modern natural language processing (NLP) systems have increased the barrier to entry for cutting-edge research while posing serious environmental concerns. Yet, progress on model efficiency has been impeded by practical challenges in model evaluation and comparison. For example, hardware is challenging to control due to disparate levels of accessibility across different institutions. Moreover, improvements in metrics such as FLOPs often fail to translate to progress in real-world applications. In response, we introduce Pentathlon, a benchmark for holistic and realistic evaluation of model efficiency. Pentathlon focuses on inference, which accounts for a majority of the compute in a model's lifecycle. It offers a strictly-controlled hardware platform, and is designed to mirror real-world applications scenarios. It incorporates a suite of metrics that target different aspects of efficiency, including latency, throughput, memory overhead, and energy consumption. Pentathlon also comes with a software library that can be seamlessly integrated into any codebase and enable evaluation. As a standardized and centralized evaluation platform, Pentathlon can drastically reduce the workload to make fair and reproducible efficiency comparisons. While initially focused on natural language processing (NLP) models, Pentathlon is designed to allow flexible extension to other fields. We envision Pentathlon will stimulate algorithmic innovations in building efficient models, and foster an increased awareness of the social and environmental implications in the development of future-generation NLP models.",arXiv.org,2023,64,4,0,True,"{'url': 'https://arxiv.org/pdf/2307.09701', 'status': None}",['Computer Science'],"{'volume': 'abs/2307.09701', 'name': 'ArXiv'}","[{'authorId': '1818378366', 'name': 'Hao Peng'}, {'authorId': '31961604', 'name': 'Qingqing Cao'}, {'authorId': '34176020', 'name': 'Jesse Dodge'}, {'authorId': '39139825', 'name': 'Matthew E. Peters'}, {'authorId': '152793333', 'name': 'Jared Fernandez'}, {'authorId': '20662387', 'name': 'Tom Sherborne'}, {'authorId': '46258841', 'name': 'Kyle Lo'}, {'authorId': '46181683', 'name': 'Sam Skjonsberg'}, {'authorId': '2268272', 'name': 'Emma Strubell'}, {'authorId': '2223952413', 'name': 'Darrell Plessas'}, {'authorId': '46181066', 'name': 'Iz Beltagy'}, {'authorId': '2158819969', 'name': 'Pete Walsh'}, {'authorId': '144365875', 'name': 'Noah A. Smith'}, {'authorId': '2548384', 'name': 'Hannaneh Hajishirzi'}]","Pentathlon is a benchmark for holistic and realistic evaluation of model efficiency, which focuses on inference, which accounts for a majority of the compute in a model's lifecycle, and is designed to mirror real-world applications scenarios."
Emma Strubell,2268272,Emma Strubell,https://www.semanticscholar.org/author/2268272,17,[],62,4143,88549b4f48b9709acdfb8b9e41656b6d133c5390,"{'DBLP': 'journals/corr/abs-2307-00101', 'ArXiv': '2307.00101', 'DOI': '10.48550/arXiv.2307.00101', 'CorpusId': 259316226}",https://www.semanticscholar.org/paper/88549b4f48b9709acdfb8b9e41656b6d133c5390,Queer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Models,"Large Language Models (LLMs) are trained primarily on minimally processed web text, which exhibits the same wide range of social biases held by the humans who created that content. Consequently, text generated by LLMs can inadvertently perpetuate stereotypes towards marginalized groups, like the LGBTQIA+ community. In this paper, we perform a comparative study of how LLMs generate text describing people with different sexual identities. Analyzing bias in the text generated by an LLM using regard score shows measurable bias against queer people. We then show that a post-hoc method based on chain-of-thought prompting using SHAP analysis can increase the regard of the sentence, representing a promising approach towards debiasing the output of LLMs in this setting.",arXiv.org,2023,32,3,0,True,"{'url': 'http://arxiv.org/pdf/2307.00101', 'status': None}",['Computer Science'],"{'volume': 'abs/2307.00101', 'name': 'ArXiv'}","[{'authorId': '2221008229', 'name': 'Harnoor Dhingra'}, {'authorId': '2146107124', 'name': 'Preetiha Jayashanker'}, {'authorId': '2091865667', 'name': 'Sayali S. Moghe'}, {'authorId': '2268272', 'name': 'Emma Strubell'}]","It is shown that a post-hoc method based on chain-of-thought prompting using SHAP analysis can increase the regard of the sentence, representing a promising approach towards debiasing the output of LLMs in this setting."
Emma Strubell,2268272,Emma Strubell,https://www.semanticscholar.org/author/2268272,17,[],62,4143,a815c3209e7baff4466dbf6e129129511f842b7e,"{'ArXiv': '2310.05674', 'DBLP': 'journals/corr/abs-2310-05674', 'DOI': '10.48550/arXiv.2310.05674', 'CorpusId': 263830616}",https://www.semanticscholar.org/paper/a815c3209e7baff4466dbf6e129129511f842b7e,Making Scalable Meta Learning Practical,"Despite its flexibility to learn diverse inductive biases in machine learning programs, meta learning (i.e., learning to learn) has long been recognized to suffer from poor scalability due to its tremendous compute/memory costs, training instability, and a lack of efficient distributed training support. In this work, we focus on making scalable meta learning practical by introducing SAMA, which combines advances in both implicit differentiation algorithms and systems. Specifically, SAMA is designed to flexibly support a broad range of adaptive optimizers in the base level of meta learning programs, while reducing computational burden by avoiding explicit computation of second-order gradient information, and exploiting efficient distributed training techniques implemented for first-order gradients. Evaluated on multiple large-scale meta learning benchmarks, SAMA showcases up to 1.7/4.8x increase in throughput and 2.0/3.8x decrease in memory consumption respectively on single-/multi-GPU setups compared to other baseline meta learning algorithms. Furthermore, we show that SAMA-based data optimization leads to consistent improvements in text classification accuracy with BERT and RoBERTa large language models, and achieves state-of-the-art results in both small- and large-scale data pruning on image classification tasks, demonstrating the practical applicability of scalable meta learning across language and vision domains.",arXiv.org,2023,72,1,0,True,"{'url': 'https://arxiv.org/pdf/2310.05674', 'status': None}",['Computer Science'],"{'volume': 'abs/2310.05674', 'name': 'ArXiv'}","[{'authorId': '32734975', 'name': 'Sang Keun Choe'}, {'authorId': '47613860', 'name': 'Sanket Vaibhav Mehta'}, {'authorId': '2257002054', 'name': 'Hwijeen Ahn'}, {'authorId': '2934259', 'name': 'W. Neiswanger'}, {'authorId': '2257001701', 'name': 'Pengtao Xie'}, {'authorId': '2268272', 'name': 'Emma Strubell'}, {'authorId': '2243234805', 'name': 'Eric P. Xing'}]","SAMA is designed to flexibly support a broad range of adaptive optimizers in the base level of meta learning programs, while reducing computational burden by avoiding explicit computation of second-order gradient information, and exploiting efficient distributed training techniques implemented for first-order gradients."
Emma Strubell,2268272,Emma Strubell,https://www.semanticscholar.org/author/2268272,17,[],62,4143,b13da1161d65a8de7a96051b5bc68d5eaa8eb37b,"{'DBLP': 'journals/corr/abs-2305-00131', 'ArXiv': '2305.00131', 'DOI': '10.48550/arXiv.2305.00131', 'CorpusId': 258426846}",https://www.semanticscholar.org/paper/b13da1161d65a8de7a96051b5bc68d5eaa8eb37b,Regularizing Self-training for Unsupervised Domain Adaptation via Structural Constraints,"Self-training based on pseudo-labels has emerged as a dominant approach for addressing conditional distribution shifts in unsupervised domain adaptation (UDA) for semantic segmentation problems. A notable drawback, however, is that this family of approaches is susceptible to erroneous pseudo labels that arise from confirmation biases in the source domain and that manifest as nuisance factors in the target domain. A possible source for this mismatch is the reliance on only photometric cues provided by RGB image inputs, which may ultimately lead to sub-optimal adaptation. To mitigate the effect of mismatched pseudo-labels, we propose to incorporate structural cues from auxiliary modalities, such as depth, to regularise conventional self-training objectives. Specifically, we introduce a contrastive pixel-level objectness constraint that pulls the pixel representations within a region of an object instance closer, while pushing those from different object categories apart. To obtain object regions consistent with the true underlying object, we extract information from both depth maps and RGB-images in the form of multimodal clustering. Crucially, the objectness constraint is agnostic to the ground-truth semantic labels and, hence, appropriate for unsupervised domain adaptation. In this work, we show that our regularizer significantly improves top performing self-training methods (by up to $2$ points) in various UDA benchmarks for semantic segmentation. We include all code in the supplementary.",arXiv.org,2023,62,1,1,True,"{'url': 'http://arxiv.org/pdf/2305.00131', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.00131', 'name': 'ArXiv'}","[{'authorId': '2052289398', 'name': 'Rajshekhar Das'}, {'authorId': '26253744', 'name': 'Jonathan M Francis'}, {'authorId': '47613860', 'name': 'Sanket Vaibhav Mehta'}, {'authorId': '143904954', 'name': 'Jean Oh'}, {'authorId': '2268272', 'name': 'Emma Strubell'}, {'authorId': '2215823092', 'name': 'Jose Moura'}]","The regularizer significantly improves top performing self-training methods in various UDA benchmarks for semantic segmentation and introduces a contrastive pixel-level objectness constraint that pulls the pixel representations within a region of an object instance closer, while pushing those from different object categories apart."
Emma Strubell,2268272,Emma Strubell,https://www.semanticscholar.org/author/2268272,17,[],62,4143,b777aa86b5a1d49ce8eababc5c2ee56d3562801e,"{'DBLP': 'journals/corr/abs-2302-06117', 'ArXiv': '2302.06117', 'DOI': '10.48550/arXiv.2302.06117', 'CorpusId': 256826923}",https://www.semanticscholar.org/paper/b777aa86b5a1d49ce8eababc5c2ee56d3562801e,The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment,"Increased focus on the computational efficiency of NLP systems has motivated the design of efficient model architectures and improvements to underlying hardware accelerators. However, the resulting increases in computational throughput and reductions in floating point operations have not directly translated to improvements in wall-clock inference latency. We demonstrate that these discrepancies can be largely attributed to bottlenecks introduced by deep learning frameworks. We denote this phenomenon as the \textit{framework tax}, and observe that the disparity is growing as hardware speed increases over time. In this work, we examine this phenomenon through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency. Code is available at https://github.com/JaredFern/Framework-Tax.",Conference on Empirical Methods in Natural Language Processing,2023,64,2,0,True,"{'url': 'http://arxiv.org/pdf/2302.06117', 'status': None}",['Computer Science'],"{'volume': 'abs/2302.06117', 'name': 'ArXiv'}","[{'authorId': '152793333', 'name': 'Jared Fernandez'}, {'authorId': '39960571', 'name': 'Jacob Kahn'}, {'authorId': '2166313248', 'name': 'Clara Na'}, {'authorId': '3312309', 'name': 'Yonatan Bisk'}, {'authorId': '2268272', 'name': 'Emma Strubell'}]","This work examines the effects of model design decisions, framework paradigms, and hardware platforms on total model latency through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency."
Emma Strubell,2268272,Emma Strubell,https://www.semanticscholar.org/author/2268272,17,[],62,4143,ba31ccac5fe5ea151727e8427e78bb300c35f899,"{'DBLP': 'conf/emnlp/ZhangSH23', 'ArXiv': '2305.12634', 'DOI': '10.48550/arXiv.2305.12634', 'CorpusId': 258832301}",https://www.semanticscholar.org/paper/ba31ccac5fe5ea151727e8427e78bb300c35f899,Data-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training,"In this work we propose a pragmatic method that reduces the annotation cost for structured label spaces using active learning. Our approach leverages partial annotation, which reduces labeling costs for structured outputs by selecting only the most informative sub-structures for annotation. We also utilize self-training to incorporate the current model's automatic predictions as pseudo-labels for un-annotated sub-structures. A key challenge in effectively combining partial annotation with self-training to reduce annotation cost is determining which sub-structures to select to label. To address this challenge, we adopt an error estimator to adaptively decide the partial selection ratio according to the current model's capability. In evaluations spanning four structured prediction tasks, we show that our combination of partial annotation and self-training using an adaptive selection ratio reduces annotation cost over strong full annotation baselines under a fair comparison scheme that takes reading time into consideration.",Conference on Empirical Methods in Natural Language Processing,2023,76,0,0,True,"{'url': 'http://arxiv.org/pdf/2305.12634', 'status': None}",['Computer Science'],{'pages': '12991-13008'},"[{'authorId': '1929423', 'name': 'Zhisong Zhang'}, {'authorId': '2268272', 'name': 'Emma Strubell'}, {'authorId': '144547315', 'name': 'E. Hovy'}]",This work proposes a pragmatic method that reduces the annotation cost for structured label spaces using active learning by adopting an error estimator to adaptively decide the partial selection ratio according to the current model's capability.
Eric Nyberg,144287919,Eric Nyberg,https://www.semanticscholar.org/author/144287919,38,[],216,6031,0f008e07d601e8f21d1df5db3d36e85484840083,"{'DBLP': 'conf/eacl/SkarphedinssonGSLEKNL23', 'ACL': '2023.eacl-demo.18', 'DOI': '10.18653/v1/2023.eacl-demo.18', 'CorpusId': 258378343}",https://www.semanticscholar.org/paper/0f008e07d601e8f21d1df5db3d36e85484840083,GameQA: Gamified Mobile App Platform for Building Multiple-Domain Question-Answering Datasets,"The methods used to create many of the well-known Question-Answering (QA) datasets are hard to replicate for low-resource languages. A commonality amongst these methods is hiring annotators to source answers from the internet by querying a single answer source, such as Wikipedia. Applying these methods for low-resource languages can be problematic since there is no single large answer source for these languages. Consequently, this can result in a high ratio of unanswered questions, since the amount of information in any single source is limited. To address this problem, we developed a novel crowd-sourcing platform to gather multiple-domain QA data for low-resource languages. Our platform, which consists of a mobile app and a web API, gamifies the data collection process. We successfully released the app for Icelandic (a low-resource language with about 350,000 native speakers) to build a dataset which rivals large QA datasets for high-resource languages both in terms of size and ratio of answered questions. We have made the platform open source with instructions on how to localize and deploy it to gather data for other low-resource languages.",Conference of the European Chapter of the Association for Computational Linguistics,2023,21,0,0,True,"{'url': 'https://aclanthology.org/2023.eacl-demo.18.pdf', 'status': None}",['Computer Science'],{'pages': '152-160'},"[{'authorId': '2215628899', 'name': 'Njall Skarphedinsson'}, {'authorId': '2215615463', 'name': 'Breki Gudmundsson'}, {'authorId': '2215622263', 'name': 'Steinar Smari'}, {'authorId': '2372164', 'name': 'M. Lárusdóttir'}, {'authorId': '40631719', 'name': 'H. Einarsson'}, {'authorId': '153675592', 'name': 'Abuzar Khan'}, {'authorId': '144287919', 'name': 'Eric Nyberg'}, {'authorId': '1713580', 'name': 'H. Loftsson'}]",This work developed a novel crowd-sourcing platform to gather multiple-domain QA data for low-resource languages and successfully released the app for Icelandic to build a dataset which rivals large QA datasets for high- resource languages both in terms of size and ratio of answered questions.
Eric Nyberg,144287919,Eric Nyberg,https://www.semanticscholar.org/author/144287919,38,[],216,6031,3a30217c4115777fb30c182c97cc77d34d065556,"{'DBLP': 'journals/corr/abs-2301-02998', 'ArXiv': '2301.02998', 'DOI': '10.48550/arXiv.2301.02998', 'CorpusId': 255546584}",https://www.semanticscholar.org/paper/3a30217c4115777fb30c182c97cc77d34d065556,InPars-Light: Cost-Effective Unsupervised Training of Efficient Rankers,"We carried out a reproducibility study of InPars, which is a method for unsupervised training of neural rankers (Bonifacio et al., 2022). As a by-product, we developed InPars-light, which is a simple-yet-effective modification of InPars. Unlike InPars, InPars-light uses 7x-100x smaller ranking models and only a freely available language model BLOOM, which -- as we found out -- produced more accurate rankers compared to a proprietary GPT-3 model. On all five English retrieval collections (used in the original InPars study) we obtained substantial (7%-30%) and statistically significant improvements over BM25 (in nDCG and MRR) using only a 30M parameter six-layer MiniLM-30M ranker and a single three-shot prompt. In contrast, in the InPars study only a 100x larger monoT5-3B model consistently outperformed BM25, whereas their smaller monoT5-220M model (which is still 7x larger than our MiniLM ranker) outperformed BM25 only on MS MARCO and TREC DL 2020. In the same three-shot prompting scenario, our 435M parameter DeBERTA v3 ranker was at par with the 7x larger monoT5-3B (average gain over BM25 of 1.3 vs 1.32): In fact, on three out of five datasets, DeBERTA slightly outperformed monoT5-3B. Finally, these good results were achieved by re-ranking only 100 candidate documents compared to 1000 used by Bonifacio et al. (2022). We believe that InPars-light is the first truly cost-effective prompt-based unsupervised recipe to train and deploy neural ranking models that outperform BM25. Our code and data is publicly available. https://github.com/searchivarius/inpars_light/",arXiv.org,2023,58,11,0,True,"{'url': 'http://arxiv.org/pdf/2301.02998', 'status': None}",['Computer Science'],"{'volume': 'abs/2301.02998', 'name': 'ArXiv'}","[{'authorId': '3308561', 'name': 'Leonid Boytsov'}, {'authorId': '1570831201', 'name': 'Preksha Patel'}, {'authorId': '40882083', 'name': 'Vivek Sourabh'}, {'authorId': '2199743435', 'name': 'Riddhi Nisar'}, {'authorId': '2147299388', 'name': 'Sayan Kundu'}, {'authorId': '2055935016', 'name': 'R. Ramanathan'}, {'authorId': '144287919', 'name': 'Eric Nyberg'}]",InPars-light is the first truly cost-effective prompt-based unsupervised recipe to train and deploy neural ranking models that outperform BM25.
Eric Nyberg,144287919,Eric Nyberg,https://www.semanticscholar.org/author/144287919,38,[],216,6031,444737639aeea4e1e616509e368afb0bae8f89d6,"{'ACL': '2023.dialdoc-1.11', 'DOI': '10.18653/v1/2023.dialdoc-1.11', 'CorpusId': 259290499}",https://www.semanticscholar.org/paper/444737639aeea4e1e616509e368afb0bae8f89d6,Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA,"The DialDoc 2023 shared task has expanded the document-grounded dialogue task to encompass multiple languages, despite having limited annotated data. This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-agnostic approach is superior. Additionally, the study investigates the impact of query rewriting techniques using large language models, such as ChatGPT, on multilingual, document-grounded question-answering systems. The experiments conducted demonstrate that, for the examples examined, query rewriting does not enhance performance compared to the original queries. This failure is due to topic switching in final dialogue turns and irrelevant topics being considered for query rewriting.",Workshop on Document-grounded Dialogue and Conversational Question Answering,2023,23,2,0,True,"{'url': 'https://aclanthology.org/2023.dialdoc-1.11.pdf', 'status': None}",,{'name': 'Proceedings of the Third DialDoc Workshop on Document-grounded Dialogue and Conversational Question Answering'},"[{'authorId': '2220844123', 'name': 'Srinivas Gowriraj'}, {'authorId': '2090315115', 'name': 'Soham Dinesh Tiwari'}, {'authorId': '2122650064', 'name': 'Mitali Potnis'}, {'authorId': '67152985', 'name': 'Srijan Bansal'}, {'authorId': '1706595', 'name': 'T. Mitamura'}, {'authorId': '144287919', 'name': 'Eric Nyberg'}]","This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-gnostic approach is superior."
Eric Nyberg,144287919,Eric Nyberg,https://www.semanticscholar.org/author/144287919,38,[],216,6031,61354e45bca908ad08f24e44bd507b4e1c958e6f,"{'DBLP': 'journals/corr/abs-2305-03130', 'ACL': '2023.acl-long.89', 'ArXiv': '2305.03130', 'DOI': '10.48550/arXiv.2305.03130', 'CorpusId': 258546861}",https://www.semanticscholar.org/paper/61354e45bca908ad08f24e44bd507b4e1c958e6f,Chain-of-Skills: A Configurable Model for Open-Domain Question Answering,"The retrieval model is an indispensable component for real-world knowledge-intensive tasks, e.g., open-domain question answering (ODQA). As separate retrieval skills are annotated for different datasets, recent work focuses on customized methods, limiting the model transfer- ability and scalability. In this work, we propose a modular retriever where individual modules correspond to key skills that can be reused across datasets. Our approach supports flexible skill configurations based on the target domain to boost performance. To mitigate task interference, we design a novel modularization parameterization inspired by sparse Transformer. We demonstrate that our model can benefit from self-supervised pretraining on Wikipedia and fine-tuning using multiple ODQA datasets, both in a multi-task fashion. Our approach outperforms recent self-supervised retrievers in zero-shot evaluations and achieves state-of-the-art fine-tuned retrieval performance on NQ, HotpotQA and OTT-QA.",Annual Meeting of the Association for Computational Linguistics,2023,71,6,0,True,"{'url': 'http://arxiv.org/pdf/2305.03130', 'status': None}",['Computer Science'],{'pages': '1599-1618'},"[{'authorId': '22244290', 'name': 'Kaixin Ma'}, {'authorId': '47413820', 'name': 'Hao Cheng'}, {'authorId': '49891156', 'name': 'Yu Zhang'}, {'authorId': '46522098', 'name': 'Xiaodong Liu'}, {'authorId': '144287919', 'name': 'Eric Nyberg'}, {'authorId': '48441311', 'name': 'Jianfeng Gao'}]","This work proposes a modular retriever where individual modules correspond to key skills that can be reused across datasets and achieves state-of-the-art fine-tuned retrieval performance on NQ, HotpotQA and OTT-QA."
Fernando-Diaz,145472333,Fernando Diaz,https://www.semanticscholar.org/author/145472333,45,[],142,7996,55704caaf3d31e1795a1ca0c3bed9e77ae3a3c95,"{'DBLP': 'journals/corr/abs-2306-07908', 'ArXiv': '2306.07908', 'DOI': '10.48550/arXiv.2306.07908', 'CorpusId': 259145213}",https://www.semanticscholar.org/paper/55704caaf3d31e1795a1ca0c3bed9e77ae3a3c95,Best-Case Retrieval Evaluation: Improving the Sensitivity of Reciprocal Rank with Lexicographic Precision,"Across a variety of ranking tasks, researchers use reciprocal rank to measure the effectiveness for users interested in exactly one relevant item. Despite its widespread use, evidence suggests that reciprocal rank is brittle when discriminating between systems. This brittleness, in turn, is compounded in modern evaluation settings where current, high-precision systems may be difficult to distinguish. We address the lack of sensitivity of reciprocal rank by introducing and connecting it to the concept of best-case retrieval, an evaluation method focusing on assessing the quality of a ranking for the most satisfied possible user across possible recall requirements. This perspective allows us to generalize reciprocal rank and define a new preference-based evaluation we call lexicographic precision or lexiprecision. By mathematical construction, we ensure that lexiprecision preserves differences detected by reciprocal rank, while empirically improving sensitivity and robustness across a broad set of retrieval and recommendation tasks.",arXiv.org,2023,24,2,0,True,"{'url': 'http://arxiv.org/pdf/2306.07908', 'status': None}",['Computer Science'],"{'volume': 'abs/2306.07908', 'name': 'ArXiv'}","[{'authorId': '145472333', 'name': 'Fernando Diaz'}]","This work addresses the lack of sensitivity of reciprocal rank by introducing and connecting it to the concept of best-case retrieval, an evaluation method focusing on assessing the quality of a ranking for the most satisfied possible user across possible recall requirements."
Fernando-Diaz,145472333,Fernando Diaz,https://www.semanticscholar.org/author/145472333,45,[],142,7996,567f6bc975deb3d728feec9bfcf7d4036ceabb12,"{'DBLP': 'journals/corr/abs-2308-14601', 'ArXiv': '2308.14601', 'DOI': '10.48550/arXiv.2308.14601', 'CorpusId': 261243847}",https://www.semanticscholar.org/paper/567f6bc975deb3d728feec9bfcf7d4036ceabb12,Fairness Through Domain Awareness: Mitigating Popularity Bias For Music Discovery,"As online music platforms grow, music recommender systems play a vital role in helping users navigate and discover content within their vast musical databases. At odds with this larger goal, is the presence of popularity bias, which causes algorithmic systems to favor mainstream content over, potentially more relevant, but niche items. In this work we explore the intrinsic relationship between music discovery and popularity bias. To mitigate this issue we propose a domain-aware, individual fairness-based approach which addresses popularity bias in graph neural network (GNNs) based recommender systems. Our approach uses individual fairness to reflect a ground truth listening experience, i.e., if two songs sound similar, this similarity should be reflected in their representations. In doing so, we facilitate meaningful music discovery that is robust to popularity bias and grounded in the music domain. We apply our BOOST methodology to two discovery based tasks, performing recommendations at both the playlist level and user level. Then, we ground our evaluation in the cold start setting, showing that our approach outperforms existing fairness benchmarks in both performance and recommendation of lesser-known content. Finally, our analysis explains why our proposed methodology is a novel and promising approach to mitigating popularity bias and improving the discovery of new and niche content in music recommender systems.",arXiv.org,2023,79,0,0,True,"{'url': 'https://arxiv.org/pdf/2308.14601', 'status': None}",['Computer Science'],"{'volume': 'abs/2308.14601', 'name': 'ArXiv'}","[{'authorId': '2184295196', 'name': 'Rebecca Salganik'}, {'authorId': '145472333', 'name': 'Fernando Diaz'}, {'authorId': '2086602', 'name': 'G. Farnadi'}]","This work proposes a domain-aware, individual fairness-based approach which addresses popularity bias in graph neural network (GNNs) based recommender systems and applies the BOOST methodology to two discovery based tasks, performing recommendations at both the playlist level and user level."
Fernando-Diaz,145472333,Fernando Diaz,https://www.semanticscholar.org/author/145472333,45,[],142,7996,5e1ba2d4416333dd6f6a31a4ff4221b40dfb74b1,"{'DBLP': 'conf/trec/EkstrandRM021', 'ArXiv': '2302.10856', 'DOI': '10.48550/arXiv.2302.10856', 'CorpusId': 214667072}",https://www.semanticscholar.org/paper/5e1ba2d4416333dd6f6a31a4ff4221b40dfb74b1,Overview of the TREC 2021 Fair Ranking Track,"The TREC Fair Ranking Track aims to provide a platform for participants to develop and evaluate novel retrieval algorithms that can provide a fair exposure to a mixture of demographics or attributes, such as ethnicity, that are represented by relevant documents in response to a search query. For example, particular demographics or attributes can be represented by the documents' topical content or authors. The 2021 Fair Ranking Track adopted a resource allocation task. The task focused on supporting Wikipedia editors who are looking to improve the encyclopedia's coverage of topics under the purview of a WikiProject. WikiProject coordinators and/or Wikipedia editors search for Wikipedia documents that are in need of editing to improve the quality of the article. The 2021 Fair Ranking track aimed to ensure that documents that are about, or somehow represent, certain protected characteristics receive a fair exposure to the Wikipedia editors, so that the documents have an fair opportunity of being improved and, therefore, be well-represented in Wikipedia. The under-representation of particular protected characteristics in Wikipedia can result in systematic biases that can have a negative human, social, and economic impact, particularly for disadvantaged or protected societal groups.",Text Retrieval Conference,2023,16,28,3,True,"{'url': 'http://arxiv.org/pdf/2302.10856', 'status': None}",['Computer Science'],"{'volume': 'abs/2302.10856', 'name': 'ArXiv'}","[{'authorId': '31908706', 'name': 'Asia J. Biega'}, {'authorId': '145472333', 'name': 'Fernando Diaz'}, {'authorId': '2386667', 'name': 'Michael D. Ekstrand'}, {'authorId': '41018147', 'name': 'Sebastian Kohlmeier'}]","The 2021 Fair Ranking track aimed to ensure that documents that are about, or somehow represent, certain protected characteristics receive a fair exposure to the Wikipedia editors, so that the documents have an fair opportunity of being improved and, therefore, be well-represented in Wikipedia."
Graham Neubig,1700325,Graham Neubig,https://www.semanticscholar.org/author/1700325,75,[],600,24256,03c7f61b0c6bc4c480ed6da4e9d7dda104ddfec3,"{'DBLP': 'journals/corr/abs-2302-05738', 'ArXiv': '2302.05738', 'DOI': '10.48550/arXiv.2302.05738', 'CorpusId': 256827706}",https://www.semanticscholar.org/paper/03c7f61b0c6bc4c480ed6da4e9d7dda104ddfec3,Cross-Modal Fine-Tuning: Align then Refine,"Fine-tuning large-scale pretrained models has led to tremendous progress in well-studied modalities such as vision and NLP. However, similar gains have not been observed in many other modalities due to a lack of relevant pretrained models. In this work, we propose ORCA, a general cross-modal fine-tuning framework that extends the applicability of a single large-scale pretrained model to diverse modalities. ORCA adapts to a target task via an align-then-refine workflow: given the target input, ORCA first learns an embedding network that aligns the embedded feature distribution with the pretraining modality. The pretrained model is then fine-tuned on the embedded data to exploit the knowledge shared across modalities. Through extensive experiments, we show that ORCA obtains state-of-the-art results on 3 benchmarks containing over 60 datasets from 12 modalities, outperforming a wide range of hand-designed, AutoML, general-purpose, and task-specific methods. We highlight the importance of data alignment via a series of ablation studies and demonstrate ORCA's utility in data-limited regimes.",International Conference on Machine Learning,2023,84,7,0,True,"{'url': 'http://arxiv.org/pdf/2302.05738', 'status': None}",['Computer Science'],{'pages': '31030-31056'},"[{'authorId': '2143669058', 'name': 'Junhong Shen'}, {'authorId': '51517360', 'name': 'Liam Li'}, {'authorId': '32273391', 'name': 'L. Dery'}, {'authorId': '2081410501', 'name': 'Corey Staten'}, {'authorId': '10398264', 'name': 'M. Khodak'}, {'authorId': '1700325', 'name': 'Graham Neubig'}, {'authorId': '145532827', 'name': 'Ameet Talwalkar'}]","This work proposes ORCA, a general cross-modal fine-tuning framework that extends the applicability of a single large-scale pretrained model to diverse modalities and highlights the importance of data alignment via a series of ablation studies and demonstrates ORCA's utility in data-limited regimes."
Graham Neubig,1700325,Graham Neubig,https://www.semanticscholar.org/author/1700325,75,[],600,24256,11a571eaab42a6ffb1d938635a093315e392756d,"{'DBLP': 'journals/corr/abs-2309-07423', 'ArXiv': '2309.07423', 'ACL': '2023.wmt-1.40', 'DOI': '10.48550/arXiv.2309.07423', 'CorpusId': 261824661}",https://www.semanticscholar.org/paper/11a571eaab42a6ffb1d938635a093315e392756d,ChatGPT MT: Competitive for High- (but Not Low-) Resource Languages,"Large language models (LLMs) implicitly learn to perform a range of language tasks, including machine translation (MT). Previous studies explore aspects of LLMs’ MT capabilities. However, there exist a wide variety of languages for which recent LLM MT performance has never before been evaluated. Without published experimental evidence on the matter, it is difficult for speakers of the world’s diverse languages to know how and whether they can use LLMs for their languages. We present the first experimental evidence for an expansive set of 204 languages, along with MT cost analysis, using the FLORES-200 benchmark. Trends reveal that GPT models approach or exceed traditional MT model performance for some high-resource languages (HRLs) but consistently lag for low-resource languages (LRLs), under-performing traditional MT for 84.1% of languages we covered. Our analysis reveals that a language’s resource level is the most important feature in determining ChatGPT’s relative ability to translate it, and suggests that ChatGPT is especially disadvantaged for LRLs and African languages.",Conference on Machine Translation,2023,24,1,0,True,"{'url': 'https://arxiv.org/pdf/2309.07423', 'status': None}",['Computer Science'],"{'volume': 'abs/2309.07423', 'name': 'ArXiv'}","[{'authorId': '2240569372', 'name': 'Nathaniel R. Robinson'}, {'authorId': '1988654955', 'name': 'Perez Ogayo'}, {'authorId': '3407646', 'name': 'David R. Mortensen'}, {'authorId': '1700325', 'name': 'Graham Neubig'}]","This work presents the first experimental evidence for an expansive set of 204 languages, along with MT cost analysis, using the FLORES-200 benchmark, and reveals that a language’s resource level is the most important feature in determining ChatGPT's relative ability to translate it, and suggests thatChatGPT is especially disadvantaged for LRLs and African languages."
Graham Neubig,1700325,Graham Neubig,https://www.semanticscholar.org/author/1700325,75,[],600,24256,17605c43ca3eb982c99642052ddc21a93d116594,"{'DBLP': 'conf/emnlp/SongK0FOWACTAN23', 'ArXiv': '2305.14716', 'DOI': '10.48550/arXiv.2305.14716', 'CorpusId': 258866051}",https://www.semanticscholar.org/paper/17605c43ca3eb982c99642052ddc21a93d116594,GlobalBench: A Benchmark for Global Progress in Natural Language Processing,"Despite the major advances in NLP, significant disparities in NLP system performance across languages still exist. Arguably, these are due to uneven resource allocation and sub-optimal incentives to work on less resourced languages. To track and further incentivize the global development of equitable language technology, we introduce GlobalBench. Prior multilingual benchmarks are static and have focused on a limited number of tasks and languages. In contrast, GlobalBench is an ever-expanding collection that aims to dynamically track progress on all NLP datasets in all languages. Rather than solely measuring accuracy, GlobalBench also tracks the estimated per-speaker utility and equity of technology across all languages, providing a multi-faceted view of how language technology is serving people of the world. Furthermore, GlobalBench is designed to identify the most under-served languages, and rewards research efforts directed towards those languages. At present, the most under-served languages are the ones with a relatively high population, but nonetheless overlooked by composite multilingual benchmarks (like Punjabi, Portuguese, and Wu Chinese). Currently, GlobalBench covers 966 datasets in 190 languages, and has 1,128 system submissions spanning 62 languages.",Conference on Empirical Methods in Natural Language Processing,2023,45,1,0,True,"{'url': 'http://arxiv.org/pdf/2305.14716', 'status': None}",['Computer Science'],{'pages': '14157-14171'},"[{'authorId': '148310739', 'name': 'Yueqi Song'}, {'authorId': '2218206121', 'name': 'Catherine Cui'}, {'authorId': '1452678825', 'name': 'Simran Khanuja'}, {'authorId': '144118452', 'name': 'Pengfei Liu'}, {'authorId': '48556979', 'name': 'FAHIM FAISAL'}, {'authorId': '1475670743', 'name': 'Alissa Ostapenko'}, {'authorId': '9162688', 'name': 'Genta Indra Winata'}, {'authorId': '8129718', 'name': 'Alham Fikri Aji'}, {'authorId': '66986482', 'name': 'Samuel Cahyawijaya'}, {'authorId': '2073587169', 'name': 'Yulia Tsvetkov'}, {'authorId': '49513989', 'name': 'Antonios Anastasopoulos'}, {'authorId': '1700325', 'name': 'Graham Neubig'}]","This work introduces GlobalBench, an ever-expanding collection that aims to dynamically track progress on all NLP datasets in all languages and tracks the estimated per-speaker utility and equity of technology across all languages, providing a multi-faceted view of how language technology is serving people of the world."
Graham Neubig,1700325,Graham Neubig,https://www.semanticscholar.org/author/1700325,75,[],600,24256,1786a2f9140ed7211b21302977de64e948b92308,"{'ArXiv': '2302.07867', 'DBLP': 'journals/corr/abs-2302-07867', 'DOI': '10.48550/arXiv.2302.07867', 'CorpusId': 256868633}",https://www.semanticscholar.org/paper/1786a2f9140ed7211b21302977de64e948b92308,Learning Performance-Improving Code Edits,"The waning of Moore's Law has shifted the focus of the tech industry towards alternative methods for continued performance gains. While optimizing compilers are a standard tool to help increase program efficiency, programmers continue to shoulder much responsibility in crafting and refactoring code with better performance characteristics. In this paper, we investigate the ability of large language models (LLMs) to suggest functionally correct, performance improving code edits. We hypothesize that language models can suggest such edits in ways that would be impractical for static analysis alone. We investigate these questions by curating a large-scale dataset of Performance-Improving Edits, PIE. PIE contains trajectories of programs, where a programmer begins with an initial, slower version and iteratively makes changes to improve the program's performance. We use PIE to evaluate and improve the capacity of large language models. Specifically, use examples from PIE to fine-tune multiple variants of CODEGEN, a billion-scale Transformer-decoder model. Additionally, we use examples from PIE to prompt OpenAI's CODEX using a few-shot prompting. By leveraging PIE, we find that both CODEX and CODEGEN can generate performance-improving edits, with speedups of more than 2.5x for over 25% of the programs, for C++ and Python, even after the C++ programs were compiled using the O3 optimization level. Crucially, we show that PIE allows CODEGEN, an open-sourced and 10x smaller model than CODEX, to match the performance of CODEX on this challenging task. Overall, this work opens new doors for creating systems and methods that can help programmers write efficient code.",arXiv.org,2023,87,26,3,True,"{'url': 'http://arxiv.org/pdf/2302.07867', 'status': None}",['Computer Science'],"{'volume': 'abs/2302.07867', 'name': 'ArXiv'}","[{'authorId': '21626987', 'name': 'Aman Madaan'}, {'authorId': '2129995371', 'name': 'Alex Shypula'}, {'authorId': '47051926', 'name': 'Uri Alon'}, {'authorId': '33798741', 'name': 'Milad Hashemi'}, {'authorId': '1770926', 'name': 'Parthasarathy Ranganathan'}, {'authorId': '46286308', 'name': 'Yiming Yang'}, {'authorId': '1700325', 'name': 'Graham Neubig'}, {'authorId': '2112229', 'name': 'A. Yazdanbakhsh'}]","This paper investigates the ability of large language models (LLMs) to suggest functionally correct, performance improving code edits, and hypothesizes that language models can suggest such edits in ways that would be impractical for static analysis alone."
Graham Neubig,1700325,Graham Neubig,https://www.semanticscholar.org/author/1700325,75,[],600,24256,31366ff634fc905affd78dbd8ddc9a872c006a87,"{'DBLP': 'journals/corr/abs-2302-05527', 'ArXiv': '2302.05527', 'DOI': '10.48550/arXiv.2302.05527', 'CorpusId': 256827797}",https://www.semanticscholar.org/paper/31366ff634fc905affd78dbd8ddc9a872c006a87,CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code,"Since the rise of neural natural-language-to-code models (NL->Code) that can generate long expressions and statements rather than a single next-token, one of the major problems has been reliably evaluating their generated output. In this paper, we propose CodeBERTScore: an evaluation metric for code generation, which builds on BERTScore (Zhang et al., 2020). Instead of encoding only the generated tokens as in BERTScore, CodeBERTScore also encodes the natural language input preceding the generated code, thus modeling the consistency between the generated code and its given natural language context as well. We perform an extensive evaluation of CodeBERTScore across four programming languages. We find that CodeBERTScore achieves a higher correlation with human preference and with functional correctness than all existing metrics. That is, generated code that receives a higher score by CodeBERTScore is more likely to be preferred by humans, as well as to function correctly when executed. We release five language-specific pretrained models to use with our publicly available code. Our language-specific models have been downloaded more than 1,000,000 times from the Huggingface Hub. Our code and data are available at https://github.com/neulab/code-bert-score",Conference on Empirical Methods in Natural Language Processing,2023,43,25,5,True,"{'url': 'http://arxiv.org/pdf/2302.05527', 'status': None}",['Computer Science'],{'pages': '13921-13937'},"[{'authorId': '2149163534', 'name': 'Shuyan Zhou'}, {'authorId': '47051926', 'name': 'Uri Alon'}, {'authorId': '2114357424', 'name': 'Sumit Agarwal'}, {'authorId': '1700325', 'name': 'Graham Neubig'}]","It is found that generated code that receives a higher score by CodeBERTScore is more likely to be preferred by humans, as well as to function correctly when executed, than all existing metrics."
Graham Neubig,1700325,Graham Neubig,https://www.semanticscholar.org/author/1700325,75,[],600,24256,405f1a5602867c66e015491c26d2be5504eed458,"{'ArXiv': '2306.06804', 'DBLP': 'journals/corr/abs-2306-06804', 'ACL': '2023.americasnlp-1.13', 'DOI': '10.48550/arXiv.2306.06804', 'CorpusId': 259138596}",https://www.semanticscholar.org/paper/405f1a5602867c66e015491c26d2be5504eed458,Neural Machine Translation for the Indigenous Languages of the Americas: An Introduction,"Neural models have drastically advanced state of the art for machine translation (MT) between high-resource languages. Traditionally, these models rely on large amounts of training data, but many language pairs lack these resources. However, an important part of the languages in the world do not have this amount of data. Most languages from the Americas are among them, having a limited amount of parallel and monolingual data, if any. Here, we present an introduction to the interested reader to the basic challenges, concepts, and techniques that involve the creation of MT systems for these languages. Finally, we discuss the recent advances and findings and open questions, product of an increased interest of the NLP community in these languages.",AMERICASNLP,2023,247,0,0,True,"{'url': 'http://arxiv.org/pdf/2306.06804', 'status': None}","['Computer Science', 'Mathematics']","{'volume': 'abs/2306.06804', 'name': 'ArXiv'}","[{'authorId': '153151470', 'name': 'Manuel Mager'}, {'authorId': '2061975276', 'name': 'R. Bhatnagar'}, {'authorId': '1700325', 'name': 'Graham Neubig'}, {'authorId': '4160376', 'name': 'Ngoc Thang Vu'}, {'authorId': '3422953', 'name': 'Katharina Kann'}]","An introduction to the interested reader to the basic challenges, concepts, and techniques that involve the creation of MT systems for high- resource languages between high-resource languages."
Graham Neubig,1700325,Graham Neubig,https://www.semanticscholar.org/author/1700325,75,[],600,24256,43c0f77f116f986b53eb04f5c9b33f10132ded55,"{'ACL': '2023.computel-1.4', 'DBLP': 'journals/corr/abs-2302-13410', 'ArXiv': '2302.13410', 'DOI': '10.48550/arXiv.2302.13410', 'CorpusId': 257219604}",https://www.semanticscholar.org/paper/43c0f77f116f986b53eb04f5c9b33f10132ded55,User-Centric Evaluation of OCR Systems for Kwak’wala,"There has been recent interest in improving optical character recognition (OCR) for endangered languages, particularly because a large number of documents and books in these languages are not in machine-readable formats. The performance of OCR systems is typically evaluated using automatic metrics such as character and word error rates. While error rates are useful for the comparison of different models and systems, they do not measure whether and how the transcriptions produced from OCR tools are useful to downstream users. In this paper, we present a human-centric evaluation of OCR systems, focusing on the Kwak'wala language as a case study. With a user study, we show that utilizing OCR reduces the time spent in the manual transcription of culturally valuable documents -- a task that is often undertaken by endangered language community members and researchers -- by over 50%. Our results demonstrate the potential benefits that OCR tools can have on downstream language documentation and revitalization efforts.",COMPUTEL,2023,25,0,0,True,"{'url': 'http://arxiv.org/pdf/2302.13410', 'status': None}",['Computer Science'],"{'volume': 'abs/2302.13410', 'name': 'ArXiv'}","[{'authorId': '7391530', 'name': 'Shruti Rijhwani'}, {'authorId': '102758386', 'name': 'Daisy Rosenblum'}, {'authorId': '2209989543', 'name': 'Michayla King'}, {'authorId': '49513989', 'name': 'Antonios Anastasopoulos'}, {'authorId': '1700325', 'name': 'Graham Neubig'}]","This paper presents a human-centric evaluation of OCR systems, focusing on the Kwak'wala language as a case study, and shows that utilizing OCR reduces the time spent in the manual transcription of culturally valuable documents by over 50%."
Graham Neubig,1700325,Graham Neubig,https://www.semanticscholar.org/author/1700325,75,[],600,24256,4d74a5048b884e8bb3842240abf98915c619c8f8,"{'ArXiv': '2306.01200', 'DBLP': 'conf/acl/JainKSF0NZ23', 'DOI': '10.18653/v1/2023.findings-acl.537', 'CorpusId': 259064002}",https://www.semanticscholar.org/paper/4d74a5048b884e8bb3842240abf98915c619c8f8,Multi-Dimensional Evaluation of Text Summarization with In-Context Learning,"Evaluation of natural language generation (NLG) is complex and multi-dimensional. Generated text can be evaluated for fluency, coherence, factuality, or any other dimensions of interest. Most frameworks that perform such multi-dimensional evaluation require training on large manually or synthetically generated datasets. In this paper, we study the efficacy of large language models as multi-dimensional evaluators using in-context learning, obviating the need for large training datasets. Our experiments show that in-context learning-based evaluators are competitive with learned evaluation frameworks for the task of text summarization, establishing state-of-the-art on dimensions such as relevance and factual consistency. We then analyze the effects of factors such as the selection and number of in-context examples on performance. Finally, we study the efficacy of in-context learning based evaluators in evaluating zero-shot summaries written by large language models such as GPT-3.",Annual Meeting of the Association for Computational Linguistics,2023,20,10,1,True,"{'url': 'https://aclanthology.org/2023.findings-acl.537.pdf', 'status': None}",['Computer Science'],"{'volume': 'abs/2306.01200', 'name': 'ArXiv'}","[{'authorId': '2116998524', 'name': 'Sameer Jain'}, {'authorId': '17320214', 'name': 'Vaishakh Keshava'}, {'authorId': '1644192946', 'name': 'Swarnashree Mysore Sathyendra'}, {'authorId': '2058640028', 'name': 'Patrick Fernandes'}, {'authorId': '144118452', 'name': 'Pengfei Liu'}, {'authorId': '1700325', 'name': 'Graham Neubig'}, {'authorId': '2384711', 'name': 'Chunting Zhou'}]","The experiments show that in-context learning-based evaluators are competitive with learned evaluation frameworks for the task of text summarization, establishing state-of-the-art on dimensions such as relevance and factual consistency."
Graham Neubig,1700325,Graham Neubig,https://www.semanticscholar.org/author/1700325,75,[],600,24256,5ea8eedcb31859c5730dd1da3804e1be529ffabb,"{'ArXiv': '2303.16750', 'DBLP': 'journals/corr/abs-2303-16750', 'DOI': '10.48550/arXiv.2303.16750', 'CorpusId': 257805004}",https://www.semanticscholar.org/paper/5ea8eedcb31859c5730dd1da3804e1be529ffabb,A Gold Standard Dataset for the Reviewer Assignment Problem,"Many peer-review venues are either using or looking to use algorithms to assign submissions to reviewers. The crux of such automated approaches is the notion of the""similarity score""--a numerical estimate of the expertise of a reviewer in reviewing a paper--and many algorithms have been proposed to compute these scores. However, these algorithms have not been subjected to a principled comparison, making it difficult for stakeholders to choose the algorithm in an evidence-based manner. The key challenge in comparing existing algorithms and developing better algorithms is the lack of the publicly available gold-standard data that would be needed to perform reproducible research. We address this challenge by collecting a novel dataset of similarity scores that we release to the research community. Our dataset consists of 477 self-reported expertise scores provided by 58 researchers who evaluated their expertise in reviewing papers they have read previously. We use this data to compare several popular algorithms employed in computer science conferences and come up with recommendations for stakeholders. Our main findings are as follows. First, all algorithms make a non-trivial amount of error. For the task of ordering two papers in terms of their relevance for a reviewer, the error rates range from 12%-30% in easy cases to 36%-43% in hard cases, highlighting the vital need for more research on the similarity-computation problem. Second, most existing algorithms are designed to work with titles and abstracts of papers, and in this regime the Specter+MFR algorithm performs best. Third, to improve performance, it may be important to develop modern deep-learning based algorithms that can make use of the full texts of papers: the classical TD-IDF algorithm enhanced with full texts of papers is on par with the deep-learning based Specter+MFR that cannot make use of this information.",arXiv.org,2023,51,8,2,True,"{'url': 'http://arxiv.org/pdf/2303.16750', 'status': None}",['Computer Science'],"{'volume': 'abs/2303.16750', 'name': 'ArXiv'}","[{'authorId': '50825200', 'name': 'Ivan Stelmakh'}, {'authorId': '1771118', 'name': 'J. Wieting'}, {'authorId': '1700325', 'name': 'Graham Neubig'}, {'authorId': '1737249', 'name': 'Nihar B. Shah'}]",A novel dataset of similarity scores provided by 58 researchers who evaluated their expertise in reviewing papers they have read previously is collected and used to compare several popular algorithms employed in computer science conferences and come up with recommendations for stakeholders.
Graham Neubig,1700325,Graham Neubig,https://www.semanticscholar.org/author/1700325,75,[],600,24256,659be1ff350634f50cc066d258ee6a45e697e552,"{'DBLP': 'conf/sigmorphon/HeTR0MNL23', 'ACL': '2023.sigmorphon-1.22', 'DOI': '10.18653/v1/2023.sigmorphon-1.22', 'CorpusId': 259833803}",https://www.semanticscholar.org/paper/659be1ff350634f50cc066d258ee6a45e697e552,SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing,"In our submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), we explore approaches to data augmentation and modeling across seven low-resource languages. For data augmentation, we explore two approaches: creating artificial data from the provided training data and utilizing existing IGT resources in other languages. On the modeling side, we test an enhanced version of the provided token classification baseline as well as a pretrained multilingual seq2seq model. Additionally, we apply post-correction using a dictionary for Gitksan, the language with the smallest amount of data. We find that our token classification models are the best performing, with the highest word-level accuracy for Arapaho and highest morpheme-level accuracy for Gitksan out of all submissions. We also show that data augmentation is an effective strategy, though applying artificial data pretraining has very different effects across both models tested.",Special Interest Group on Computational Morphology and Phonology Workshop,2023,18,2,0,True,"{'url': 'https://aclanthology.org/2023.sigmorphon-1.22.pdf', 'status': None}",['Computer Science'],{'pages': '209-216'},"[{'authorId': '2107034039', 'name': 'Taiqi He'}, {'authorId': '2219036626', 'name': 'Lindia Tjuatja'}, {'authorId': '2067645226', 'name': 'Nathaniel R. Robinson'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '3407646', 'name': 'David R. Mortensen'}, {'authorId': '1700325', 'name': 'Graham Neubig'}, {'authorId': '145585627', 'name': 'L. Levin'}]","In this submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), approaches to data augmentation and modeling across seven low-resource languages are explored and token classification models are found to be the best performing."
Graham Neubig,1700325,Graham Neubig,https://www.semanticscholar.org/author/1700325,75,[],600,24256,74b05bba46db21e589a2cc0f916f81069b0368ef,"{'DBLP': 'journals/corr/abs-2305-00955', 'ArXiv': '2305.00955', 'DOI': '10.48550/arXiv.2305.00955', 'CorpusId': 258426970}",https://www.semanticscholar.org/paper/74b05bba46db21e589a2cc0f916f81069b0368ef,Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation,"Many recent advances in natural language generation have been fueled by training large language models on internet-scale data. However, this paradigm can lead to models that generate toxic, inaccurate, and unhelpful content, and automatic evaluation metrics often fail to identify these behaviors. As models become more capable, human feedback is an invaluable signal for evaluating and improving models. This survey aims to provide an overview of the recent research that has leveraged human feedback to improve natural language generation. First, we introduce an encompassing formalization of feedback, and identify and organize existing research into a taxonomy following this formalization. Next, we discuss how feedback can be described by its format and objective, and cover the two approaches proposed to use feedback (either for training or decoding): directly using the feedback or training feedback models. We also discuss existing datasets for human-feedback data collection, and concerns surrounding feedback collection. Finally, we provide an overview of the nascent field of AI feedback, which exploits large language models to make judgments based on a set of principles and minimize the need for human intervention.",arXiv.org,2023,155,23,7,True,"{'url': 'http://arxiv.org/pdf/2305.00955', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.00955', 'name': 'ArXiv'}","[{'authorId': '2058640028', 'name': 'Patrick Fernandes'}, {'authorId': '21626987', 'name': 'Aman Madaan'}, {'authorId': '1381444447', 'name': 'Emmy Liu'}, {'authorId': '1748971692', 'name': 'António Farinhas'}, {'authorId': '144869806', 'name': 'Pedro Henrique Martins'}, {'authorId': '2138301112', 'name': 'Amanda Bertsch'}, {'authorId': '34876539', 'name': 'José G. C. de Souza'}, {'authorId': '2149163534', 'name': 'Shuyan Zhou'}, {'authorId': '35232494', 'name': 'Tongshuang Sherry Wu'}, {'authorId': '1700325', 'name': 'Graham Neubig'}, {'authorId': '1400227478', 'name': 'André F. T. Martins'}]","An overview of the recent research that has leveraged human feedback to improve natural language generation and the nascent field of AI feedback, which exploits large language models to make judgments based on a set of principles and minimize the need for human intervention is provided."
Graham Neubig,1700325,Graham Neubig,https://www.semanticscholar.org/author/1700325,75,[],600,24256,7a5b44ea10a51708e18786595c8d70b18950da11,"{'DBLP': 'journals/corr/abs-2307-13528', 'ArXiv': '2307.13528', 'DOI': '10.48550/arXiv.2307.13528', 'CorpusId': 260154834}",https://www.semanticscholar.org/paper/7a5b44ea10a51708e18786595c8d70b18950da11,FacTool: Factuality Detection in Generative AI - A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios,"The emergence of generative pre-trained models has facilitated the synthesis of high-quality text, but it has also posed challenges in identifying factual errors in the generated text. In particular: (1) A wider range of tasks now face an increasing risk of containing factual errors when handled by generative models. (2) Generated texts tend to be lengthy and lack a clearly defined granularity for individual facts. (3) There is a scarcity of explicit evidence available during the process of fact checking. With the above challenges in mind, in this paper, we propose FacTool, a task and domain agnostic framework for detecting factual errors of texts generated by large language models (e.g., ChatGPT). Experiments on four different tasks (knowledge-based QA, code generation, mathematical reasoning, and scientific literature review) show the efficacy of the proposed method. We release the code of FacTool associated with ChatGPT plugin interface at https://github.com/GAIR-NLP/factool .",arXiv.org,2023,48,44,6,True,"{'url': 'https://arxiv.org/pdf/2307.13528', 'status': None}",['Computer Science'],"{'volume': 'abs/2307.13528', 'name': 'ArXiv'}","[{'authorId': '2047713083', 'name': 'Ethan Chern'}, {'authorId': '2224851117', 'name': 'Steffi Chern'}, {'authorId': '2108956946', 'name': 'Shiqi Chen'}, {'authorId': '30300197', 'name': 'Weizhe Yuan'}, {'authorId': '2224772135', 'name': 'Kehua Feng'}, {'authorId': '2110714400', 'name': 'Chunting Zhou'}, {'authorId': '6215698', 'name': 'Junxian He'}, {'authorId': '1700325', 'name': 'Graham Neubig'}, {'authorId': '144118452', 'name': 'Pengfei Liu'}]","This paper proposes FacTool, a task and domain agnostic framework for detecting factual errors of texts generated by large language models (e.g., ChatGPT), and demonstrates the efficacy of the proposed method."
Graham Neubig,1700325,Graham Neubig,https://www.semanticscholar.org/author/1700325,75,[],600,24256,88884b8806262a4095036041e3567d450dba39f7,"{'DBLP': 'journals/corr/abs-2305-06983', 'ArXiv': '2305.06983', 'DOI': '10.48550/arXiv.2305.06983', 'CorpusId': 258615731}",https://www.semanticscholar.org/paper/88884b8806262a4095036041e3567d450dba39f7,Active Retrieval Augmented Generation,"Despite the remarkable ability of large language models (LMs) to comprehend and generate language, they have a tendency to hallucinate and create factually inaccurate output. Augmenting LMs by retrieving information from external knowledge resources is one promising solution. Most existing retrieval augmented LMs employ a retrieve-and-generate setup that only retrieves information once based on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout generation is essential. In this work, we provide a generalized view of active retrieval augmented generation, methods that actively decide when and what to retrieve across the course of the generation. We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens. We test FLARE along with baselines comprehensively over 4 long-form knowledge-intensive generation tasks/datasets. FLARE achieves superior or competitive performance on all tasks, demonstrating the effectiveness of our method. Code and datasets are available at https://github.com/jzbjyb/FLARE.",Conference on Empirical Methods in Natural Language Processing,2023,78,46,6,True,"{'url': 'http://arxiv.org/pdf/2305.06983', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.06983', 'name': 'ArXiv'}","[{'authorId': '2669515', 'name': 'Zhengbao Jiang'}, {'authorId': '40027632', 'name': 'Frank F. Xu'}, {'authorId': '49715441', 'name': 'Luyu Gao'}, {'authorId': '48064856', 'name': 'Zhiqing Sun'}, {'authorId': '1409707585', 'name': 'Qian Liu'}, {'authorId': '2173509991', 'name': 'Jane Dwivedi-Yu'}, {'authorId': '46286308', 'name': 'Yiming Yang'}, {'authorId': '144987107', 'name': 'Jamie Callan'}, {'authorId': '1700325', 'name': 'Graham Neubig'}]","This work proposes Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens."
Graham Neubig,1700325,Graham Neubig,https://www.semanticscholar.org/author/1700325,75,[],600,24256,8e8a1489bf4d782d2435cdeb93f7d1f165747c63,"{'ArXiv': '2307.00524', 'DBLP': 'journals/corr/abs-2307-00524', 'DOI': '10.48550/arXiv.2307.00524', 'CorpusId': 259317075}",https://www.semanticscholar.org/paper/8e8a1489bf4d782d2435cdeb93f7d1f165747c63,Large Language Models Enable Few-Shot Clustering,"Unlike traditional unsupervised clustering, semi-supervised clustering allows users to provide meaningful structure to the data, which helps the clustering algorithm to match the user's intent. Existing approaches to semi-supervised clustering require a significant amount of feedback from an expert to improve the clusters. In this paper, we ask whether a large language model can amplify an expert's guidance to enable query-efficient, few-shot semi-supervised text clustering. We show that LLMs are surprisingly effective at improving clustering. We explore three stages where LLMs can be incorporated into clustering: before clustering (improving input features), during clustering (by providing constraints to the clusterer), and after clustering (using LLMs post-correction). We find incorporating LLMs in the first two stages can routinely provide significant improvements in cluster quality, and that LLMs enable a user to make trade-offs between cost and accuracy to produce desired clusters. We release our code and LLM prompts for the public to use.",arXiv.org,2023,38,6,0,True,"{'url': 'http://arxiv.org/pdf/2307.00524', 'status': None}",['Computer Science'],"{'volume': 'abs/2307.00524', 'name': 'ArXiv'}","[{'authorId': '2061499362', 'name': 'Vijay Viswanathan'}, {'authorId': '24868638', 'name': 'Kiril Gashteovski'}, {'authorId': '19752252', 'name': 'Carolin (Haas) Lawrence'}, {'authorId': '35232494', 'name': 'Tongshuang Sherry Wu'}, {'authorId': '1700325', 'name': 'Graham Neubig'}]","It is found that incorporating LLMs in the first two stages can routinely provide significant improvements in cluster quality, and that LLMs enable a user to make trade-offs between cost and accuracy to produce desired clusters."
Graham Neubig,1700325,Graham Neubig,https://www.semanticscholar.org/author/1700325,75,[],600,24256,9bce3661f01825ad56dc9d2b3d254fd9e3792360,"{'DBLP': 'journals/corr/abs-2305-11789', 'ArXiv': '2305.11789', 'DOI': '10.48550/arXiv.2305.11789', 'CorpusId': 258823453}",https://www.semanticscholar.org/paper/9bce3661f01825ad56dc9d2b3d254fd9e3792360,Solving NLP Problems through Human-System Collaboration: A Discussion-based Approach,"Humans work together to solve common problems by having discussions, explaining, and agreeing or disagreeing with each other. Similarly, if a system can have discussions with humans when solving tasks, it can improve the system's performance and reliability. In previous research on explainability, it has only been possible for the system to make predictions and for humans to ask questions about them rather than having a mutual exchange of opinions. This research aims to create a dataset and computational framework for systems that discuss and refine their predictions through dialogue. Through experiments, we show that the proposed system can have beneficial discussions with humans improving the accuracy by up to 25 points in the natural language inference task.",arXiv.org,2023,73,5,0,True,"{'url': 'http://arxiv.org/pdf/2305.11789', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.11789', 'name': 'ArXiv'}","[{'authorId': '143655216', 'name': 'Masahiro Kaneko'}, {'authorId': '1700325', 'name': 'Graham Neubig'}, {'authorId': '1764004', 'name': 'Naoaki Okazaki'}]",This research aims to create a dataset and computational framework for systems that discuss and refine their predictions through dialogue and shows that the proposed system can have beneficial discussions with humans improving the accuracy by up to 25 points in the natural language inference task.
Graham Neubig,1700325,Graham Neubig,https://www.semanticscholar.org/author/1700325,75,[],600,24256,b4987da792dd45a84232cfb06d71b1c2ec488f38,"{'DBLP': 'conf/emnlp/LiuCN23', 'ArXiv': '2310.07081', 'DOI': '10.48550/arXiv.2310.07081', 'CorpusId': 265907218}",https://www.semanticscholar.org/paper/b4987da792dd45a84232cfb06d71b1c2ec488f38,Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting,"Idioms are common in everyday language, but often pose a challenge to translators because their meanings do not follow from the meanings of their parts. Despite significant advances, machine translation systems still struggle to translate idiomatic expressions. We provide a simple characterization of idiomatic translation and related issues. This allows us to conduct a synthetic experiment revealing a tipping point at which transformer-based machine translation models correctly default to idiomatic translations. To expand multilingual resources, we compile a dataset of ~4k natural sentences containing idiomatic expressions in French, Finnish, and Japanese. To improve translation of natural idioms, we introduce two straightforward yet effective techniques: the strategic upweighting of training loss on potentially idiomatic sentences, and using retrieval-augmented models. This not only improves the accuracy of a strong pretrained MT model on idiomatic sentences by up to 13% in absolute accuracy, but also holds potential benefits for non-idiomatic sentences.",Conference on Empirical Methods in Natural Language Processing,2023,52,0,0,True,"{'url': 'https://arxiv.org/pdf/2310.07081', 'status': None}",['Computer Science'],{'pages': '15095-15111'},"[{'authorId': '2266945896', 'name': 'Emmy Liu'}, {'authorId': '2266465306', 'name': 'Aditi Chaudhary'}, {'authorId': '1700325', 'name': 'Graham Neubig'}]","To improve translation of natural idioms, this work introduces two straightforward yet effective techniques: the strategic upweighting of training loss on potentially idiomatic sentences, and using retrieval-augmented models."
Graham Neubig,1700325,Graham Neubig,https://www.semanticscholar.org/author/1700325,75,[],600,24256,c432aff446d55e72a28394a1508e760cc9a25c08,"{'DBLP': 'conf/icml/Xu0N23', 'ArXiv': '2301.02828', 'DOI': '10.48550/arXiv.2301.02828', 'CorpusId': 255546631}",https://www.semanticscholar.org/paper/c432aff446d55e72a28394a1508e760cc9a25c08,Why do Nearest Neighbor Language Models Work?,"Language models (LMs) compute the probability of a text by sequentially computing a representation of an already-seen context and using this representation to predict the next word. Currently, most LMs calculate these representations through a neural network consuming the immediate previous context. However recently, retrieval-augmented LMs have shown to improve over standard neural LMs, by accessing information retrieved from a large datastore, in addition to their standard, parametric, next-word prediction. In this paper, we set out to understand why retrieval-augmented language models, and specifically why k-nearest neighbor language models (kNN-LMs) perform better than standard parametric LMs, even when the k-nearest neighbor component retrieves examples from the same training set that the LM was originally trained on. To this end, we perform a careful analysis of the various dimensions over which kNN-LM diverges from standard LMs, and investigate these dimensions one by one. Empirically, we identify three main reasons why kNN-LM performs better than standard LMs: using a different input representation for predicting the next tokens, approximate kNN search, and the importance of softmax temperature for the kNN distribution. Further, we incorporate these insights into the model architecture or the training procedure of the standard parametric LM, improving its results without the need for an explicit retrieval component. The code is available at https://github.com/frankxu2004/knnlm-why.",International Conference on Machine Learning,2023,44,10,1,True,"{'url': 'http://arxiv.org/pdf/2301.02828', 'status': None}",['Computer Science'],"{'volume': 'abs/2301.02828', 'name': 'ArXiv'}","[{'authorId': '40027632', 'name': 'Frank F. Xu'}, {'authorId': '47051926', 'name': 'Uri Alon'}, {'authorId': '1700325', 'name': 'Graham Neubig'}]","This paper identifies three main reasons why k-nearest neighbor language models (kNN-LM) perform better than standard LMs: using a different input representation for predicting the next tokens, approximate kNN search, and the importance of softmax temperature for the kNN distribution."
Graham Neubig,1700325,Graham Neubig,https://www.semanticscholar.org/author/1700325,75,[],600,24256,c5207241406586f4263b235667e004b71ea68953,"{'ArXiv': '2305.18185', 'ACL': '2023.starsem-1.14', 'DBLP': 'conf/starsem/TjuatjaLLN23', 'DOI': '10.48550/arXiv.2305.18185', 'CorpusId': 258959069}",https://www.semanticscholar.org/paper/c5207241406586f4263b235667e004b71ea68953,Syntax and Semantics Meet in the “Middle”: Probing the Syntax-Semantics Interface of LMs Through Agentivity,"Recent advances in large language models have prompted researchers to examine their abilities across a variety of linguistic tasks, but little has been done to investigate how models handle the interactions in meaning across words and larger syntactic forms—i.e. phenomena at the intersection of syntax and semantics. We present the semantic notion of agentivity as a case study for probing such interactions. We created a novel evaluation dataset by utilitizing the unique linguistic properties of a subset of optionally transitive English verbs. This dataset was used to prompt varying sizes of three model classes to see if they are sensitive to agentivity at the lexical level, and if they can appropriately employ these word-level priors given a specific syntactic context. Overall, GPT-3 text-davinci-003 performs extremely well across all experiments, outperforming all other models tested by far. In fact, the results are even better correlated with human judgements than both syntactic and semantic corpus statistics. This suggests that LMs may potentially serve as more useful tools for linguistic annotation, theory testing, and discovery than select corpora for certain tasks.",STARSEM,2023,51,1,0,True,"{'url': 'https://arxiv.org/pdf/2305.18185', 'status': None}",['Computer Science'],{'pages': '149-164'},"[{'authorId': '2219036626', 'name': 'Lindia Tjuatja'}, {'authorId': '1381444447', 'name': 'Emmy Liu'}, {'authorId': '145585627', 'name': 'L. Levin'}, {'authorId': '1700325', 'name': 'Graham Neubig'}]","GPT-3 text-davinci-003 performs extremely well across all experiments, outperforming all other models tested by far and suggests that LMs may potentially serve as more useful tools for linguistic annotation, theory testing, and discovery than select corpora for certain tasks."
Graham Neubig,1700325,Graham Neubig,https://www.semanticscholar.org/author/1700325,75,[],600,24256,cc1705fe421c70d85254b557634bd4669fdd49b0,"{'ArXiv': '2305.16636', 'ACL': '2023.acl-long.573', 'DBLP': 'journals/corr/abs-2305-16636', 'DOI': '10.48550/arXiv.2305.16636', 'CorpusId': 258947254}",https://www.semanticscholar.org/paper/cc1705fe421c70d85254b557634bd4669fdd49b0,DataFinder: Scientific Dataset Recommendation from Natural Language Descriptions,"Modern machine learning relies on datasets to develop and validate research ideas. Given the growth of publicly available data, finding the right dataset to use is increasingly difficult. Any research question imposes explicit and implicit constraints on how well a given dataset will enable researchers to answer this question, such as dataset size, modality, and domain. We operationalize the task of recommending datasets given a short natural language description of a research idea, to help people find relevant datasets for their needs. Dataset recommendation poses unique challenges as an information retrieval problem; datasets are hard to directly index for search and there are no corpora readily available for this task. To facilitate this task, we build the DataFinder Dataset which consists of a larger automatically-constructed training set (17.5K queries) and a smaller expert-annotated evaluation set (392 queries). Using this data, we compare various information retrieval algorithms on our test set and present a superior bi-encoder retriever for text-based dataset recommendation. This system, trained on the DataFinder Dataset, finds more relevant search results than existing third-party dataset search engines. To encourage progress on dataset recommendation, we release our dataset and models to the public.",Annual Meeting of the Association for Computational Linguistics,2023,53,3,0,True,"{'url': 'http://arxiv.org/pdf/2305.16636', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.16636', 'name': 'ArXiv'}","[{'authorId': '2061499362', 'name': 'Vijay Viswanathan'}, {'authorId': '49715441', 'name': 'Luyu Gao'}, {'authorId': '35232494', 'name': 'Tongshuang Sherry Wu'}, {'authorId': '144118452', 'name': 'Pengfei Liu'}, {'authorId': '1700325', 'name': 'Graham Neubig'}]","This work operationalizes the task of recommending datasets given a short natural language description of a research idea, to help people find relevant datasets for their needs, and builds the DataFinder Dataset, a larger automatically-constructed training set and a smaller expert-annotated evaluation set."
Graham Neubig,1700325,Graham Neubig,https://www.semanticscholar.org/author/1700325,75,[],600,24256,d5dd7230cccace7e77095d3b5fd8394850f59170,"{'DBLP': 'conf/acl/KabraLKAWCAON23', 'ArXiv': '2305.16171', 'DOI': '10.48550/arXiv.2305.16171', 'CorpusId': 258887835}",https://www.semanticscholar.org/paper/d5dd7230cccace7e77095d3b5fd8394850f59170,Multi-lingual and Multi-cultural Figurative Language Understanding,"Figurative language permeates human communication, but at the same time is relatively understudied in NLP. Datasets have been created in English to accelerate progress towards measuring and improving figurative language processing in language models (LMs). However, the use of figurative language is an expression of our cultural and societal experiences, making it difficult for these phrases to be universally applicable. In this work, we create a figurative language inference dataset, \datasetname, for seven diverse languages associated with a variety of cultures: Hindi, Indonesian, Javanese, Kannada, Sundanese, Swahili and Yoruba. Our dataset reveals that each language relies on cultural and regional concepts for figurative expressions, with the highest overlap between languages originating from the same region. We assess multilingual LMs' abilities to interpret figurative language in zero-shot and few-shot settings. All languages exhibit a significant deficiency compared to English, with variations in performance reflecting the availability of pre-training and fine-tuning data, emphasizing the need for LMs to be exposed to a broader range of linguistic and cultural variation during training.",Annual Meeting of the Association for Computational Linguistics,2023,44,11,1,True,"{'url': 'http://arxiv.org/pdf/2305.16171', 'status': None}",['Computer Science'],{'pages': '8269-8284'},"[{'authorId': '1735001746', 'name': 'Anubha Kabra'}, {'authorId': '1381444447', 'name': 'Emmy Liu'}, {'authorId': '1452678825', 'name': 'Simran Khanuja'}, {'authorId': '8129718', 'name': 'Alham Fikri Aji'}, {'authorId': '9162688', 'name': 'Genta Indra Winata'}, {'authorId': '2220548276', 'name': 'Samuel Cahyawijaya'}, {'authorId': '2056773747', 'name': 'Anuoluwapo Aremu'}, {'authorId': '1988654955', 'name': 'Perez Ogayo'}, {'authorId': '1700325', 'name': 'Graham Neubig'}]","This work assesses multilingual LMs' abilities to interpret figurative language in zero-shot and few-shot settings, and reveals that each language relies on cultural and regional concepts for figurative expressions, with the highest overlap between languages originating from the same region."
Graham Neubig,1700325,Graham Neubig,https://www.semanticscholar.org/author/1700325,75,[],600,24256,d6ae4c0679bdceb029f652efd2a854ac5ade772f,"{'DBLP': 'journals/corr/abs-2310-01387', 'ACL': '2023.bigpicture-1.9', 'ArXiv': '2310.01387', 'DOI': '10.48550/arXiv.2310.01387', 'CorpusId': 263605610}",https://www.semanticscholar.org/paper/d6ae4c0679bdceb029f652efd2a854ac5ade772f,It’s MBR All the Way Down: Modern Generation Techniques Through the Lens of Minimum Bayes Risk,"Minimum Bayes Risk (MBR) decoding is a method for choosing the outputs of a machine learning system based not on the output with the highest probability, but the output with the lowest risk (expected error) among multiple candidates. It is a simple but powerful method: for an additional cost at inference time, MBR provides reliable several-point improvements across metrics for a wide variety of tasks without any additional data or training. Despite this, MBR is not frequently applied in NLP works, and knowledge of the method itself is limited. We first provide an introduction to the method and the recent literature. We show that several recent methods that do not reference MBR can be written as special cases of MBR; this reformulation provides additional theoretical justification for the performance of these methods, explaining some results that were previously only empirical. We provide theoretical and empirical results about the effectiveness of various MBR variants and make concrete recommendations for the application of MBR in NLP models, including future directions in this area.",BIGPICTURE,2023,94,6,0,True,"{'url': 'https://arxiv.org/pdf/2310.01387', 'status': None}",['Computer Science'],"{'volume': 'abs/2310.01387', 'name': 'ArXiv'}","[{'authorId': '2138301112', 'name': 'Amanda Bertsch'}, {'authorId': '2253395527', 'name': 'Alex Xie'}, {'authorId': '1700325', 'name': 'Graham Neubig'}, {'authorId': '1762110', 'name': 'Matthew R. Gormley'}]","It is shown that several recent methods that do not reference MBR can be written as special cases of MBR; this reformulation provides additional theoretical justification for the performance of these methods, explaining some results that were previously only empirical."
Graham Neubig,1700325,Graham Neubig,https://www.semanticscholar.org/author/1700325,75,[],600,24256,dbc368bc8b49347dd27679894524fa62f88492c9,"{'ArXiv': '2305.01625', 'DBLP': 'journals/corr/abs-2305-01625', 'DOI': '10.48550/arXiv.2305.01625', 'CorpusId': 258436892}",https://www.semanticscholar.org/paper/dbc368bc8b49347dd27679894524fa62f88492c9,Unlimiformer: Long-Range Transformers with Unlimited Length Input,"Since the proposal of transformers, these models have been limited to bounded input lengths, because of their need to attend to every token in the input. In this work, we propose Unlimiformer: a general approach that wraps any existing pretrained encoder-decoder transformer, and offloads the cross-attention computation to a single k-nearest-neighbor (kNN) index, while the returned kNN distances are the attention dot-product scores. This kNN index can be kept on either the GPU or CPU memory and queried in sub-linear time; this way, we can index practically unlimited input sequences, while every attention head in every decoder layer retrieves its top-k keys, instead of attending to every key. We evaluate Unlimiformer on several long-document and book-summarization benchmarks, showing that it can process even 500k token-long inputs from the BookSum dataset, without any input truncation at test time. We demonstrate that Unlimiformer improves pretrained models such as BART and Longformer by extending them to unlimited inputs without additional learned weights and without modifying their code. We make our code and models publicly available at https://github.com/abertsch72/unlimiformer .",arXiv.org,2023,56,38,3,True,"{'url': 'http://arxiv.org/pdf/2305.01625', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.01625', 'name': 'ArXiv'}","[{'authorId': '2138301112', 'name': 'Amanda Bertsch'}, {'authorId': '47051926', 'name': 'Uri Alon'}, {'authorId': '1700325', 'name': 'Graham Neubig'}, {'authorId': '1762110', 'name': 'Matthew R. Gormley'}]","This work proposes Unlimiformer: a general approach that wraps any existing pretrained encoder-decoder transformer, and offloads the cross-attention computation to a single k-nearest-neighbor (kNN) index, while the returned kNN distances are the attention dot-product scores."
Graham Neubig,1700325,Graham Neubig,https://www.semanticscholar.org/author/1700325,75,[],600,24256,e41482f4ee984f17382f6cdd900df094d928be06,"{'ArXiv': '2307.13854', 'DBLP': 'journals/corr/abs-2307-13854', 'DOI': '10.48550/arXiv.2307.13854', 'CorpusId': 260164780}",https://www.semanticscholar.org/paper/e41482f4ee984f17382f6cdd900df094d928be06,WebArena: A Realistic Web Environment for Building Autonomous Agents,"With advances in generative AI, there is now potential for autonomous agents to manage daily tasks via natural language commands. However, current agents are primarily created and tested in simplified synthetic environments, leading to a disconnect with real-world scenarios. In this paper, we build an environment for language-guided agents that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on the web, and create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our environment is enriched with tools (e.g., a map) and external knowledge bases (e.g., user manuals) to encourage human-like task-solving. Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and designed to emulate tasks that humans routinely perform on the internet. We experiment with several baseline agents, integrating recent techniques such as reasoning before acting. The results demonstrate that solving complex tasks is challenging: our best GPT-4-based agent only achieves an end-to-end task success rate of 14.41%, significantly lower than the human performance of 78.24%. These results highlight the need for further development of robust agents, that current state-of-the-art large language models are far from perfect performance in these real-life tasks, and that WebArena can be used to measure such progress.",arXiv.org,2023,63,60,7,True,"{'url': 'https://arxiv.org/pdf/2307.13854', 'status': None}",['Computer Science'],"{'volume': 'abs/2307.13854', 'name': 'ArXiv'}","[{'authorId': '2149163534', 'name': 'Shuyan Zhou'}, {'authorId': '40027632', 'name': 'Frank F. Xu'}, {'authorId': '2115313911', 'name': 'Hao Zhu'}, {'authorId': '144101734', 'name': 'Xuhui Zhou'}, {'authorId': '145250604', 'name': 'Robert Lo'}, {'authorId': '66820957', 'name': 'Abishek Sridhar'}, {'authorId': '144691454', 'name': 'Xianyi Cheng'}, {'authorId': '3312309', 'name': 'Yonatan Bisk'}, {'authorId': '47070750', 'name': 'Daniel Fried'}, {'authorId': '47051926', 'name': 'Uri Alon'}, {'authorId': '1700325', 'name': 'Graham Neubig'}]","This paper builds an environment for language-guided agents that is highly realistic and reproducible, and creates an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management."
Graham Neubig,1700325,Graham Neubig,https://www.semanticscholar.org/author/1700325,75,[],600,24256,e69684fb06a7b1fe621d7ef0c97fc2ca0e122c43,"{'DBLP': 'conf/emnlp/ViswanathanZBWN23', 'ArXiv': '2308.12261', 'DOI': '10.48550/arXiv.2308.12261', 'CorpusId': 261075905}",https://www.semanticscholar.org/paper/e69684fb06a7b1fe621d7ef0c97fc2ca0e122c43,Prompt2Model: Generating Deployable Models from Natural Language Instructions,"Large language models (LLMs) enable system builders today to create competent NLP systems through prompting, where they only need to describe the task in natural language and provide a few examples. However, in other ways, LLMs are a step backward from traditional special-purpose NLP models; they require extensive computational resources for deployment and can be gated behind APIs. In this paper, we propose Prompt2Model, a general-purpose method that takes a natural language task description like the prompts provided to LLMs, and uses it to train a special-purpose model that is conducive to deployment. This is done through a multi-step process of retrieval of existing datasets and pretrained models, dataset generation using LLMs, and supervised fine-tuning on these retrieved and generated datasets. Over three tasks, we demonstrate that given the same few-shot prompt as input, Prompt2Model trains models that outperform the results of a strong LLM, gpt-3.5-turbo, by an average of 20% while being up to 700 times smaller. We also show that this data can be used to obtain reliable performance estimates of model performance, enabling model developers to assess model reliability before deployment. Prompt2Model is available open-source at https://github.com/neulab/prompt2model.",Conference on Empirical Methods in Natural Language Processing,2023,43,5,0,True,"{'url': 'https://arxiv.org/pdf/2308.12261', 'status': None}",['Computer Science'],"{'volume': 'abs/2308.12261', 'name': 'ArXiv'}","[{'authorId': '2061499362', 'name': 'Vijay Viswanathan'}, {'authorId': '2023526', 'name': 'Chenyang Zhao'}, {'authorId': '2138301112', 'name': 'Amanda Bertsch'}, {'authorId': '35232494', 'name': 'Tongshuang Sherry Wu'}, {'authorId': '1700325', 'name': 'Graham Neubig'}]","This paper proposes Prompt2Model, a general-purpose method that takes a natural language task description like the prompts provided to LLMs, and uses it to train a special-purpose model that is conducive to deployment."
Graham Neubig,1700325,Graham Neubig,https://www.semanticscholar.org/author/1700325,75,[],600,24256,e7b3b692b0816821aafc0d354749bc3802cbf6ac,"{'DBLP': 'journals/corr/abs-2303-01502', 'ArXiv': '2303.01502', 'DOI': '10.48550/arXiv.2303.01502', 'CorpusId': 257280165}",https://www.semanticscholar.org/paper/e7b3b692b0816821aafc0d354749bc3802cbf6ac,Computational Language Acquisition with Theory of Mind,"Unlike current state-of-the-art language models, young children actively acquire language through interactions with their surrounding environment and caretakers. One mechanism that has been argued to be critical to language learning is the ability to infer the mental states of other agents in social environments, coined Theory of Mind (ToM) by Premack&Woodruff (1978). Drawing inspiration from the modern operationalized versions of ToM implemented in Rabinowitz et al. (2018) and Zhu et al. (2021), we build language-learning agents equipped with ToM, and measure its effects on the learning process. We model ToM by giving the speaker agent an internal listener model that is trained alongside the speaker and used to rerank potential utterances. We experiment with varying task difficulty, hypothesizing that models will acquire more complex language to adapt to stronger environmental pressures. We find that training speakers with a highly weighted ToM listener component leads to performance gains in our image referential game setting. We also find some evidence that increasing task difficulty in the training process results in more fluent and precise utterances in evaluation. This suggests the potential utility of further incorporating ToM, as well as other insights from child language acquisition, into computational models of language acquisition.",International Conference on Learning Representations,2023,35,6,0,True,"{'url': 'http://arxiv.org/pdf/2303.01502', 'status': None}",['Computer Science'],"{'volume': 'abs/2303.01502', 'name': 'ArXiv'}","[{'authorId': '46263614', 'name': 'Andy T. Liu'}, {'authorId': '2115314674', 'name': 'Hao Zhu'}, {'authorId': '1381444447', 'name': 'Emmy Liu'}, {'authorId': '3312309', 'name': 'Yonatan Bisk'}, {'authorId': '1700325', 'name': 'Graham Neubig'}]","It is found that training speakers with a highly weighted ToM listener component leads to performance gains in the authors' image referential game setting, and suggests the potential utility of further incorporating ToM, as well as other insights from child language acquisition, into computational models of language acquisition."
Graham Neubig,1700325,Graham Neubig,https://www.semanticscholar.org/author/1700325,75,[],600,24256,f640e89fcede075b4bde3b2fa0dc78f591589ba3,"{'ACL': '2023.trustnlp-1.6', 'ArXiv': '2307.04507', 'DBLP': 'journals/corr/abs-2307-04507', 'DOI': '10.48550/arXiv.2307.04507', 'CorpusId': 259501636}",https://www.semanticscholar.org/paper/f640e89fcede075b4bde3b2fa0dc78f591589ba3,Improving Factuality of Abstractive Summarization via Contrastive Reward Learning,"Modern abstractive summarization models often generate summaries that contain hallucinated or contradictory information. In this paper, we propose a simple but effective contrastive learning framework that incorporates recent developments in reward learning and factuality metrics. Empirical studies demonstrate that the proposed framework enables summarization models to learn from feedback of factuality metrics using contrastive reward learning, leading to more factual summaries by human evaluations. This suggests that further advances in learning and evaluation algorithms can feed directly into providing more factual summaries. Code and human evaluation results will be publicly available at \url{https://github.com/EthanC111/factuality_summarization}.",TRUSTNLP,2023,31,2,0,True,"{'url': 'https://arxiv.org/pdf/2307.04507', 'status': None}",['Computer Science'],"{'volume': 'abs/2307.04507', 'name': 'ArXiv'}","[{'authorId': '2047713083', 'name': 'Ethan Chern'}, {'authorId': '1390877035', 'name': 'Zhiruo Wang'}, {'authorId': '2221736765', 'name': 'Sanjan Das'}, {'authorId': '2118766697', 'name': 'Bhavuk Sharma'}, {'authorId': '144118452', 'name': 'Pengfei Liu'}, {'authorId': '1700325', 'name': 'Graham Neubig'}]","Empirical studies demonstrate that the proposed framework enables summarization models to learn from feedback of factuality metrics using contrastive reward learning, leading to more factual summaries by human evaluations, suggesting that further advances in learning and evaluation algorithms can feed directly into providing morefactuality summaries."
Graham Neubig,1700325,Graham Neubig,https://www.semanticscholar.org/author/1700325,75,[],600,24256,fd80f7f3673fc6ca02f192d5d73426f11a4be659,"{'DBLP': 'journals/corr/abs-2308-07286', 'ArXiv': '2308.07286', 'ACL': '2023.wmt-1.100', 'DOI': '10.48550/arXiv.2308.07286', 'CorpusId': 260886800}",https://www.semanticscholar.org/paper/fd80f7f3673fc6ca02f192d5d73426f11a4be659,The Devil Is in the Errors: Leveraging Large Language Models for Fine-grained Machine Translation Evaluation,"Automatic evaluation of machine translation (MT) is a critical tool driving the rapid iterative development of MT systems. While considerable progress has been made on estimating a single scalar quality score, current metrics lack the informativeness of more detailed schemes that annotate individual errors, such as Multidimensional Quality Metrics (MQM). In this paper, we help fill this gap by proposing AutoMQM, a prompting technique which leverages the reasoning and in-context learning capabilities of large language models (LLMs) and asks them to identify and categorize errors in translations. We start by evaluating recent LLMs, such as PaLM and PaLM-2, through simple score prediction prompting, and we study the impact of labeled data through in-context learning and finetuning. We then evaluate AutoMQM with PaLM-2 models, and we find that it improves performance compared to just prompting for scores (with particularly large gains for larger models) while providing interpretability through error spans that align with human annotations.",Conference on Machine Translation,2023,36,19,2,True,"{'url': 'https://arxiv.org/pdf/2308.07286', 'status': None}",['Computer Science'],{'pages': '1066-1083'},"[{'authorId': '2058640028', 'name': 'Patrick Fernandes'}, {'authorId': '145346875', 'name': 'Daniel Deutsch'}, {'authorId': '2056981575', 'name': 'M. Finkelstein'}, {'authorId': '47718053', 'name': 'Parker Riley'}, {'authorId': '145644643', 'name': 'André F. T. Martins'}, {'authorId': '1700325', 'name': 'Graham Neubig'}, {'authorId': '2499663', 'name': 'Ankush Garg'}, {'authorId': '144797264', 'name': 'J. Clark'}, {'authorId': '35307070', 'name': 'Markus Freitag'}, {'authorId': '2345617', 'name': 'Orhan Firat'}]","This paper proposes AutoMQM, a prompting technique which leverages the reasoning and in-context learning capabilities of large language models (LLMs) and asks them to identify and categorize errors in translations, and finds that it improves performance compared to just prompting for scores."
Jamie Callan,144987107,Jamie Callan,https://www.semanticscholar.org/author/144987107,75,['Carnegie Mellon University'],331,19329,197d5fbc3764ff18186275545d0764d5b1c7659b,"{'DBLP': 'conf/ictir/GoncalvesMC23', 'DOI': '10.1145/3578337.3605125', 'CorpusId': 260736623}",https://www.semanticscholar.org/paper/197d5fbc3764ff18186275545d0764d5b1c7659b,Conversational Search with Random Walks over Entity Graphs,"The entities that emerge during a conversation can be used to model topics, but not all entities are equally useful for this task. Modeling the conversation with entity graphs and predicting each entity's centrality in the conversation provides additional information that improves the retrieval of answer passages for the current question. Experiments show that using random walks to estimate entity centrality on conversation entity graphs improves top precision answer passage ranking over competitive transformer-based baselines.",International Conference on the Theory of Information Retrieval,2023,49,1,0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/3578337.3605125', 'status': None}",['Computer Science'],{'name': 'Proceedings of the 2023 ACM SIGIR International Conference on Theory of Information Retrieval'},"[{'authorId': '144813741', 'name': 'Gustavo Gonçalves'}, {'authorId': '2065423489', 'name': 'João Magalhães'}, {'authorId': '144987107', 'name': 'Jamie Callan'}]",Experiments show that using random walks to estimate entity centrality on conversation entity graphs improves top precision answer passage ranking over competitive transformer-based baselines.
Jamie Callan,144987107,Jamie Callan,https://www.semanticscholar.org/author/144987107,75,['Carnegie Mellon University'],331,19329,1e0a4ff0c5d2d850ff5907e310ffcedc9cad9718,"{'DBLP': 'conf/ictir/Borges0C23', 'DOI': '10.1145/3578337.3605131', 'CorpusId': 260737097}",https://www.semanticscholar.org/paper/1e0a4ff0c5d2d850ff5907e310ffcedc9cad9718,KALE: Using a K-Sparse Projector for Lexical Expansion,"Recent research has proposed retrieval approaches based on sparse representations and inverted indexes, with terms produced by neural language models and leveraging the advantages from both neural retrieval and lexical matching. This paper proposes KALE, a new lightweight method of this family that uses a small model with a k-sparse projector to convert dense representations into a sparse set of entries from a latent vocabulary. The KALE vocabulary captures semantic concepts than perform well when used in isolation, and perform better when extending the original lexical vocabulary, this way improving first-stage retrieval accuracy. Experiments with the MSMARCOv1 passage retrieval dataset, the TREC Deep Learning dataset, and BEIR datasets, examined the effectiveness of KALE under varying conditions. Results show that the KALE terms can replace the original lexical vocabulary, with gains in accuracy and efficiency. Combining KALE with the original lexical vocabulary, or with other learned terms, can further improve retrieval accuracy with only a modest increase in computational cost.",International Conference on the Theory of Information Retrieval,2023,45,0,0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/3578337.3605131', 'status': None}",['Computer Science'],{'name': 'Proceedings of the 2023 ACM SIGIR International Conference on Theory of Information Retrieval'},"[{'authorId': '2073056726', 'name': 'Luís Borges'}, {'authorId': '144694868', 'name': 'Bruno Martins'}, {'authorId': '144987107', 'name': 'Jamie Callan'}]","KALE is a new lightweight method that uses a small model with a k-sparse projector to convert dense representations into a sparse set of entries from a latent vocabulary, which can replace the original lexical vocabulary with gains in accuracy and efficiency."
Jamie Callan,144987107,Jamie Callan,https://www.semanticscholar.org/author/144987107,75,['Carnegie Mellon University'],331,19329,6b7eefa15c0a461afeab4fa13cf862c5340fdc2a,"{'DBLP': 'conf/ictir/0003GC23', 'DOI': '10.1145/3578337.3605126', 'CorpusId': 260736470}",https://www.semanticscholar.org/paper/6b7eefa15c0a461afeab4fa13cf862c5340fdc2a,CSurF: Sparse Lexical Retrieval through Contextualized Surface Forms,"Lexical exact-match systems perform text retrieval efficiently with sparse matching signals and fast retrieval through inverted lists, but naturally suffer from the mismatch between lexical surface form and implicit term semantics. This paper proposes to directly bridge the surface form space and the term semantics space in lexical exact-match retrieval via contextualized surface forms (CSF). Each CSF pairs a lexical surface form with a context source, and is represented by a lexical form weight and a contextualized semantic vector representation. This framework is able to perform sparse lexicon-based retrieval by learning to represent each query and document as a ""bag-of-CSFs"", simultaneously addressing two key factors in sparse retrieval: vocabulary expansion of surface form and semantic representation of term meaning. At retrieval time, it efficiently matches CSFs through exact-match of learned surface forms, and effectively scores each CSF pair via contextual semantic representations, leading to joint improvement in both term match and term scoring. Multiple experiments show that this approach successfully resolves the main mismatch issues in lexical exact-match retrieval and outperforms state-of-the-art lexical exact-match systems, reaching comparable accuracy as lexical all-to-all soft match systems as an efficient exact-match-based system.",International Conference on the Theory of Information Retrieval,2023,52,0,0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/3578337.3605126', 'status': None}",['Computer Science'],{'name': 'Proceedings of the 2023 ACM SIGIR International Conference on Theory of Information Retrieval'},"[{'authorId': '143783743', 'name': 'Zhen Fan'}, {'authorId': '49715441', 'name': 'Luyu Gao'}, {'authorId': '144987107', 'name': 'Jamie Callan'}]","This paper proposes to directly bridge the surface form space and the term semantics space in lexical exact-match retrieval via contextualized surface forms (CSF), reaching comparable accuracy as lexical all-to-all soft match systems as an efficient exact- match-based system."
Jamie Callan,144987107,Jamie Callan,https://www.semanticscholar.org/author/144987107,75,['Carnegie Mellon University'],331,19329,88884b8806262a4095036041e3567d450dba39f7,"{'DBLP': 'journals/corr/abs-2305-06983', 'ArXiv': '2305.06983', 'DOI': '10.48550/arXiv.2305.06983', 'CorpusId': 258615731}",https://www.semanticscholar.org/paper/88884b8806262a4095036041e3567d450dba39f7,Active Retrieval Augmented Generation,"Despite the remarkable ability of large language models (LMs) to comprehend and generate language, they have a tendency to hallucinate and create factually inaccurate output. Augmenting LMs by retrieving information from external knowledge resources is one promising solution. Most existing retrieval augmented LMs employ a retrieve-and-generate setup that only retrieves information once based on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout generation is essential. In this work, we provide a generalized view of active retrieval augmented generation, methods that actively decide when and what to retrieve across the course of the generation. We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens. We test FLARE along with baselines comprehensively over 4 long-form knowledge-intensive generation tasks/datasets. FLARE achieves superior or competitive performance on all tasks, demonstrating the effectiveness of our method. Code and datasets are available at https://github.com/jzbjyb/FLARE.",Conference on Empirical Methods in Natural Language Processing,2023,78,46,6,True,"{'url': 'http://arxiv.org/pdf/2305.06983', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.06983', 'name': 'ArXiv'}","[{'authorId': '2669515', 'name': 'Zhengbao Jiang'}, {'authorId': '40027632', 'name': 'Frank F. Xu'}, {'authorId': '49715441', 'name': 'Luyu Gao'}, {'authorId': '48064856', 'name': 'Zhiqing Sun'}, {'authorId': '1409707585', 'name': 'Qian Liu'}, {'authorId': '2173509991', 'name': 'Jane Dwivedi-Yu'}, {'authorId': '46286308', 'name': 'Yiming Yang'}, {'authorId': '144987107', 'name': 'Jamie Callan'}, {'authorId': '1700325', 'name': 'Graham Neubig'}]","This work proposes Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens."
Jamie Callan,144987107,Jamie Callan,https://www.semanticscholar.org/author/144987107,75,['Carnegie Mellon University'],331,19329,ac9ee72a5cd611e9143e385f668af662583721ee,"{'DBLP': 'journals/corr/abs-2308-11387', 'ArXiv': '2308.11387', 'DOI': '10.48550/arXiv.2308.11387', 'CorpusId': 261064649}",https://www.semanticscholar.org/paper/ac9ee72a5cd611e9143e385f668af662583721ee,Multi-Objective Improvement of Android Applications,"Non-functional properties, such as runtime or memory use, are important to mobile app users and developers, as they affect user experience. Previous work on automated improvement of non-functional properties in mobile apps failed to address the inherent trade-offs between such properties. We propose a practical approach and the first open-source tool, GIDroid (2023), for multi-objective automated improvement of Android apps. In particular, we use Genetic improvement, a search-based technique that navigates the space of software variants to find improved software. We use a simulation-based testing framework to greatly improve the speed of search. GIDroid contains three state-of-the-art multi-objective algorithms, and two new mutation operators, which cache the results of method calls. Genetic improvement relies on testing to validate patches. Previous work showed that tests in open-source Android applications are scarce. We thus wrote tests for 21 versions of 7 Android apps, creating a new benchmark for performance improvements. We used GIDroid to improve versions of mobile apps where developers had previously found improvements to runtime, memory, and bandwidth use. Our technique automatically re-discovers 64% of existing improvements. We then applied our approach to current versions of software in which there were no known improvements. We were able to improve execution time by up to 35%, and memory use by up to 33% in these apps.",arXiv.org,2023,76,0,0,True,"{'url': 'https://arxiv.org/pdf/2308.11387', 'status': None}",['Computer Science'],"{'volume': 'abs/2308.11387', 'name': 'ArXiv'}","[{'authorId': '144987107', 'name': 'Jamie Callan'}, {'authorId': '1923360', 'name': 'J. Petke'}]","This work proposes a practical approach and the first open-source tool, GIDroid, for multi-objective automated improvement of Android apps, and uses Genetic improvement, a search-based technique that navigates the space of software variants to find improved software."
Jeffrey Bigham,1744846,Jeffrey P. Bigham,https://www.semanticscholar.org/author/1744846,56,[],288,10897,0e84679cf0945a2868245ba2be68c90453e48f2e,"{'DBLP': 'journals/corr/abs-2301-08372', 'ArXiv': '2301.08372', 'DOI': '10.48550/arXiv.2301.08372', 'CorpusId': 256080602}",https://www.semanticscholar.org/paper/0e84679cf0945a2868245ba2be68c90453e48f2e,Screen Correspondence: Mapping Interchangeable Elements between UIs,"Understanding user interface (UI) functionality is a useful yet challenging task for both machines and people. In this paper, we investigate a machine learning approach for screen correspondence, which allows reasoning about UIs by mapping their elements onto previously encountered examples with known functionality and properties. We describe and implement a model that incorporates element semantics, appearance, and text to support correspondence computation without requiring any labeled examples. Through a comprehensive performance evaluation, we show that our approach improves upon baselines by incorporating multi-modal properties of UIs. Finally, we show three example applications where screen correspondence facilitates better UI understanding for humans and machines: (i) instructional overlay generation, (ii) semantic UI element search, and (iii) automated interface testing.",arXiv.org,2023,70,4,0,True,"{'url': 'http://arxiv.org/pdf/2301.08372', 'status': None}",['Computer Science'],"{'volume': 'abs/2301.08372', 'name': 'ArXiv'}","[{'authorId': '2109186166', 'name': 'Jason Wu'}, {'authorId': '3246971', 'name': 'Amanda Swearngin'}, {'authorId': '2141934656', 'name': 'Xiaoyi Zhang'}, {'authorId': '2057155807', 'name': 'Jeffrey Nichols'}, {'authorId': '1744846', 'name': 'Jeffrey P. Bigham'}]","This paper describes and implements a model that incorporates element semantics, appearance, and text to support correspondence computation without requiring any labeled examples, and shows that this approach improves upon baselines by incorporating multi-modal properties of UIs."
Jeffrey Bigham,1744846,Jeffrey P. Bigham,https://www.semanticscholar.org/author/1744846,56,[],288,10897,3f261fb980858e39129af5bc8a6c8565d7bb8329,"{'DBLP': 'journals/access/PaulinoCYBLVGBP23', 'DOI': '10.1109/ACCESS.2023.3319597', 'CorpusId': 263180410}",https://www.semanticscholar.org/paper/3f261fb980858e39129af5bc8a6c8565d7bb8329,Exploring Stigmergic Collaboration and Task Modularity Through an Expert Crowdsourcing Annotation System: The Case of Storm Phenomena in the Euro-Atlantic Region,"Extreme weather events, such as windstorms, hurricanes, and heat waves, exert a significant impact on global natural catastrophes and pose substantial challenges for weather forecasting systems. To enhance the accuracy and preparedness for extreme weather events, this study explores the potential of using expert crowdsourcing in storm forecasting research through the application of stigmergic collaboration. We present the development and implementation of an expert Crowdsourcing for Semantic Annotation of Atmospheric Phenomena (eCSAAP) system, designed to leverage the collective knowledge and experience of meteorological experts. Through a participatory co-creation process, we iteratively developed a web-based annotation tool capable of capturing multi-faceted insights from weather data and generating visualizations for expert crowdsourcing campaigns. In this context, this article investigates the intrinsic coordination among experts engaged in crowdsourcing tasks focused on the semantic annotation of extreme weather events. The study brings insights about the behavior of expert crowds by considering the cognitive biases and highlighting the impact of existing annotations on the quality of data gathered from the crowd and the collective knowledge generated. The insights regarding the crowdsourcing dynamics, particularly stigmergy, offer a promising starting point for utilizing stigmergic collaboration as an effective coordination mechanism for weather experts in crowdsourcing platforms but also in other domains requiring expertise-driven collective intelligence.",IEEE Access,2023,111,0,0,True,"{'url': 'https://ieeexplore.ieee.org/ielx7/6287639/6514899/10265012.pdf', 'status': None}",['Computer Science'],"{'volume': '11', 'pages': '106485-106502', 'name': 'IEEE Access'}","[{'authorId': '9574315', 'name': 'Dennis Paulino'}, {'authorId': '121795834', 'name': 'António Correia'}, {'authorId': '40936903', 'name': 'M. Yagui'}, {'authorId': '2244407761', 'name': 'João Barroso'}, {'authorId': '2248556495', 'name': 'Margarida L. R. Liberato'}, {'authorId': '1784835', 'name': 'A. Vivacqua'}, {'authorId': '2248197228', 'name': 'Andrea Grover'}, {'authorId': '1744846', 'name': 'Jeffrey P. Bigham'}, {'authorId': '145288702', 'name': 'Hugo Paredes'}]","The intrinsic coordination among experts engaged in crowdsourcing tasks focused on the semantic annotation of extreme weather events is investigated, bringing insights about the behavior of expert crowds by considering the cognitive biases and highlighting the impact of existing annotations on the quality of data gathered from the crowd and the collective knowledge generated."
Jeffrey Bigham,1744846,Jeffrey P. Bigham,https://www.semanticscholar.org/author/1744846,56,[],288,10897,7ee7d32c3e7f01f49c40e5ba7e0b4d5e9ea040c9,"{'DBLP': 'journals/cacm/ValenciaSRBBA24', 'DOI': '10.1145/3610939', 'CorpusId': 266436632}",https://www.semanticscholar.org/paper/7ee7d32c3e7f01f49c40e5ba7e0b4d5e9ea040c9,Nonverbal Communication through Expressive Objects,"Augmentative and alternative communication (AAC) devices enable speech-based communication, but generating speech is not the only resource needed to have a successful conversation. Being able to signal one wishes to take a turn by raising a hand or providing some other cue is critical in securing a turn to speak. Experienced conversation partners know how to recognize the nonverbal communication an augmented communicator (AC) displays, but these same nonverbal gestures can be hard to interpret by people who meet an AC for the first time. Prior work has identified motion through robots and expressive objects as a modality that can support communication. In this work, we work closely with an AAC user to understand how motion through a physical expressive object can support their communication. We present our process and resulting lessons on the designed object and the co-design process.",Communications of the ACM,2023,18,0,0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/3610939', 'status': None}",['Computer Science'],"{'volume': '67', 'pages': '123 - 131', 'name': 'Communications of the ACM'}","[{'authorId': '48114196', 'name': 'Stephanie Valencia'}, {'authorId': '2275634215', 'name': 'Mark Steidl'}, {'authorId': '2275635568', 'name': 'Michael L. Rivera'}, {'authorId': '2275629380', 'name': 'Cynthia L. Bennett'}, {'authorId': '1744846', 'name': 'Jeffrey P. Bigham'}, {'authorId': '1882027', 'name': 'H. Admoni'}]",This work works closely with an AAC user to understand how motion through a physical expressive object can support their communication and presents the process and resulting lessons on the designed object and the co-design process.
Jeffrey Bigham,1744846,Jeffrey P. Bigham,https://www.semanticscholar.org/author/1744846,56,[],288,10897,8ab27849799286459465d2262f926354093b20a9,"{'ArXiv': '2305.14296', 'DBLP': 'journals/corr/abs-2305-14296', 'DOI': '10.48550/arXiv.2305.14296', 'CorpusId': 258840901}",https://www.semanticscholar.org/paper/8ab27849799286459465d2262f926354093b20a9,USB: A Unified Summarization Benchmark Across Tasks and Domains,"While the NLP community has produced numerous summarization benchmarks, none provide the rich annotations required to simultaneously address many important problems related to control and reliability. We introduce a Wikipedia-derived benchmark, complemented by a rich set of crowd-sourced annotations, that supports $8$ interrelated tasks: (i) extractive summarization; (ii) abstractive summarization; (iii) topic-based summarization; (iv) compressing selected sentences into a one-line summary; (v) surfacing evidence for a summary sentence; (vi) predicting the factual accuracy of a summary sentence; (vii) identifying unsubstantiated spans in a summary sentence; (viii) correcting factual errors in summaries. We compare various methods on this benchmark and discover that on multiple tasks, moderately-sized fine-tuned models consistently outperform much larger few-shot prompted language models. For factuality-related tasks, we also evaluate existing heuristics to create training data and find that training on them results in worse performance than training on $20\times$ less human-labeled data. Our articles draw from $6$ domains, facilitating cross-domain analysis. On some tasks, the amount of training data matters more than the domain where it comes from, while for other tasks training specifically on data from the target domain, even if limited, is more beneficial.",Conference on Empirical Methods in Natural Language Processing,2023,50,1,0,True,"{'url': 'http://arxiv.org/pdf/2305.14296', 'status': None}",['Computer Science'],{'pages': '8826-8845'},"[{'authorId': '38716503', 'name': 'Kundan Krishna'}, {'authorId': '1491232062', 'name': 'Prakhar Gupta'}, {'authorId': '98806251', 'name': 'S. Ramprasad'}, {'authorId': '1912476', 'name': 'Byron C. Wallace'}, {'authorId': '1744846', 'name': 'Jeffrey P. Bigham'}, {'authorId': '32219137', 'name': 'Zachary Chase Lipton'}]","A Wikipedia-derived benchmark is introduced, complemented by a rich set of crowd-sourced annotations, that supports interrelated tasks and finds that on multiple tasks, moderately-sized fine-tuned models consistently outperform much larger few-shot prompted language models."
Jeffrey Bigham,1744846,Jeffrey P. Bigham,https://www.semanticscholar.org/author/1744846,56,[],288,10897,98abc6de98a24d599cf009a9670eaa5c97cba9bb,"{'DBLP': 'conf/chi/WuWSPNB23', 'ArXiv': '2301.13280', 'DOI': '10.1145/3544548.3581158', 'CorpusId': 256416083}",https://www.semanticscholar.org/paper/98abc6de98a24d599cf009a9670eaa5c97cba9bb,WebUI: A Dataset for Enhancing Visual UI Understanding with Web Semantics,"Modeling user interfaces (UIs) from visual information allows systems to make inferences about the functionality and semantics needed to support use cases in accessibility, app automation, and testing. Current datasets for training machine learning models are limited in size due to the costly and time-consuming process of manually collecting and annotating UIs. We crawled the web to construct WebUI, a large dataset of 400,000 rendered web pages associated with automatically extracted metadata. We analyze the composition of WebUI and show that while automatically extracted data is noisy, most examples meet basic criteria for visual UI modeling. We applied several strategies for incorporating semantics found in web pages to increase the performance of visual UI understanding models in the mobile domain, where less labeled data is available: (i) element detection, (ii) screen classification and (iii) screen similarity.",International Conference on Human Factors in Computing Systems,2023,60,15,0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/3544548.3581158', 'status': None}",['Computer Science'],{'name': 'Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems'},"[{'authorId': '2109186166', 'name': 'Jason Wu'}, {'authorId': '2191079032', 'name': 'Siyan Wang'}, {'authorId': '2203460332', 'name': 'Siman Shen'}, {'authorId': '152609527', 'name': 'Yi-Hao Peng'}, {'authorId': '2057156585', 'name': 'Jeffrey Nichols'}, {'authorId': '1744846', 'name': 'Jeffrey P. Bigham'}]","This work crawled the web to construct WebUI, a large dataset of 400,000 rendered web pages associated with automatically extracted metadata, and analyzed the composition of WebUI to show that while automatically extracted data is noisy, most examples meet basic criteria for visual UI modeling."
Jeffrey Bigham,1744846,Jeffrey P. Bigham,https://www.semanticscholar.org/author/1744846,56,[],288,10897,c84f0a204827065338c412ace037952900a1a279,"{'ArXiv': '2308.08726', 'DBLP': 'conf/uist/WuKSSBN23', 'DOI': '10.1145/3586183.3606824', 'CorpusId': 261030456}",https://www.semanticscholar.org/paper/c84f0a204827065338c412ace037952900a1a279,Never-ending Learning of User Interfaces,"Machine learning models have been trained to predict semantic information about user interfaces (UIs) to make apps more accessible, easier to test, and to automate. Currently, most models rely on datasets of static screenshots that are labeled by human annotators, a process that is costly and surprisingly error-prone for certain tasks. For example, workers labeling whether a UI element is “tappable” from a screenshot must guess using visual signifiers, and do not have the benefit of tapping on the UI element in the running app and observing the effects. In this paper, we present the Never-ending UI Learner, an app crawler that automatically installs real apps from a mobile app store and crawls them to infer semantic properties of UIs by interacting with UI elements, discovering new and challenging training examples to learn from, and continually updating machine learning models designed to predict these semantics. The Never-ending UI Learner so far has crawled for more than 5,000 device-hours, performing over half a million actions on 6,000 apps to train three computer vision models for i) tappability prediction, ii) draggability prediction, and iii) screen similarity.",ACM Symposium on User Interface Software and Technology,2023,58,1,0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/3586183.3606824', 'status': None}",['Computer Science'],{'name': 'Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology'},"[{'authorId': '2109186166', 'name': 'Jason Wu'}, {'authorId': '2251531', 'name': 'Rebecca Krosnick'}, {'authorId': '3396325', 'name': 'E. Schoop'}, {'authorId': '3246971', 'name': 'Amanda Swearngin'}, {'authorId': '1744846', 'name': 'Jeffrey P. Bigham'}, {'authorId': '2057156585', 'name': 'Jeffrey Nichols'}]","The Never-ending UI Learner is presented, an app crawler that automatically installs real apps from a mobile app store and crawls them to infer semantic properties of UIs by interacting with UI elements, discovering new and challenging training examples to learn from, and continually updating machine learning models designed to predict these semantics."
Jeffrey Bigham,1744846,Jeffrey P. Bigham,https://www.semanticscholar.org/author/1744846,56,[],288,10897,d757a58200254625c3326a32a1da6fa8eaa2eff3,"{'DBLP': 'journals/corr/abs-2306-05446', 'ArXiv': '2306.05446', 'DOI': '10.48550/arXiv.2306.05446', 'CorpusId': 259129537}",https://www.semanticscholar.org/paper/d757a58200254625c3326a32a1da6fa8eaa2eff3,Latent Phrase Matching for Dysarthric Speech,"Many consumer speech recognition systems are not tuned for people with speech disabilities, resulting in poor recognition and user experience, especially for severe speech differences. Recent studies have emphasized interest in personalized speech models from people with atypical speech patterns. We propose a query-by-example-based personalized phrase recognition system that is trained using small amounts of speech, is language agnostic, does not assume a traditional pronunciation lexicon, and generalizes well across speech difference severities. On an internal dataset collected from 32 people with dysarthria, this approach works regardless of severity and shows a 60% improvement in recall relative to a commercial speech recognition system. On the public EasyCall dataset of dysarthric speech, our approach improves accuracy by 30.5%. Performance degrades as the number of phrases increases, but consistently outperforms ASR systems when trained with 50 unique phrases.",Interspeech,2023,32,0,0,True,"{'url': 'http://arxiv.org/pdf/2306.05446', 'status': None}","['Computer Science', 'Engineering']","{'volume': 'abs/2306.05446', 'name': 'ArXiv'}","[{'authorId': '98658818', 'name': 'Colin S. Lea'}, {'authorId': '27371588', 'name': 'Dianna Yee'}, {'authorId': '30888277', 'name': 'Jaya Narain'}, {'authorId': '2109594780', 'name': 'Zifang Huang'}, {'authorId': '2114426903', 'name': 'Lauren Tooley'}, {'authorId': '1744846', 'name': 'Jeffrey P. Bigham'}, {'authorId': '1689620', 'name': 'Leah Findlater'}]","A query-by-example-based personalized phrase recognition system that is trained using small amounts of speech, is language agnostic, does not assume a traditional pronunciation lexicon, and generalizes well across speech difference severities is proposed."
Jeffrey Bigham,1744846,Jeffrey P. Bigham,https://www.semanticscholar.org/author/1744846,56,[],288,10897,f29922cbfaf825d5e1d4986dc01bda74b4d88e04,"{'DBLP': 'conf/chi/LeaHNTYTGBF23', 'ArXiv': '2302.09044', 'DOI': '10.1145/3544548.3581224', 'CorpusId': 257019977}",https://www.semanticscholar.org/paper/f29922cbfaf825d5e1d4986dc01bda74b4d88e04,From User Perceptions to Technical Improvement: Enabling People Who Stutter to Better Use Speech Recognition,"Consumer speech recognition systems do not work as well for many people with speech differences, such as stuttering, relative to the rest of the general population. However, what is not clear is the degree to which these systems do not work, how they can be improved, or how much people want to use them. In this paper, we first address these questions using results from a 61-person survey from people who stutter and find participants want to use speech recognition but are frequently cut off, misunderstood, or speech predictions do not represent intent. In a second study, where 91 people who stutter recorded voice assistant commands and dictation, we quantify how dysfluencies impede performance in a consumer-grade speech recognition system. Through three technical investigations, we demonstrate how many common errors can be prevented, resulting in a system that cuts utterances off 79.1% less often and improves word error rate from 25.4% to 9.9%.",International Conference on Human Factors in Computing Systems,2023,91,5,1,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/3544548.3581224', 'status': None}",['Computer Science'],{'name': 'Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems'},"[{'authorId': '98658818', 'name': 'Colin S. Lea'}, {'authorId': '2109594780', 'name': 'Zifang Huang'}, {'authorId': '30888277', 'name': 'Jaya Narain'}, {'authorId': '2114426903', 'name': 'Lauren Tooley'}, {'authorId': '27371588', 'name': 'Dianna Yee'}, {'authorId': '2214744586', 'name': 'Dung Tien Tran'}, {'authorId': '1765829', 'name': 'P. Georgiou'}, {'authorId': '1744846', 'name': 'Jeffrey P. Bigham'}, {'authorId': '1689620', 'name': 'Leah Findlater'}]","Through three technical investigations, it is demonstrated how many common errors can be prevented, resulting in a system that cuts utterances off 79.1% less often and improves word error rate from 25.4% to 9.9%."
Justine Cassell,145431806,Justine Cassell,https://www.semanticscholar.org/author/145431806,62,"['Carnegie Mellon University', 'Inria Paris']",218,16004,24bff26f19051b1413d1e343322c1ae4bba05428,"{'ACL': '2023.sigdial-1.53', 'DBLP': 'conf/sigdial/AbulimitiCC23', 'ArXiv': '2307.15582', 'DOI': '10.48550/arXiv.2307.15582', 'CorpusId': 260315817}",https://www.semanticscholar.org/paper/24bff26f19051b1413d1e343322c1ae4bba05428,When to generate hedges in peer-tutoring interactions,"This paper explores the application of machine learning techniques to predict where hedging occurs in peer-tutoring interactions. The study uses a naturalistic face-to-face dataset annotated for natural language turns, conversational strategies, tutoring strategies, and nonverbal behaviors. These elements are processed into a vector representation of the previous turns, which serves as input to several machine learning models, including MLP and LSTM. The results show that embedding layers, capturing the semantic information of the previous turns, significantly improves the model’s performance. Additionally, the study provides insights into the importance of various features, such as interpersonal rapport and nonverbal behaviors, in predicting hedges by using Shapley values for feature explanation. We discover that the eye gaze of both the tutor and the tutee has a significant impact on hedge prediction. We further validate this observation through a follow-up ablation study.",SIGDIAL Conferences,2023,43,0,0,True,"{'url': 'https://arxiv.org/pdf/2307.15582', 'status': None}",['Computer Science'],{'pages': '572-583'},"[{'authorId': '2220550049', 'name': 'Alafate Abulimiti'}, {'authorId': '2049106', 'name': 'C. Clavel'}, {'authorId': '145431806', 'name': 'Justine Cassell'}]","The results show that embedding layers, capturing the semantic information of the previous turns, significantly improves the model’s performance and provides insights into the importance of various features, such as interpersonal rapport and nonverbal behaviors, in predicting hedges by using Shapley values for feature explanation."
Justine Cassell,145431806,Justine Cassell,https://www.semanticscholar.org/author/145431806,62,"['Carnegie Mellon University', 'Inria Paris']",218,16004,74fedee9d809ec766a2089a89435fa7dd1346693,"{'ArXiv': '2306.14696', 'ACL': '2023.acl-long.50', 'DBLP': 'conf/acl/AbulimitiCC23', 'DOI': '10.48550/arXiv.2306.14696', 'CorpusId': 259252057}",https://www.semanticscholar.org/paper/74fedee9d809ec766a2089a89435fa7dd1346693,How About Kind of Generating Hedges using End-to-End Neural Models?,"Hedging is a strategy for softening the impact of a statement in conversation. In reducing the strength of an expression, it may help to avoid embarrassment (more technically, “face threat”) to one’s listener. For this reason, it is often found in contexts of instruction, such as tutoring. In this work, we develop a model of hedge generation based on i) fine-tuning state-of-the-art language models trained on human-human tutoring data, followed by ii) reranking to select the candidate that best matches the expected hedging strategy within a candidate pool using a hedge classifier. We apply this method to a natural peer-tutoring corpus containing a significant number of disfluencies, repetitions, and repairs. The results show that generation in this noisy environment is feasible with reranking. By conducting an error analysis for both approaches, we reveal the challenges faced by systems attempting to accomplish both social and task-oriented goals in conversation.",Annual Meeting of the Association for Computational Linguistics,2023,75,1,0,True,"{'url': 'http://arxiv.org/pdf/2306.14696', 'status': None}",['Computer Science'],"{'volume': 'abs/2306.14696', 'name': 'ArXiv'}","[{'authorId': '2220550049', 'name': 'Alafate Abulimiti'}, {'authorId': '2049106', 'name': 'C. Clavel'}, {'authorId': '145431806', 'name': 'Justine Cassell'}]","This work develops a model of hedge generation based on fine-tuning state-of-the-art language models trained on human-human tutoring data, followed by reranking to select the candidate that best matches the expected hedging strategy within a candidate pool using a hedge classifier."
Justine Cassell,145431806,Justine Cassell,https://www.semanticscholar.org/author/145431806,62,"['Carnegie Mellon University', 'Inria Paris']",218,16004,b3efaa75beada858414a5ba2346dec317203633c,"{'DBLP': 'journals/corr/abs-2306-14911', 'ArXiv': '2306.14911', 'ACL': '2022.acl-long.153', 'DOI': '10.18653/v1/2022.acl-long.153', 'CorpusId': 247774353}",https://www.semanticscholar.org/paper/b3efaa75beada858414a5ba2346dec317203633c,"""You might think about slightly revising the title”: Identifying Hedges in Peer-tutoring Interactions","Hedges have an important role in the management of rapport. In peer-tutoring, they are notably used by tutors in dyads experiencing low rapport to tone down the impact of instructions and negative feedback.Pursuing the objective of building a tutoring agent that manages rapport with teenagers in order to improve learning, we used a multimodal peer-tutoring dataset to construct a computational framework for identifying hedges. We compared approaches relying on pre-trained resources with others that integrate insights from the social science literature. Our best performance involved a hybrid approach that outperforms the existing baseline while being easier to interpret. We employ a model explainability tool to explore the features that characterize hedges in peer-tutoring conversations, and we identify some novel features, and the benefits of a such a hybrid model approach.",Annual Meeting of the Association for Computational Linguistics,2023,57,10,0,True,"{'url': 'https://aclanthology.org/2022.acl-long.153.pdf', 'status': None}",['Computer Science'],{'pages': '2160-2174'},"[{'authorId': '2160596647', 'name': 'Yann Raphalen'}, {'authorId': '2049106', 'name': 'C. Clavel'}, {'authorId': '145431806', 'name': 'Justine Cassell'}]","A model explainability tool is employed to explore the features that characterize hedges in peer-tutoring conversations, and some novel features, and the benefits of a such a hybrid model approach are identified."
Lei Li,143900005,Lei Li,https://www.semanticscholar.org/author/143900005,47,['University of California Santa Barbara'],181,9898,145c90515c04f40c4e88a177adeb4fcd6c1009b0,"{'DOI': '10.1038/s41558-023-01692-7', 'CorpusId': 259362436}",https://www.semanticscholar.org/paper/145c90515c04f40c4e88a177adeb4fcd6c1009b0,Co-benefits of carbon neutrality in enhancing and stabilizing solar and wind energy,,Nature Climate Change,2023,75,14,0,True,"{'url': 'https://www.nature.com/articles/s41558-023-01692-7.pdf', 'status': None}",,"{'volume': '13', 'pages': '693-700', 'name': 'Nature Climate Change'}","[{'authorId': '33405856', 'name': 'Yadong Lei'}, {'authorId': '2048796589', 'name': 'Zhili Wang'}, {'authorId': '2145352209', 'name': 'Deying Wang'}, {'authorId': '2109107295', 'name': 'Xiaoye Zhang'}, {'authorId': '27756452', 'name': 'H. Che'}, {'authorId': '2144065292', 'name': 'Xu Yue'}, {'authorId': '2000480587', 'name': 'Chenguang Tian'}, {'authorId': '35588756', 'name': 'J. Zhong'}, {'authorId': '48357865', 'name': 'Lifeng Guo'}, {'authorId': '143900005', 'name': 'Lei Li'}, {'authorId': '2111824218', 'name': 'Hao Zhou'}, {'authorId': '2221296240', 'name': 'Lin Liu'}, {'authorId': '2154893865', 'name': 'Yangyang Xu'}]",TLDR not found
Lei Li,143900005,Lei Li,https://www.semanticscholar.org/author/143900005,47,['University of California Santa Barbara'],181,9898,17b16a2b31797a8fd4bcd5fd952294357db39b25,"{'DOI': '10.1109/TPEL.2023.3317263', 'CorpusId': 262187486}",https://www.semanticscholar.org/paper/17b16a2b31797a8fd4bcd5fd952294357db39b25,A Reverse-Biased Voltage Controlling Method for Mitigating Arm Overcurrent and Submodule Overvoltage in Hybrid MMCs During DC Faults,"Blocking all submodules (SMs) of the hybrid modular multilevel converter is a simple way to clear dc fault currents. However, each arm's reverse-biased voltage (RBV) is uncontrolled in this method. In this case, the dc fault current will concentrate into two of the six arms. Thus, the maximum arm current will increase to the fault current in the dc line, which will lead to arm overcurrent. Moreover, full-bridge submodules (FB-SMs) will be charged by the large arm currents and may suffer from severe overvoltage. The arm overcurrent and FB-SM overvoltage problems have not been solved properly. This letter proposes a method to control the RBV of each arm during the dc fault-clearing process to relieve the arm overcurrent and FB-SM overvoltage. Thus, the safety of the converter can be improved. In the meantime, the impact on the dc fault clearing time is well limited. Simulations and experiments validated the proposed method.",IEEE transactions on power electronics,2023,13,0,0,True,"{'url': 'https://backend.orbit.dtu.dk/ws/files/336503094/BERAT_A_Reverse-Biased_Voltage_Controlling_Method_for_Mitigating_Arm_Overcurrent_and_Submodule_Overvoltage_in_Hybrid_MMCs_During_DC_Faults.pdf', 'status': None}",,"{'volume': '38', 'pages': '15147-15151', 'name': 'IEEE Transactions on Power Electronics'}","[{'authorId': '1844367783', 'name': 'Xiongfeng Fang'}, {'authorId': '2154591557', 'name': 'Gen Li'}, {'authorId': '2244588279', 'name': 'Cheng Wang'}, {'authorId': '143900005', 'name': 'Lei Li'}]",TLDR not found
Lei Li,143900005,Lei Li,https://www.semanticscholar.org/author/143900005,47,['University of California Santa Barbara'],181,9898,2c331e93a1648ab6492787bb81287b9c8100d9f3,"{'DBLP': 'journals/remotesensing/LiuSLSLZZZHLCZ23', 'DOI': '10.3390/rs15174119', 'CorpusId': 261144647}",https://www.semanticscholar.org/paper/2c331e93a1648ab6492787bb81287b9c8100d9f3,"Impacts of Aerosol Chemical Composition on Cloud Condensation Nuclei (CCN) Activity during Wintertime in Beijing, China","The cloud condensation nuclei (CCN) activity and aerosol chemical composition were concurrently measured via a scanning mobility CCN analyzer (SMCA) and an Aerodyne Time-of-Flight Aerosol Chemical Speciation Monitor (ACSM), respectively, during wintertime 2022 in Beijing, China. During the observation period, the mean CCN number concentrations ranged from 1345 ± 1270 cm−3 at SS = 0.1% to 3267 ± 2325 cm−3 at SS = 0.3%. The mean critical activation diameters (D50) at SS = 0.1%, 0.2%, and 0.3% were 172 ± 13 nm, 102 ± 8 nm, and 84 ± 7 nm, corresponding to the average hygroscopicity parameters (κCCN) of 0.34, 0.33, and 0.26, respectively. The diurnal variations in D50 suggested that the local primary emissions significantly enhanced D50 at SS = 0.2% and 0.3%, but had less influence on D50 at SS = 0.1% due to the limited size (<150 nm) of particles emitted from primary sources. As PM2.5 concentration increases, the dominant driver of CCN activity transitions from sulfate to nitrate. At a specific SS, D50 decreased with increases in the degree of internal mixing, implying that the elevated internal mixing degree during atmospheric aging was beneficial to CCN activation. In this study, the commonly used f44 (or O:C) was weakly correlated with κorg and failed to describe the variations in κorg. Instead, the variations in κorg can be well parameterized with the Org/BC ratio. The correlation between κ derived from bulk chemical compositions and CCN measurements was substantially improved when this κorg scheme was adopted, emphasizing the importance of considering κorg variations on deriving κchem from aerosol chemical composition.",Remote Sensing,2023,59,0,0,True,"{'url': 'https://www.mdpi.com/2072-4292/15/17/4119/pdf?version=1692690110', 'status': None}",['Computer Science'],"{'volume': '15', 'pages': '4119', 'name': 'Remote. Sens.'}","[{'authorId': '145014498', 'name': 'QUAN LIU'}, {'authorId': '144586081', 'name': 'X. Shen'}, {'authorId': '143900005', 'name': 'Lei Li'}, {'authorId': '34239302', 'name': 'Junying Sun'}, {'authorId': '11182003', 'name': 'Zirui Liu'}, {'authorId': '2184487252', 'name': 'Weibin Zhu'}, {'authorId': '35588756', 'name': 'J. Zhong'}, {'authorId': '2145954606', 'name': 'Yangmei Zhang'}, {'authorId': '2110048610', 'name': 'Xinyao Hu'}, {'authorId': '2187271339', 'name': 'Shuo Liu'}, {'authorId': '27756452', 'name': 'H. Che'}, {'authorId': '2109107295', 'name': 'Xiaoye Zhang'}]",TLDR not found
Lei Li,143900005,Lei Li,https://www.semanticscholar.org/author/143900005,47,['University of California Santa Barbara'],181,9898,71f6931c4a5f7dda0382090a2c01bd5bff27d31e,"{'PubMedCentral': '10268272', 'DOI': '10.1021/acsomega.3c02309', 'CorpusId': 258939476, 'PubMed': '37323393'}",https://www.semanticscholar.org/paper/71f6931c4a5f7dda0382090a2c01bd5bff27d31e,Quantitative Analysis of Natural Gas Diffusion Characteristics in Tight Oil Reservoirs Based on Experimental and Numerical Simulation Methods,"As an important mechanism in gas injection development, the diffusion characteristics of natural gas in tight reservoirs are important in the dynamic prediction of the development effect and optimization of injection-production parameters. In this paper, a high-pressure and high-temperature oil–gas diffusion experimental device was built, which was used to study the effects of the porous medium, pressure, permeability, and fracture on oil–gas diffusion under tight reservoir conditions. Two mathematical models were used to calculate the diffusion coefficients of natural gas in bulk oil and cores. Besides, the numerical simulation model was established to study the diffusion characteristics of natural gas in gas flooding and huff-n-puff, and five diffusion coefficients were selected based on experimental results for simulation study. The remaining oil saturation of grids, the recovery of single layers, and the distribution of CH4 mole fraction in oil were analyzed based on the simulation results. The experimental results show that the diffusion process can be divided into three stages: the initial stage of instability, the diffusion stage, and the stable stage. The absence of medium, high pressure, high permeability, and the existence of fracture are beneficial to natural gas diffusion, which can also reduce the equilibrium time and increase the gas pressure drop. Furthermore, the existence of fracture is beneficial to the early diffusion of gas. The simulation results show that the diffusion coefficient has a greater influence on the oil recovery of huff-n-puff. For gas flooding and huff-n-puff, the diffusion features both perform such that a high diffusion coefficient results in a close diffusion distance, small sweep range, and low oil recovery. However, a high diffusion coefficient can achieve high oil washing efficiency near the injecting well. The study is helpful to provide theoretical guidance for natural gas injection in tight oil reservoirs.",ACS Omega,2023,41,0,0,True,"{'url': 'https://pubs.acs.org/doi/pdf/10.1021/acsomega.3c02309', 'status': None}",['Medicine'],"{'volume': '8', 'pages': '21195 - 21211', 'name': 'ACS Omega'}","[{'authorId': '1878722104', 'name': 'Baishuo Liu'}, {'authorId': '16142314', 'name': 'C. Yao'}, {'authorId': '2189509050', 'name': 'Yaqian Liu'}, {'authorId': '2188175691', 'name': 'Jia Zhao'}, {'authorId': '46259634', 'name': 'Zhengdong Lei'}, {'authorId': '2108194470', 'name': 'Zhe Wang'}, {'authorId': '150318114', 'name': 'Tianxiang Cheng'}, {'authorId': '143900005', 'name': 'Lei Li'}]",TLDR not found
Lei Li,143900005,Lei Li,https://www.semanticscholar.org/author/143900005,47,['University of California Santa Barbara'],181,9898,a84e98cb2d0a3624523f15eaa10c6321704526ab,"{'DBLP': 'journals/remotesensing/LiCSZGZZZLLZZWZ23', 'DOI': '10.3390/rs15020388', 'CorpusId': 255736597}",https://www.semanticscholar.org/paper/a84e98cb2d0a3624523f15eaa10c6321704526ab,Quantitative Evaluation of Dust and Black Carbon Column Concentration in the MERRA-2 Reanalysis Dataset Using Satellite-Based Component Retrievals,"The aerosol optical property products of Modern-Era Retrospective Analysis for Research and Applications, version 2 (MERRA-2) reanalysis dataset have been extensively investigated on a global or regional scale. However, the understanding of MERRA-2 aerosol component products on an extensive temporal and spatial scale is inadequate. Recently, the aerosol component products have been derived from the observations of Polarization and Directionality of the Earth’s Reflectances/Polarization and Anisotropy of Reflectance for Atmospheric Science coupled with observations from a Lidar (POLDER/PARASOL). This study presents a quantitative evaluation of the MERRA-2 reanalysis dust and black carbon (BC) column concentration using independent satellite-based aerosol component concentration retrievals. Both GRASP/Component and MERRA-2 reanalysis products can capture well the temporal variation in dust column concentration over the dust emission resource and downwind dust-dominated regions with the correlation coefficient (R) varying from 0.80 to 0.98. MERRA-2 reanalysis dust products present higher column concentration than GRASP/Component dust retrievals with relative differences of about 20~70%, except in the Taklamakan Desert and Bay of Bengal, where the relative differences can be negative. The differences in dust column concentration over the African dust regions are larger than that over the Asian dust regions. Similar temporal variations in BC column concentration are characterized by both GRASP/Component BC retrievals and MERRA-2 BC products with R of about 0.70~0.90, except in the North China Plain region. We should pay more caution with the regional applicability of MERRA-2 component products when large differences and high correlation coefficients are obtained simultaneously. The results are favorable for identifying the behavior of MERRA-2 reanalysis component estimation in a new view and demonstrate a practical application of the satellite-based component retrievals, which could make more contributions to the improvement of model estimation in the near future.",Remote Sensing,2023,0,2,0,True,"{'url': 'https://www.mdpi.com/2072-4292/15/2/388/pdf?version=1673964581', 'status': None}",['Computer Science'],"{'volume': '15', 'pages': '388', 'name': 'Remote. Sens.'}","[{'authorId': '143900005', 'name': 'Lei Li'}, {'authorId': '27756452', 'name': 'H. Che'}, {'authorId': '2120036164', 'name': 'Xin Su'}, {'authorId': '2107960058', 'name': 'Xindan Zhang'}, {'authorId': '40607269', 'name': 'K. Gui'}, {'authorId': '145473097', 'name': 'Yu Zheng'}, {'authorId': '49453228', 'name': 'Hujia Zhao'}, {'authorId': '2184016787', 'name': 'Hengheng Zhao'}, {'authorId': '46992177', 'name': 'Yuanxin Liang'}, {'authorId': '2000430769', 'name': 'Yadong Lei'}, {'authorId': '2152829229', 'name': 'Lei Zhang'}, {'authorId': '35588756', 'name': 'J. Zhong'}, {'authorId': '2048796589', 'name': 'Zhili Wang'}, {'authorId': '2109107295', 'name': 'Xiaoye Zhang'}]",TLDR not found
Lei Li,143900005,Lei Li,https://www.semanticscholar.org/author/143900005,47,['University of California Santa Barbara'],181,9898,bdbf385090f6c988c419c9db1673a2c03c94b7a1,"{'DBLP': 'journals/remotesensing/ZhangZCGLZLYZZLZ23', 'DOI': '10.3390/rs15020475', 'CorpusId': 255874419}",https://www.semanticscholar.org/paper/bdbf385090f6c988c419c9db1673a2c03c94b7a1,"Seasonal and Diurnal Characteristics of the Vertical Profile of Aerosol Optical Properties in Urban Beijing, 2017-2021","Seasonal and diurnal characteristics of the vertical profiles of aerosol properties are essential for detecting the regional transport and the climatic radiative effects of aerosol particles. We have studied the seasonal and diurnal characteristics of the vertical distribution of aerosols in urban Beijing from 2017 to 2021 based on long-term Raman–Mie LiDAR observations. The influence of the vertical distribution of aerosols, the meteorological conditions within the boundary layer, the optical–radiometric properties of aerosols, and their interconnections, were investigated during a heavy haze pollution event in Beijing from 8 to 15 February 2020 using both meteorological and sun photometer data. The aerosol extinction coefficient was highest in summer (0.4 km−1), followed by winter (0.35 km−1), and roughly equal in spring and autumn (0.3 km−1). The aerosol extinction coefficient showed clear daily variations and was different in different seasons as a result of the variation in the height of the boundary layer. During the haze pollution event, the particulate matter mainly consisted of scattered spherical fine particles and the accumulation time of pollutants measured via the AOD440nm and PM2.5 mass concentration was different as a result of the hygroscopic growth of the aerosol particles. This growth increased scattering and led to an increase in the aerosol optical depth. The vertical transport of particulate matter also contributed to the increase in the aerosol optical depth.",Remote Sensing,2023,80,1,0,True,"{'url': 'https://www.mdpi.com/2072-4292/15/2/475/pdf?version=1673599964', 'status': None}",['Computer Science'],"{'volume': '15', 'pages': '475', 'name': 'Remote. Sens.'}","[{'authorId': '2183927580', 'name': 'Xinglu Zhang'}, {'authorId': '145473097', 'name': 'Yu Zheng'}, {'authorId': '27756452', 'name': 'H. Che'}, {'authorId': '40607269', 'name': 'K. Gui'}, {'authorId': '143900005', 'name': 'Lei Li'}, {'authorId': '49453228', 'name': 'Hujia Zhao'}, {'authorId': '46992177', 'name': 'Yuanxin Liang'}, {'authorId': '2089088725', 'name': 'Wenrui Yao'}, {'authorId': '2107960058', 'name': 'Xindan Zhang'}, {'authorId': '2184016787', 'name': 'Hengheng Zhao'}, {'authorId': '2201636441', 'name': 'Yanting Lu'}, {'authorId': '2109107295', 'name': 'Xiaoye Zhang'}]",TLDR not found
Lei Li,143900005,Lei Li,https://www.semanticscholar.org/author/143900005,47,['University of California Santa Barbara'],181,9898,c8b27d092e0f9e286bb354bb892984a30126c702,"{'ACL': '2023.americasnlp-1.19', 'DOI': '10.18653/v1/2023.americasnlp-1.19', 'CorpusId': 259833798}",https://www.semanticscholar.org/paper/c8b27d092e0f9e286bb354bb892984a30126c702,PlayGround Low Resource Machine Translation System for the 2023 AmericasNLP Shared Task,"This paper presents PlayGround’s submission to the AmericasNLP 2023 shared task on machine translation (MT) into indigenous languages. We finetuned NLLB-600M, a multilingual MT model pre-trained on Flores-200, on 10 low-resource language directions and examined the effectiveness of weight averaging and back translation. Our experiments showed that weight averaging, on average, led to a 0.0169 improvement in the ChrF++ score. Additionally, we found that back translation resulted in a 0.008 improvement in the ChrF++ score.",AMERICASNLP,2023,12,1,0,True,"{'url': 'https://aclanthology.org/2023.americasnlp-1.19.pdf', 'status': None}",,{'name': 'Proceedings of the Workshop on Natural Language Processing for Indigenous Languages of the Americas (AmericasNLP)'},"[{'authorId': '2222940030', 'name': 'Tianrui Gu'}, {'authorId': '2223154650', 'name': 'Kaie Chen'}, {'authorId': '51152981', 'name': 'Siqi Ouyang'}, {'authorId': '143900005', 'name': 'Lei Li'}]",PlayGround’s submission to the AmericasNLP 2023 shared task on machine translation (MT) into indigenous languages is presented and the effectiveness of weight averaging and back translation is examined.
Lei Li,143900005,Lei Li,https://www.semanticscholar.org/author/143900005,47,['University of California Santa Barbara'],181,9898,dfd8944d39b378489b878d6e105d040fa0e524db,"{'DBLP': 'journals/corr/abs-2304-04675', 'ArXiv': '2304.04675', 'DOI': '10.48550/arXiv.2304.04675', 'CorpusId': 258048937}",https://www.semanticscholar.org/paper/dfd8944d39b378489b878d6e105d040fa0e524db,Multilingual Machine Translation with Large Language Models: Empirical Results and Analysis,"Large language models (LLMs) have demonstrated remarkable potential in handling multilingual machine translation (MMT). In this paper, we systematically investigate the advantages and challenges of LLMs for MMT by answering two questions: 1) How well do LLMs perform in translating massive languages? 2) Which factors affect LLMs' performance in translation? We thoroughly evaluate eight popular LLMs, including ChatGPT and GPT-4. Our empirical results show that translation capabilities of LLMs are continually improving. GPT-4 has beat the strong supervised baseline NLLB in 40.91% of translation directions but still faces a large gap towards the commercial translation system, especially on low-resource languages. Through further analysis, we discover that LLMs exhibit new working patterns when used for MMT. First, instruction semantics can surprisingly be ignored when given in-context exemplars. Second, cross-lingual exemplars can provide better task guidance for low-resource translation than exemplars in the same language pairs. Third, LLM can acquire translation ability in a resource-efficient way and generate moderate translation even on zero-resource languages.",arXiv.org,2023,53,50,3,True,"{'url': 'http://arxiv.org/pdf/2304.04675', 'status': None}",['Computer Science'],"{'volume': 'abs/2304.04675', 'name': 'ArXiv'}","[{'authorId': '2131383723', 'name': 'Wenhao Zhu'}, {'authorId': '2115669628', 'name': 'Hongyi Liu'}, {'authorId': '2047143813', 'name': 'Qingxiu Dong'}, {'authorId': '47883405', 'name': 'Jingjing Xu'}, {'authorId': '47648549', 'name': 'Lingpeng Kong'}, {'authorId': '1838162', 'name': 'Jiajun Chen'}, {'authorId': '143900005', 'name': 'Lei Li'}, {'authorId': '2046010', 'name': 'Shujian Huang'}]",It is discovered that LLMs exhibit new working patterns when used for MMT and cross-lingual exemplars can provide better task guidance for low-resource translation than exemplars in the same language pairs.
Lori S Levin,1686960,Lori S. Levin,https://www.semanticscholar.org/author/1686960,34,[],174,3290,2cdc646a6b70418e7cbd7fbdb8bb113176c4659f,"{'DOI': '10.1016/j.brainres.2023.148262', 'CorpusId': 256195620, 'PubMed': '36706858'}",https://www.semanticscholar.org/paper/2cdc646a6b70418e7cbd7fbdb8bb113176c4659f,Somatosensory and motor representations following bilateral transplants of the hands: A 6-year longitudinal case report on the first pediatric bilateral hand transplant patient,,Brain Research,2023,38,0,0,True,,['Medicine'],"{'volume': '1804', 'name': 'Brain Research'}","[{'authorId': '2532481', 'name': 'W. Gaetz'}, {'authorId': '2542295', 'name': 'C. Dockstader'}, {'authorId': '34745197', 'name': 'P. Furlong'}, {'authorId': '116811428', 'name': 'S. Amaral'}, {'authorId': '21516218', 'name': 'A. Vossough'}, {'authorId': '2065000669', 'name': 'E. Schwartz'}, {'authorId': '2053044636', 'name': 'T. Roberts'}, {'authorId': '1686960', 'name': 'Lori S. Levin'}]",
Lori S Levin,1686960,Lori S. Levin,https://www.semanticscholar.org/author/1686960,34,[],174,3290,2f540bab03c2672715539ecf17ff4872ea521605,"{'DOI': '10.1016/j.apmr.2023.01.001', 'CorpusId': 255801403, 'PubMed': '36639091'}",https://www.semanticscholar.org/paper/2f540bab03c2672715539ecf17ff4872ea521605,Identifying Health-Related Quality of Life Domains after Upper Extremity Transplantation.,,Archives of Physical Medicine and Rehabilitation,2023,0,1,0,True,,['Medicine'],{'name': 'Archives of physical medicine and rehabilitation'},"[{'authorId': '5190415', 'name': 'D. Tulsky'}, {'authorId': '4680808', 'name': 'Pamela A. Kisala'}, {'authorId': '4783700', 'name': 'Callie E Tyner'}, {'authorId': '3930930', 'name': 'J. Slotkin'}, {'authorId': '2073240864', 'name': 'C. Kaufman'}, {'authorId': '5008173', 'name': 'C. Dearth'}, {'authorId': '3573036', 'name': 'A. Horan'}, {'authorId': '143843027', 'name': 'S. Talbot'}, {'authorId': '3495197', 'name': 'J. Shores'}, {'authorId': '4927302', 'name': 'K. Azari'}, {'authorId': '153362468', 'name': 'C. Cetrulo'}, {'authorId': '4578737', 'name': 'G. Brandacher'}, {'authorId': '32387675', 'name': 'C. Cooney'}, {'authorId': '3552081', 'name': 'David E Victorson'}, {'authorId': '47951447', 'name': 'M. Dooley'}, {'authorId': '1686960', 'name': 'Lori S. Levin'}, {'authorId': '2200710797', 'name': 'Cdr Scott M Tintle'}]","This study identified key constructs for use in evaluation of the potentially substantial physical, medical, social, and emotional effects of UET, including physical functioning and medical complications, positive and negative emotional functioning, and social participation, relationships, and independence."
Lori S Levin,1686960,Lori S. Levin,https://www.semanticscholar.org/author/1686960,34,[],174,3290,52a97ad16605c18e23c9750a388a26a9cdf12200,"{'PubMedCentral': '9902934', 'DOI': '10.3389/fpsyg.2022.989593', 'CorpusId': 256107600, 'PubMed': '36760917'}",https://www.semanticscholar.org/paper/52a97ad16605c18e23c9750a388a26a9cdf12200,Assessment of quality of life after upper extremity transplantation: Framework for patient-reported outcome scale domains,"Upper extremity transplantation offers the promise of restored function and regained quality of life (QOL) for individuals who have sustained hand or arm amputation. However, a major challenge for this procedure becoming an accessible treatment option for patients is the lack of standard measures to document benefits to QOL. Patient-reported outcomes (PRO) measures are well-suited for this kind of intervention, where the perspective of the patient is central to defining treatment success. To date, qualitative work with experts, clinicians, and patients has been used to identify the most important domains of QOL for PRO item development. Specifically, our group’s qualitative work has identified several domains of QOL that are unique to individuals who have received upper extremity transplants, which are distinct from topics covered by existing PRO measures. These include emotional and social aspects of upper extremity transplant, such as Expectations and Perceived Outcomes, Integration and Assimilation of Transplant, Fitting in, and Post-Surgical Challenges and Complications. The broad topic of Satisfaction with Transplant was subdivided into three subtopics: Function, Sensation, and Aesthetics. Satisfaction with Sensation was also identified as a unique domain not evaluated by existing PRO measures. This report operationalizes these eight QOL domains by presenting scoping definitions. This manuscript describes the work that has been completed for domain characterization as an early step toward developing standardized PRO measures to evaluate these important outcomes specific to upper extremity transplantation.",Frontiers in Psychology,2023,69,1,0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2022.989593/pdf', 'status': None}",['Medicine'],"{'volume': '13', 'name': 'Frontiers in Psychology'}","[{'authorId': '4783700', 'name': 'Callie E Tyner'}, {'authorId': '3930930', 'name': 'J. Slotkin'}, {'authorId': '4680808', 'name': 'Pamela A. Kisala'}, {'authorId': '1686960', 'name': 'Lori S. Levin'}, {'authorId': '6355309', 'name': 'Scott M. Tintle'}, {'authorId': '5190415', 'name': 'D. Tulsky'}]","Qualitative work with experts, clinicians, and patients has identified several domains of QOL that are unique to individuals who have received upper extremity transplants, which are distinct from topics covered by existing PRO measures."
Louis-Philippe Morency,49933077,Louis-Philippe Morency,https://www.semanticscholar.org/author/49933077,79,[],443,28711,0a425c0d87c674b142104a07e17c5084b3ad28ca,"{'DBLP': 'journals/corr/abs-2302-12247', 'DOI': '10.48550/arXiv.2302.12247', 'CorpusId': 257102902}",https://www.semanticscholar.org/paper/0a425c0d87c674b142104a07e17c5084b3ad28ca,Quantifying & Modeling Feature Interactions: An Information Decomposition Framework,"The recent explosion of interest in multimodal applications has resulted in a wide selection of datasets and methods for representing and inte-grating information from different signals. Despite these empirical advances, there remain fundamental research questions: how can we quantify the nature of interactions that exist among input features? Subsequently, how can we capture these interactions using suitable data-driven methods? To answer this question, we propose an information-theoretic approach to quantify the degree of redundancy , uniqueness , and synergy across input features, which we term the PID statistics of a multimodal distribution. Using 2 newly proposed estimators that scale to high-dimensional distributions, we demonstrate their usefulness in quantifying the interactions within multimodal datasets, the nature of interactions captured by multimodal models, and principled approaches for model selection. We conduct extensive experiments on both synthetic datasets where the PID statistics are known and on large-scale multimodal benchmarks where PID estimation was previously impossible. Finally, to demonstrate the real-world applicability of our approach, we present three case studies in pathology, mood prediction, and robotic perception where our framework accurately recommends strong multimodal models for each application.",arXiv.org,2023,93,9,0,True,"{'url': 'https://arxiv.org/pdf/2302.12247', 'status': None}",['Computer Science'],"{'volume': 'abs/2302.12247', 'name': 'ArXiv'}","[{'authorId': '28130078', 'name': 'P. Liang'}, {'authorId': '2153511720', 'name': 'Yun Cheng'}, {'authorId': '2152774190', 'name': 'Xiang Fan'}, {'authorId': '37087787', 'name': 'Chun Kai Ling'}, {'authorId': '2199946235', 'name': 'Suzanne Nie'}, {'authorId': '2108279369', 'name': 'Richard J. Chen'}, {'authorId': '4692365', 'name': 'Zihao Deng'}, {'authorId': '37122655', 'name': 'Faisal Mahmood'}, {'authorId': '145124475', 'name': 'R. Salakhutdinov'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}]","This work proposes an information-theoretic approach to quantify the degree of redundancy, uniqueness, and synergy across input features, which is term the PID statistics of a multimodal distribution."
Louis-Philippe Morency,49933077,Louis-Philippe Morency,https://www.semanticscholar.org/author/49933077,79,[],443,28711,114eafdb14145f002d503f259d768d67dae87479,"{'DOI': '10.1167/jov.23.9.5487', 'CorpusId': 261372998}",https://www.semanticscholar.org/paper/114eafdb14145f002d503f259d768d67dae87479,Reconstructing the neurodynamics of face perception during real world vision in humans using intracranial EEG recordings,,Journal of Vision,2023,0,0,0,True,,,{'name': 'Journal of Vision'},"[{'authorId': '49772780', 'name': 'Arish Alreja'}, {'authorId': '152813999', 'name': 'Michael J. Ward'}, {'authorId': '2236474925', 'name': 'J. A. Colan'}, {'authorId': '2237087099', 'name': 'Qianli Ma'}, {'authorId': '2053790192', 'name': 'R. M. Richardson'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}, {'authorId': '10294075', 'name': 'A. Ghuman'}]",TLDR not found
Louis-Philippe Morency,49933077,Louis-Philippe Morency,https://www.semanticscholar.org/author/49933077,79,[],443,28711,40fb36ee67fdde99b196b4d1772de114aa821698,"{'ArXiv': '2306.16413', 'DBLP': 'journals/corr/abs-2306-16413', 'DOI': '10.48550/arXiv.2306.16413', 'CorpusId': 259274645}",https://www.semanticscholar.org/paper/40fb36ee67fdde99b196b4d1772de114aa821698,MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning,"Learning multimodal representations involves integrating information from multiple heterogeneous sources of data. In order to accelerate progress towards understudied modalities and tasks while ensuring real-world robustness, we release MultiZoo, a public toolkit consisting of standardized implementations of>20 core multimodal algorithms and MultiBench, a large-scale benchmark spanning 15 datasets, 10 modalities, 20 prediction tasks, and 6 research areas. Together, these provide an automated end-to-end machine learning pipeline that simplifies and standardizes data loading, experimental setup, and model evaluation. To enable holistic evaluation, we offer a comprehensive methodology to assess (1) generalization, (2) time and space complexity, and (3) modality robustness. MultiBench paves the way towards a better understanding of the capabilities and limitations of multimodal models, while ensuring ease of use, accessibility, and reproducibility. Our toolkits are publicly available, will be regularly updated, and welcome inputs from the community.",arXiv.org,2023,48,2,0,True,"{'url': 'http://arxiv.org/pdf/2306.16413', 'status': None}",['Computer Science'],"{'volume': 'abs/2306.16413', 'name': 'ArXiv'}","[{'authorId': '28130078', 'name': 'P. Liang'}, {'authorId': '2066413750', 'name': 'Yiwei Lyu'}, {'authorId': '2152774190', 'name': 'Xiang Fan'}, {'authorId': '2152116534', 'name': 'Arav Agarwal'}, {'authorId': '2153511720', 'name': 'Yun Cheng'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}, {'authorId': '145124475', 'name': 'R. Salakhutdinov'}]","MultiZoo is released, a public toolkit consisting of standardized implementations of>20 core multimodal algorithms and MultiBench, a large-scale benchmark spanning 15 datasets, 10 modalities, 20 prediction tasks, and 6 research areas that provide an automated end-to-end machine learning pipeline that simplifies and standardizes data loading, experimental setup, and model evaluation."
Louis-Philippe Morency,49933077,Louis-Philippe Morency,https://www.semanticscholar.org/author/49933077,79,[],443,28711,47a4ac301820c3ea7da4efb8e2466cc6468ad631,"{'ArXiv': '2305.14728', 'DBLP': 'conf/acl/0001M23', 'DOI': '10.48550/arXiv.2305.14728', 'CorpusId': 258866171}",https://www.semanticscholar.org/paper/47a4ac301820c3ea7da4efb8e2466cc6468ad631,SenteCon: Leveraging Lexicons to Learn Human-Interpretable Language Representations,"Although deep language representations have become the dominant form of language featurization in recent years, in many settings it is important to understand a model's decision-making process. This necessitates not only an interpretable model but also interpretable features. In particular, language must be featurized in a way that is interpretable while still characterizing the original text well. We present SenteCon, a method for introducing human interpretability in deep language representations. Given a passage of text, SenteCon encodes the text as a layer of interpretable categories in which each dimension corresponds to the relevance of a specific category. Our empirical evaluations indicate that encoding language with SenteCon provides high-level interpretability at little to no cost to predictive performance on downstream tasks. Moreover, we find that SenteCon outperforms existing interpretable language representations with respect to both its downstream performance and its agreement with human characterizations of the text.",Annual Meeting of the Association for Computational Linguistics,2023,50,0,0,True,"{'url': 'http://arxiv.org/pdf/2305.14728', 'status': None}",['Computer Science'],{'pages': '4312-4331'},"[{'authorId': '2060138164', 'name': 'Victoria Lin'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}]","This work presents SenteCon, a method for introducing human interpretability in deep language representations that outperforms existing interpretable language representations with respect to both its downstream performance and its agreement with human characterizations of the text."
Louis-Philippe Morency,49933077,Louis-Philippe Morency,https://www.semanticscholar.org/author/49933077,79,[],443,28711,64703e760f662b1c0f647931bb63fe57e5ba91e4,"{'DBLP': 'journals/corr/abs-2306-08149', 'ArXiv': '2306.08149', 'DOI': '10.1145/3577190.3614115', 'CorpusId': 259164865}",https://www.semanticscholar.org/paper/64703e760f662b1c0f647931bb63fe57e5ba91e4,Neural Mixed Effects for Nonlinear Personalized Predictions,"Personalized prediction is a machine learning approach that predicts a person’s future observations based on their past labeled observations and is typically used for sequential tasks, e.g., to predict daily mood ratings. When making personalized predictions, a model can combine two types of trends: (a) trends shared across people, i.e., person-generic trends, such as being happier on weekends, and (b) unique trends for each person, i.e., person-specific trends, such as a stressful weekly meeting. Mixed effect models are popular statistical models to study both trends by combining person-generic and person-specific parameters. Though linear mixed effect models are gaining popularity in machine learning by integrating them with neural networks, these integrations are currently limited to linear person-specific parameters: ruling out nonlinear person-specific trends. In this paper, we propose Neural Mixed Effect (NME) models to optimize nonlinear person-specific parameters anywhere in a neural network in a scalable manner1. NME combines the efficiency of neural network optimization with nonlinear mixed effects modeling. Empirically, we observe that NME improves performance across six unimodal and multimodal datasets, including a smartphone dataset to predict daily mood and a mother-adolescent dataset to predict affective state sequences where half the mothers experience symptoms of depression. Furthermore, we evaluate NME for two model architectures, including for neural conditional random fields (CRF) to predict affective state sequences where the CRF learns nonlinear person-specific temporal transitions between affective states. Analysis of these person-specific transitions on the mother-adolescent dataset shows interpretable trends related to the mother’s depression symptoms.",International Conference on Multimodal Interaction,2023,61,0,0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/3577190.3614115', 'status': None}",['Computer Science'],{'name': 'Proceedings of the 25th International Conference on Multimodal Interaction'},"[{'authorId': '2159324', 'name': 'T. Wörtwein'}, {'authorId': '2060747421', 'name': 'Nicholas Allen'}, {'authorId': '2165789644', 'name': 'Lisa B. Sheeber'}, {'authorId': '5512630', 'name': 'R. Auerbach'}, {'authorId': '1737918', 'name': 'J. Cohn'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}]","NME combines the efficiency of neural network optimization with nonlinear mixed effects modeling and improves performance across six unimodal and multimodal datasets, including a smartphone dataset to predict daily mood and a mother-adolescent datasets to predict affective state sequences where half the mothers experience symptoms of depression."
Louis-Philippe Morency,49933077,Louis-Philippe Morency,https://www.semanticscholar.org/author/49933077,79,[],443,28711,6838c43e702a3f995967ba2e3edd5f65ff5f5511,"{'DBLP': 'conf/icmi/BilalpurHCSAMC23', 'DOI': '10.1145/3577190.3614136', 'CorpusId': 263629967}",https://www.semanticscholar.org/paper/6838c43e702a3f995967ba2e3edd5f65ff5f5511,SHAP-based Prediction of Mother's History of Depression to Understand the Influence on Child Behavior,"Depression strongly impacts parents’ behavior. Does parents’ depression strongly affect the behavior of their children as well? To investigate this question, we compared dyadic interactions between 73 depressed and 75 non-depressed mothers and their adolescent child. Families were of low income and 84% were white. Child behavior was measured from audio-video recordings using manual annotation of verbal and nonverbal behavior by expert coders and by multimodal computational measures of facial expression, face and head dynamics, prosody, speech behavior, and linguistics. For both sets of measures, we used Support Vector Machines. For computational measures, we investigated the relative contribution of single versus multiple modalities using a novel approach to SHapley Additive exPlanations (SHAP). Computational measures outperformed manual ratings by human experts. Among individual computational measures, prosody was the most informative. SHAP reduction resulted in a four-fold decrease in the number of features and highest performance (77% accuracy; positive and negative agreements at 75% and 76%, respectively). These findings suggest that maternal depression strongly impacts the behavior of adolescent children; differences are most revealed in prosody; multimodal features together with SHAP reduction are most powerful.",International Conference on Multimodal Interaction,2023,36,0,0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/3577190.3614136', 'status': None}",['Computer Science'],{'name': 'Proceedings of the 25th International Conference on Multimodal Interaction'},"[{'authorId': '23973985', 'name': 'Maneesh Bilalpur'}, {'authorId': '71088012', 'name': 'Saurabh Hinduja'}, {'authorId': '2253782441', 'name': 'Laura Cariola'}, {'authorId': '2165789644', 'name': 'Lisa B. Sheeber'}, {'authorId': '2253741044', 'name': 'Nicholas B Allen'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}, {'authorId': '2206204148', 'name': 'Jeffrey F. Cohn'}]",TLDR not found
Louis-Philippe Morency,49933077,Louis-Philippe Morency,https://www.semanticscholar.org/author/49933077,79,[],443,28711,7dab13685363176edc5cc7882d0890811d2cb584,"{'DBLP': 'journals/corr/abs-2305-14083', 'ArXiv': '2305.14083', 'DOI': '10.48550/arXiv.2305.14083', 'CorpusId': 258841779}",https://www.semanticscholar.org/paper/7dab13685363176edc5cc7882d0890811d2cb584,Counterfactual Augmentation for Multimodal Learning Under Presentation Bias,"In real-world machine learning systems, labels are often derived from user behaviors that the system wishes to encourage. Over time, new models must be trained as new training examples and features become available. However, feedback loops between users and models can bias future user behavior, inducing a presentation bias in the labels that compromises the ability to train new models. In this paper, we propose counterfactual augmentation, a novel causal method for correcting presentation bias using generated counterfactual labels. Our empirical evaluations demonstrate that counterfactual augmentation yields better downstream performance compared to both uncorrected models and existing bias-correction methods. Model analyses further indicate that the generated counterfactuals align closely with true counterfactuals in an oracle setting.",Conference on Empirical Methods in Natural Language Processing,2023,31,0,0,True,"{'url': 'http://arxiv.org/pdf/2305.14083', 'status': None}",['Computer Science'],{'pages': '592-606'},"[{'authorId': '2060138293', 'name': 'Victoria Lin'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}, {'authorId': '1780137', 'name': 'D. Dimitriadis'}, {'authorId': '2109668081', 'name': 'Srinagesh Sharma'}]","Empirical evaluations demonstrate that counterfactual augmentation yields better downstream performance compared to both uncorrected models and existing bias-correction methods, and model analyses indicate that the generatedcounterfactuals align closely with true counterfactUALs in an oracle setting."
Louis-Philippe Morency,49933077,Louis-Philippe Morency,https://www.semanticscholar.org/author/49933077,79,[],443,28711,8d0c37eee7162f33178979b4183f0211e2dcae0d,"{'ArXiv': '2305.14577', 'DBLP': 'journals/corr/abs-2305-14577', 'DOI': '10.48550/arXiv.2305.14577', 'CorpusId': 258865571}",https://www.semanticscholar.org/paper/8d0c37eee7162f33178979b4183f0211e2dcae0d,Difference-Masking: Choosing What to Mask in Continued Pretraining,"The self-supervised objective of masking-and-predicting has led to promising performance gains on a variety of downstream tasks. However, while most approaches randomly mask tokens, there is strong intuition that deciding what to mask can substantially improve learning outcomes. We investigate this in continued pretraining setting in which pretrained models continue to pretrain on domain-specific data before performing some downstream task. We introduce Difference-Masking, a masking strategy that automatically chooses what to mask during continued pretraining by considering what makes a task domain different from the pretraining domain. Empirically, we find that Difference-Masking outperforms baselines on continued pretraining settings across four diverse language-only and multimodal video tasks.",Conference on Empirical Methods in Natural Language Processing,2023,56,0,0,True,"{'url': 'http://arxiv.org/pdf/2305.14577', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.14577', 'name': 'ArXiv'}","[{'authorId': '2000786644', 'name': 'Alex Wilf'}, {'authorId': '1900302322', 'name': 'Syeda Nahida Akter'}, {'authorId': '1413897871', 'name': 'Leena Mathur'}, {'authorId': '28130078', 'name': 'P. Liang'}, {'authorId': '31322912', 'name': 'Sheryl Mathew'}, {'authorId': '2218143553', 'name': 'Mengrou Shou'}, {'authorId': '46841006', 'name': 'Eric Nyberg'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}]","Difference-Masking is introduced, a masking strategy that automatically chooses what to mask during continued pretraining by considering what makes a task domain different from the pretraining domain."
Louis-Philippe Morency,49933077,Louis-Philippe Morency,https://www.semanticscholar.org/author/49933077,79,[],443,28711,8d53c510928ad1164aebea4d9477812ed1893be2,"{'DBLP': 'conf/icmi/MathurMM23', 'ArXiv': '2305.10827', 'DOI': '10.1145/3577190.3614171', 'CorpusId': 258762712}",https://www.semanticscholar.org/paper/8d53c510928ad1164aebea4d9477812ed1893be2,Expanding the Role of Affective Phenomena in Multimodal Interaction Research,"In recent decades, the field of affective computing has made substantial progress in advancing the ability of AI systems to recognize and express affective phenomena, such as affect and emotions, during human-human and human-machine interactions. This paper describes our examination of research at the intersection of multimodal interaction and affective computing, with the objective of observing trends and identifying understudied areas. We examined over 16,000 papers from selected conferences in multimodal interaction, affective computing, and natural language processing: ACM International Conference on Multimodal Interaction, AAAC International Conference on Affective Computing and Intelligent Interaction, Annual Meeting of the Association for Computational Linguistics, and Conference on Empirical Methods in Natural Language Processing. We identified 910 affect-related papers and present our analysis of the role of affective phenomena in these papers. We find that this body of research has primarily focused on enabling machines to recognize or express affect and emotion; there has been limited research on how affect and emotion predictions might, in turn, be used by AI systems to enhance machine understanding of human social behaviors and cognitive states. Based on our analysis, we discuss directions to expand the role of affective phenomena in multimodal interaction research.",International Conference on Multimodal Interaction,2023,87,0,0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/3577190.3614171', 'status': None}",['Computer Science'],{'name': 'Proceedings of the 25th International Conference on Multimodal Interaction'},"[{'authorId': '1413897871', 'name': 'Leena Mathur'}, {'authorId': '2217758079', 'name': ""Maja J Matari'c""}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}]","An examination of research at the intersection of multimodal interaction and affective computing, with the objective of observing trends and identifying understudied areas, finds that this body of research has primarily focused on enabling machines to recognize or express affect and emotion."
Louis-Philippe Morency,49933077,Louis-Philippe Morency,https://www.semanticscholar.org/author/49933077,79,[],443,28711,90b09bdb1bd78875ee8d8d324a568a36955e4765,"{'DBLP': 'conf/icmi/LiangCSM23', 'ArXiv': '2306.04125', 'DOI': '10.1145/3577190.3614151', 'CorpusId': 259095686}",https://www.semanticscholar.org/paper/90b09bdb1bd78875ee8d8d324a568a36955e4765,Multimodal Fusion Interactions: A Study of Human and Automatic Quantification,"In order to perform multimodal fusion of heterogeneous signals, we need to understand their interactions: how each modality individually provides information useful for a task and how this information changes in the presence of other modalities. In this paper, we perform a comparative study of how humans annotate two categorizations of multimodal interactions: (1) partial labels, where different annotators annotate the label given the first, second, and both modalities, and (2) counterfactual labels, where the same annotator annotates the label given the first modality before asking them to explicitly reason about how their answer changes when given the second. We further propose an alternative taxonomy based on (3) information decomposition, where annotators annotate the degrees of redundancy: the extent to which modalities individually and together give the same predictions, uniqueness: the extent to which one modality enables a prediction that the other does not, and synergy: the extent to which both modalities enable one to make a prediction that one would not otherwise make using individual modalities. Through experiments and annotations, we highlight several opportunities and limitations of each approach and propose a method to automatically convert annotations of partial and counterfactual labels to information decomposition, yielding an accurate and efficient method for quantifying multimodal interactions.",International Conference on Multimodal Interaction,2023,79,0,0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/3577190.3614151', 'status': None}",['Computer Science'],{'name': 'Proceedings of the 25th International Conference on Multimodal Interaction'},"[{'authorId': '28130078', 'name': 'P. Liang'}, {'authorId': '2153511720', 'name': 'Yun Cheng'}, {'authorId': '145124475', 'name': 'R. Salakhutdinov'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}]","A comparative study of how humans annotate two categorizations of multimodal interactions is performed and a method to automatically convert annotations of partial and counterfactual labels to information decomposition is proposed, yielding an accurate and efficient method for quantifying multimodals interactions."
Louis-Philippe Morency,49933077,Louis-Philippe Morency,https://www.semanticscholar.org/author/49933077,79,[],443,28711,a988c09b7e76e86a93edcbf3f284dd028b0fb406,"{'ArXiv': '2306.04539', 'DBLP': 'journals/corr/abs-2306-04539', 'DOI': '10.48550/arXiv.2306.04539', 'CorpusId': 259096096}",https://www.semanticscholar.org/paper/a988c09b7e76e86a93edcbf3f284dd028b0fb406,Multimodal Learning Without Labeled Multimodal Data: Guarantees and Applications,"In many machine learning systems that jointly learn from multiple modalities, a core research question is to understand the nature of multimodal interactions: the emergence of new task-relevant information during learning from both modalities that was not present in either alone. We study this challenge of interaction quantification in a semi-supervised setting with only labeled unimodal data and naturally co-occurring multimodal data (e.g., unlabeled images and captions, video and corresponding audio) but when labeling them is time-consuming. Using a precise information-theoretic definition of interactions, our key contributions are the derivations of lower and upper bounds to quantify the amount of multimodal interactions in this semi-supervised setting. We propose two lower bounds based on the amount of shared information between modalities and the disagreement between separately trained unimodal classifiers, and derive an upper bound through connections to approximate algorithms for min-entropy couplings. We validate these estimated bounds and show how they accurately track true interactions. Finally, two semi-supervised multimodal applications are explored based on these theoretical results: (1) analyzing the relationship between multimodal performance and estimated interactions, and (2) self-supervised learning that embraces disagreement between modalities beyond agreement as is typically done.",arXiv.org,2023,107,3,0,True,"{'url': 'http://arxiv.org/pdf/2306.04539', 'status': None}","['Computer Science', 'Mathematics']","{'volume': 'abs/2306.04539', 'name': 'ArXiv'}","[{'authorId': '28130078', 'name': 'P. Liang'}, {'authorId': '37087787', 'name': 'Chun Kai Ling'}, {'authorId': '2153511720', 'name': 'Yun Cheng'}, {'authorId': '71931352', 'name': 'A. Obolenskiy'}, {'authorId': '2144409312', 'name': 'Yudong Liu'}, {'authorId': '1471734043', 'name': 'Rohan Pandey'}, {'authorId': '2000786644', 'name': 'Alex Wilf'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}, {'authorId': '145124475', 'name': 'R. Salakhutdinov'}]","This work proposes two lower bounds based on the amount of shared information between modalities and the disagreement between separately trained unimodal classifiers, and derive an upper bound through connections to approximate algorithms for min-entropy couplings and validate these estimated bounds and show how they accurately track true interactions."
Louis-Philippe Morency,49933077,Louis-Philippe Morency,https://www.semanticscholar.org/author/49933077,79,[],443,28711,bd94ea913fcf8698f2257f87a17755b46a420458,"{'DBLP': 'conf/icmi/VailGBFSCM23', 'DOI': '10.1145/3577190.3614118', 'CorpusId': 263742861}",https://www.semanticscholar.org/paper/bd94ea913fcf8698f2257f87a17755b46a420458,Representation Learning for Interpersonal and Multimodal Behavior Dynamics: A Multiview Extension of Latent Change Score Models,"Characterizing the dynamics of behavior across multiple modalities and individuals is a vital component of computational behavior analysis. This is especially important in certain applications, such as psychotherapy, where individualized tracking of behavior patterns can provide valuable information about the patient’s mental state. Conventional methods that rely on aggregate statistics and correlational metrics may not always suffice, as they are often unable to capture causal relationships or evaluate the true probability of identified patterns. To address these challenges, we present a novel approach to learning multimodal and interpersonal representations of behavior dynamics during one-on-one interaction. Our approach is enabled by the introduction of a multiview extension of latent change score models, which facilitates the concurrent capture of both inter-modal and interpersonal behavior dynamics and the identification of directional relationships between them. A core advantage of our approach is its high level of interpretability while simultaneously achieving strong predictive performance. We evaluate our approach within the domain of therapist-client interactions, with the objective of gaining a deeper understanding about the collaborative relationship between the two, a crucial element of the therapeutic process. Our results demonstrate improved performance over conventional approaches that rely upon summary statistics or correlational metrics. Furthermore, since our multiview approach includes the explicit modeling of uncertainty, it naturally lends itself to integration with probabilistic classifiers, such as Gaussian process models. We demonstrate that this integration leads to even further improved performance, all the while maintaining highly interpretable qualities. Our analysis provides compelling motivation for further exploration of stochastic systems within computational models of behavior.",International Conference on Multimodal Interaction,2023,57,0,0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/3577190.3614118', 'status': None}",['Computer Science'],{'name': 'Proceedings of the 25th International Conference on Multimodal Interaction'},"[{'authorId': '2404385', 'name': 'A. Vail'}, {'authorId': '36185909', 'name': 'J. Girard'}, {'authorId': '3822686', 'name': 'Lauren M. Bylsma'}, {'authorId': '2053154214', 'name': 'Jay Fournier'}, {'authorId': '2256151835', 'name': 'Holly A. Swartz'}, {'authorId': '2206204148', 'name': 'Jeffrey F. Cohn'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}]",This work presents a novel approach to learning multimodal and interpersonal representations of behavior dynamics during one-on-one interaction enabled by the introduction of a multiview extension of latent change score models that demonstrates improved performance over conventional approaches that rely upon summary statistics or correlational metrics.
Louis-Philippe Morency,49933077,Louis-Philippe Morency,https://www.semanticscholar.org/author/49933077,79,[],443,28711,d01cc51c0d06583b809833a5f7ce71101d278528,"{'DBLP': 'conf/chi/LiangLCJDWMS23', 'DOI': '10.1145/3544549.3585604', 'CorpusId': 258217161}",https://www.semanticscholar.org/paper/d01cc51c0d06583b809833a5f7ce71101d278528,MultiViz: Towards User-Centric Visualizations and Interpretations of Multimodal Models,"The nature of human and computer interactions are inherently multimodal, which has led to substantial interest in building interpretable, interactive, and reliable multimodal interfaces. However, modern multimodal models and interfaces are typically black-box neural networks, which makes it challenging to understand their internal mechanics. How can we visualize their internal workings in order to empower stakeholders to visualize model behavior, perform model debugging, and promote trust in these models? Our paper proposes MultiViz, a method for analyzing the behavior of multimodal models via 4 stages: (1) unimodal importance, (2) cross-modal interactions, (3) multimodal representations and (4) multimodal prediction. MultiViz includes modular visualization tools for each stage before combining outputs from all stages through an interactive and human-in-the-loop API. Through user studies with 21 participants on 8 trained models across 6 real-world tasks, we show that the complementary stages in MultiViz together enable users to (1) simulate model predictions, (2) assign interpretable concepts to features, (3) perform error analysis on model misclassifications, and (4) use insights from error analysis to debug models. MultiViz is publicly available at https://github.com/pliang279/MultiViz, will be regularly updated with new visualization tools and metrics, and welcomes input from the community1.",CHI Extended Abstracts,2023,98,0,0,True,,['Computer Science'],{'name': 'Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems'},"[{'authorId': '28130078', 'name': 'P. Liang'}, {'authorId': '2066413750', 'name': 'Yiwei Lyu'}, {'authorId': '1509809381', 'name': 'Gunjan Chhablani'}, {'authorId': '2146677401', 'name': 'Nihal Jain'}, {'authorId': '4692365', 'name': 'Zihao Deng'}, {'authorId': '50141732', 'name': 'Xingbo Wang'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}, {'authorId': '145124475', 'name': 'R. Salakhutdinov'}]","It is shown that the complementary stages in MultiViz together enable users to simulate model predictions, assign interpretable concepts to features, perform error analysis on model misclassifications, and use insights from error analysis to debug models."
Louis-Philippe Morency,49933077,Louis-Philippe Morency,https://www.semanticscholar.org/author/49933077,79,[],443,28711,dcb4f2b9b0e6da0d629878d1ad0469aee3df2020,"{'DBLP': 'journals/corr/abs-2306-04898', 'ArXiv': '2306.04898', 'DOI': '10.1109/CVPR52729.2023.00765', 'CorpusId': 259108864}",https://www.semanticscholar.org/paper/dcb4f2b9b0e6da0d629878d1ad0469aee3df2020,Understanding Masked Autoencoders via Hierarchical Latent Variable Models,"Masked autoencoder (MAE), a simple and effective self-supervised learning framework based on the reconstruction of masked image regions, has recently achieved prominent success in a variety of vision tasks. Despite the emergence of intriguing empirical observations on MAE, a theoretically principled understanding is still lacking. In this work, we formally characterize and justify existing empirical in-sights and provide theoretical guarantees of MAE. We formulate the underlying data-generating process as a hierarchical latent variable model, and show that under reasonable assumptions, MAE provably identifies a set of latent variables in the hierarchical model, explaining why MAE can extract high-level information from pixels. Further, we show how key hyperparameters in MAE (the masking ratio and the patch size) determine which true latent variables to be recovered, therefore influencing the level of semantic information in the representation. Specifically, extremely large or small masking ratios inevitably lead to low-level representations. Our theory offers coherent explanations of existing empirical observations and provides insights for potential empirical improvements and fundamental limitations of the masked-reconstruction paradigm. We conduct extensive experiments to validate our theoretical insights.",Computer Vision and Pattern Recognition,2023,74,8,0,True,"{'url': 'https://arxiv.org/pdf/2306.04898', 'status': None}",['Computer Science'],"{'pages': '7918-7928', 'name': '2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)'}","[{'authorId': '2069275317', 'name': 'Lingjing Kong'}, {'authorId': '1384374825', 'name': 'Martin Q. Ma'}, {'authorId': '2155315836', 'name': 'Guan-Hong Chen'}, {'authorId': '143977260', 'name': 'E. Xing'}, {'authorId': '1784472', 'name': 'Yuejie Chi'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}, {'authorId': '2175349484', 'name': 'Kun Zhang'}]","This work formally characterize and justify existing empirical in-sights and provide theoretical guarantees of MAE, and formulate the underlying data-generating process as a hierarchical latent variable model, and shows that under reasonable assumptions, MAE provably identifies a set of latent variables in the hierarchical model."
Louis-Philippe Morency,49933077,Louis-Philippe Morency,https://www.semanticscholar.org/author/49933077,79,[],443,28711,e1b2a35a000ca296c32284b323c7e36a28fe0693,"{'DBLP': 'journals/corr/abs-2306-05268', 'ArXiv': '2306.05268', 'DOI': '10.48550/arXiv.2306.05268', 'CorpusId': 259108395}",https://www.semanticscholar.org/paper/e1b2a35a000ca296c32284b323c7e36a28fe0693,Factorized Contrastive Learning: Going Beyond Multi-view Redundancy,"In a wide range of multimodal tasks, contrastive learning has become a particularly appealing approach since it can successfully learn representations from abundant unlabeled data with only pairing information (e.g., image-caption or video-audio pairs). Underpinning these approaches is the assumption of multi-view redundancy - that shared information between modalities is necessary and sufficient for downstream tasks. However, in many real-world settings, task-relevant information is also contained in modality-unique regions: information that is only present in one modality but still relevant to the task. How can we learn self-supervised multimodal representations to capture both shared and unique information relevant to downstream tasks? This paper proposes FactorCL, a new multimodal representation learning method to go beyond multi-view redundancy. FactorCL is built from three new contributions: (1) factorizing task-relevant information into shared and unique representations, (2) capturing task-relevant information via maximizing MI lower bounds and removing task-irrelevant information via minimizing MI upper bounds, and (3) multimodal data augmentations to approximate task relevance without labels. On large-scale real-world datasets, FactorCL captures both shared and unique information and achieves state-of-the-art results on six benchmarks",arXiv.org,2023,94,6,0,True,"{'url': 'http://arxiv.org/pdf/2306.05268', 'status': None}",['Computer Science'],"{'volume': 'abs/2306.05268', 'name': 'ArXiv'}","[{'authorId': '28130078', 'name': 'P. Liang'}, {'authorId': '4692365', 'name': 'Zihao Deng'}, {'authorId': '1384374825', 'name': 'Martin Q. Ma'}, {'authorId': '145085305', 'name': 'James Y. Zou'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}, {'authorId': '145124475', 'name': 'R. Salakhutdinov'}]",FactorCL is a new multimodal representation learning method to go beyond multi-view redundancy and captures both shared and unique information and achieves state-of-the-art results on six benchmarks.
Louis-Philippe Morency,49933077,Louis-Philippe Morency,https://www.semanticscholar.org/author/49933077,79,[],443,28711,f891e9eeedbf20cdc54429ffcc0402a10f48494e,"{'DBLP': 'journals/corr/abs-2306-04597', 'ArXiv': '2306.04597', 'ACL': '2023.acl-short.30', 'DOI': '10.48550/arXiv.2306.04597', 'CorpusId': 259095603}",https://www.semanticscholar.org/paper/f891e9eeedbf20cdc54429ffcc0402a10f48494e,Language Models Get a Gender Makeover: Mitigating Gender Bias with Few-Shot Data Interventions,"Societal biases present in pre-trained large language models are a critical issue as these models have been shown to propagate biases in countless downstream applications, rendering them unfair towards specific groups of people. Since large-scale retraining of these models from scratch is both time and compute-expensive, a variety of approaches have been previously proposed that de-bias a pre-trained model. While the majority of current state-of-the-art debiasing methods focus on changes to the training regime, in this paper, we propose data intervention strategies as a powerful yet simple technique to reduce gender bias in pre-trained models. Specifically, we empirically show that by fine-tuning a pre-trained model on only 10 debiased (intervened) training examples, the tendency to favor any gender is significantly reduced. Since our proposed method only needs a few training examples, we argue that our few-shot de-biasing approach is highly feasible and practical. Through extensive experimentation, we show that our de-biasing technique performs better than competitive state-of-the-art baselines with minimal loss in language modeling ability.",Annual Meeting of the Association for Computational Linguistics,2023,31,7,0,True,"{'url': 'http://arxiv.org/pdf/2306.04597', 'status': None}",['Computer Science'],{'pages': '340-351'},"[{'authorId': '2221493995', 'name': 'Himanshu Thakur'}, {'authorId': '1819271266', 'name': 'Atishay Jain'}, {'authorId': '2127734657', 'name': 'Praneetha Vaddamanu'}, {'authorId': '28130078', 'name': 'P. Liang'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}]","This paper empirically shows that by fine-tuning a pre-trained model on only 10 debiased (intervened) training examples, the tendency to favor any gender is significantly reduced, and argues that the few-shot de-biasing approach is highly feasible and practical."
Lu Jiang,39978626,Lu Jiang,https://www.semanticscholar.org/author/39978626,41,['Google Research'],79,7875,2a3213cb3c755f036d5dfec7261d726a819c78c1,"{'DBLP': 'conf/icml/ChangZBML00MFRL23', 'ArXiv': '2301.00704', 'DOI': '10.48550/arXiv.2301.00704', 'CorpusId': 255372955}",https://www.semanticscholar.org/paper/2a3213cb3c755f036d5dfec7261d726a819c78c1,Muse: Text-To-Image Generation via Masked Generative Transformers,"We present Muse, a text-to-image Transformer model that achieves state-of-the-art image generation performance while being significantly more efficient than diffusion or autoregressive models. Muse is trained on a masked modeling task in discrete token space: given the text embedding extracted from a pre-trained large language model (LLM), Muse is trained to predict randomly masked image tokens. Compared to pixel-space diffusion models, such as Imagen and DALL-E 2, Muse is significantly more efficient due to the use of discrete tokens and requiring fewer sampling iterations; compared to autoregressive models, such as Parti, Muse is more efficient due to the use of parallel decoding. The use of a pre-trained LLM enables fine-grained language understanding, translating to high-fidelity image generation and the understanding of visual concepts such as objects, their spatial relationships, pose, cardinality etc. Our 900M parameter model achieves a new SOTA on CC3M, with an FID score of 6.06. The Muse 3B parameter model achieves an FID of 7.88 on zero-shot COCO evaluation, along with a CLIP score of 0.32. Muse also directly enables a number of image editing applications without the need to fine-tune or invert the model: inpainting, outpainting, and mask-free editing. More results are available at https://muse-model.github.io",International Conference on Machine Learning,2023,87,235,17,True,"{'url': 'http://arxiv.org/pdf/2301.00704', 'status': None}",['Computer Science'],"{'volume': 'abs/2301.00704', 'name': 'ArXiv'}","[{'authorId': '2914394', 'name': 'Huiwen Chang'}, {'authorId': '2146204239', 'name': 'Han Zhang'}, {'authorId': '152630175', 'name': 'Jarred Barber'}, {'authorId': '2199119286', 'name': 'AJ Maschinot'}, {'authorId': '143923528', 'name': 'José Lezama'}, {'authorId': '39978626', 'name': 'Lu Jiang'}, {'authorId': '152790163', 'name': 'Ming Yang'}, {'authorId': '1702318', 'name': 'K. Murphy'}, {'authorId': '1768236', 'name': 'W. Freeman'}, {'authorId': '144544291', 'name': 'Michael Rubinstein'}, {'authorId': '2167749913', 'name': 'Yuanzhen Li'}, {'authorId': '1707347', 'name': 'Dilip Krishnan'}]",
Lu Jiang,39978626,Lu Jiang,https://www.semanticscholar.org/author/39978626,41,['Google Research'],79,7875,376f494126d1ea4f571ea0263c43ac2b6331800a,"{'ArXiv': '2306.17842', 'DBLP': 'journals/corr/abs-2306-17842', 'DOI': '10.48550/arXiv.2306.17842', 'CorpusId': 259308960}",https://www.semanticscholar.org/paper/376f494126d1ea4f571ea0263c43ac2b6331800a,SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs,"In this work, we introduce Semantic Pyramid AutoEncoder (SPAE) for enabling frozen LLMs to perform both understanding and generation tasks involving non-linguistic modalities such as images or videos. SPAE converts between raw pixels and interpretable lexical tokens (or words) extracted from the LLM's vocabulary. The resulting tokens capture both the semantic meaning and the fine-grained details needed for visual reconstruction, effectively translating the visual content into a language comprehensible to the LLM, and empowering it to perform a wide array of multimodal tasks. Our approach is validated through in-context learning experiments with frozen PaLM 2 and GPT 3.5 on a diverse set of image understanding and generation tasks. Our method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.",arXiv.org,2023,52,9,1,True,"{'url': 'http://arxiv.org/pdf/2306.17842', 'status': None}",['Computer Science'],"{'volume': 'abs/2306.17842', 'name': 'ArXiv'}","[{'authorId': '8547960', 'name': 'Lijun Yu'}, {'authorId': '2109716647', 'name': 'Yong Cheng'}, {'authorId': '1390877035', 'name': 'Zhiruo Wang'}, {'authorId': '2107989922', 'name': 'Vivek Kumar'}, {'authorId': '3153147', 'name': 'Wolfgang Macherey'}, {'authorId': '2145438541', 'name': 'Yanping Huang'}, {'authorId': '144711958', 'name': 'David A. Ross'}, {'authorId': '145955800', 'name': 'Irfan Essa'}, {'authorId': '3312309', 'name': 'Yonatan Bisk'}, {'authorId': '152790163', 'name': 'Ming Yang'}, {'authorId': '1702318', 'name': 'K. Murphy'}, {'authorId': '145788702', 'name': 'A. Hauptmann'}, {'authorId': '39978626', 'name': 'Lu Jiang'}]","This method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%."
Lu Jiang,39978626,Lu Jiang,https://www.semanticscholar.org/author/39978626,41,['Google Research'],79,7875,861370f7c2d18bed09905fde334a19cc96e83e14,"{'ArXiv': '2306.00983', 'DBLP': 'journals/corr/abs-2306-00983', 'DOI': '10.48550/arXiv.2306.00983', 'CorpusId': 258999204}",https://www.semanticscholar.org/paper/861370f7c2d18bed09905fde334a19cc96e83e14,StyleDrop: Text-to-Image Generation in Any Style,"Pre-trained large text-to-image models synthesize impressive images with an appropriate use of text prompts. However, ambiguities inherent in natural language and out-of-distribution effects make it hard to synthesize image styles, that leverage a specific design pattern, texture or material. In this paper, we introduce StyleDrop, a method that enables the synthesis of images that faithfully follow a specific style using a text-to-image model. The proposed method is extremely versatile and captures nuances and details of a user-provided style, such as color schemes, shading, design patterns, and local and global effects. It efficiently learns a new style by fine-tuning very few trainable parameters (less than $1\%$ of total model parameters) and improving the quality via iterative training with either human or automated feedback. Better yet, StyleDrop is able to deliver impressive results even when the user supplies only a single image that specifies the desired style. An extensive study shows that, for the task of style tuning text-to-image models, StyleDrop implemented on Muse convincingly outperforms other methods, including DreamBooth and textual inversion on Imagen or Stable Diffusion. More results are available at our project website: https://styledrop.github.io",arXiv.org,2023,43,35,4,True,"{'url': 'http://arxiv.org/pdf/2306.00983', 'status': None}",['Computer Science'],"{'volume': 'abs/2306.00983', 'name': 'ArXiv'}","[{'authorId': '1729571', 'name': 'Kihyuk Sohn'}, {'authorId': '31601235', 'name': 'Nataniel Ruiz'}, {'authorId': '3436470', 'name': 'Kimin Lee'}, {'authorId': '2218790269', 'name': 'Daniel Castro Chin'}, {'authorId': '2197077579', 'name': 'Irina Blok'}, {'authorId': '2914394', 'name': 'Huiwen Chang'}, {'authorId': '152630175', 'name': 'Jarred Barber'}, {'authorId': '39978626', 'name': 'Lu Jiang'}, {'authorId': '2905100', 'name': 'Glenn Entis'}, {'authorId': '2167749913', 'name': 'Yuanzhen Li'}, {'authorId': '2153968179', 'name': 'Yuan Hao'}, {'authorId': '145955800', 'name': 'Irfan Essa'}, {'authorId': '144544291', 'name': 'Michael Rubinstein'}, {'authorId': '1707347', 'name': 'Dilip Krishnan'}]",
Lu Jiang,39978626,Lu Jiang,https://www.semanticscholar.org/author/39978626,41,['Google Research'],79,7875,8670133f0839a83c47c5bd2a506d0254d73f1a2c,"{'DBLP': 'journals/corr/abs-2306-00763', 'ArXiv': '2306.00763', 'DOI': '10.48550/arXiv.2306.00763', 'CorpusId': 258999626}",https://www.semanticscholar.org/paper/8670133f0839a83c47c5bd2a506d0254d73f1a2c,Learning Disentangled Prompts for Compositional Image Synthesis,"We study domain-adaptive image synthesis, the problem of teaching pretrained image generative models a new style or concept from as few as one image to synthesize novel images, to better understand the compositional image synthesis. We present a framework that leverages a pretrained class-conditional generation model and visual prompt tuning. Specifically, we propose a novel source class distilled visual prompt that learns disentangled prompts of semantic (e.g., class) and domain (e.g., style) from a few images. Learned domain prompt is then used to synthesize images of any classes in the style of target domain. We conduct studies on various target domains with the number of images ranging from one to a few to many, and show qualitative results which show the compositional generalization of our method. Moreover, we show that our method can help improve zero-shot domain adaptation classification accuracy.",arXiv.org,2023,61,4,0,True,"{'url': 'http://arxiv.org/pdf/2306.00763', 'status': None}",['Computer Science'],"{'volume': 'abs/2306.00763', 'name': 'ArXiv'}","[{'authorId': '1729571', 'name': 'Kihyuk Sohn'}, {'authorId': '47291134', 'name': 'Albert Eaton Shaw'}, {'authorId': '2153968179', 'name': 'Yuan Hao'}, {'authorId': '2146204239', 'name': 'Han Zhang'}, {'authorId': '2454625', 'name': 'Luisa F. Polanía'}, {'authorId': '2914394', 'name': 'Huiwen Chang'}, {'authorId': '39978626', 'name': 'Lu Jiang'}, {'authorId': '145955800', 'name': 'Irfan Essa'}]","This work proposes a novel source class distilled visual prompt that learns disentangled prompts of semantic and domain from a few images, and shows that this method can help improve zero-shot domain adaptation classification accuracy."
Lu Jiang,39978626,Lu Jiang,https://www.semanticscholar.org/author/39978626,41,['Google Research'],79,7875,985f0c89c5a607742ec43c1fdc2cbfe54541cbad,"{'DBLP': 'journals/corr/abs-2310-05737', 'ArXiv': '2310.05737', 'DOI': '10.48550/arXiv.2310.05737', 'CorpusId': 263830733}",https://www.semanticscholar.org/paper/985f0c89c5a607742ec43c1fdc2cbfe54541cbad,Language Model Beats Diffusion - Tokenizer is Key to Visual Generation,"While Large Language Models (LLMs) are the dominant models for generative tasks in language, they do not perform as well as diffusion models on image and video generation. To effectively use LLMs for visual generation, one crucial component is the visual tokenizer that maps pixel-space inputs to discrete tokens appropriate for LLM learning. In this paper, we introduce MAGVIT-v2, a video tokenizer designed to generate concise and expressive tokens for both videos and images using a common token vocabulary. Equipped with this new tokenizer, we show that LLMs outperform diffusion models on standard image and video generation benchmarks including ImageNet and Kinetics. In addition, we demonstrate that our tokenizer surpasses the previously top-performing video tokenizer on two more tasks: (1) video compression comparable to the next-generation video codec (VCC) according to human evaluations, and (2) learning effective representations for action recognition tasks.",arXiv.org,2023,79,12,2,True,"{'url': 'https://arxiv.org/pdf/2310.05737', 'status': None}",['Computer Science'],"{'volume': 'abs/2310.05737', 'name': 'ArXiv'}","[{'authorId': '8547960', 'name': 'Lijun Yu'}, {'authorId': '2256999290', 'name': ""Jos'e Lezama""}, {'authorId': '1387987945', 'name': 'Nitesh B. Gundavarapu'}, {'authorId': '2256995349', 'name': 'Luca Versari'}, {'authorId': '2256996545', 'name': 'Kihyuk Sohn'}, {'authorId': '3144223', 'name': 'David C. Minnen'}, {'authorId': '2198464317', 'name': 'Yong Cheng'}, {'authorId': '2265716291', 'name': 'Agrim Gupta'}, {'authorId': '2257336985', 'name': 'Xiuye Gu'}, {'authorId': '2257000091', 'name': 'Alexander G. Hauptmann'}, {'authorId': '2257000670', 'name': 'Boqing Gong'}, {'authorId': '2257132345', 'name': 'Ming-Hsuan Yang'}, {'authorId': '145955800', 'name': 'Irfan Essa'}, {'authorId': '2257003564', 'name': 'David A. Ross'}, {'authorId': '39978626', 'name': 'Lu Jiang'}]",
Lu Jiang,39978626,Lu Jiang,https://www.semanticscholar.org/author/39978626,41,['Google Research'],79,7875,c5202ab27294d5c1eb4d2f0ca7e82afef91888f0,"{'DBLP': 'journals/corr/abs-2307-03166', 'ArXiv': '2307.03166', 'DOI': '10.48550/arXiv.2307.03166', 'CorpusId': 259360947}",https://www.semanticscholar.org/paper/c5202ab27294d5c1eb4d2f0ca7e82afef91888f0,VideoGLUE: Video General Understanding Evaluation of Foundation Models,"We evaluate existing foundation models video understanding capabilities using a carefully designed experiment protocol consisting of three hallmark tasks (action recognition, temporal localization, and spatiotemporal localization), eight datasets well received by the community, and four adaptation methods tailoring a foundation model (FM) for a downstream task. Moreover, we propose a scalar VideoGLUE score (VGS) to measure an FMs efficacy and efficiency when adapting to general video understanding tasks. Our main findings are as follows. First, task-specialized models significantly outperform the six FMs studied in this work, in sharp contrast to what FMs have achieved in natural language and image understanding. Second,video-native FMs, whose pretraining data contains the video modality, are generally better than image-native FMs in classifying motion-rich videos, localizing actions in time, and understanding a video of more than one action. Third, the video-native FMs can perform well on video tasks under light adaptations to downstream tasks(e.g., freezing the FM backbones), while image-native FMs win in full end-to-end finetuning. The first two observations reveal the need and tremendous opportunities to conduct research on video-focused FMs, and the last confirms that both tasks and adaptation methods matter when it comes to the evaluation of FMs. Our code is released under: https://github.com/tensorflow/models/tree/master/official/projects/videoglue.",arXiv.org,2023,64,1,0,True,"{'url': 'https://arxiv.org/pdf/2307.03166', 'status': None}",['Computer Science'],"{'volume': 'abs/2307.03166', 'name': 'ArXiv'}","[{'authorId': '36001694', 'name': 'Liangzhe Yuan'}, {'authorId': '1387987945', 'name': 'Nitesh B. Gundavarapu'}, {'authorId': '48096253', 'name': 'Long Zhao'}, {'authorId': None, 'name': 'Hao Zhou'}, {'authorId': '2115350367', 'name': 'Yin Cui'}, {'authorId': '39978626', 'name': 'Lu Jiang'}, {'authorId': '2184563494', 'name': 'Xu Yang'}, {'authorId': '51502783', 'name': 'Menglin Jia'}, {'authorId': '47447630', 'name': 'Tobias Weyand'}, {'authorId': '2217253911', 'name': 'Luke Friedman'}, {'authorId': '89903811', 'name': 'Mikhail Sirotenko'}, {'authorId': '3154495', 'name': 'H. Wang'}, {'authorId': '3302320', 'name': 'Florian Schroff'}, {'authorId': '2595180', 'name': 'Hartwig Adam'}, {'authorId': '152790163', 'name': 'Ming Yang'}, {'authorId': '2115431213', 'name': 'Ting Liu'}, {'authorId': '40206014', 'name': 'Boqing Gong'}]",
Madhavi Ganapathiraju,32747279,M. Ganapathiraju,https://www.semanticscholar.org/author/32747279,20,[],94,2040,bc603b3878dd8638254f3746b892100cad687ea5,"{'DOI': '10.1101/2023.11.05.565716', 'CorpusId': 265068565}",https://www.semanticscholar.org/paper/bc603b3878dd8638254f3746b892100cad687ea5,Pathogenic mechanisms underlying adverse neurodevelopmental outcome in congenital heart disease,"Background Hypoplastic left heart syndrome (HLHS), a severe congenital heart disease, is associated with poor neurodevelopmental outcomes, microcephaly, reduced cortical brain volume, brain dysmaturation, and neurobehavioral disorders such as autism. The involvement of patient intrinsic factors was indicated, but the mechanism is largely unknown. Methods Ohia mice with HLHS causing mutations in chromatin modifier Sin3A-associated protein 130 (Sap130) and cell adhesion protein ProtocadherinA9 (Pcdha9) were investigated for brain abnormalities by histology, immunomicroscopy, and molecular profiling by RNAseq, Sap130 ChIPseq, and genome-wide methylome analysis. Additionally, adult viable Pcdha9m/m and Emx1-cre:Sap130f/− mice with forebrain deletion of Sap130 were examined by brain MRI and behavioral assessments. Results Ohia mice have brain abnormalities comprising forebrain hypoplasia and microcephaly in conjunction with a cortical neurogenesis defect. This is associated with loss of intermediate progenitors due to mitotic arrest and apoptosis from multipolar spindle formation, a mechanism also observed in primary microcephaly. Brain RNAseq showed perturbation of REST transcriptional regulation of neurogenesis, disruption of CREB signaling regulating synaptic plasticity and memory, and defects in neurovascular coupling indicating perturbation of brain-sparing cerebral autoregulation. Disease pathways recovered included autism, intellectual disability, and other neurobehavioral/neurological deficits. These same pathways were observed upon intersection of genes that are differentially expressed with those that are differentially methylated and also are ChIPseq targets of Sap130, suggesting the transcriptional changes are epigenetically regulated. Adult viable mice harboring either the Pcdha9 mutation or forebrain-specific Sap130 deletion showed similar learning/memory deficits and autism-like behavior, suggesting they act on convergent pathways. Conclusions Our observations indicate the intrinsic factors contributing to the adverse neurodevelopmental outcome associated with HLHS involve spindle defects causing impaired corticoneurogenesis, and brain and behavioral deficits associated with perturbed epigenetic regulation of neurodevelopmental pathways. Novelty and Significance What is known? Hypoplastic left heart syndrome (HLHS), a severe congenital heart disease, is associated with adverse neurodevelopmental outcome attributable to patient intrinsic factors. Cortical neurogenesis defect with reduced brain volume and microcephaly are observed beginning in utero, suggesting a developmental etiology. Learning impairment and autism spectrum disorder are commonly observed in HLHS. What new information does this article contribute? The Ohia HLHS mouse model exhibits neurodevelopmental deficits comprising microcephaly and cortical neurogenesis defects with loss of neural progenitors from multipolar spindle formation, as well as impaired neurovascular coupling. Molecular profiling showed disturbance of REST, transcriptional regulator of neural stem cells, and CREB signaling regulating synaptic plasticity, with neurobehavioral assessments of the mutant mice showing learning/memory and autism-like behavioral deficits. Intersection of transcriptome and DNA methylation analyses uncovered an epigenetic basis for the neurodevelopmental/neurobehavioral abnormalities, Analysis of an HLHS mouse model indicated patient intrinsic factors causing adverse neurodevelopment in HLHS are genetic and epigenetic in etiology. This may include a mitotic spindle defect that would not be rescued by in utero aortic valvuloplasty, and a defect in neurovascular coupling that is likely to reduce the efficacy of maternal hyperoxygenation. However, epigenetic therapy may provide a new avenue for treatment that should be explored.",bioRxiv,2023,0,0,0,True,"{'url': 'https://www.biorxiv.org/content/biorxiv/early/2023/11/06/2023.11.05.565716.full.pdf', 'status': None}",['Biology'],{'name': 'bioRxiv'},"[{'authorId': '34143058', 'name': 'George C Gabriel'}, {'authorId': '7490049', 'name': 'Hisato Yagi'}, {'authorId': '2069451266', 'name': 'Tuantuan Tan'}, {'authorId': '48065344', 'name': 'A. Bais'}, {'authorId': '2197459719', 'name': 'Benjamin J. Glennon'}, {'authorId': '2268149463', 'name': 'Margaret C. Stapleton'}, {'authorId': '2265954286', 'name': 'Lihua Huang'}, {'authorId': '49529264', 'name': 'William T Reynolds'}, {'authorId': '2265760879', 'name': 'Marla G. Shaffer'}, {'authorId': '2152776709', 'name': 'Xinxiu Xu'}, {'authorId': '32747279', 'name': 'M. Ganapathiraju'}, {'authorId': '2265761755', 'name': 'Dennis Simon'}, {'authorId': '2247616664', 'name': 'Ashok Panigrahy'}, {'authorId': '2241933055', 'name': 'Yijen L. Wu'}, {'authorId': '2238421226', 'name': 'Cecilia W Lo'}]","The observations indicate the intrinsic factors contributing to the adverse neurodevelopmental outcome associated with HLHS involve spindle defects causing impaired corticoneurogenesis, and brain and behavioral deficits associated with perturbed epigenetic regulation of neuro developmental pathways."
Madhavi Ganapathiraju,32747279,M. Ganapathiraju,https://www.semanticscholar.org/author/32747279,20,[],94,2040,de52a2f746c5cf145ee2af3a978ee1942eec1a57,"{'DOI': '10.3389/fsysb.2023.1293298', 'CorpusId': 263319943}",https://www.semanticscholar.org/paper/de52a2f746c5cf145ee2af3a978ee1942eec1a57,"Editorial: Systems biology, women in science 2021/22: translational systems biology and in silico trials",,Frontiers in Systems Biology,2023,6,0,0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fsysb.2023.1293298/pdf?isPublishedV2=False', 'status': None}",,{'name': 'Frontiers in Systems Biology'},"[{'authorId': '2249650044', 'name': 'Jane A. Leopold'}, {'authorId': '32747279', 'name': 'M. Ganapathiraju'}, {'authorId': '50585303', 'name': 'N. Yanamala'}]",TLDR not found
Maarten Sap,2729164,Maarten Sap,https://www.semanticscholar.org/author/2729164,36,"['Carnegie Mellon University, Allen Institute for AI']",75,7517,14ddefae2be4b5bb50b9fcb4a085e45fbecb5c5c,"{'DBLP': 'conf/emnlp/ShenSCPB23', 'ArXiv': '2305.14246', 'DOI': '10.48550/arXiv.2305.14246', 'CorpusId': 258841858}",https://www.semanticscholar.org/paper/14ddefae2be4b5bb50b9fcb4a085e45fbecb5c5c,Modeling Empathic Similarity in Personal Narratives,"The most meaningful connections between people are often fostered through expression of shared vulnerability and emotional experiences in personal narratives. We introduce a new task of identifying similarity in personal stories based on empathic resonance, i.e., the extent to which two people empathize with each others' experiences, as opposed to raw semantic or lexical similarity, as has predominantly been studied in NLP. Using insights from social psychology, we craft a framework that operationalizes empathic similarity in terms of three key features of stories: main events, emotional trajectories, and overall morals or takeaways. We create EmpathicStories, a dataset of 1,500 personal stories annotated with our empathic similarity features, and 2,000 pairs of stories annotated with empathic similarity scores. Using our dataset, we fine-tune a model to compute empathic similarity of story pairs, and show that this outperforms semantic similarity models on automated correlation and retrieval metrics. Through a user study with 150 participants, we also assess the effect our model has on retrieving stories that users empathize with, compared to naive semantic similarity-based retrieval, and find that participants empathized significantly more with stories retrieved by our model. Our work has strong implications for the use of empathy-aware models to foster human connection and empathy between people.",Conference on Empirical Methods in Natural Language Processing,2023,79,1,0,True,"{'url': 'http://arxiv.org/pdf/2305.14246', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.14246', 'name': 'ArXiv'}","[{'authorId': '2115509633', 'name': 'Jocelyn Shen'}, {'authorId': '2729164', 'name': 'Maarten Sap'}, {'authorId': '1410565307', 'name': 'Pedro Colon-Hernandez'}, {'authorId': '2756001', 'name': 'Hae Won Park'}, {'authorId': '1711777', 'name': 'C. Breazeal'}]","A new task of identifying similarity in personal stories based on empathic resonance is introduced, i.e., the extent to which two people empathize with each others' experiences, as opposed to raw semantic or lexical similarity, as has predominantly been studied in NLP."
Maarten Sap,2729164,Maarten Sap,https://www.semanticscholar.org/author/2729164,36,"['Carnegie Mellon University, Allen Institute for AI']",75,7517,185ace5661963e2e1eb998e739e4110272a6bb43,"{'DBLP': 'conf/acl/ZhouZYDHSS23', 'ArXiv': '2306.01985', 'DOI': '10.48550/arXiv.2306.01985', 'CorpusId': 259075355}",https://www.semanticscholar.org/paper/185ace5661963e2e1eb998e739e4110272a6bb43,COBRA Frames: Contextual Reasoning about Effects and Harms of Offensive Statements,"Warning: This paper contains content that may be offensive or upsetting. Understanding the harms and offensiveness of statements requires reasoning about the social and situational context in which statements are made. For example, the utterance""your English is very good""may implicitly signal an insult when uttered by a white man to a non-white colleague, but uttered by an ESL teacher to their student would be interpreted as a genuine compliment. Such contextual factors have been largely ignored by previous approaches to toxic language detection. We introduce COBRA frames, the first context-aware formalism for explaining the intents, reactions, and harms of offensive or biased statements grounded in their social and situational context. We create COBRACORPUS, a dataset of 33k potentially offensive statements paired with machine-generated contexts and free-text explanations of offensiveness, implied biases, speaker intents, and listener reactions. To study the contextual dynamics of offensiveness, we train models to generate COBRA explanations, with and without access to the context. We find that explanations by context-agnostic models are significantly worse than by context-aware ones, especially in situations where the context inverts the statement's offensiveness (29% accuracy drop). Our work highlights the importance and feasibility of contextualized NLP by modeling social factors.",Annual Meeting of the Association for Computational Linguistics,2023,83,8,0,True,"{'url': 'http://arxiv.org/pdf/2306.01985', 'status': None}",['Computer Science'],"{'volume': 'abs/2306.01985', 'name': 'ArXiv'}","[{'authorId': '144101734', 'name': 'Xuhui Zhou'}, {'authorId': '2122171840', 'name': 'Haojie Zhu'}, {'authorId': '1388021166', 'name': 'Akhila Yerukola'}, {'authorId': '2054378953', 'name': 'Thomas Davidson'}, {'authorId': '2012510', 'name': 'Jena D. Hwang'}, {'authorId': '2133324514', 'name': 'Swabha Swayamdipta'}, {'authorId': '2729164', 'name': 'Maarten Sap'}]","COBRA frames are introduced, the first context-aware formalism for explaining the intents, reactions, and harms of offensive or biased statements grounded in their social and situational context, and the importance and feasibility of contextualized NLP by modeling social factors are highlighted."
Maarten Sap,2729164,Maarten Sap,https://www.semanticscholar.org/author/2729164,36,"['Carnegie Mellon University, Allen Institute for AI']",75,7517,27553f8bd9cbee90f6e65b9cdecadff0e7cc55ee,"{'ACL': '2023.acl-demo.36', 'ArXiv': '2312.09536', 'DBLP': 'conf/acl/AntoniakFMWKS23', 'DOI': '10.18653/v1/2023.acl-demo.36', 'CorpusId': 259106728}",https://www.semanticscholar.org/paper/27553f8bd9cbee90f6e65b9cdecadff0e7cc55ee,Riveter: Measuring Power and Social Dynamics Between Entities,"Riveter provides a complete easy-to-use pipeline for analyzing verb connotations associated with entities in text corpora. We prepopulate the package with connotation frames of sentiment, power, and agency, which have demonstrated usefulness for capturing social phenomena, such as gender bias, in a broad range of corpora. For decades, lexical frameworks have been foundational tools in computational social science, digital humanities, and natural language processing, facilitating multifaceted analysis of text corpora. But working with verb-centric lexica specifically requires natural language processing skills, reducing their accessibility to other researchers. By organizing the language processing pipeline, providing complete lexicon scores and visualizations for all entities in a corpus, and providing functionality for users to target specific research questions, Riveter greatly improves the accessibility of verb lexica and can facilitate a broad range of future research.",Annual Meeting of the Association for Computational Linguistics,2023,43,2,0,True,"{'url': 'https://aclanthology.org/2023.acl-demo.36.pdf', 'status': None}",['Computer Science'],"{'volume': 'abs/2312.09536', 'name': 'ArXiv'}","[{'authorId': '34199564', 'name': 'Maria Antoniak'}, {'authorId': '49713890', 'name': 'Anjalie Field'}, {'authorId': '2219642161', 'name': 'Jimin Mun'}, {'authorId': '51038621', 'name': 'Melanie Walsh'}, {'authorId': '3458698', 'name': 'Lauren F. Klein'}, {'authorId': '2729164', 'name': 'Maarten Sap'}]","Riveter greatly improves the accessibility of verb lexica and can facilitate a broad range of future research by organizing the language processing pipeline, providing complete lexicon scores and visualizations for all entities in a corpus, and providing functionality for users to target specific research questions."
Maarten Sap,2729164,Maarten Sap,https://www.semanticscholar.org/author/2729164,36,"['Carnegie Mellon University, Allen Institute for AI']",75,7517,57d65e85c62aef04dfb2a48380e415fbb790e5ee,"{'DBLP': 'conf/emnlp/YerukolaZCS23', 'DOI': '10.18653/v1/2023.emnlp-main.701', 'CorpusId': 266164131}",https://www.semanticscholar.org/paper/57d65e85c62aef04dfb2a48380e415fbb790e5ee,Don't Take This Out of Context!: On the Need for Contextual Models and Evaluations for Stylistic Rewriting,,Conference on Empirical Methods in Natural Language Processing,2023,0,0,0,True,"{'url': 'https://aclanthology.org/2023.emnlp-main.701.pdf', 'status': None}",['Computer Science'],{'pages': '11419-11444'},"[{'authorId': '1388021166', 'name': 'Akhila Yerukola'}, {'authorId': '2260306432', 'name': 'Xuhui Zhou'}, {'authorId': '2273363657', 'name': 'Elizabeth Clark'}, {'authorId': '2729164', 'name': 'Maarten Sap'}]",TLDR not found
Maarten Sap,2729164,Maarten Sap,https://www.semanticscholar.org/author/2729164,36,"['Carnegie Mellon University, Allen Institute for AI']",75,7517,85a5ffc509fa50c96b415e09ae87fb6e5f435b37,"{'ArXiv': '2305.13589', 'DBLP': 'journals/corr/abs-2305-13589', 'DOI': '10.48550/arXiv.2305.13589', 'CorpusId': 258840909}",https://www.semanticscholar.org/paper/85a5ffc509fa50c96b415e09ae87fb6e5f435b37,"BiasX: ""Thinking Slow"" in Toxic Content Moderation with Explanations of Implied Social Biases","Toxicity annotators and content moderators often default to mental shortcuts when making decisions. This can lead to subtle toxicity being missed, and seemingly toxic but harmless content being over-detected. We introduce BiasX, a framework that enhances content moderation setups with free-text explanations of statements' implied social biases, and explore its effectiveness through a large-scale crowdsourced user study. We show that indeed, participants substantially benefit from explanations for correctly identifying subtly (non-)toxic content. The quality of explanations is critical: imperfect machine-generated explanations (+2.4% on hard toxic examples) help less compared to expert-written human explanations (+7.2%). Our results showcase the promise of using free-text explanations to encourage more thoughtful toxicity moderation.",Conference on Empirical Methods in Natural Language Processing,2023,33,0,0,True,"{'url': 'http://arxiv.org/pdf/2305.13589', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.13589', 'name': 'ArXiv'}","[{'authorId': '49889218', 'name': 'Yiming Zhang'}, {'authorId': '2218424381', 'name': 'Sravani Nanduri'}, {'authorId': '2112504145', 'name': 'Liwei Jiang'}, {'authorId': '2116417519', 'name': 'Tongshuang Wu'}, {'authorId': '2729164', 'name': 'Maarten Sap'}]","BiasX, a framework that enhances content moderation setups with free-text explanations of statements' implied social biases, is introduced and it is shown that indeed, participants substantially benefit from explanations for correctly identifying subtly (non-)toxic content."
Maarten Sap,2729164,Maarten Sap,https://www.semanticscholar.org/author/2729164,36,"['Carnegie Mellon University, Allen Institute for AI']",75,7517,9d2dc57903e99f33b9cf727c3903718751d82663,"{'ArXiv': '2305.14718', 'DBLP': 'journals/corr/abs-2305-14718', 'DOI': '10.48550/arXiv.2305.14718', 'CorpusId': 258865581}",https://www.semanticscholar.org/paper/9d2dc57903e99f33b9cf727c3903718751d82663,Improving Language Models with Advantage-based Offline Policy Gradients,"Language Models (LMs) achieve substantial language capabilities when finetuned using Reinforcement Learning with Human Feedback (RLHF). However, RLHF is an unstable and data-hungry process that continually requires new high-quality LM-generated data for finetuning. We introduce Advantage-Leftover Lunch RL (A-LoL), a new class of offline policy gradient algorithms that enable RL training on any pre-existing data. By assuming the entire LM output sequence as a single action, A-LoL allows incorporating sequence-level classifiers or human-designed scoring functions as rewards. Subsequently, by using LM's internal sequence-level value estimate, A-LoL filters negative advantage (low-quality) data points during training, making it resilient to noise. Overall, A-LoL is an easy-to-implement LM training recipe that is sample-efficient and stable. We demonstrate the effectiveness of A-LoL and its variants with a set of four different language generation tasks. We compare against both online RL (PPO) and recent preference-based (DPO, PRO) and reward-based (GOLD) offline RL baselines. On the commonly-used RLHF benchmark, Helpful and Harmless Assistant (HHA), LMs trained with A-LoL methods achieve the highest diversity while also being rated more safe and helpful than baselines according to humans. Additionally, in the remaining three tasks, A-LoL could optimize multiple distinct reward functions even when using noisy or suboptimal training data. We also release our experimental code. https://github.com/abaheti95/LoL-RL",arXiv.org,2023,91,4,0,True,"{'url': 'https://arxiv.org/pdf/2305.14718', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.14718', 'name': 'ArXiv'}","[{'authorId': '3458166', 'name': 'Ashutosh Baheti'}, {'authorId': '50085131', 'name': 'Ximing Lu'}, {'authorId': '9252833', 'name': 'Faeze Brahman'}, {'authorId': '39227408', 'name': 'Ronan Le Bras'}, {'authorId': '2729164', 'name': 'Maarten Sap'}, {'authorId': '2065904932', 'name': 'Mark O. Riedl'}]","Advantage-Leftover Lunch RL (A-LoL), a new class of offline policy gradient algorithms that enable RL training on any pre-existing data that assumes the entire LM output sequence as a single action, and allows incorporating sequence-level classifiers or human-designed scoring functions as rewards."
Maarten Sap,2729164,Maarten Sap,https://www.semanticscholar.org/author/2729164,36,"['Carnegie Mellon University, Allen Institute for AI']",75,7517,a5731b32060909bfc8848fa5f7e1e14ca3b53240,"{'DBLP': 'journals/corr/abs-2305-17174', 'ArXiv': '2305.17174', 'ACL': '2023.acl-long.845', 'DOI': '10.48550/arXiv.2305.17174', 'CorpusId': 258959384}",https://www.semanticscholar.org/paper/a5731b32060909bfc8848fa5f7e1e14ca3b53240,From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models,"Dogwhistles are coded expressions that simultaneously convey one meaning to a broad audience and a second, often hateful or provocative, meaning to a narrow in-group; they are deployed to evade both political repercussions and algorithmic content moderation. For example, the word “cosmopolitan” in a sentence such as “we need to end the cosmopolitan experiment” can mean “worldly” to many but also secretly mean “Jewish” to a select few. We present the first large-scale computational investigation of dogwhistles. We develop a typology of dogwhistles, curate the largest-to-date glossary of over 300 dogwhistles with rich contextual information and examples, and analyze their usage in historical U.S. politicians’ speeches. We then assess whether a large language model (GPT-3) can identify dogwhistles and their meanings, and find that GPT-3’s performance varies widely across types of dogwhistles and targeted groups. Finally, we show that harmful content containing dogwhistles avoids toxicity detection, highlighting online risks presented by such coded language. This work sheds light on the theoretical and applied importance of dogwhistles in both NLP and computational social science, and provides resources to facilitate future research in modeling dogwhistles and mitigating their online harms.",Annual Meeting of the Association for Computational Linguistics,2023,66,7,0,True,"{'url': 'http://arxiv.org/pdf/2305.17174', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.17174', 'name': 'ArXiv'}","[{'authorId': '32163938', 'name': 'Julia Mendelsohn'}, {'authorId': '39227408', 'name': 'Ronan Le Bras'}, {'authorId': '1699545', 'name': 'Yejin Choi'}, {'authorId': '2729164', 'name': 'Maarten Sap'}]",TLDR not found
Maarten Sap,2729164,Maarten Sap,https://www.semanticscholar.org/author/2729164,36,"['Carnegie Mellon University, Allen Institute for AI']",75,7517,a66ff335f5934fe7503a99d3eb3abed493994df1,"{'ACL': '2023.acl-long.505', 'DBLP': 'journals/corr/abs-2306-01943', 'ArXiv': '2306.01943', 'DOI': '10.48550/arXiv.2306.01943', 'CorpusId': 259076120}",https://www.semanticscholar.org/paper/a66ff335f5934fe7503a99d3eb3abed493994df1,NLPositionality: Characterizing Design Biases of Datasets and Models,"Design biases in NLP systems, such as performance differences for different populations, often stem from their creator’s positionality, i.e., views and lived experiences shaped by identity and background. Despite the prevalence and risks of design biases, they are hard to quantify because researcher, system, and dataset positionality is often unobserved. We introduce NLPositionality, a framework for characterizing design biases and quantifying the positionality of NLP datasets and models. Our framework continuously collects annotations from a diverse pool of volunteer participants on LabintheWild, and statistically quantifies alignment with dataset labels and model predictions. We apply NLPositionality to existing datasets and models for two tasks—social acceptability and hate speech detection. To date, we have collected 16,299 annotations in over a year for 600 instances from 1,096 annotators across 87 countries.We find that datasets and models align predominantly with Western, White, college-educated, and younger populations. Additionally, certain groups, such as non-binary people and non-native English speakers, are further marginalized by datasets and models as they rank least in alignment across all tasks. Finally, we draw from prior literature to discuss how researchers can examine their own positionality and that of their datasets and models, opening the door for more inclusive NLP systems.",Annual Meeting of the Association for Computational Linguistics,2023,92,16,1,True,"{'url': 'http://arxiv.org/pdf/2306.01943', 'status': None}",['Computer Science'],{'pages': '9080-9102'},"[{'authorId': '50074956', 'name': 'Sebastin Santy'}, {'authorId': '50685571', 'name': 'Jenny T Liang'}, {'authorId': '39227408', 'name': 'Ronan Le Bras'}, {'authorId': '2832085', 'name': 'Katharina Reinecke'}, {'authorId': '2729164', 'name': 'Maarten Sap'}]","NLPositionality, a framework for characterizing design biases and quantifying the positionality of NLP datasets and models, is introduced and it is found that dataset and models align predominantly with Western, White, college-educated, and younger populations."
Maarten Sap,2729164,Maarten Sap,https://www.semanticscholar.org/author/2729164,36,"['Carnegie Mellon University, Allen Institute for AI']",75,7517,a89c30ceca55783a1b2ff843eb6a4793e4a54b66,"{'ArXiv': '2305.14755', 'DBLP': 'journals/corr/abs-2305-14755', 'DOI': '10.48550/arXiv.2305.14755', 'CorpusId': 258865793}",https://www.semanticscholar.org/paper/a89c30ceca55783a1b2ff843eb6a4793e4a54b66,Don't Take This Out of Context! On the Need for Contextual Models and Evaluations for Stylistic Rewriting,"Most existing stylistic text rewriting methods and evaluation metrics operate on a sentence level, but ignoring the broader context of the text can lead to preferring generic, ambiguous, and incoherent rewrites. In this paper, we investigate integrating the preceding textual context into both the $\textit{rewriting}$ and $\textit{evaluation}$ stages of stylistic text rewriting, and introduce a new composite contextual evaluation metric $\texttt{CtxSimFit}$ that combines similarity to the original sentence with contextual cohesiveness. We comparatively evaluate non-contextual and contextual rewrites in formality, toxicity, and sentiment transfer tasks. Our experiments show that humans significantly prefer contextual rewrites as more fitting and natural over non-contextual ones, yet existing sentence-level automatic metrics (e.g., ROUGE, SBERT) correlate poorly with human preferences ($\rho$=0--0.3). In contrast, human preferences are much better reflected by both our novel $\texttt{CtxSimFit}$ ($\rho$=0.7--0.9) as well as proposed context-infused versions of common metrics ($\rho$=0.4--0.7). Overall, our findings highlight the importance of integrating context into the generation and especially the evaluation stages of stylistic text rewriting.",arXiv.org,2023,94,1,0,True,"{'url': 'http://arxiv.org/pdf/2305.14755', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.14755', 'name': 'ArXiv'}","[{'authorId': '1388021166', 'name': 'Akhila Yerukola'}, {'authorId': '144101734', 'name': 'Xuhui Zhou'}, {'authorId': '2729164', 'name': 'Maarten Sap'}]",A new composite contextual evaluation metric is introduced that combines similarity to the original sentence with contextual cohesiveness and highlights the importance of integrating context into the generation and especially the evaluation stages of stylistic text rewriting.
Maarten Sap,2729164,Maarten Sap,https://www.semanticscholar.org/author/2729164,36,"['Carnegie Mellon University, Allen Institute for AI']",75,7517,c2850c897a179c07a25023029306600e0ea82f75,"{'ArXiv': '2303.16972', 'DBLP': 'conf/fat/QueerinaiOSSVSL23', 'DOI': '10.1145/3593013.3594134', 'CorpusId': 257833657}",https://www.semanticscholar.org/paper/c2850c897a179c07a25023029306600e0ea82f75,Queer In AI: A Case Study in Community-Led Participatory AI,"Queerness and queer people face an uncertain future in the face of ever more widely deployed and invasive artificial intelligence (AI). These technologies have caused numerous harms to queer people, including privacy violations, censoring and downranking queer content, exposing queer people and spaces to harassment by making them hypervisible, deadnaming and outing queer people. More broadly, they have violated core tenets of queerness by classifying and controlling queer identities. In response to this, the queer community in AI has organized Queer in AI, a global, decentralized, volunteer-run grassroots organization that employs intersectional and community-led participatory design to build an inclusive and equitable AI future. In this paper, we present Queer in AI as a case study for community-led participatory design in AI. We examine how participatory design and intersectional tenets started and shaped this community’s programs over the years. We discuss different challenges that emerged in the process, look at ways this organization has fallen short of operationalizing participatory and intersectional principles, and then assess the organization’s impact. Queer in AI provides important lessons and insights for practitioners and theorists of participatory methods broadly through its rejection of hierarchy in favor of decentralization, success at building aid and programs by and for the queer community, and effort to change actors and institutions outside of the queer community. Finally, we theorize how communities like Queer in AI contribute to the participatory design in AI more broadly by fostering cultures of participation in AI, welcoming and empowering marginalized participants, critiquing poor or exploitative participatory practices, and bringing participation to institutions outside of individual research projects. Queer in AI’s work serves as a case study of grassroots activism and participatory methods within AI, demonstrating the potential of community-led participatory methods and intersectional praxis, while also providing challenges, case studies, and nuanced insights to researchers developing and using participatory methods.","Conference on Fairness, Accountability and Transparency",2023,149,12,0,True,"{'url': 'https://arrow.tudublin.ie/context/scschcomcon/article/1430/viewcontent/Queer_In_AI___A_Case_Study_in_Community_Led_Participatory_AI.pdf', 'status': None}",['Computer Science'],"{'name': 'Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency'}","[{'authorId': '2218541546', 'name': 'AI OrganizersOfQueerin'}, {'authorId': '51494507', 'name': 'Anaelia Ovalle'}, {'authorId': '1677386832', 'name': 'Arjun Subramonian'}, {'authorId': '1736747863', 'name': 'Ashwin Singh'}, {'authorId': '1387979639', 'name': 'C. Voelcker'}, {'authorId': '36326783', 'name': 'Danica J. Sutherland'}, {'authorId': '2187298466', 'name': 'Davide Locatelli'}, {'authorId': '71670796', 'name': 'Eva Breznik'}, {'authorId': '3201315', 'name': 'Filip Klubicka'}, {'authorId': '2114128156', 'name': 'Hang Yuan'}, {'authorId': '2218541541', 'name': 'J. Hetvi'}, {'authorId': '2218574157', 'name': 'Huan Zhang'}, {'authorId': '2126958277', 'name': 'Jaidev Shriram'}, {'authorId': '2218537291', 'name': 'Kruno Lehman'}, {'authorId': '3328733', 'name': 'Luca Soldaini'}, {'authorId': '2729164', 'name': 'Maarten Sap'}, {'authorId': '2261881', 'name': 'M. Deisenroth'}, {'authorId': '32727925', 'name': 'Maria Leonor Pacheco'}, {'authorId': '1410648718', 'name': 'Maria Ryskina'}, {'authorId': '2218834122', 'name': 'Martin Mundt'}, {'authorId': '121465663', 'name': 'M. Agarwal'}, {'authorId': '113684790', 'name': 'Nyx McLean'}, {'authorId': '47568847', 'name': 'Pan Xu'}, {'authorId': '144890152', 'name': 'Pranav A'}, {'authorId': '26336279', 'name': 'Raj Korpan'}, {'authorId': '2137541587', 'name': 'Ruchira Ray'}, {'authorId': '51218838', 'name': 'Sarah Mathew'}, {'authorId': '3141157', 'name': 'Sarthak Arora'}, {'authorId': '144104356', 'name': 'S. T. John'}, {'authorId': '1455135470', 'name': 'Tanvi Anand'}, {'authorId': '2053001357', 'name': 'Vishakha Agrawal'}, {'authorId': '27377925', 'name': 'William Agnew'}, {'authorId': '2147432885', 'name': 'Yanan Long'}, {'authorId': '1390877819', 'name': 'Zijie J. Wang'}, {'authorId': '2138053020', 'name': 'Zeerak Talat'}, {'authorId': '2217841900', 'name': 'Avijit Ghosh'}, {'authorId': '2067002450', 'name': 'N. Dennler'}, {'authorId': '38107789', 'name': 'Michael Noseworthy'}, {'authorId': '2218590691', 'name': 'Sharvani Jha'}, {'authorId': '2026649806', 'name': 'Emi Baylor'}, {'authorId': '1387436311', 'name': 'Aditya Joshi'}, {'authorId': '37016119', 'name': 'Natalia Y. Bilenko'}, {'authorId': '145654703', 'name': 'Andrew McNamara'}, {'authorId': '2158366935', 'name': 'Raphael Gontijo-Lopes'}, {'authorId': '40325765', 'name': 'Alex Markham'}, {'authorId': '2218539335', 'name': 'Evyn Dǒng'}, {'authorId': '50979962', 'name': 'J. Kay'}, {'authorId': '1753548783', 'name': 'Manu Saraswat'}, {'authorId': '2218539506', 'name': 'Nikhil Vytla'}, {'authorId': '30353442', 'name': 'Luke Stark'}]","This paper examines how participatory design and intersectional tenets started and shaped this community’s programs over the years, and discusses different challenges that emerged in the process, and looks at ways this organization has fallen short of operationalizing participatory and intersectionsal principles."
Maarten Sap,2729164,Maarten Sap,https://www.semanticscholar.org/author/2729164,36,"['Carnegie Mellon University, Allen Institute for AI']",75,7517,d655f652d02251b45db43181c5e3c73dfc59cd51,"{'ArXiv': '2309.00779', 'DBLP': 'journals/corr/abs-2309-00779', 'DOI': '10.48550/arXiv.2309.00779', 'CorpusId': 261531157}",https://www.semanticscholar.org/paper/d655f652d02251b45db43181c5e3c73dfc59cd51,"Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties","Human values are crucial to human decision-making. Value pluralism is the view that multiple correct values may be held in tension with one another (e.g., when considering lying to a friend to protect their feelings, how does one balance honesty with friendship?). As statistical learners, AI systems fit to averages by default, washing out these potentially irreducible value conflicts. To improve AI systems to better reflect value pluralism, the first-order challenge is to explore the extent to which AI systems can model pluralistic human values, rights, and duties as well as their interaction. We introduce ValuePrism, a large-scale dataset of 218k values, rights, and duties connected to 31k human-written situations. ValuePrism's contextualized values are generated by GPT-4 and deemed high-quality by human annotators 91% of the time. We conduct a large-scale study with annotators across diverse social and demographic backgrounds to try to understand whose values are represented. With ValuePrism, we build Kaleido, an open, light-weight, and structured language-based multi-task model that generates, explains, and assesses the relevance and valence (i.e., support or oppose) of human values, rights, and duties within a specific context. Humans prefer the sets of values output by our system over the teacher GPT-4, finding them more accurate and with broader coverage. In addition, we demonstrate that Kaleido can help explain variability in human decision-making by outputting contrasting values. Finally, we show that Kaleido's representations transfer to other philosophical frameworks and datasets, confirming the benefit of an explicit, modular, and interpretable approach to value pluralism. We hope that our work will serve as a step to making more explicit the implicit values behind human decision-making and to steering AI systems to make decisions that are more in accordance with them.",arXiv.org,2023,158,8,0,True,"{'url': 'https://arxiv.org/pdf/2309.00779', 'status': None}",['Computer Science'],"{'volume': 'abs/2309.00779', 'name': 'ArXiv'}","[{'authorId': '122436831', 'name': 'Taylor Sorensen'}, {'authorId': '2112504145', 'name': 'Liwei Jiang'}, {'authorId': '2012510', 'name': 'Jena D. Hwang'}, {'authorId': '2237802624', 'name': 'Sydney Levine'}, {'authorId': '22330666', 'name': 'Valentina Pyatkin'}, {'authorId': '119659229', 'name': 'Peter West'}, {'authorId': '46217681', 'name': 'Nouha Dziri'}, {'authorId': '50085131', 'name': 'Ximing Lu'}, {'authorId': '2237944445', 'name': 'Kavel Rao'}, {'authorId': '1857797', 'name': 'Chandra Bhagavatula'}, {'authorId': '2729164', 'name': 'Maarten Sap'}, {'authorId': '3360730', 'name': 'J. Tasioulas'}, {'authorId': '1699545', 'name': 'Yejin Choi'}]","Kaleido is built, an open, light-weight, and structured language-based multi-task model that generates, explains, and assesses the relevance and valence of human values, rights, and duties within a specific context and demonstrates that Kaleido can help explain variability in human decision-making by outputting contrasting values."
Maarten Sap,2729164,Maarten Sap,https://www.semanticscholar.org/author/2729164,36,"['Carnegie Mellon University, Allen Institute for AI']",75,7517,ddcd2bcc809bd0c2755a4a9487473d61ac327c50,"{'ArXiv': '2305.14763', 'DBLP': 'journals/corr/abs-2305-14763', 'DOI': '10.48550/arXiv.2305.14763', 'CorpusId': 258865502}",https://www.semanticscholar.org/paper/ddcd2bcc809bd0c2755a4a9487473d61ac327c50,Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models,"The escalating debate on AI's capabilities warrants developing reliable metrics to assess machine""intelligence"". Recently, many anecdotal examples were used to suggest that newer large language models (LLMs) like ChatGPT and GPT-4 exhibit Neural Theory-of-Mind (N-ToM); however, prior work reached conflicting conclusions regarding those abilities. We investigate the extent of LLMs' N-ToM through an extensive evaluation on 6 tasks and find that while LLMs exhibit certain N-ToM abilities, this behavior is far from being robust. We further examine the factors impacting performance on N-ToM tasks and discover that LLMs struggle with adversarial examples, indicating reliance on shallow heuristics rather than robust ToM abilities. We caution against drawing conclusions from anecdotal examples, limited benchmark testing, and using human-designed psychological tests to evaluate models.",arXiv.org,2023,63,38,5,True,"{'url': 'http://arxiv.org/pdf/2305.14763', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.14763', 'name': 'ArXiv'}","[{'authorId': '2067118898', 'name': 'Natalie Shapira'}, {'authorId': '51028767', 'name': 'Mosh Levy'}, {'authorId': '143654999', 'name': 'S. Alavi'}, {'authorId': '144101734', 'name': 'Xuhui Zhou'}, {'authorId': '1699545', 'name': 'Yejin Choi'}, {'authorId': '79775260', 'name': 'Yoav Goldberg'}, {'authorId': '2729164', 'name': 'Maarten Sap'}, {'authorId': '3103343', 'name': 'Vered Shwartz'}]","It is found that while LLMs exhibit certain N-ToM abilities, this behavior is far from being robust, indicating reliance on shallow heuristics rather than robust ToM abilities."
Maarten Sap,2729164,Maarten Sap,https://www.semanticscholar.org/author/2729164,36,"['Carnegie Mellon University, Allen Institute for AI']",75,7517,ea0585ed23e25d5f8682eb91f20c6ddbeb6a27b4,"{'DBLP': 'journals/corr/abs-2303-16173', 'ArXiv': '2303.16173', 'DOI': '10.48550/arXiv.2303.16173', 'CorpusId': 257771544}",https://www.semanticscholar.org/paper/ea0585ed23e25d5f8682eb91f20c6ddbeb6a27b4,Towards Countering Essentialism through Social Bias Reasoning,"Essentialist beliefs (i.e., believing that members of the same group are fundamentally alike) play a central role in social stereotypes and can lead to harm when left unchallenged. In our work, we conduct exploratory studies into the task of countering essentialist beliefs (e.g., ``liberals are stupid''). Drawing on prior work from psychology and NLP, we construct five types of counterstatements and conduct human studies on the effectiveness of these different strategies. Our studies also investigate the role in choosing a counterstatement of the level of explicitness with which an essentialist belief is conveyed. We find that statements that broaden the scope of a stereotype (e.g., to other groups, as in ``conservatives can also be stupid'') are the most popular countering strategy. We conclude with a discussion of challenges and open questions for future work in this area (e.g., improving factuality, studying community-specific variation) and we emphasize the importance of work at the intersection of NLP and psychology.",arXiv.org,2023,42,3,0,True,"{'url': 'http://arxiv.org/pdf/2303.16173', 'status': None}",['Computer Science'],"{'volume': 'abs/2303.16173', 'name': 'ArXiv'}","[{'authorId': '46208659', 'name': 'Emily Allaway'}, {'authorId': '70655120', 'name': 'Nina Taneja'}, {'authorId': '144790242', 'name': 'S. Leslie'}, {'authorId': '2729164', 'name': 'Maarten Sap'}]",TLDR not found
Malihe Alikhani,2715920,Malihe Alikhani,https://www.semanticscholar.org/author/2715920,12,['Rutgers University'],58,520,2386c6a7c40b5129960f2eb3c6be27db65b04c1f,"{'ACL': '2023.acl-long.163', 'ArXiv': '2307.04303', 'DBLP': 'journals/corr/abs-2307-04303', 'DOI': '10.48550/arXiv.2307.04303', 'CorpusId': 259370533}",https://www.semanticscholar.org/paper/2386c6a7c40b5129960f2eb3c6be27db65b04c1f,Learning to Generate Equitable Text in Dialogue from Biased Training Data,"The ingrained principles of fairness in a dialogue system’s decision-making process and generated responses are crucial for user engagement, satisfaction, and task achievement. Absence of equitable and inclusive principles can hinder the formation of common ground, which in turn negatively impacts the overall performance of the system. For example, misusing pronouns in a user interaction may cause ambiguity about the intended subject. Yet, there is no comprehensive study of equitable text generation in dialogue. Aptly, in this work, we use theories of computational learning to study this problem. We provide formal definitions of equity in text generation, and further, prove formal connections between learning human-likeness and learning equity: algorithms for improving equity ultimately reduce to algorithms for improving human-likeness (on augmented data). With this insight, we also formulate reasonable conditions under which text generation algorithms can learn to generate equitable text without any modifications to the biased training data on which they learn. To exemplify our theory in practice, we look at a group of algorithms for the GuessWhat?! visual dialogue game and, using this example, test our theory empirically. Our theory accurately predicts relative-performance of multiple algorithms in generating equitable text as measured by both human and automated evaluation.",Annual Meeting of the Association for Computational Linguistics,2023,40,3,0,True,"{'url': 'https://arxiv.org/pdf/2307.04303', 'status': None}",['Computer Science'],{'pages': '2898-2917'},"[{'authorId': '51137683', 'name': 'Anthony Sicilia'}, {'authorId': '2715920', 'name': 'Malihe Alikhani'}]","This work provides formal definitions of equity in text generation, and proves formal connections between learning human-likeness and learning equity: algorithms for improving equity ultimately reduce to algorithms forimproving human- likeness (on augmented data)."
Malihe Alikhani,2715920,Malihe Alikhani,https://www.semanticscholar.org/author/2715920,12,['Rutgers University'],58,520,2605bc92935ca67829e9542030be0e44ae81c22e,"{'DBLP': 'conf/sigdial/ChengIMGCSPWA23', 'ACL': '2023.sigdial-1.41', 'DOI': '10.18653/v1/2023.sigdial-1.41', 'CorpusId': 263609496}",https://www.semanticscholar.org/paper/2605bc92935ca67829e9542030be0e44ae81c22e,Learning Multimodal Cues of Children’s Uncertainty,"Understanding uncertainty plays a critical role in achieving common ground (Clark et al., 1983). This is especially important for multimodal AI systems that collaborate with users to solve a problem or guide the user through a challenging concept. In this work, for the first time, we present a dataset annotated in collaboration with developmental and cognitive psychologists for the purpose of studying nonverbal cues of uncertainty. We then present an analysis of the data, studying different roles of uncertainty and its relationship with task difficulty and performance. Lastly, we present a multimodal machine learning model that can predict uncertainty given a real-time video clip of a participant, which we find improves upon a baseline multimodal transformer model. This work informs research on cognitive coordination between human-human and human-AI and has broad implications for gesture understanding and generation. The anonymized version of our data and code will be publicly available upon the completion of the required consent forms and data sheets.",SIGDIAL Conferences,2023,39,0,0,True,"{'url': 'https://aclanthology.org/2023.sigdial-1.41.pdf', 'status': None}",['Computer Science'],{'pages': '433-443'},"[{'authorId': '2253429593', 'name': 'Qi Cheng'}, {'authorId': '2253599252', 'name': 'Mert Inan'}, {'authorId': '2253601035', 'name': 'Rahma Mbarki'}, {'authorId': '2253599591', 'name': 'Grace Grmek'}, {'authorId': '2253599790', 'name': 'Theresa Choi'}, {'authorId': '2254288848', 'name': 'Yiming Sun'}, {'authorId': '35197700', 'name': 'Kimele Persaud'}, {'authorId': '2253859242', 'name': 'Jenny Wang'}, {'authorId': '2715920', 'name': 'Malihe Alikhani'}]","A multimodal machine learning model that can predict uncertainty given a real-time video clip of a participant is presented, which improves upon a baseline multimodAL transformer model and has broad implications for gesture understanding and generation."
Malihe Alikhani,2715920,Malihe Alikhani,https://www.semanticscholar.org/author/2715920,12,['Rutgers University'],58,520,604cc00ff6a4d57d97856b49be4df89452cf30a8,"{'ACL': '2023.wmt-1.4', 'DBLP': 'conf/wmt/0002AABBCEEGGIJ23', 'DOI': '10.18653/v1/2023.wmt-1.4', 'CorpusId': 265607856}",https://www.semanticscholar.org/paper/604cc00ff6a4d57d97856b49be4df89452cf30a8,Findings of the Second WMT Shared Task on Sign Language Translation (WMT-SLT23),"This paper presents the results of the Second WMT Shared Task on Sign Language Translation (WMT-SLT23; https://www.wmt-slt.com/). This shared task is concerned with automatic translation between signed and spoken languages. The task is unusual in the sense that it requires processing visual information (such as video frames or human pose estimation) beyond the well-known paradigm of text-to-text machine translation (MT). The task offers four tracks involving the following languages: Swiss German Sign Language (DSGS), French Sign Language of Switzerland (LSF-CH), Italian Sign Language of Switzerland (LIS-CH), German, French and Italian. Four teams (including one working on a baseline submission) participated in this second edition of the task, all submitting to the DSGS-to-German track. Besides a system ranking and system papers describing state-of-the-art techniques, this shared task makes the following scientific contributions: novel corpora and reproducible baseline systems. Finally, the task also resulted in publicly available sets of system outputs and more human evaluation scores for sign language translation.",Conference on Machine Translation,2023,98,4,0,True,"{'url': 'https://aclanthology.org/2023.wmt-1.4.pdf', 'status': None}",['Computer Science'],{'pages': '68-94'},"[{'authorId': '2237606710', 'name': 'Mathias Müller'}, {'authorId': '2715920', 'name': 'Malihe Alikhani'}, {'authorId': '2837687', 'name': 'Eleftherios Avramidis'}, {'authorId': '2269460134', 'name': 'Richard Bowden'}, {'authorId': '1704441', 'name': 'Annelies Braffort'}, {'authorId': '2146804008', 'name': 'Necati Cihan Camgöz'}, {'authorId': '2243317498', 'name': 'Sarah Ebling'}, {'authorId': '2237430141', 'name': 'Cristina España-Bonet'}, {'authorId': '1962058', 'name': 'A. Göhring'}, {'authorId': '3272639', 'name': 'Roman Grundkiewicz'}, {'authorId': '2253599252', 'name': 'Mert Inan'}, {'authorId': '2112347487', 'name': 'Zifan Jiang'}, {'authorId': '2237429415', 'name': 'Oscar Koller'}, {'authorId': '2237431969', 'name': 'Amit Moryossef'}, {'authorId': '2269456698', 'name': 'Annette Rios'}, {'authorId': '2129048972', 'name': 'D. Shterionov'}, {'authorId': '1405015074', 'name': 'Sandra Sidler-Miserez'}, {'authorId': '19296987', 'name': 'Katja Tissi'}, {'authorId': '2123124715', 'name': 'Davy Van Landuyt'}]","This paper presents the results of the Second WMT Shared Task on Sign Language Translation, concerned with automatic translation between signed and spoken languages, which resulted in publicly available sets of system outputs and more human evaluation scores for sign language translation."
Malihe Alikhani,2715920,Malihe Alikhani,https://www.semanticscholar.org/author/2715920,12,['Rutgers University'],58,520,78ee30f94bfa9c08306cd2f5bf92e98240aa692d,"{'ArXiv': '2302.09618', 'ACL': '2023.eacl-main.276', 'DBLP': 'conf/eacl/YeSAHDA23', 'DOI': '10.48550/arXiv.2302.09618', 'CorpusId': 257038107}",https://www.semanticscholar.org/paper/78ee30f94bfa9c08306cd2f5bf92e98240aa692d,Multilingual Content Moderation: A Case Study on Reddit,"Content moderation is the process of flagging content based on pre-defined platform rules. There has been a growing need for AI moderators to safeguard users as well as protect the mental health of human moderators from traumatic content. While prior works have focused on identifying hateful/offensive language, they are not adequate for meeting the challenges of content moderation since 1) moderation decisions are based on violation of rules, which subsumes detection of offensive speech, and 2) such rules often differ across communities which entails an adaptive solution. We propose to study the challenges of content moderation by introducing a multilingual dataset of 1.8 Million Reddit comments spanning 56 subreddits in English, German, Spanish and French1. We perform extensive experimental analysis to highlight the underlying challenges and suggest related research problems such as cross-lingual transfer, learning under label noise (human biases), transfer of moderation models, and predicting the violated rule. Our dataset and analysis can help better prepare for the challenges and opportunities of auto moderation.",Conference of the European Chapter of the Association for Computational Linguistics,2023,34,3,0,True,"{'url': 'http://arxiv.org/pdf/2302.09618', 'status': None}",['Computer Science'],"{'volume': 'abs/2302.09618', 'name': 'ArXiv'}","[{'authorId': '2054892429', 'name': 'Meng Ye'}, {'authorId': '39707211', 'name': 'Karan Sikka'}, {'authorId': '2115500561', 'name': 'Katherine Atwell'}, {'authorId': '67114070', 'name': 'Sabit Hassan'}, {'authorId': '47977519', 'name': 'Ajay Divakaran'}, {'authorId': '2715920', 'name': 'Malihe Alikhani'}]","This work proposes to study the challenges of content moderation by introducing a multilingual dataset of 1.8 Million Reddit comments spanning 56 subreddits in English, German, Spanish and French and performs extensive experimental analysis to highlight the underlying challenges and suggest related research problems."
Malihe Alikhani,2715920,Malihe Alikhani,https://www.semanticscholar.org/author/2715920,12,['Rutgers University'],58,520,e2be92ff1ae2abdc05c1929d6d02623c58f37097,"{'PubMedCentral': '10226667', 'DOI': '10.3389/frai.2023.1048874', 'CorpusId': 258678310, 'PubMed': '37255946'}",https://www.semanticscholar.org/paper/e2be92ff1ae2abdc05c1929d6d02623c58f37097,Image–text coherence and its implications for multimodal AI,"Human communication often combines imagery and text into integrated presentations, especially online. In this paper, we show how image–text coherence relations can be used to model the pragmatics of image–text presentations in AI systems. In contrast to alternative frameworks that characterize image–text presentations in terms of the priority, relevance, or overlap of information across modalities, coherence theory postulates that each unit of a discourse stands in specific pragmatic relations to other parts of the discourse, with each relation involving its own information goals and inferential connections. Text accompanying an image may, for example, characterize what's visible in the image, explain how the image was obtained, offer the author's appraisal of or reaction to the depicted situation, and so forth. The advantage of coherence theory is that it provides a simple, robust, and effective abstraction of communicative goals for practical applications. To argue this, we review case studies describing coherence in image–text data sets, predicting coherence from few-shot annotations, and coherence models of image–text tasks such as caption generation and caption evaluation.",Frontiers in Artificial Intelligence,2023,57,2,0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/frai.2023.1048874/pdf', 'status': None}",['Medicine'],"{'volume': '6', 'name': 'Frontiers in Artificial Intelligence'}","[{'authorId': '2715920', 'name': 'Malihe Alikhani'}, {'authorId': '1468726581', 'name': 'Baber Khalid'}, {'authorId': '144884556', 'name': 'Matthew Stone'}]","This paper shows how image–text coherence relations can be used to model the pragmatics of image-text presentations in AI systems, and reviews case studies describing coherence in image– Text data sets, predicting coherence from few-shot annotations, and coherence models of image– text tasks such as caption generation and caption evaluation."
Malihe Alikhani,2715920,Malihe Alikhani,https://www.semanticscholar.org/author/2715920,12,['Rutgers University'],58,520,ee866d0dd47351542e4924f14203a767dd03194a,"{'DOI': '10.1007/s10579-023-09689-6', 'CorpusId': 265419296}",https://www.semanticscholar.org/paper/ee866d0dd47351542e4924f14203a767dd03194a,A corpus of Persian literary text,,Language Resources and Evaluation,2023,35,0,0,True,"{'url': 'https://link.springer.com/content/pdf/10.1007/s10579-023-09689-6.pdf', 'status': None}",,"{'volume': '', 'pages': '1-17', 'name': 'Language Resources and Evaluation'}","[{'authorId': '1490966668', 'name': 'Shahab Raji'}, {'authorId': '2715920', 'name': 'Malihe Alikhani'}, {'authorId': '2264892123', 'name': 'Gerard de Melo'}, {'authorId': '2268139970', 'name': 'Matthew Stone'}]","The corpus, the tools, and experiments described in this paper can be used not only for digital humanities studies of Persian literature but also for processing Persian texts in general, as well as in other broader cross-linguistic applications."
Malihe Alikhani,2715920,Malihe Alikhani,https://www.semanticscholar.org/author/2715920,12,['Rutgers University'],58,520,f19180afd6cae7c241fa461eed122e4c04a14217,"{'DBLP': 'journals/corr/abs-2305-17013', 'ArXiv': '2305.17013', 'DOI': '10.48550/arXiv.2305.17013', 'CorpusId': 258947612}",https://www.semanticscholar.org/paper/f19180afd6cae7c241fa461eed122e4c04a14217,D-CALM: A Dynamic Clustering-based Active Learning Approach for Mitigating Bias,"Despite recent advancements, NLP models continue to be vulnerable to bias. This bias often originates from the uneven distribution of real-world data and can propagate through the annotation process. Escalated integration of these models in our lives calls for methods to mitigate bias without overbearing annotation costs. While active learning (AL) has shown promise in training models with a small amount of annotated data, AL's reliance on the model's behavior for selective sampling can lead to an accumulation of unwanted bias rather than bias mitigation. However, infusing clustering with AL can overcome the bias issue of both AL and traditional annotation methods while exploiting AL's annotation efficiency. In this paper, we propose a novel adaptive clustering-based active learning algorithm, D-CALM, that dynamically adjusts clustering and annotation efforts in response to an estimated classifier error-rate. Experiments on eight datasets for a diverse set of text classification tasks, including emotion, hatespeech, dialog act, and book type detection, demonstrate that our proposed algorithm significantly outperforms baseline AL approaches with both pretrained transformers and traditional Support Vector Machines. D-CALM showcases robustness against different measures of information gain and, as evident from our analysis of label and error distribution, can significantly reduce unwanted model bias.",Annual Meeting of the Association for Computational Linguistics,2023,51,1,0,True,"{'url': 'http://arxiv.org/pdf/2305.17013', 'status': None}",['Computer Science'],{'pages': '5540-5553'},"[{'authorId': '67114070', 'name': 'Sabit Hassan'}, {'authorId': '2715920', 'name': 'Malihe Alikhani'}]","A novel adaptive clustering-based active learning algorithm that dynamically adjusts clustering and annotation efforts in response to an estimated classifier error-rate, D-CALM, which showcases robustness against different measures of information gain and can significantly reduce unwanted model bias."
Matt Gormley,1762110,Matthew R. Gormley,https://www.semanticscholar.org/author/1762110,17,[],42,1117,d6ae4c0679bdceb029f652efd2a854ac5ade772f,"{'DBLP': 'journals/corr/abs-2310-01387', 'ACL': '2023.bigpicture-1.9', 'ArXiv': '2310.01387', 'DOI': '10.48550/arXiv.2310.01387', 'CorpusId': 263605610}",https://www.semanticscholar.org/paper/d6ae4c0679bdceb029f652efd2a854ac5ade772f,It’s MBR All the Way Down: Modern Generation Techniques Through the Lens of Minimum Bayes Risk,"Minimum Bayes Risk (MBR) decoding is a method for choosing the outputs of a machine learning system based not on the output with the highest probability, but the output with the lowest risk (expected error) among multiple candidates. It is a simple but powerful method: for an additional cost at inference time, MBR provides reliable several-point improvements across metrics for a wide variety of tasks without any additional data or training. Despite this, MBR is not frequently applied in NLP works, and knowledge of the method itself is limited. We first provide an introduction to the method and the recent literature. We show that several recent methods that do not reference MBR can be written as special cases of MBR; this reformulation provides additional theoretical justification for the performance of these methods, explaining some results that were previously only empirical. We provide theoretical and empirical results about the effectiveness of various MBR variants and make concrete recommendations for the application of MBR in NLP models, including future directions in this area.",BIGPICTURE,2023,94,6,0,True,"{'url': 'https://arxiv.org/pdf/2310.01387', 'status': None}",['Computer Science'],"{'volume': 'abs/2310.01387', 'name': 'ArXiv'}","[{'authorId': '2138301112', 'name': 'Amanda Bertsch'}, {'authorId': '2253395527', 'name': 'Alex Xie'}, {'authorId': '1700325', 'name': 'Graham Neubig'}, {'authorId': '1762110', 'name': 'Matthew R. Gormley'}]","It is shown that several recent methods that do not reference MBR can be written as special cases of MBR; this reformulation provides additional theoretical justification for the performance of these methods, explaining some results that were previously only empirical."
Matt Gormley,1762110,Matthew R. Gormley,https://www.semanticscholar.org/author/1762110,17,[],42,1117,dbc368bc8b49347dd27679894524fa62f88492c9,"{'ArXiv': '2305.01625', 'DBLP': 'journals/corr/abs-2305-01625', 'DOI': '10.48550/arXiv.2305.01625', 'CorpusId': 258436892}",https://www.semanticscholar.org/paper/dbc368bc8b49347dd27679894524fa62f88492c9,Unlimiformer: Long-Range Transformers with Unlimited Length Input,"Since the proposal of transformers, these models have been limited to bounded input lengths, because of their need to attend to every token in the input. In this work, we propose Unlimiformer: a general approach that wraps any existing pretrained encoder-decoder transformer, and offloads the cross-attention computation to a single k-nearest-neighbor (kNN) index, while the returned kNN distances are the attention dot-product scores. This kNN index can be kept on either the GPU or CPU memory and queried in sub-linear time; this way, we can index practically unlimited input sequences, while every attention head in every decoder layer retrieves its top-k keys, instead of attending to every key. We evaluate Unlimiformer on several long-document and book-summarization benchmarks, showing that it can process even 500k token-long inputs from the BookSum dataset, without any input truncation at test time. We demonstrate that Unlimiformer improves pretrained models such as BART and Longformer by extending them to unlimited inputs without additional learned weights and without modifying their code. We make our code and models publicly available at https://github.com/abertsch72/unlimiformer .",arXiv.org,2023,56,38,3,True,"{'url': 'http://arxiv.org/pdf/2305.01625', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.01625', 'name': 'ArXiv'}","[{'authorId': '2138301112', 'name': 'Amanda Bertsch'}, {'authorId': '47051926', 'name': 'Uri Alon'}, {'authorId': '1700325', 'name': 'Graham Neubig'}, {'authorId': '1762110', 'name': 'Matthew R. Gormley'}]","This work proposes Unlimiformer: a general approach that wraps any existing pretrained encoder-decoder transformer, and offloads the cross-attention computation to a single k-nearest-neighbor (kNN) index, while the returned kNN distances are the attention dot-product scores."
Matt Gormley,1762110,Matthew R. Gormley,https://www.semanticscholar.org/author/1762110,17,[],42,1117,e80f1b4c254a5c135f5f3416ba3a863f8ec4e06c,"{'DBLP': 'conf/acl/ChengJRKLSG23', 'ArXiv': '2307.03859', 'ACL': '2023.acl-long.416', 'DOI': '10.48550/arXiv.2307.03859', 'CorpusId': 259370675}",https://www.semanticscholar.org/paper/e80f1b4c254a5c135f5f3416ba3a863f8ec4e06c,MDACE: MIMIC Documents Annotated with Code Evidence,"We introduce a dataset for evidence/rationale extraction on an extreme multi-label classification task over long medical documents. One such task is Computer-Assisted Coding (CAC) which has improved significantly in recent years, thanks to advances in machine learning technologies. Yet simply predicting a set of final codes for a patient encounter is insufficient as CAC systems are required to provide supporting textual evidence to justify the billing codes. A model able to produce accurate and reliable supporting evidence for each code would be a tremendous benefit. However, a human annotated code evidence corpus is extremely difficult to create because it requires specialized knowledge. In this paper, we introduce MDACE, the first publicly available code evidence dataset, which is built on a subset of the MIMIC-III clinical records. The dataset – annotated by professional medical coders – consists of 302 Inpatient charts with 3,934 evidence spans and 52 Profee charts with 5,563 evidence spans. We implemented several evidence extraction methods based on the EffectiveCAN model (Liu et al., 2021) to establish baseline performance on this dataset. MDACE can be used to evaluate code evidence extraction methods for CAC systems, as well as the accuracy and interpretability of deep learning models for multi-label classification. We believe that the release of MDACE will greatly improve the understanding and application of deep learning technologies for medical coding and document classification.",Annual Meeting of the Association for Computational Linguistics,2023,44,1,1,True,"{'url': 'https://arxiv.org/pdf/2307.03859', 'status': None}",['Computer Science'],"{'volume': 'abs/2307.03859', 'name': 'ArXiv'}","[{'authorId': '2117908368', 'name': 'Hua Cheng'}, {'authorId': '2161140029', 'name': 'Rana Jafari'}, {'authorId': '2221287414', 'name': 'April Russell'}, {'authorId': '2139750121', 'name': 'Russell Klopfer'}, {'authorId': '2221287131', 'name': 'Edmond Lu'}, {'authorId': '48227397', 'name': 'Benjamin Striner'}, {'authorId': '1762110', 'name': 'Matthew R. Gormley'}]","MDACE is introduced, the first publicly available code evidence dataset, which is built on a subset of the MIMIC-III clinical records and can be used to evaluate code evidence extraction methods for CAC systems, as well as the accuracy and interpretability of deep learning models for multi-label classification."
Matt Gormley,1762110,Matthew R. Gormley,https://www.semanticscholar.org/author/1762110,17,[],42,1117,ebb3d299213bae89b5d302cc3dfc36573ec83956,"{'ACL': '2023.clinicalnlp-1.51', 'DBLP': 'conf/acl-clinicalnlp/MathurRKPBG23', 'ArXiv': '2306.17384', 'DOI': '10.48550/arXiv.2306.17384', 'CorpusId': 259309155}",https://www.semanticscholar.org/paper/ebb3d299213bae89b5d302cc3dfc36573ec83956,SummQA at MEDIQA-Chat 2023: In-Context Learning with GPT-4 for Medical Summarization,"Medical dialogue summarization is challenging due to the unstructured nature of medical conversations, the use of medical terminologyin gold summaries, and the need to identify key information across multiple symptom sets. We present a novel system for the Dialogue2Note Medical Summarization tasks in the MEDIQA 2023 Shared Task. Our approach for sectionwise summarization (Task A) is a two-stage process of selecting semantically similar dialogues and using the top-k similar dialogues as in-context examples for GPT-4. For full-note summarization (Task B), we use a similar solution with k=1. We achieved 3rd place in Task A (2nd among all teams), 4th place in Task B Division Wise Summarization (2nd among all teams), 15th place in Task A Section Header Classification (9th among all teams), and 8th place among all teams in Task B. Our results highlight the effectiveness of few-shot prompting for this task, though we also identify several weaknesses of prompting-based approaches. We compare GPT-4 performance with several finetuned baselines. We find that GPT-4 summaries are more abstractive and shorter. We make our code publicly available.",Clinical Natural Language Processing Workshop,2023,48,4,1,True,"{'url': 'http://arxiv.org/pdf/2306.17384', 'status': None}",['Computer Science'],{'pages': '490-502'},"[{'authorId': '2003826361', 'name': 'Yash Mathur'}, {'authorId': '2031481495', 'name': 'Sanketh Rangreji'}, {'authorId': '32536265', 'name': 'Raghav Kapoor'}, {'authorId': '2220962946', 'name': 'Medha Palavalli'}, {'authorId': '2138301112', 'name': 'Amanda Bertsch'}, {'authorId': '1762110', 'name': 'Matthew R. Gormley'}]","This work presents a novel system for the Dialogue2Note Medical Summarization tasks in the MEDIQA 2023 Shared Task, and highlights the effectiveness of few-shot prompting for this task, though it also identifies several weaknesses of prompting-based approaches."
Matthias Grabmair,2869551,Matthias Grabmair,https://www.semanticscholar.org/author/2869551,13,[],38,464,1109a51ff68d8c7a09d651d706028e9e380f2af8,"{'DBLP': 'journals/corr/abs-2302-06448', 'ArXiv': '2302.06448', 'DOI': '10.48550/arXiv.2302.06448', 'CorpusId': 256826724}",https://www.semanticscholar.org/paper/1109a51ff68d8c7a09d651d706028e9e380f2af8,Joint Span Segmentation and Rhetorical Role Labeling with Data Augmentation for Legal Documents,"Segmentation and Rhetorical Role Labeling of legal judgements play a crucial role in retrieval and adjacent tasks, including case summarization, semantic search, argument mining etc. Previous approaches have formulated this task either as independent classification or sequence labeling of sentences. In this work, we reformulate the task at span level as identifying spans of multiple consecutive sentences that share the same rhetorical role label to be assigned via classification. We employ semi-Markov Conditional Random Fields (CRF) to jointly learn span segmentation and span label assignment. We further explore three data augmentation strategies to mitigate the data scarcity in the specialized domain of law where individual documents tend to be very long and annotation cost is high. Our experiments demonstrate improvement of span-level prediction metrics with a semi-Markov CRF model over a CRF baseline. This benefit is contingent on the presence of multi sentence spans in the document.",European Conference on Information Retrieval,2023,33,1,0,True,"{'url': 'http://arxiv.org/pdf/2302.06448', 'status': None}",['Computer Science'],{'pages': '627-636'},"[{'authorId': '134765210', 'name': 'Santosh T.Y.S.S'}, {'authorId': '2205540369', 'name': 'Philipp Bock'}, {'authorId': '2869551', 'name': 'Matthias Grabmair'}]","This work reformulates the task at span level as identifying spans of multiple consecutive sentences that share the same rhetorical role label to be assigned via classification, and employs semi-Markov Conditional Random Fields (CRF) to jointly learn span segmentation and span label assignment."
Matthias Grabmair,2869551,Matthias Grabmair,https://www.semanticscholar.org/author/2869551,13,[],38,464,5315883bd39a4e4af6332e344bb32d29613b3c97,"{'ACL': '2023.findings-eacl.44', 'DBLP': 'journals/corr/abs-2302-00609', 'ArXiv': '2302.00609', 'DOI': '10.48550/arXiv.2302.00609', 'CorpusId': 256826728}",https://www.semanticscholar.org/paper/5315883bd39a4e4af6332e344bb32d29613b3c97,Zero-shot Transfer of Article-aware Legal Outcome Classification for European Court of Human Rights Cases,"In this paper, we cast Legal Judgment Prediction on European Court of Human Rights cases into an article-aware classification task, where the case outcome is classified from a combined input of case facts and convention articles. This configuration facilitates the model learning some legal reasoning ability in mapping article text to specific case fact text. It also provides an opportunity to evaluate the model’s ability to generalize to zero-shot settings when asked to classify the case outcome with respect to articles not seen during training. We devise zero-shot experiments and apply domain adaptation methods based on domain discrimination and Wasserstein distance. Our results demonstrate that the article-aware architecture outperforms straightforward fact classification. We also find that domain adaptation methods improve zero-shot transfer performance, with article relatedness and encoder pre-training influencing the effect.",Findings,2023,71,5,0,True,"{'url': 'http://arxiv.org/pdf/2302.00609', 'status': None}",['Computer Science'],{'pages': '593-605'},"[{'authorId': '134765210', 'name': 'Santosh T.Y.S.S'}, {'authorId': '9458728', 'name': 'O. Ichim'}, {'authorId': '2869551', 'name': 'Matthias Grabmair'}]","This paper casts Legal Judgment Prediction on European Court of Human Rights cases into an article-aware classification task, where the case outcome is classified from a combined input of case facts and convention articles, and finds that domain adaptation methods improve zero-shot transfer performance."
Matthias Grabmair,2869551,Matthias Grabmair,https://www.semanticscholar.org/author/2869551,13,[],38,464,ff28f812113a7082f7d285ed3bf6dcbed49d0320,"{'ACL': '2023.eacl-main.78', 'DBLP': 'journals/corr/abs-2302-00768', 'ArXiv': '2302.00768', 'DOI': '10.48550/arXiv.2302.00768', 'CorpusId': 256503823}",https://www.semanticscholar.org/paper/ff28f812113a7082f7d285ed3bf6dcbed49d0320,Leveraging Task Dependency and Contrastive Learning for Case Outcome Classification on European Court of Human Rights Cases,"We report on an experiment in case outcome classification on European Court of Human Rights cases where our model first learns to identify the convention articles allegedly violated by the state from case facts descriptions, and subsequently uses that information to classify whether the court finds a violation of those articles. We assess the dependency between these two tasks at the feature and outcome level. Furthermore, we leverage a hierarchical contrastive loss to pull together article-specific representations of cases at the higher level, leading to distinctive article clusters. The cases in each article cluster are further pulled closer based on their outcome, leading to sub-clusters of cases with similar outcomes. Our experiment results demonstrate that, given a static pre-trained encoder, our models produce a small but consistent improvement in classification performance over single-task and joint models without contrastive loss.",Conference of the European Chapter of the Association for Computational Linguistics,2023,49,4,0,True,"{'url': 'http://arxiv.org/pdf/2302.00768', 'status': None}",['Computer Science'],"{'volume': 'abs/2302.00768', 'name': 'ArXiv'}","[{'authorId': '2203911024', 'name': 'Santosh T.Y.S.S'}, {'authorId': '134765210', 'name': 'Santosh T.Y.S.S'}, {'authorId': '2203912234', 'name': 'Phillip Kemper'}, {'authorId': '2869551', 'name': 'Matthias Grabmair'}]",
Mona Diab,1700007,Mona T. Diab,https://www.semanticscholar.org/author/1700007,50,[],228,12703,45f7ab2dd1bd86703f3fc0f713d35851ae15b038,"{'DBLP': 'journals/air/BashirANZDAQ23', 'DOI': '10.1007/s10462-023-10390-x', 'CorpusId': 257752011}",https://www.semanticscholar.org/paper/45f7ab2dd1bd86703f3fc0f713d35851ae15b038,Author Correction: Arabic natural language processing for Qur’anic research: a systematic review,,Artificial Intelligence Review,2023,0,0,0,True,"{'url': 'https://link.springer.com/content/pdf/10.1007/s10462-023-10390-x.pdf', 'status': None}",['Computer Science'],"{'volume': '56', 'pages': '13951-13952', 'name': 'Artificial Intelligence Review'}","[{'authorId': '2140200074', 'name': 'M. Bashir'}, {'authorId': '2569677', 'name': 'Aqil M. Azmi'}, {'authorId': '2074413963', 'name': 'H. Nawaz'}, {'authorId': '2034351', 'name': 'W. Zaghouani'}, {'authorId': '1700007', 'name': 'Mona T. Diab'}, {'authorId': '1404786833', 'name': 'Ala I. Al-Fuqaha'}, {'authorId': '1734917', 'name': 'Junaid Qadir'}]",TLDR not found
Mona Diab,1700007,Mona T. Diab,https://www.semanticscholar.org/author/1700007,50,[],228,12703,c5849f406e8263806a84e1a407ec0e0fe131bd5c,"{'DBLP': 'conf/iwslt/SaleskyDADN23', 'ACL': '2023.iwslt-1.2', 'DOI': '10.18653/v1/2023.iwslt-1.2', 'CorpusId': 259376542}",https://www.semanticscholar.org/paper/c5849f406e8263806a84e1a407ec0e0fe131bd5c,Evaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology,"We present the ACL 60/60 evaluation sets for multilingual translation of ACL 2022 technical presentations into 10 target languages. This dataset enables further research into multilingual speech translation under realistic recording conditions with unsegmented audio and domain-specific terminology, applying NLP tools to text and speech in the technical domain, and evaluating and improving model robustness to diverse speaker demographics.",International Workshop on Spoken Language Translation,2023,43,7,0,True,"{'url': 'https://aclanthology.org/2023.iwslt-1.2.pdf', 'status': None}",['Computer Science'],{'pages': '62-78'},"[{'authorId': '3448427', 'name': 'Elizabeth Salesky'}, {'authorId': '143758717', 'name': 'Kareem Darwish'}, {'authorId': '1403096563', 'name': 'Mohamed Al-Badrashiny'}, {'authorId': '1700007', 'name': 'Mona T. Diab'}, {'authorId': '2920247', 'name': 'J. Niehues'}]","This dataset enables further research into multilingual speech translation under realistic recording conditions with unsegmented audio and domain-specific terminology, applying NLP tools to text and speech in the technical domain, and evaluating and improving model robustness to diverse speaker demographics."
Mona Diab,2138579860,Mona T. Diab,https://www.semanticscholar.org/author/2138579860,10,[],23,2128,0a94fbb5e1c93513523f00e75d672ef4553861f9,"{'DBLP': 'journals/corr/abs-2306-05836', 'ArXiv': '2306.05836', 'DOI': '10.48550/arXiv.2306.05836', 'CorpusId': 259129342}",https://www.semanticscholar.org/paper/0a94fbb5e1c93513523f00e75d672ef4553861f9,Can Large Language Models Infer Causation from Correlation?,"Causal inference is one of the hallmarks of human intelligence. While the field of CausalNLP has attracted much interest in the recent years, existing causal inference datasets in NLP primarily rely on discovering causality from empirical knowledge (e.g., commonsense knowledge). In this work, we propose the first benchmark dataset to test the pure causal inference skills of large language models (LLMs). Specifically, we formulate a novel task Corr2Cause, which takes a set of correlational statements and determines the causal relationship between the variables. We curate a large-scale dataset of more than 200K samples, on which we evaluate seventeen existing LLMs. Through our experiments, we identify a key shortcoming of LLMs in terms of their causal inference skills, and show that these models achieve almost close to random performance on the task. This shortcoming is somewhat mitigated when we try to re-purpose LLMs for this skill via finetuning, but we find that these models still fail to generalize -- they can only perform causal inference in in-distribution settings when variable names and textual expressions used in the queries are similar to those in the training set, but fail in out-of-distribution settings generated by perturbing these queries. Corr2Cause is a challenging task for LLMs, and would be helpful in guiding future research on improving LLMs' pure reasoning skills and generalizability. Our data is at https://huggingface.co/datasets/causalnlp/corr2cause. Our code is at https://github.com/causalNLP/corr2cause.",arXiv.org,2023,49,27,1,True,"{'url': 'http://arxiv.org/pdf/2306.05836', 'status': None}",['Computer Science'],"{'volume': 'abs/2306.05836', 'name': 'ArXiv'}","[{'authorId': '2111472502', 'name': 'Zhijing Jin'}, {'authorId': '146961917', 'name': 'Jiarui Liu'}, {'authorId': '2114227440', 'name': 'Zhiheng Lyu'}, {'authorId': '1753626755', 'name': 'Spencer Poff'}, {'authorId': '2790926', 'name': 'Mrinmaya Sachan'}, {'authorId': '2105984203', 'name': 'Rada Mihalcea'}, {'authorId': '2138579860', 'name': 'Mona T. Diab'}, {'authorId': '1707625', 'name': 'B. Scholkopf'}]","This work proposes the first benchmark dataset to test the pure causal inference skills of large language models (LLMs), and formulates a novel task Corr2Cause, which takes a set of correlational statements and determines the causal relationship between the variables."
Mona Diab,2138579860,Mona T. Diab,https://www.semanticscholar.org/author/2138579860,10,[],23,2128,4286d07449447f3bfffc1eeb2ee0de9b00dfadfd,"{'DBLP': 'conf/acl/YuWGAVJGDC23', 'DOI': '10.18653/v1/2023.acl-long.60', 'CorpusId': 259370626}",https://www.semanticscholar.org/paper/4286d07449447f3bfffc1eeb2ee0de9b00dfadfd,ALERT: Adapt Language Models to Reasoning Tasks,,Annual Meeting of the Association for Computational Linguistics,2023,0,0,0,True,"{'url': 'https://aclanthology.org/2023.acl-long.60.pdf', 'status': None}",['Computer Science'],{'pages': '1055-1081'},"[{'authorId': '2114104308', 'name': 'Ping Yu'}, {'authorId': '1785372925', 'name': 'Tianlu Wang'}, {'authorId': '100664938', 'name': 'O. Yu. Golovneva'}, {'authorId': '2006905770', 'name': 'Badr AlKhamissi'}, {'authorId': '1799945508', 'name': 'Siddharth Verma'}, {'authorId': '2111472502', 'name': 'Zhijing Jin'}, {'authorId': '134007132', 'name': 'Gargi Ghosh'}, {'authorId': '2138579860', 'name': 'Mona T. Diab'}, {'authorId': '1709797', 'name': 'Asli Celikyilmaz'}]","The extensive empirical analysis shows that language models learn more reasoning skills such as textual entailment, abductive reasoning, and analogical reasoning during the finetuning stage compared to pretraining stage, but also finds that when language models are finetuned they tend to overfit to the prompt template, which hurts the robustness of models causing generalization problems."
Mona Diab,2138579860,Mona T. Diab,https://www.semanticscholar.org/author/2138579860,10,[],23,2128,5e2f8088647e357bb6440d271ed1fcc4d5ed7e7c,"{'ACL': '2023.clinicalnlp-1.55', 'DBLP': 'conf/acl-clinicalnlp/AlQahtaniSDY23', 'DOI': '10.18653/v1/2023.clinicalnlp-1.55', 'CorpusId': 259833895}",https://www.semanticscholar.org/paper/5e2f8088647e357bb6440d271ed1fcc4d5ed7e7c,Care4Lang at MEDIQA-Chat 2023: Fine-tuning Language Models for Classifying and Summarizing Clinical Dialogues,"Summarizing medical conversations is one of the tasks proposed by MEDIQA-Chat to promote research on automatic clinical note generation from doctor-patient conversations. In this paper, we present our submission to this task using fine-tuned language models, including T5, BART and BioGPT models. The fine-tuned models are evaluated using ensemble metrics including ROUGE, BERTScore andBLEURT. Among the fine-tuned models, Flan-T5 achieved the highest aggregated score for dialogue summarization.",Clinical Natural Language Processing Workshop,2023,18,1,0,True,"{'url': 'https://aclanthology.org/2023.clinicalnlp-1.55.pdf', 'status': None}",['Computer Science'],{'pages': '524-528'},"[{'authorId': '2057134736', 'name': 'Amal AlQahtani'}, {'authorId': '66799313', 'name': 'R. Salama'}, {'authorId': '2138579860', 'name': 'Mona T. Diab'}, {'authorId': '145555732', 'name': 'Abdou Youssef'}]","This paper presents their submission to this task using fine-tuned language models, including T5, BART and BioGPT models, and finds Flan-T5 achieved the highest aggregated score for dialogue summarization."
Mona Diab,2138579860,Mona T. Diab,https://www.semanticscholar.org/author/2138579860,10,[],23,2128,99bfe503743c5ec8e16e50ab8438159cdb533a89,"{'DBLP': 'journals/corr/abs-2310-04988', 'ArXiv': '2310.04988', 'DOI': '10.48550/arXiv.2310.04988', 'CorpusId': 263831293}",https://www.semanticscholar.org/paper/99bfe503743c5ec8e16e50ab8438159cdb533a89,"The Troubling Emergence of Hallucination in Large Language Models - An Extensive Definition, Quantification, and Prescriptive Remediations","The recent advancements in Large Language Models (LLMs) have garnered widespread acclaim for their remarkable emerging capabilities. However, the issue of hallucination has parallelly emerged as a by-product, posing significant concerns. While some recent endeavors have been made to identify and mitigate different types of hallucination, there has been a limited emphasis on the nuanced categorization of hallucination and associated mitigation methods. To address this gap, we offer a fine-grained discourse on profiling hallucination based on its degree, orientation, and category, along with offering strategies for alleviation. As such, we define two overarching orientations of hallucination: (i) factual mirage (FM) and (ii) silver lining (SL). To provide a more comprehensive understanding, both orientations are further sub-categorized into intrinsic and extrinsic, with three degrees of severity - (i) mild, (ii) moderate, and (iii) alarming. We also meticulously categorize hallucination into six types: (i) acronym ambiguity, (ii) numeric nuisance, (iii) generated golem, (iv) virtual voice, (v) geographic erratum, and (vi) time wrap. Furthermore, we curate HallucInation eLiciTation (HILT), a publicly available dataset comprising of 75,000 samples generated using 15 contemporary LLMs along with human annotations for the aforementioned categories. Finally, to establish a method for quantifying and to offer a comparative spectrum that allows us to evaluate and rank LLMs based on their vulnerability to producing hallucinations, we propose Hallucination Vulnerability Index (HVI). We firmly believe that HVI holds significant value as a tool for the wider NLP community, with the potential to serve as a rubric in AI-related policy-making. In conclusion, we propose two solution strategies for mitigating hallucinations.",Conference on Empirical Methods in Natural Language Processing,2023,59,19,2,True,"{'url': 'https://arxiv.org/pdf/2310.04988', 'status': None}",['Computer Science'],{'pages': '2541-2573'},"[{'authorId': '9460529', 'name': 'Vipula Rawte'}, {'authorId': '2257001500', 'name': 'Swagata Chakraborty'}, {'authorId': '2257001966', 'name': 'Agnibh Pathak'}, {'authorId': '2189479826', 'name': 'Anubhav Sarkar'}, {'authorId': '2103483687', 'name': 'S.M. Towhidul Islam Tonmoy'}, {'authorId': '2229651428', 'name': 'Islam Tonmoy'}, {'authorId': '40016108', 'name': 'Aman Chadha'}, {'authorId': '2064342742', 'name': 'Amit P. Sheth'}, {'authorId': '2258322706', 'name': 'Amitava Das'}, {'authorId': '2076602721', 'name': 'Paris'}, {'authorId': '2064327462', 'name': 'A. Sridhar'}, {'authorId': '2238206449', 'name': 'Erik Visser'}, {'authorId': '2257006156', 'name': 'Improved'}, {'authorId': '2258099188', 'name': 'Jianlin Su'}, {'authorId': '2257339854', 'name': 'Yu Lu'}, {'authorId': '1382633722', 'name': 'Shengfeng Pan'}, {'authorId': '2159557286', 'name': 'Ahmed Murtadha'}, {'authorId': '2079396269', 'name': 'Bo Wen'}, {'authorId': '2257345549', 'name': 'Yunfeng Liu'}, {'authorId': '2257006862', 'name': 'Roformer'}, {'authorId': '46199305', 'name': 'Rohan Taori'}, {'authorId': '2708454', 'name': 'Ishaan Gulrajani'}, {'authorId': '2256233130', 'name': 'Tianyi Zhang'}, {'authorId': '2257007362', 'name': 'Yann Dubois'}, {'authorId': '2250724754', 'name': 'Xuechen Li'}, {'authorId': '1412355294', 'name': 'Carlos Guestrin'}, {'authorId': '2256995425', 'name': 'Percy Liang'}, {'authorId': '2117567142', 'name': 'Tatsunori Hashimoto'}, {'authorId': '2250092519', 'name': 'Stanford'}, {'authorId': '2113243762', 'name': 'Hugo Touvron'}, {'authorId': '46183616', 'name': 'Thibaut Lavril'}, {'authorId': '1410231361', 'name': 'Gautier Izacard'}, {'authorId': '1490887583', 'name': 'Xavier Martinet'}, {'authorId': '114952298', 'name': 'Marie-Anne Lachaux'}, {'authorId': '47733973', 'name': 'Timothée Lacroix'}, {'authorId': '3361236', 'name': 'Baptiste Rozière'}, {'authorId': '39589154', 'name': 'Naman Goyal'}, {'authorId': '2072738644', 'name': 'Eric Hambro'}, {'authorId': '2209986197', 'name': 'Faisal Azhar'}, {'authorId': '2166043087', 'name': 'Aurelien Rodriguez'}, {'authorId': '2319608', 'name': 'Armand Joulin'}, {'authorId': '2257007291', 'name': 'Thomas Wolf'}, {'authorId': '1380459402', 'name': 'Lysandre Debut'}, {'authorId': '51918868', 'name': 'Victor Sanh'}, {'authorId': '40811585', 'name': 'Julien Chaumond'}, {'authorId': '40899333', 'name': 'Clement Delangue'}, {'authorId': '1382164294', 'name': 'Anthony Moi'}, {'authorId': '1382164165', 'name': 'Pierric Cistac'}, {'authorId': '1382164170', 'name': 'Tim Rault'}, {'authorId': '2185329', 'name': 'Rémi Louf'}, {'authorId': '2257005341', 'name': 'Morgan Funtow-icz'}, {'authorId': '48776237', 'name': 'Joe Davison'}, {'authorId': '88728159', 'name': 'Sam Shleifer'}, {'authorId': '138609838', 'name': 'Patrick von Platen'}, {'authorId': '2257128341', 'name': 'Clara Ma'}, {'authorId': '2262249', 'name': 'Yacine Jernite'}, {'authorId': '3008389', 'name': 'Julien Plu'}, {'authorId': '2257127518', 'name': 'Canwen Xu'}, {'authorId': '1379806208', 'name': 'Teven Le Scao'}, {'authorId': '103682620', 'name': 'Sylvain Gugger'}, {'authorId': '2125818054', 'name': 'Mariama Drame'}, {'authorId': '2113836945', 'name': 'Quentin Lhoest'}, {'authorId': '2238121623', 'name': 'Susan Zhang'}, {'authorId': '3849208', 'name': 'Stephen Roller'}, {'authorId': '2347956', 'name': 'Mikel Artetxe'}, {'authorId': '2108267192', 'name': 'Moya Chen'}, {'authorId': '2257570528', 'name': 'Shuohui Chen'}, {'authorId': '2257006163', 'name': 'Christopher De-wan'}, {'authorId': '2138579860', 'name': 'Mona T. Diab'}, {'authorId': '2257006892', 'name': 'Xi Xian Li'}, {'authorId': '2257007395', 'name': 'Todor Victoria Lin'}, {'authorId': '40511414', 'name': 'Myle Ott'}, {'authorId': '35752280', 'name': 'Kurt Shuster'}, {'authorId': '2257006894', 'name': 'Punit Daniel Simig'}, {'authorId': '2257006866', 'name': 'Singh Koura'}, {'authorId': '2257007723', 'name': 'Anjali Sridhar'}, {'authorId': '2238056517', 'name': 'Tianlu Wang'}, {'authorId': '2257007614', 'name': 'Luke Zettlemoyer. 2022'}, {'authorId': '2052152920', 'name': 'Daniel M. Ziegler'}, {'authorId': '1387983862', 'name': 'Nisan Stiennon'}, {'authorId': '2257137166', 'name': 'Jeffrey Wu'}, {'authorId': '2257135738', 'name': 'Tom Brown'}, {'authorId': '38909097', 'name': 'Alec Radford'}, {'authorId': '2698777', 'name': 'Dario Amodei'}, {'authorId': '2257006890', 'name': 'Paul F. Chris-tiano'}]","This work defines two overarching orientations of hallucination and proposes two solution strategies for mitigating hallucinations, and firmly believes that HVI holds significant value as a tool for the wider NLP community, with the potential to serve as a rubric in AI-related policy-making."
Mona Diab,2138579860,Mona T. Diab,https://www.semanticscholar.org/author/2138579860,10,[],23,2128,c218cd1772999517b137bbbc9872c4f67e540b7f,"{'DBLP': 'journals/corr/abs-2305-12001', 'ACL': '2023.nlrse-1.10', 'ArXiv': '2305.12001', 'DOI': '10.18653/v1/2023.nlrse-1.10', 'CorpusId': 258832540}",https://www.semanticscholar.org/paper/c218cd1772999517b137bbbc9872c4f67e540b7f,OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models,"We conduct a thorough investigation into the reasoning capabilities of Large Language Models (LLMs), focusing specifically on the Open Pretrained Transformers (OPT) models as a representative of such models. Our study entails finetuning three different sizes of OPT on a carefully curated reasoning corpus, resulting in two sets of finetuned models: OPT-R, finetuned without explanations, and OPT-RE, finetuned with explanations. We then evaluate all models on 57 out-of-domain tasks drawn from the Super-NaturalInstructions benchmark, covering 26 distinct reasoning skills, utilizing three prompting techniques. Through a comprehensive grid of 27 configurations and 6,156 test evaluations, we investigate the dimensions of finetuning, prompting, and scale to understand the role of explanations on different reasoning skills. Our findings reveal that having explanations in the fewshot exemplar has no significant impact on the model’s performance when the model is finetuned, while positively affecting the non-finetuned counterpart. Moreover, we observe a slight yet consistent increase in classification accuracy as we incorporate explanations during prompting and finetuning, respectively. Finally, we offer insights on which reasoning skills benefit the most from incorporating explanations during finetuning and prompting, such as Numerical (+20.4%) and Analogical (+13.9%) reasoning, as well as skills that exhibit negligible or negative effects.",NLRSE,2023,28,2,0,True,"{'url': 'https://aclanthology.org/2023.nlrse-1.10.pdf', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.12001', 'name': 'ArXiv'}","[{'authorId': '2006905770', 'name': 'Badr AlKhamissi'}, {'authorId': '1799945508', 'name': 'Siddharth Verma'}, {'authorId': '2114104308', 'name': 'Ping Yu'}, {'authorId': '2111472502', 'name': 'Zhijing Jin'}, {'authorId': '1709797', 'name': 'Asli Celikyilmaz'}, {'authorId': '2138579860', 'name': 'Mona T. Diab'}]","It is revealed that having explanations in the fewshot exemplar has no significant impact on the model’s performance when the model is finetuned, while positively affecting the non-finetuned counterpart, and a slight yet consistent increase in classification accuracy as the authors incorporate explanations during prompting and finetuning."
Mona Diab,2138579860,Mona T. Diab,https://www.semanticscholar.org/author/2138579860,10,[],23,2128,f727f928e7e179307d8d4a1da2387393f2bd7915,"{'ACL': '2023.eacl-main.199', 'DBLP': 'conf/eacl/HaseDCLKSBI23', 'DOI': '10.18653/v1/2023.eacl-main.199', 'CorpusId': 258378150}",https://www.semanticscholar.org/paper/f727f928e7e179307d8d4a1da2387393f2bd7915,"Methods for Measuring, Updating, and Visualizing Factual Beliefs in Language Models","Language models can memorize a considerable amount of factual information during pretraining that can be elicited through prompting or finetuning models on tasks like question answering. In this paper, we discuss approaches to measuring model factual beliefs, updating incorrect factual beliefs in models, and visualizing graphical relationships between factual beliefs. Our main contributions include: (1) new metrics for evaluating belief-updating methods focusing on the logical consistency of beliefs, (2) a training objective for Sequential, Local, and Generalizing updates (SLAG) that improves the performance of existing hypernetwork approaches, and (3) the introduction of the belief graph, a new form of visualization for language models that shows relationships between stored model beliefs. Our experiments suggest that models show only limited consistency between factual beliefs, but update methods can both fix incorrect model beliefs and greatly improve their consistency. Although off-the-shelf optimizers are surprisingly strong belief-updating baselines, our learned optimizers can outperform them in more difficult settings than have been considered in past work.",Conference of the European Chapter of the Association for Computational Linguistics,2023,30,26,1,True,"{'url': 'https://aclanthology.org/2023.eacl-main.199.pdf', 'status': None}",['Computer Science'],{'pages': '2706-2723'},"[{'authorId': '144625004', 'name': 'Peter Hase'}, {'authorId': '2138579860', 'name': 'Mona T. Diab'}, {'authorId': '1709797', 'name': 'Asli Celikyilmaz'}, {'authorId': '2116235416', 'name': 'Xian Li'}, {'authorId': '1714932', 'name': 'Zornitsa Kozareva'}, {'authorId': '1759422', 'name': 'Veselin Stoyanov'}, {'authorId': '143977268', 'name': 'Mohit Bansal'}, {'authorId': '1900163', 'name': 'Srini Iyer'}]","The experiments suggest that models show only limited consistency between factual beliefs, but update methods can both fix incorrect model beliefs and greatly improve their consistency, and off-the-shelf optimizers can outperform them in more difficult settings than have been considered in past work."
Norman Sadeh,2464164,N. Sadeh,https://www.semanticscholar.org/author/2464164,68,[],262,17165,3c6d1884d5f15577b76356a3f1e7da6ffba6e2bd,"{'DOI': '10.14722/usec.2023.232482', 'CorpusId': 257493011}",https://www.semanticscholar.org/paper/3c6d1884d5f15577b76356a3f1e7da6ffba6e2bd,Do Privacy Labels Answer Users' Privacy Questions?,"—Inspired by earlier academic research, iOS app privacy labels and the recent Google Play data safety labels have been introduced as a way to systematically present users with concise summaries of an app’s data practices. Yet, little research has been conducted to deter- mine how well today’s mobile app privacy labels address people’s actual privacy concerns or questions. We analyze a crowd-sourced corpus of privacy questions collected from mobile app users to determine to what extent these mobile app labels actually address users’ privacy concerns and questions. While there are differences between iOS labels and Google Play labels, our results indicate that an important percentage of people’s privacy questions are not answered or only partially addressed in today’s labels. Findings from this work not only shed light on the additional fields that would need to be included in mobile app privacy labels but can also help inform refinements to existing labels to better address users’ typical privacy questions",Proceedings 2023 Symposium on Usable Security,2023,28,4,0,True,,,{'name': 'Proceedings 2023 Symposium on Usable Security'},"[{'authorId': '2145402827', 'name': 'Shikun Zhang'}, {'authorId': '2464164', 'name': 'N. Sadeh'}]",A crowd-sourced corpus of privacy questions collected from mobile app users is analyzed to determine to what extent these mobile app labels actually address users’ privacy concerns and questions.
Norman Sadeh,2464164,N. Sadeh,https://www.semanticscholar.org/author/2464164,68,[],262,17165,3f165dae2310a5d8aa7294ffdc45573a51c957b8,"{'DBLP': 'conf/eurosp/LeWYFHST23', 'ArXiv': '2303.04955', 'DOI': '10.1109/EuroSP57164.2023.00064', 'CorpusId': 257427579}",https://www.semanticscholar.org/paper/3f165dae2310a5d8aa7294ffdc45573a51c957b8,Exploring Smart Commercial Building Occupants’ Perceptions and Notification Preferences of Internet of Things Data Collection in the United States,"Data collection through the Internet of Things (IoT) devices, or smart devices, in commercial buildings enables possibilities for increased convenience and energy efficiency. However, such benefits face a large perceptual challenge when being implemented in practice, due to the different ways occupants working in the buildings understand and trust in the data collection. The semi-public, pervasive, and multi-modal nature of data collection in smart buildings points to the need to study occupants’ understanding of data collection and notification preferences. We conduct an online study with 492 participants in the US who report working in smart commercial buildings regarding: 1) awareness and perception of data collection in smart commercial buildings, 2) privacy notification preferences, and 3) potential factors for privacy notification preferences. We find that around half of the participants are not fully aware of the data collection and use practices of IoT even though they notice the presence of IoT devices and sensors. We also discover many misunderstandings around different data practices. The majority of participants want to be notified of data practices in smart buildings, and they prefer push notifications to passive ones such as websites or physical signs. Surprisingly, mobile app notification, despite being a popular channel for smart homes, is the least preferred method for smart commercial buildings.",European Symposium on Security and Privacy,2023,58,1,0,True,"{'url': 'https://arxiv.org/pdf/2303.04955', 'status': None}",['Computer Science'],"{'pages': '1030-1046', 'name': '2023 IEEE 8th European Symposium on Security and Privacy (EuroS&P)'}","[{'authorId': '143977071', 'name': 'Tu Le'}, {'authorId': '2115766531', 'name': 'Alan Wang'}, {'authorId': '2170740', 'name': 'Yaxing Yao'}, {'authorId': '144334587', 'name': 'Yuanyuan Feng'}, {'authorId': '1981752', 'name': 'Arsalan Heydarian'}, {'authorId': '2464164', 'name': 'N. Sadeh'}, {'authorId': '2152947811', 'name': 'Yuan Tian'}]",It is found that around half of the participants are not fully aware of the data collection and use practices of IoT even though they notice the presence of IoT devices and sensors.
Norman Sadeh,2464164,N. Sadeh,https://www.semanticscholar.org/author/2464164,68,[],262,17165,88efd1663016c4170674c8f30067e7096b172598,"{'DBLP': 'conf/eurosp/RodriguezJAS23', 'DOI': '10.1109/EuroSPW59978.2023.00022', 'CorpusId': 260388094}",https://www.semanticscholar.org/paper/88efd1663016c4170674c8f30067e7096b172598,Comparing Privacy Label Disclosures of Apps Published in both the App Store and Google Play Stores,"Apple and Android introduced privacy labels in 2020 and 2022 respectively as a way of providing consumers with succinct summaries of mobile apps’ more salient data practices. A number of apps are published in both stores, offering us the opportunity to compare their privacy label disclosures in the two app stores. This paper compares the data practices privacy labels are intended to capture in each store. It then proceeds to analyze the disclosures of 822 apps published in both app stores, focusing on possible discrepancies. This analysis reveals that privacy label disclosures of what is ostensibly the same mobile app can be quite different. We discuss the different possible reasons behind these differences, including the possibility that these discrepancies might be indicative of potential privacy compliance issues. In particular, focusing on data collection disclosures of five different data types (location, contact info, sensitive info, identifiers, and health & fitness) we find discrepancies between iOS and Google Play privacy label disclosures in 66.5% of the mobile apps we analyze.",2023 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW),2023,26,2,0,True,"{'url': 'https://oa.upm.es/75608/1/Final_Submission_Article.pdf', 'status': None}",['Computer Science'],"{'pages': '150-157', 'name': '2023 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW)'}","[{'authorId': '2224735075', 'name': 'David Rodriguez'}, {'authorId': '2110511801', 'name': 'Akshatha Jain'}, {'authorId': '2015658', 'name': 'J. D. Álamo'}, {'authorId': '2464164', 'name': 'N. Sadeh'}]","It is revealed that privacy label disclosures of what is ostensibly the same mobile app can be quite different, including the possibility that these discrepancies might be indicative of potential privacy compliance issues."
Norman Sadeh,2464164,N. Sadeh,https://www.semanticscholar.org/author/2464164,68,[],262,17165,d07e77f0477c3568d64086ef4d50ea1fcff63b8c,"{'ArXiv': '2306.09247', 'DBLP': 'journals/corr/abs-2306-09247', 'DOI': '10.1109/EuroSPW59978.2023.00016', 'CorpusId': 259164851}",https://www.semanticscholar.org/paper/d07e77f0477c3568d64086ef4d50ea1fcff63b8c,ATLAS: Automatically Detecting Discrepancies Between Privacy Policies and Privacy Labels,"Privacy policies are long, complex documents that end-users seldom read. Privacy labels aim to ameliorate these issues by providing succinct summaries of salient data practices. In December 2020, Apple began requiring that app developers submit privacy labels describing their apps’ data practices. Yet, research suggests that app developers often struggle to do so. In this paper, we automatically identify possible discrepancies between mobile app privacy policies and their privacy labels. Such discrepancies could be indicators of potential privacy compliance issues. We introduce the Automated Privacy Label Analysis System (ATLAS). ATLAS includes three components: a pipeline to systematically retrieve iOS App Store listings and privacy policies; an ensemble-based classifier capable of predicting privacy labels from the text of privacy policies with 91.3% accuracy using state-of-the-art NLP techniques; and a discrepancy analysis mechanism that enables a large-scale privacy analysis of the iOS App Store. Our system has enabled us to analyze 354,725 iOS apps. We find several interesting trends. For example, only 40.3% of apps in the App Store provide easily accessible privacy policies, and only 29.6% of apps provide both accessible privacy policies and privacy labels. Among apps that provide both, 88.0% have at least one possible discrepancy between the text of their privacy policy and their privacy label, which could be indicative of a potential compliance issue. We find that, on average, apps have 5.32 such potential compliance issues. We hope that ATLAS will help app developers, researchers, regulators, and mobile app stores alike. For example, app developers could use our classifier to check for discrepancies between their privacy policies and privacy labels, and regulators could use our system to help review apps at scale for potential compliance issues.",2023 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW),2023,49,3,1,True,"{'url': 'https://figshare.com/articles/thesis/ATLAS_Automatically_Detecting_Discrepancies_Between_Privacy_Policies_and_Privacy_Labels/23502054/1/files/41219358.pdf', 'status': None}",['Computer Science'],"{'pages': '94-107', 'name': '2023 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW)'}","[{'authorId': '2110511801', 'name': 'Akshatha Jain'}, {'authorId': '2220351840', 'name': 'David Rodríguez Torrado'}, {'authorId': '2015658', 'name': 'J. D. Álamo'}, {'authorId': '2464164', 'name': 'N. Sadeh'}]","This paper automatically identifies possible discrepancies between mobile app privacy policies and their privacy labels, and finds that, on average, apps have 5.32 potential compliance issues."
Richard Stern,1697819,R. Stern,https://www.semanticscholar.org/author/1697819,45,[],294,8518,8b49ebfc2b436c8b064ecf5b1eb3c5a12fc8d4b8,"{'DBLP': 'conf/icassp/LindseyVS23', 'DOI': '10.1109/ICASSP49357.2023.10097194', 'CorpusId': 258541612}",https://www.semanticscholar.org/paper/8b49ebfc2b436c8b064ecf5b1eb3c5a12fc8d4b8,Unsupervised Voice Type Discrimination Score Adaptation Using X-Vector Clusters,"Voice type discrimination (VTD) is the task of automatically detecting speech produced in the same room as a recording device (""live speech"") among other speech and non-speech noises, such as traffic noises or radio broadcasts (""distractor audio""). Existing work has described methods for performing the VTD task. This paper presents a method for adapting the output of these existing methods in an unsupervised manner via x-vector clustering and correlation. This adaptation method can be applied to the output of any VTD algorithm, requires no additional training data, and has been shown to yield a relative decrease in decision cost function (DCF) score of up to 47% on a standardized database collected for the task.","IEEE International Conference on Acoustics, Speech, and Signal Processing",2023,22,0,0,True,,['Computer Science'],"{'pages': '1-5', 'name': 'ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)'}","[{'authorId': '145969426', 'name': 'Mark Lindsey'}, {'authorId': '144520009', 'name': 'Tyler Vuong'}, {'authorId': '1697819', 'name': 'R. Stern'}]","This adaptation method can be applied to the output of any VTD algorithm, requires no additional training data, and has been shown to yield a relative decrease in decision cost function (DCF) score of up to 47% on a standardized database collected for the task."
Rita Singh,153915824,Rita Singh,https://www.semanticscholar.org/author/153915824,25,[],146,2781,3bd320ddb25886417ae90011b00f13f5d558097b,"{'ArXiv': '2307.08217', 'DBLP': 'journals/corr/abs-2307-08217', 'DOI': '10.48550/arXiv.2307.08217', 'CorpusId': 259936797}",https://www.semanticscholar.org/paper/3bd320ddb25886417ae90011b00f13f5d558097b,BASS: Block-wise Adaptation for Speech Summarization,"End-to-end speech summarization has been shown to improve performance over cascade baselines. However, such models are difficult to train on very large inputs (dozens of minutes or hours) owing to compute restrictions and are hence trained with truncated model inputs. Truncation leads to poorer models, and a solution to this problem rests in block-wise modeling, i.e., processing a portion of the input frames at a time. In this paper, we develop a method that allows one to train summarization models on very long sequences in an incremental manner. Speech summarization is realized as a streaming process, where hypothesis summaries are updated every block based on new acoustic information. We devise and test strategies to pass semantic context across the blocks. Experiments on the How2 dataset demonstrate that the proposed block-wise training method improves by 3 points absolute on ROUGE-L over a truncated input baseline.",Interspeech,2023,28,1,0,True,"{'url': 'https://arxiv.org/pdf/2307.08217', 'status': None}","['Computer Science', 'Engineering']","{'volume': 'abs/2307.08217', 'name': 'ArXiv'}","[{'authorId': '145521253', 'name': 'Roshan Sharma'}, {'authorId': '2163585699', 'name': 'Kenneth Zheng'}, {'authorId': '72401599', 'name': 'Siddhant Arora'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '153915824', 'name': 'Rita Singh'}, {'authorId': '1681921', 'name': 'B. Raj'}]",This paper develops a method that allows one to train summarization models on very long sequences in an incremental manner and devise and test strategies to pass semantic context across the blocks.
Rita Singh,153915824,Rita Singh,https://www.semanticscholar.org/author/153915824,25,[],146,2781,5a3307b2e64bbcaff1202e261b8a83f7d03418a8,"{'ArXiv': '2307.13948', 'DBLP': 'journals/corr/abs-2307-13948', 'DOI': '10.1145/3581783.3611779', 'CorpusId': 260165102}",https://www.semanticscholar.org/paper/5a3307b2e64bbcaff1202e261b8a83f7d03418a8,Rethinking Voice-Face Correlation: A Geometry View,"Previous works on voice-face matching and voice-guided face synthesis demonstrate strong correlations between voice and face, but mainly rely on coarse semantic cues such as gender, age, and emotion. In this paper, we aim to investigate the capability of reconstructing the 3D facial shape from voice from a geometry perspective without any semantic information. We propose a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable facial AMs from the voice and uses them to guide 3D face reconstruction. By leveraging AMs as a proxy to link the voice and face geometry, we can eliminate the influence of unpredictable AMs and make the face geometry tractable. Our approach is evaluated on our proposed dataset with ground-truth 3D face scans and corresponding voice recordings, and we find significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium. Our work offers a new perspective on voice-face correlation and can serve as a good empirical study for anthropometry science.",ACM Multimedia,2023,56,1,0,True,"{'url': 'https://arxiv.org/pdf/2307.13948', 'status': None}","['Computer Science', 'Engineering']",{'name': 'Proceedings of the 31st ACM International Conference on Multimedia'},"[{'authorId': '2108280244', 'name': 'Xiang Li'}, {'authorId': '145357606', 'name': 'Yandong Wen'}, {'authorId': '72966973', 'name': 'Muqiao Yang'}, {'authorId': '2110107884', 'name': 'Jinglu Wang'}, {'authorId': '153915824', 'name': 'Rita Singh'}, {'authorId': '1681921', 'name': 'B. Raj'}]","This work proposes a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable facial AMs from the voice and uses them to guide 3D face reconstruction and finds significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium."
Rita Singh,153915824,Rita Singh,https://www.semanticscholar.org/author/153915824,25,[],146,2781,63a4150c9ad87c003de43b32828c8ceec6bb4468,"{'DBLP': 'journals/entropy/Singh23', 'PubMedCentral': '10297681', 'DOI': '10.3390/e25060897', 'CorpusId': 259269897, 'PubMed': '37372241'}",https://www.semanticscholar.org/paper/63a4150c9ad87c003de43b32828c8ceec6bb4468,A Gene-Based Algorithm for Identifying Factors That May Affect a Speaker’s Voice,"Over the past decades, many machine-learning- and artificial-intelligence-based technologies have been created to deduce biometric or bio-relevant parameters of speakers from their voice. These voice profiling technologies have targeted a wide range of parameters, from diseases to environmental factors, based largely on the fact that they are known to influence voice. Recently, some have also explored the prediction of parameters whose influence on voice is not easily observable through data-opportunistic biomarker discovery techniques. However, given the enormous range of factors that can possibly influence voice, more informed methods for selecting those that may be potentially deducible from voice are needed. To this end, this paper proposes a simple path-finding algorithm that attempts to find links between vocal characteristics and perturbing factors using cytogenetic and genomic data. The links represent reasonable selection criteria for use by computational by profiling technologies only, and are not intended to establish any unknown biological facts. The proposed algorithm is validated using a simple example from medical literature—that of the clinically observed effects of specific chromosomal microdeletion syndromes on the vocal characteristics of affected people. In this example, the algorithm attempts to link the genes involved in these syndromes to a single example gene (FOXP2) that is known to play a broad role in voice production. We show that in cases where strong links are exposed, vocal characteristics of the patients are indeed reported to be correspondingly affected. Validation experiments and subsequent analyses confirm that the methodology could be potentially useful in predicting the existence of vocal signatures in naïve cases where their existence has not been otherwise observed.",Entropy,2023,82,0,0,True,"{'url': 'https://www.mdpi.com/1099-4300/25/6/897/pdf?version=1685718244', 'status': None}","['Medicine', 'Computer Science']","{'volume': '25', 'name': 'Entropy'}","[{'authorId': '153915824', 'name': 'Rita Singh'}]","A simple path-finding algorithm that attempts to find links between vocal characteristics and perturbing factors using cytogenetic and genomic data and shows that in cases where strong links are exposed, vocal characteristics of the patients are indeed reported to be correspondingly affected."
Rita Singh,153915824,Rita Singh,https://www.semanticscholar.org/author/153915824,25,[],146,2781,721b39472c801124b5e3102edffe9d6f0754e1c2,"{'PubMedCentral': '10378572', 'DBLP': 'journals/entropy/ZhaoS23', 'DOI': '10.3390/e25071039', 'CorpusId': 259893099, 'PubMed': '37509986'}",https://www.semanticscholar.org/paper/721b39472c801124b5e3102edffe9d6f0754e1c2,Deriving Vocal Fold Oscillation Information from Recorded Voice Signals Using Models of Phonation,"During phonation, the vocal folds exhibit a self-sustained oscillatory motion, which is influenced by the physical properties of the speaker’s vocal folds and driven by the balance of bio-mechanical and aerodynamic forces across the glottis. Subtle changes in the speaker’s physical state can affect voice production and alter these oscillatory patterns. Measuring these can be valuable in developing computational tools that analyze voice to infer the speaker’s state. Traditionally, vocal fold oscillations (VFOs) are measured directly using physical devices in clinical settings. In this paper, we propose a novel analysis-by-synthesis approach that allows us to infer the VFOs directly from recorded speech signals on an individualized, speaker-by-speaker basis. The approach, called the ADLES-VFT algorithm, is proposed in the context of a joint model that combines a phonation model (with a glottal flow waveform as the output) and a vocal tract acoustic wave propagation model such that the output of the joint model is an estimated waveform. The ADLES-VFT algorithm is a forward-backward algorithm which minimizes the error between the recorded waveform and the output of this joint model to estimate its parameters. Once estimated, these parameter values are used in conjunction with a phonation model to obtain its solutions. Since the parameters correlate with the physical properties of the vocal folds of the speaker, model solutions obtained using them represent the individualized VFOs for each speaker. The approach is flexible and can be applied to various phonation models. In addition to presenting the methodology, we show how the VFOs can be quantified from a dynamical systems perspective for classification purposes. Mathematical derivations are provided in an appendix for better readability.",Entropy,2023,55,1,1,True,"{'url': 'https://www.mdpi.com/1099-4300/25/7/1039/pdf?version=1689132568', 'status': None}","['Computer Science', 'Medicine']","{'volume': '25', 'name': 'Entropy'}","[{'authorId': '2223487053', 'name': 'Wayne Zhao'}, {'authorId': '153915824', 'name': 'Rita Singh'}]","A novel analysis-by-synthesis approach that allows us to infer the VFOs directly from recorded speech signals on an individualized, speaker- by-speaker basis is proposed and it is shown how the V FOs can be quantified from a dynamical systems perspective for classification purposes."
Rita Singh,153915824,Rita Singh,https://www.semanticscholar.org/author/153915824,25,[],146,2781,8665c864d71df1e918d2010778fc06712f4e5550,"{'ArXiv': '2305.12715', 'DBLP': 'journals/corr/abs-2305-12715', 'DOI': '10.48550/arXiv.2305.12715', 'CorpusId': 258832327}",https://www.semanticscholar.org/paper/8665c864d71df1e918d2010778fc06712f4e5550,Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations,"Learning with reduced labeling standards, such as noisy label, partial label, and multiple label candidates, which we generically refer to as \textit{imprecise} labels, is a commonplace challenge in machine learning tasks. Previous methods tend to propose specific designs for every emerging imprecise label configuration, which is usually unsustainable when multiple configurations of imprecision coexist. In this paper, we introduce imprecise label learning (ILL), a framework for the unification of learning with various imprecise label configurations. ILL leverages expectation-maximization (EM) for modeling the imprecise label information, treating the precise labels as latent variables.Instead of approximating the correct labels for training, it considers the entire distribution of all possible labeling entailed by the imprecise information. We demonstrate that ILL can seamlessly adapt to partial label learning, semi-supervised learning, noisy label learning, and, more importantly, a mixture of these settings. Notably, ILL surpasses the existing specified techniques for handling imprecise labels, marking the first unified framework with robust and effective performance across various challenging settings. We hope our work will inspire further research on this topic, unleashing the full potential of ILL in wider scenarios where precise labels are expensive and complicated to obtain.",arXiv.org,2023,136,3,0,True,"{'url': 'https://arxiv.org/pdf/2305.12715', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.12715', 'name': 'ArXiv'}","[{'authorId': '2051536212', 'name': 'Hao Chen'}, {'authorId': '47287745', 'name': 'Ankit Shah'}, {'authorId': '1519290245', 'name': 'Jindong Wang'}, {'authorId': '26151496', 'name': 'R. Tao'}, {'authorId': '2108024273', 'name': 'Yidong Wang'}, {'authorId': '1576441343', 'name': 'Xingxu Xie'}, {'authorId': '67154907', 'name': 'Masashi Sugiyama'}, {'authorId': '153915824', 'name': 'Rita Singh'}, {'authorId': '1681921', 'name': 'B. Raj'}]","Imprecise label learning (ILL) is introduced, a framework for the unification of learning with various imprecise label configurations, marking the first unified framework with robust and effective performance across various challenging settings."
Rita Singh,153915824,Rita Singh,https://www.semanticscholar.org/author/153915824,25,[],146,2781,a6e3a10a6286967413e3406374bbeea533640030,"{'ArXiv': '2307.13953', 'DBLP': 'journals/corr/abs-2307-13953', 'DOI': '10.48550/arXiv.2307.13953', 'CorpusId': 260164956}",https://www.semanticscholar.org/paper/a6e3a10a6286967413e3406374bbeea533640030,The Hidden Dance of Phonemes and Visage: Unveiling the Enigmatic Link between Phonemes and Facial Features,"This work unveils the enigmatic link between phonemes and facial features. Traditional studies on voice-face correlations typically involve using a long period of voice input, including generating face images from voices and reconstructing 3D face meshes from voices. However, in situations like voice-based crimes, the available voice evidence may be short and limited. Additionally, from a physiological perspective, each segment of speech -- phoneme -- corresponds to different types of airflow and movements in the face. Therefore, it is advantageous to discover the hidden link between phonemes and face attributes. In this paper, we propose an analysis pipeline to help us explore the voice-face relationship in a fine-grained manner, i.e., phonemes v.s. facial anthropometric measurements (AM). We build an estimator for each phoneme-AM pair and evaluate the correlation through hypothesis testing. Our results indicate that AMs are more predictable from vowels compared to consonants, particularly with plosives. Additionally, we observe that if a specific AM exhibits more movement during phoneme pronunciation, it is more predictable. Our findings support those in physiology regarding correlation and lay the groundwork for future research on speech-face multimodal learning.",Interspeech,2023,29,2,0,True,"{'url': 'https://arxiv.org/pdf/2307.13953', 'status': None}","['Computer Science', 'Engineering']","{'volume': 'abs/2307.13953', 'name': 'ArXiv'}","[{'authorId': '2125181846', 'name': 'Liao Qu'}, {'authorId': '1818224862', 'name': 'X. Zou'}, {'authorId': '2108280244', 'name': 'Xiang Li'}, {'authorId': '145357606', 'name': 'Yandong Wen'}, {'authorId': '153915824', 'name': 'Rita Singh'}, {'authorId': '1681921', 'name': 'B. Raj'}]","This work proposes an analysis pipeline to help explore the voice-face relationship in a fine-grained manner, i.s. phonemes v. facial anthropometric measurements (AM), and indicates that AMs are more predictable from vowels compared to consonants, particularly with plosives."
Rita Singh,153915824,Rita Singh,https://www.semanticscholar.org/author/153915824,25,[],146,2781,ad22af138fa1d1490cda0301abf8159a7c30c5a2,"{'DBLP': 'journals/corr/abs-2305-11834', 'ArXiv': '2305.11834', 'DOI': '10.48550/arXiv.2305.11834', 'CorpusId': 258823141}",https://www.semanticscholar.org/paper/ad22af138fa1d1490cda0301abf8159a7c30c5a2,Pengi: An Audio Language Model for Audio Tasks,"In the domain of audio processing, Transfer Learning has facilitated the rise of Self-Supervised Learning and Zero-Shot Learning techniques. These approaches have led to the development of versatile models capable of tackling a wide array of tasks, while delivering state-of-the-art performance. However, current models inherently lack the capacity to produce the requisite language for open-ended tasks, such as Audio Captioning or Audio Question&Answering. We introduce Pengi, a novel Audio Language Model that leverages Transfer Learning by framing all audio tasks as text-generation tasks. It takes as input, an audio recording, and text, and generates free-form text as output. The input audio is represented as a sequence of continuous embeddings by an audio encoder. A text encoder does the same for the corresponding text input. Both sequences are combined as a prefix to prompt a pre-trained frozen language model. The unified architecture of Pengi enables open-ended tasks and close-ended tasks without any additional fine-tuning or task-specific extensions. When evaluated on 22 downstream tasks, our approach yields state-of-the-art performance in several of them. Our results show that connecting language models with audio models is a major step towards general-purpose audio understanding",arXiv.org,2023,68,33,7,True,"{'url': 'http://arxiv.org/pdf/2305.11834', 'status': None}","['Engineering', 'Computer Science']","{'volume': 'abs/2305.11834', 'name': 'ArXiv'}","[{'authorId': '67345939', 'name': 'Soham Deshmukh'}, {'authorId': '2532460', 'name': 'Benjamin Elizalde'}, {'authorId': '153915824', 'name': 'Rita Singh'}, {'authorId': '2145337420', 'name': 'Huaming Wang'}]","Pengi is introduced, a novel Audio Language Model that leverages Transfer Learning by framing all audio tasks as text-generation tasks, and shows that connecting language models with audio models is a major step towards general-purpose audio understanding."
Roni Rosenfeld,88507334,Roni Rosenfeld,https://www.semanticscholar.org/author/88507334,24,[],66,2904,11b798422679ebd291e0eb62d97aace5cc0bd290,"{'PubMedCentral': '10760285', 'DOI': '10.1101/2023.12.08.23299726', 'CorpusId': 266150017, 'PubMed': '38168429'}",https://www.semanticscholar.org/paper/11b798422679ebd291e0eb62d97aace5cc0bd290,Evaluation of FluSight influenza forecasting in the 2021–22 and 2022–23 seasons with a new target laboratory-confirmed influenza hospitalizations,"Accurate forecasts can enable more effective public health responses during seasonal influenza epidemics. Forecasting teams were asked to provide national and jurisdiction-specific probabilistic predictions of weekly confirmed influenza hospital admissions for one through four weeks ahead for the 2021-22 and 2022-23 influenza seasons. Across both seasons, 26 teams submitted forecasts, with the submitting teams varying between seasons. Forecast skill was evaluated using the Weighted Interval Score (WIS), relative WIS, and coverage. Six out of 23 models outperformed the baseline model across forecast weeks and locations in 2021-22 and 12 out of 18 models in 2022-23. Averaging across all forecast targets, the FluSight ensemble was the 2nd most accurate model measured by WIS in 2021-22 and the 5th most accurate in the 2022-23 season. Forecast skill and 95% coverage for the FluSight ensemble and most component models degraded over longer forecast horizons and during periods of rapid change. Current influenza forecasting efforts help inform situational awareness, but research is needed to address limitations, including decreased performance during periods of changing epidemic dynamics.",medRxiv,2023,8,0,0,True,,['Medicine'],{'name': 'medRxiv'},"[{'authorId': '2273808711', 'name': 'Sarabeth M. Mathis'}, {'authorId': '2273815979', 'name': 'Alexander E. Webber'}, {'authorId': '2238191554', 'name': 'Tomás M León'}, {'authorId': '2273770226', 'name': 'Erin L. Murray'}, {'authorId': '2273904053', 'name': 'Monica Sun'}, {'authorId': '2065520310', 'name': 'L. A. White'}, {'authorId': '31577231', 'name': 'L. Brooks'}, {'authorId': '30008497', 'name': 'Alden Green'}, {'authorId': '2145301068', 'name': 'Addison J. Hu'}, {'authorId': '2053515721', 'name': 'Daniel J McDonald'}, {'authorId': '88507334', 'name': 'Roni Rosenfeld'}, {'authorId': '2273805951', 'name': 'Dmitry Shemetov'}, {'authorId': '2242472434', 'name': 'R. Tibshirani'}, {'authorId': '2794000', 'name': 'S. Kandula'}, {'authorId': '2253782340', 'name': 'Sen Pei'}, {'authorId': '2065410149', 'name': 'Jeffrey Shaman'}, {'authorId': '2067187219', 'name': 'R. Yaari'}, {'authorId': '6871095', 'name': 'T. Yamana'}, {'authorId': '2269919365', 'name': 'Pulak Agarwal'}, {'authorId': '2273819033', 'name': 'Srikar Balusu'}, {'authorId': '1972468232', 'name': 'Gautham Gururajan'}, {'authorId': '151024076', 'name': 'Harshavardhan Kamarthi'}, {'authorId': '2266467183', 'name': 'B. A. Prakash'}, {'authorId': '2270146199', 'name': 'Rishi Raman'}, {'authorId': '2253737006', 'name': 'Alexander Rodríguez'}, {'authorId': '2257259600', 'name': 'Zhiyuan Zhao'}, {'authorId': '81370667', 'name': 'Akilan Meiyappan'}, {'authorId': '2273745514', 'name': 'Shalina Omar'}, {'authorId': '2310863', 'name': 'P. Baccam'}, {'authorId': '2156849175', 'name': 'H. Gurung'}, {'authorId': '31717630', 'name': 'S. Stage'}, {'authorId': '2226716', 'name': 'B. Suchoski'}, {'authorId': '2685443', 'name': 'M. Ajelli'}, {'authorId': '2122786857', 'name': 'A. G. Kummer'}, {'authorId': '47581291', 'name': 'M. Litvinova'}, {'authorId': '2273766187', 'name': 'Paulo C. Ventura'}, {'authorId': '2259931529', 'name': 'Spencer Wadsworth'}, {'authorId': '2247541858', 'name': 'Jarad Niemi'}, {'authorId': '2261694535', 'name': 'Erica Carcelen'}, {'authorId': '2253136518', 'name': 'Alison Hill'}, {'authorId': '2261691878', 'name': 'Sung-Mok Jung'}, {'authorId': '41125501', 'name': 'J. Lemaitre'}, {'authorId': '2106996218', 'name': 'J. Lessler'}, {'authorId': '19303511', 'name': 'Sara L. Loo'}, {'authorId': '2223830875', 'name': 'Clif McKee'}, {'authorId': '2261755077', 'name': 'Koji Sato'}, {'authorId': '2110209856', 'name': 'Clair Smith'}, {'authorId': '32952599', 'name': 'S. Truelove'}, {'authorId': '2253358441', 'name': 'Thomas McAndrew'}, {'authorId': '2273813352', 'name': 'Wenxuan Ye'}, {'authorId': '2273815388', 'name': 'Nikos Bosse'}, {'authorId': '1893088', 'name': 'W. Hlavacek'}, {'authorId': '2249158165', 'name': 'Yen Ting Lin'}, {'authorId': '3421868', 'name': 'A. Mallela'}, {'authorId': '2258291211', 'name': 'Ye Chen'}, {'authorId': '2213508241', 'name': 'Shelby Lamm'}, {'authorId': '2273908288', 'name': 'Jaechoul Lee'}, {'authorId': '2253358151', 'name': 'Richard G Posner'}, {'authorId': '12234750', 'name': 'A. Perofsky'}, {'authorId': '2261446471', 'name': 'Cécile Viboud'}, {'authorId': '90773352', 'name': 'Leonardo Clemente'}, {'authorId': '2273815240', 'name': 'Fred Lu'}, {'authorId': '2273735895', 'name': 'Austin G Meyer'}, {'authorId': '2247480179', 'name': 'Mauricio Santillana'}, {'authorId': '2142213732', 'name': 'Matteo Chinazzi'}, {'authorId': '1557302037', 'name': 'Jessica T. Davis'}, {'authorId': '1518270846', 'name': 'K. Mu'}, {'authorId': '1951564', 'name': 'A. Pastore y Piontti'}, {'authorId': '80273596', 'name': 'A. Vespignani'}, {'authorId': '39519033', 'name': 'X. Xiong'}, {'authorId': '1443443423', 'name': 'M. Ben-Nun'}, {'authorId': '47718177', 'name': 'P. Riley'}, {'authorId': '90656586', 'name': 'J. Turtle'}, {'authorId': '2273819030', 'name': 'Chis Hulme-Lowe'}, {'authorId': '2120848534', 'name': 'Shakeel Jessa'}, {'authorId': '1390025785', 'name': 'V. Nagraj'}, {'authorId': '2248150357', 'name': 'Stephen D. Turner'}, {'authorId': '2248714346', 'name': 'Desiree Williams'}, {'authorId': '2273819747', 'name': 'Avranil Basu'}, {'authorId': '2253276372', 'name': 'John M Drake'}, {'authorId': '39101750', 'name': 'S. Fox'}, {'authorId': '47938476', 'name': 'G. Gibson'}, {'authorId': '27561855', 'name': 'Ehsan Suez'}, {'authorId': '2998721', 'name': 'E. Thommes'}, {'authorId': '2239323759', 'name': 'Monica G. Cojocaru'}, {'authorId': '51242881', 'name': 'E. Cramer'}, {'authorId': '102976561', 'name': 'Aaron Gerding'}, {'authorId': '2138286665', 'name': 'A. Stark'}, {'authorId': '32465738', 'name': 'E. Ray'}, {'authorId': '2259929853', 'name': 'Nick Reich'}, {'authorId': '2273815390', 'name': 'Li Shandross'}, {'authorId': '123928372', 'name': 'N. Wattanachit'}, {'authorId': '2143484169', 'name': 'Yijin Wang'}, {'authorId': '2273781074', 'name': 'Martha W Zorn'}, {'authorId': '2134565466', 'name': 'Majd Al Aawar'}, {'authorId': '2192265975', 'name': 'A. Srivastava'}, {'authorId': '2250059095', 'name': 'L. A. Meyers'}, {'authorId': '2478233', 'name': 'A. Adiga'}, {'authorId': '2053226528', 'name': 'Benjamin Hurt'}, {'authorId': '102320831', 'name': 'Gursharn Kaur'}, {'authorId': '2238605745', 'name': 'Bryan L Lewis'}, {'authorId': '2007521700', 'name': 'M. Marathe'}, {'authorId': '49446805', 'name': 'S. Venkatramanan'}, {'authorId': '144711811', 'name': 'P. Butler'}, {'authorId': '2141359998', 'name': 'Andrew Farabow'}, {'authorId': '50027530', 'name': 'N. Muralidhar'}, {'authorId': '2263149583', 'name': 'Naren Ramakrishnan'}, {'authorId': '2247656855', 'name': 'Carrie Reed'}, {'authorId': '5925453', 'name': 'M. Biggerstaff'}, {'authorId': '48873499', 'name': 'R. Borchering'}]","Averaging across all forecast targets, the FluSight ensemble was the 2nd most accurate model measured by WIS in 2021-22 and the 5th most accurate in the 2022-23 season and most component models degraded over longer forecast horizons and during periods of rapid change."
Roni Rosenfeld,88507334,Roni Rosenfeld,https://www.semanticscholar.org/author/88507334,24,[],66,2904,61c7e06e7d6760ecf2f5d20f86711287d131d8ea,"{'DBLP': 'conf/ijcai/0001iMRW23', 'ArXiv': '2306.16914', 'DOI': '10.48550/arXiv.2306.16914', 'CorpusId': 259287111}",https://www.semanticscholar.org/paper/61c7e06e7d6760ecf2f5d20f86711287d131d8ea,Computationally Assisted Quality Control for Public Health Data Streams,"Irregularities in public health data streams (like COVID-19 Cases) hamper data-driven decision-making for public health stakeholders. A real-time, computer-generated list of the most important, outlying data points from thousands of public health data streams could assist an expert reviewer in identifying these irregularities. However, existing outlier detection frameworks perform poorly on this task because they do not account for the data volume or for the statistical properties of public health streams. Accordingly, we developed FlaSH (Flagging Streams in public Health), a practical outlier detection framework for public health data users that uses simple, scalable models to capture these statistical properties explicitly. In an experiment where human experts evaluate FlaSH and existing methods (including deep learning approaches), FlaSH scales to the data volume of this task, matches or exceeds these other methods in mean accuracy, and identifies the outlier points that users empirically rate as more helpful. Based on these results, FlaSH has been deployed on data streams used by public health stakeholders.",International Joint Conference on Artificial Intelligence,2023,47,1,0,True,"{'url': 'http://arxiv.org/pdf/2306.16914', 'status': None}",['Computer Science'],{'pages': '6004-6012'},"[{'authorId': '2188940945', 'name': 'Ananya Joshi'}, {'authorId': '2406799', 'name': 'Kathryn Mazaitis'}, {'authorId': '88507334', 'name': 'Roni Rosenfeld'}, {'authorId': '38105796', 'name': 'Bryan Wilder'}]","FlaSH (Flagging Streams in public Health), a practical outlier detection framework for public health data users that uses simple, scalable models to capture these statistical properties explicitly, has been deployed on data streams used by public health stakeholders."
Roni Rosenfeld,88507334,Roni Rosenfeld,https://www.semanticscholar.org/author/88507334,24,[],66,2904,d486295e298f682b2f98e21106af659d88d396a5,"{'DBLP': 'journals/corr/abs-2309-16546', 'ArXiv': '2309.16546', 'DOI': '10.48550/arXiv.2309.16546', 'CorpusId': 263130924}",https://www.semanticscholar.org/paper/d486295e298f682b2f98e21106af659d88d396a5,Correcting for heterogeneity in real-time epidemiological indicators,"Auxiliary data sources have become increasingly important in epidemiological surveillance, as they are often available at a finer spatial and temporal resolution, larger coverage, and lower latency than traditional surveillance signals. We describe the problem of spatial and temporal heterogeneity in these signals derived from these data sources, where spatial and/or temporal biases are present. We present a method to use a ``guiding'' signal to correct for these biases and produce a more reliable signal that can be used for modeling and forecasting. The method assumes that the heterogeneity can be approximated by a low-rank matrix and that the temporal heterogeneity is smooth over time. We also present a hyperparameter selection algorithm to choose the parameters representing the matrix rank and degree of temporal smoothness of the corrections. In the absence of ground truth, we use maps and plots to argue that this method does indeed reduce heterogeneity. Reducing heterogeneity from auxiliary data sources greatly increases their utility in modeling and forecasting epidemics.",arXiv.org,2023,17,0,0,True,"{'url': 'https://arxiv.org/pdf/2309.16546', 'status': None}",['Computer Science'],"{'volume': 'abs/2309.16546', 'name': 'ArXiv'}","[{'authorId': '2151793132', 'name': 'Aaron M. Rumack'}, {'authorId': '88507334', 'name': 'Roni Rosenfeld'}, {'authorId': '8167675', 'name': 'F. W. Townes'}]",This work presents a method to use a ``guiding'' signal to correct for spatial and temporal biases and produce a more reliable signal that can be used for modeling and forecasting.
Scott Fahlman,1758714,S. Fahlman,https://www.semanticscholar.org/author/1758714,23,[],123,6875,13922d438c437cea443b6c4747c54a29a8bdd742,"{'ArXiv': '2305.04154', 'DBLP': 'journals/corr/abs-2305-04154', 'DOI': '10.48550/arXiv.2305.04154', 'CorpusId': 258557274}",https://www.semanticscholar.org/paper/13922d438c437cea443b6c4747c54a29a8bdd742,Score: A Rule Engine for the Scone Knowledge Base System,"We present Score, a rule engine designed and implemented for the Scone knowledge base system. Scone is a knowledge base system designed for storing and manipulating rich representations of general knowledge in symbolic form. It represents knowledge in the form of nodes and links in a network structure, and it can perform basic inference about the relationships between different elements efficiently. On its own, Scone acts as a sort of""smart memory""that can interface with other software systems. One area of improvement for Scone is how useful it can be in supplying knowledge to an intelligent agent that can use the knowledge to perform actions and update the knowledge base with its observations. We augment the Scone system with a production rule engine that automatically performs simple inference based on existing and newly-added structures in Scone's knowledge base, potentially improving the capabilities of any planning systems built on top of Scone. Production rule systems consist of""if-then""production rules that try to match their predicates to existing knowledge and fire their actions when their predicates are satisfied. We propose two kinds of production rules, if-added and if-needed rules, that differ in how they are checked and fired to cover multiple use cases. We then implement methods to efficiently check and fire these rules in a large knowledge base. The new rule engine is not meant to be a complex stand-alone planner, so we discuss how it fits into the context of Scone and future work on planning systems.",arXiv.org,2023,15,0,0,True,"{'url': 'http://arxiv.org/pdf/2305.04154', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.04154', 'name': 'ArXiv'}","[{'authorId': '2216567724', 'name': 'Jeffrey Chen'}, {'authorId': '1758714', 'name': 'S. Fahlman'}]","The Scone system is augmented with a production rule engine that automatically performs simple inference based on existing and newly-added structures in Scone's knowledge base, potentially improving the capabilities of any planning systems built on top of Scone."
Sean Welleck,2129663,S. Welleck,https://www.semanticscholar.org/author/2129663,23,[],42,2845,3aaf6a2cbad5850ad81ab5c163599cb3d523436f,"{'DBLP': 'journals/corr/abs-2303-17651', 'ArXiv': '2303.17651', 'DOI': '10.48550/arXiv.2303.17651', 'CorpusId': 257900871}",https://www.semanticscholar.org/paper/3aaf6a2cbad5850ad81ab5c163599cb3d523436f,Self-Refine: Iterative Refinement with Self-Feedback,"Like humans, large language models (LLMs) do not always generate the best output on their first try. Motivated by how humans refine their written text, we introduce Self-Refine, an approach for improving initial outputs from LLMs through iterative feedback and refinement. The main idea is to generate an initial output using an LLMs; then, the same LLMs provides feedback for its output and uses it to refine itself, iteratively. Self-Refine does not require any supervised training data, additional training, or reinforcement learning, and instead uses a single LLM as the generator, refiner, and feedback provider. We evaluate Self-Refine across 7 diverse tasks, ranging from dialog response generation to mathematical reasoning, using state-of-the-art (GPT-3.5, ChatGPT, and GPT-4) LLMs. Across all evaluated tasks, outputs generated with Self-Refine are preferred by humans and automatic metrics over those generated with the same LLM using conventional one-step generation, improving by ~20% absolute on average in task performance. Our work demonstrates that even state-of-the-art LLMs like GPT-4 can be further improved at test time using our simple, standalone approach.",arXiv.org,2023,52,383,25,True,"{'url': 'http://arxiv.org/pdf/2303.17651', 'status': None}",['Computer Science'],"{'volume': 'abs/2303.17651', 'name': 'ArXiv'}","[{'authorId': '21626987', 'name': 'Aman Madaan'}, {'authorId': '1721168', 'name': 'Niket Tandon'}, {'authorId': '1491232062', 'name': 'Prakhar Gupta'}, {'authorId': '1474550731', 'name': 'Skyler Hallinan'}, {'authorId': '49715441', 'name': 'Luyu Gao'}, {'authorId': '35823986', 'name': 'Sarah Wiegreffe'}, {'authorId': '47051926', 'name': 'Uri Alon'}, {'authorId': '46217681', 'name': 'Nouha Dziri'}, {'authorId': '9358910', 'name': 'Shrimai Prabhumoye'}, {'authorId': '46286308', 'name': 'Yiming Yang'}, {'authorId': '2129663', 'name': 'S. Welleck'}, {'authorId': '3165738', 'name': 'Bodhisattwa Prasad Majumder'}, {'authorId': '2152953535', 'name': 'Shashank Gupta'}, {'authorId': '2112229', 'name': 'A. Yazdanbakhsh'}, {'authorId': '48323507', 'name': 'Peter Clark'}]","Self-Refine is introduced, an approach for improving initial outputs from LLMs through iterative feedback and refinement that demonstrates that even state-of-the-art LLMs like GPT-4 can be further improved at test time using this simple, standalone approach."
Sean Welleck,2129663,S. Welleck,https://www.semanticscholar.org/author/2129663,23,[],42,2845,ca991e0283a1c30a46eb585d9eb499fc0ec8ecc2,"{'DBLP': 'conf/emnlp/LuBWJCRAJRDFLHQ23', 'ArXiv': '2305.15065', 'DOI': '10.48550/arXiv.2305.15065', 'CorpusId': 258865629}",https://www.semanticscholar.org/paper/ca991e0283a1c30a46eb585d9eb499fc0ec8ecc2,Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs without Fine-tuning,"While extreme-scale language models have demonstrated exceptional performance on a variety of language tasks, the degree of control over these language models through pure prompting can often be limited. Directly fine-tuning such language models can be effective for tailoring them, but it can be either extremely costly (e.g., GPT-3) or not even feasible for the broader community (e.g., GPT-4). We propose Inference-time Policy Adapters (IPA), which efficiently tailors a language model such as GPT-3 without fine-tuning it. IPA guides a large base model during decoding time through a lightweight policy adapter trained to optimize an arbitrary user objective with reinforcement learning. On five challenging text generation tasks, such as toxicity reduction and lexically constrained generation, IPA consistently brings significant improvements over off-the-shelf language models. It outperforms competitive baseline methods, sometimes even including expensive fine-tuning. In particular, tailoring GPT-2 with IPA can outperform GPT-3, while tailoring GPT-3 with IPA brings a major performance boost over GPT-3 (and sometimes even over GPT-4). Our promising results highlight the potential of IPA as a lightweight alternative to tailoring extreme-scale language models.",Conference on Empirical Methods in Natural Language Processing,2023,100,6,0,True,"{'url': 'http://arxiv.org/pdf/2305.15065', 'status': None}",['Computer Science'],{'pages': '6863-6883'},"[{'authorId': '50085131', 'name': 'Ximing Lu'}, {'authorId': '9252833', 'name': 'Faeze Brahman'}, {'authorId': '119659229', 'name': 'Peter West'}, {'authorId': '2148334242', 'name': 'Jaehun Jang'}, {'authorId': '37619618', 'name': 'Khyathi Raghavi Chandu'}, {'authorId': '3023068', 'name': 'Abhilasha Ravichander'}, {'authorId': '3444092', 'name': 'Lianhui Qin'}, {'authorId': '19179135', 'name': 'Prithviraj Ammanabrolu'}, {'authorId': '2112504145', 'name': 'Liwei Jiang'}, {'authorId': '1399403094', 'name': 'Sahana Ramnath'}, {'authorId': '46217681', 'name': 'Nouha Dziri'}, {'authorId': '33772445', 'name': 'Jillian R. Fisher'}, {'authorId': '51583409', 'name': 'Bill Yuchen Lin'}, {'authorId': '1474550731', 'name': 'Skyler Hallinan'}, {'authorId': '1384550891', 'name': 'Xiang Ren'}, {'authorId': '2129663', 'name': 'S. Welleck'}, {'authorId': '1699545', 'name': 'Yejin Choi'}]","Inference-time Policy Adapters (IPA) is proposed, which efficiently tailors a language model such as GPT-3 without fine-tuning it, and consistently brings significant improvements over off-the-shelf language models."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,00542e510058b11d1faf612de9b45fa0d4d3f4e5,"{'PubMedCentral': '10114312', 'DOI': '10.1016/j.isci.2023.106694', 'CorpusId': 258239706, 'PubMed': '37124417'}",https://www.semanticscholar.org/paper/00542e510058b11d1faf612de9b45fa0d4d3f4e5,Saturation time of exposure interval for cross-neutralization response to SARS-CoV-2: Implications for vaccine dose interval,,iScience,2023,39,1,0,True,"{'url': 'http://www.cell.com/article/S258900422300771X/pdf', 'status': None}",['Medicine'],"{'volume': '26', 'name': 'iScience'}","[{'authorId': '2878708', 'name': 'Sho Miyamoto'}, {'authorId': '151382092', 'name': 'Y. Kuroda'}, {'authorId': '48392636', 'name': 'T. Kanno'}, {'authorId': '2129912669', 'name': 'A. Ueno'}, {'authorId': '2148243684', 'name': 'N. Shiwa-Sudo'}, {'authorId': '1402059466', 'name': 'N. Iwata-Yoshikawa'}, {'authorId': '2110889791', 'name': 'Yusuke Sakai'}, {'authorId': '49988763', 'name': 'N. Nagata'}, {'authorId': '4094926', 'name': 'T. Arashiro'}, {'authorId': '5440897', 'name': 'A. Ainai'}, {'authorId': '144805847', 'name': 'Saya Moriyama'}, {'authorId': '1870898', 'name': 'N. Kishida'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '34579632', 'name': 'K. Nojima'}, {'authorId': '49058738', 'name': 'Y. Seki'}, {'authorId': '31711005', 'name': 'T. Mizukami'}, {'authorId': '1759434', 'name': 'H. Hasegawa'}, {'authorId': '144160410', 'name': 'H. Ebihara'}, {'authorId': '2282838', 'name': 'S. Fukushi'}, {'authorId': '1788585', 'name': 'Yoshimasa Takahashi'}, {'authorId': '2096052275', 'name': 'Maeda Ken'}, {'authorId': '2004824863', 'name': 'Tadaki Suzuki'}]","The results highlight the importance of vaccine dosage intervals of 4 months or longer, regardless of the antigenicity of the exposed antigen, to maximize the breadth of serum cross-neutralization covering SARS-CoV-2 Omicron lineages."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,01a819f7155bb87c32f1e4c13d9439c080e6aa97,"{'DBLP': 'journals/corr/abs-2309-15317', 'ArXiv': '2309.15317', 'DOI': '10.1109/ASRU57964.2023.10389735', 'CorpusId': 262935178}",https://www.semanticscholar.org/paper/01a819f7155bb87c32f1e4c13d9439c080e6aa97,Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning,"Multilingual self-supervised learning (SSL) has often lagged behind state-of-the-art (SOTA) methods due to the expenses and complexity required to handle many languages. This further harms the reproducibility of SSL, which is already limited to few research groups due to its resource usage. We show that more powerful techniques can actually lead to more efficient pre-training, opening SSL to more research groups. We propose WavLabLM, which extends WavLM’s joint prediction and denoising to 40k hours of data across 136 languages. To build WavLabLM, we devise a novel multi-stage pre-training method, designed to address the language imbalance of multilingual data. WavLabLM achieves comparable performance to XLS-R on ML-SUPERB with less than $10 \%$ of the training data, making SSL realizable with academic compute. We show that further efficiency can be achieved with a vanilla HuBERT Base model, which can maintain $94 \%$ of XLS-R’s performance with only $3 \%$ of the data, 4 GPUs, and limited trials. We open-source all code and models in ESPnet.",Automatic Speech Recognition & Understanding,2023,50,2,0,True,"{'url': 'https://arxiv.org/pdf/2309.15317', 'status': None}","['Computer Science', 'Engineering']","{'pages': '1-8', 'name': '2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)'}","[{'authorId': '2144302389', 'name': 'William Chen'}, {'authorId': '1485531923', 'name': 'Jiatong Shi'}, {'authorId': '2087059555', 'name': 'Brian Yan'}, {'authorId': '2142561945', 'name': 'Dan Berrebbi'}, {'authorId': '1390725481', 'name': 'Wangyou Zhang'}, {'authorId': '2111014429', 'name': 'Yifan Peng'}, {'authorId': '8776560', 'name': 'Xuankai Chang'}, {'authorId': '31949212', 'name': 'Soumi Maiti'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}]","This work proposes WavLabLM, which extends WavLM’s joint prediction and denoising to 40k hours of data across 136 languages, and devise a novel multi-stage pre-training method, designed to address the language imbalance of multilingual data."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,0534fd0ed04acaa60f820b730bf3c4816767fa43,"{'ArXiv': '2306.01247', 'DOI': '10.21437/interspeech.2023-1299', 'CorpusId': 259064251}",https://www.semanticscholar.org/paper/0534fd0ed04acaa60f820b730bf3c4816767fa43,Tensor decomposition for minimization of E2E SLU model toward on-device processing,"Spoken Language Understanding (SLU) is a critical speech recognition application and is often deployed on edge devices. Consequently, on-device processing plays a significant role in the practical implementation of SLU. This paper focuses on the end-to-end (E2E) SLU model due to its small latency property, unlike a cascade system, and aims to minimize the computational cost. We reduce the model size by applying tensor decomposition to the Conformer and E-Branchformer architectures used in our E2E SLU models. We propose to apply singular value decomposition to linear layers and the Tucker decomposition to convolution layers, respectively. We also compare COMP/PARFAC decomposition and Tensor-Train decomposition to the Tucker decomposition. Since the E2E model is represented by a single neural network, our tensor decomposition can flexibly control the number of parameters without changing feature dimensions. On the STOP dataset, we achieved 70.9% exact match accuracy under the tight constraint of only 15 million parameters.",Interspeech,2023,35,1,0,True,"{'url': 'https://arxiv.org/pdf/2306.01247', 'status': None}",['Engineering'],{'name': 'INTERSPEECH 2023'},"[{'authorId': '3165422', 'name': 'Yosuke Kashiwagi'}, {'authorId': '72401599', 'name': 'Siddhant Arora'}, {'authorId': '1866674954', 'name': 'Hayato Futami'}, {'authorId': '50306945', 'name': 'Jessica Huynh'}, {'authorId': '1854017630', 'name': 'Shih-Lun Wu'}, {'authorId': '2111014429', 'name': 'Yifan Peng'}, {'authorId': '2087059555', 'name': 'Brian Yan'}, {'authorId': '2779505', 'name': 'E. Tsunoo'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}]","This paper aims to minimize the computational cost of the end-to-end (E2E) SLU model due to its small latency property, unlike a cascade system, and reduces the model size by applying tensor decomposition to the Conformer and E-Branchformer architectures used in the E2E SLU models."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,06353e1b7e7c8dc701ac76dcd4db5061b24468c9,"{'DBLP': 'journals/corr/abs-2309-08876', 'ArXiv': '2309.08876', 'DOI': '10.48550/arXiv.2309.08876', 'CorpusId': 262043613}",https://www.semanticscholar.org/paper/06353e1b7e7c8dc701ac76dcd4db5061b24468c9,Decoder-only Architecture for Speech Recognition with CTC Prompts and Text Data Augmentation,"Collecting audio-text pairs is expensive; however, it is much easier to access text-only data. Unless using shallow fusion, end-to-end automatic speech recognition (ASR) models require architecture modifications or additional training schemes to use text-only data. Inspired by recent advances in decoder-only language models (LMs), such as GPT-3 and PaLM adopted for speech-processing tasks, we propose using a decoder-only architecture for ASR with simple text augmentation. To provide audio information, encoder features compressed by CTC prediction are used as prompts for the decoder, which can be regarded as refining CTC prediction using the decoder-only model. Because the decoder architecture is the same as an autoregressive LM, it is simple to enhance the model by leveraging external text data with LM training. An experimental comparison using LibriSpeech and Switchboard shows that our proposed models with text augmentation training reduced word error rates from ordinary CTC by 0.3% and 1.4% on LibriSpeech test-clean and testother set, respectively, and 2.9% and 5.0% on Switchboard and CallHome. The proposed model had advantage on computational efficiency compared with conventional encoder-decoder ASR models with a similar parameter setup, and outperformed them on the LibriSpeech 100h and Switchboard training scenarios.",arXiv.org,2023,27,2,0,True,"{'url': 'https://arxiv.org/pdf/2309.08876', 'status': None}","['Computer Science', 'Engineering']","{'volume': 'abs/2309.08876', 'name': 'ArXiv'}","[{'authorId': '2779505', 'name': 'E. Tsunoo'}, {'authorId': '1866674954', 'name': 'Hayato Futami'}, {'authorId': '3165422', 'name': 'Yosuke Kashiwagi'}, {'authorId': '72401599', 'name': 'Siddhant Arora'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}]","This work proposes using a decoder-only architecture for ASR with simple text augmentation training that had advantage on computational efficiency compared with conventional encoder-decoder ASR models with a similar parameter setup, and outperformed them on the LibriSpeech 100h and Switchboard training scenarios."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,090b284b2f8fc93ac3e7a92fc9f91bf4965ba75c,"{'ArXiv': '2305.10615', 'DBLP': 'journals/corr/abs-2305-10615', 'DOI': '10.48550/arXiv.2305.10615', 'CorpusId': 258762486}",https://www.semanticscholar.org/paper/090b284b2f8fc93ac3e7a92fc9f91bf4965ba75c,ML-SUPERB: Multilingual Speech Universal PERformance Benchmark,"Speech processing Universal PERformance Benchmark (SUPERB) is a leaderboard to benchmark the performance of Self-Supervised Learning (SSL) models on various speech processing tasks. However, SUPERB largely considers English speech in its evaluation. This paper presents multilingual SUPERB (ML-SUPERB), covering 143 languages (ranging from high-resource to endangered), and considering both automatic speech recognition and language identification. Following the concept of SUPERB, ML-SUPERB utilizes frozen SSL features and employs a simple framework for multilingual tasks by learning a shallow downstream model. Similar to the SUPERB benchmark, we find speech SSL models can significantly improve performance compared to FBANK features. Furthermore, we find that multilingual models do not always perform better than their monolingual counterparts. We will release ML-SUPERB as a challenge with organized datasets and reproducible training scripts for future multilingual representation research.",Interspeech,2023,46,17,2,True,"{'url': 'https://arxiv.org/pdf/2305.10615', 'status': None}","['Computer Science', 'Engineering']","{'volume': 'abs/2305.10615', 'name': 'ArXiv'}","[{'authorId': '1485531923', 'name': 'Jiatong Shi'}, {'authorId': '2142561945', 'name': 'Dan Berrebbi'}, {'authorId': '2144302389', 'name': 'William Chen'}, {'authorId': '1994122063', 'name': 'Ho-Lam Chung'}, {'authorId': '2203366419', 'name': 'En-Pei Hu'}, {'authorId': '2152490890', 'name': 'Wei Huang'}, {'authorId': '8776560', 'name': 'Xuankai Chang'}, {'authorId': '2530311', 'name': 'Shang-Wen Li'}, {'authorId': '40360972', 'name': 'Abdel-rahman Mohamed'}, {'authorId': '1706104', 'name': 'Hung-yi Lee'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}]",
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,1028bf42a4c792acefd3be9da45e58f2b1620fe3,"{'ArXiv': '2302.14132', 'DBLP': 'conf/icassp/PengKWSW23', 'DOI': '10.1109/ICASSP49357.2023.10095780', 'CorpusId': 257232952}",https://www.semanticscholar.org/paper/1028bf42a4c792acefd3be9da45e58f2b1620fe3,Structured Pruning of Self-Supervised Pre-Trained Models for Speech Recognition and Understanding,"Self-supervised speech representation learning (SSL) has shown to be effective in various downstream tasks, but SSL models are usually large and slow. Model compression techniques such as pruning aim to reduce the model size and computation without degradation in accuracy. Prior studies focus on the pruning of Transformers; however, speech models not only utilize a stack of Transformer blocks, but also combine a frontend network based on multiple convolutional layers for low-level feature representation learning. This frontend has a small size but a heavy computational cost. In this work, we propose three task-specific structured pruning methods to deal with such heterogeneous networks. Experiments on LibriSpeech and SLURP show that the proposed method is more accurate than the original wav2vec2-base with 10% to 30% less computation, and is able to reduce the computation by 40% to 50% without any degradation.","IEEE International Conference on Acoustics, Speech, and Signal Processing",2023,44,10,2,True,"{'url': 'https://arxiv.org/pdf/2302.14132', 'status': None}","['Computer Science', 'Engineering']","{'pages': '1-5', 'name': 'ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)'}","[{'authorId': '2111014429', 'name': 'Yifan Peng'}, {'authorId': '7826646', 'name': 'Kwangyoun Kim'}, {'authorId': '24277779', 'name': 'Felix Wu'}, {'authorId': '2074241507', 'name': 'Prashant Sridhar'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}]","This work proposes three task-specific structured pruning methods to deal with heterogeneous speech models that not only utilize a stack of Transformer blocks, but also combine a frontend network based on multiple convolutional layers for low-level feature representation learning."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,10e8dc07ea256c6a88d7043cf135417402ed38f4,"{'DBLP': 'journals/corr/abs-2305-11095', 'ArXiv': '2305.11095', 'DOI': '10.48550/arXiv.2305.11095', 'CorpusId': 258762742}",https://www.semanticscholar.org/paper/10e8dc07ea256c6a88d7043cf135417402ed38f4,Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization,"We investigate the emergent abilities of the recently proposed web-scale speech model Whisper, by adapting it to unseen tasks with prompt engineering. We selected three tasks: audio-visual speech recognition (AVSR), code-switched speech recognition (CS-ASR), and speech translation (ST) on unseen language pairs. We design task-specific prompts, by either leveraging another large-scale model, or simply manipulating the special tokens in the default prompts. Experiments show that compared to the default prompts, our proposed prompts improve performance by 10% to 45% on the three zero-shot tasks, and even outperform SotA supervised models on some datasets. In addition, our experiments reveal many interesting properties of Whisper, including its robustness to prompts, bias on accents, and the multilingual understanding in its latent space. Code is available at https://github.com/jasonppy/PromptingWhisper",Interspeech,2023,36,17,1,True,"{'url': 'https://arxiv.org/pdf/2305.11095', 'status': None}","['Computer Science', 'Engineering']","{'volume': 'abs/2305.11095', 'name': 'ArXiv'}","[{'authorId': '30598090', 'name': 'Puyuan Peng'}, {'authorId': '2087059555', 'name': 'Brian Yan'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '30507748', 'name': 'David F. Harwath'}]","This work investigates the emergent abilities of the recently proposed web-scale speech model Whisper, by adapting it to unseen tasks with prompt engineering, and designs task-specific prompts that improve performance on the three zero-shot tasks and even outperform SotA supervised models on some datasets."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,14f5fd91d75bc10d9fff53dfe7ee73484fc4273b,"{'DBLP': 'journals/corr/abs-2305-11073', 'ArXiv': '2305.11073', 'DOI': '10.48550/arXiv.2305.11073', 'CorpusId': 258762753}",https://www.semanticscholar.org/paper/14f5fd91d75bc10d9fff53dfe7ee73484fc4273b,"A Comparative Study on E-Branchformer vs Conformer in Speech Recognition, Translation, and Understanding Tasks","Conformer, a convolution-augmented Transformer variant, has become the de facto encoder architecture for speech processing due to its superior performance in various tasks, including automatic speech recognition (ASR), speech translation (ST) and spoken language understanding (SLU). Recently, a new encoder called E-Branchformer has outperformed Conformer in the LibriSpeech ASR benchmark, making it promising for more general speech applications. This work compares E-Branchformer and Conformer through extensive experiments using different types of end-to-end sequence-to-sequence models. Results demonstrate that E-Branchformer achieves comparable or better performance than Conformer in almost all evaluation sets across 15 ASR, 2 ST, and 3 SLU benchmarks, while being more stable during training. We will release our training configurations and pre-trained models for reproducibility, which can benefit the speech community.",Interspeech,2023,58,7,0,True,"{'url': 'http://arxiv.org/pdf/2305.11073', 'status': None}","['Computer Science', 'Engineering']","{'volume': 'abs/2305.11073', 'name': 'ArXiv'}","[{'authorId': '2111014429', 'name': 'Yifan Peng'}, {'authorId': '7826646', 'name': 'Kwangyoun Kim'}, {'authorId': '24277779', 'name': 'Felix Wu'}, {'authorId': '2087059555', 'name': 'Brian Yan'}, {'authorId': '72401599', 'name': 'Siddhant Arora'}, {'authorId': '2144302389', 'name': 'William Chen'}, {'authorId': '1677684712', 'name': 'Jiyang Tang'}, {'authorId': '2927349', 'name': 'Suwon Shon'}, {'authorId': '2074241507', 'name': 'Prashant Sridhar'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}]","E-Branchformer achieves comparable or better performance than Conformer in almost all evaluation sets across 15 ASR, 2 ST, and 3 SLU benchmarks, while being more stable during training."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,16fbcf340648b302ad8d4e6ed34c7ab5ad346db9,"{'DBLP': 'conf/icml/XuJMH0G23', 'ArXiv': '2304.06795', 'DOI': '10.48550/arXiv.2304.06795', 'CorpusId': 258170288}",https://www.semanticscholar.org/paper/16fbcf340648b302ad8d4e6ed34c7ab5ad346db9,Efficient Sequence Transduction by Jointly Predicting Tokens and Durations,"This paper introduces a novel Token-and-Duration Transducer (TDT) architecture for sequence-to-sequence tasks. TDT extends conventional RNN-Transducer architectures by jointly predicting both a token and its duration, i.e. the number of input frames covered by the emitted token. This is achieved by using a joint network with two outputs which are independently normalized to generate distributions over tokens and durations. During inference, TDT models can skip input frames guided by the predicted duration output, which makes them significantly faster than conventional Transducers which process the encoder output frame by frame. TDT models achieve both better accuracy and significantly faster inference than conventional Transducers on different sequence transduction tasks. TDT models for Speech Recognition achieve better accuracy and up to 2.82X faster inference than conventional Transducers. TDT models for Speech Translation achieve an absolute gain of over 1 BLEU on the MUST-C test compared with conventional Transducers, and its inference is 2.27X faster. In Speech Intent Classification and Slot Filling tasks, TDT models improve the intent accuracy by up to over 1% (absolute) over conventional Transducers, while running up to 1.28X faster. Our implementation of the TDT model will be open-sourced with the NeMo (https://github.com/NVIDIA/NeMo) toolkit.",International Conference on Machine Learning,2023,41,2,0,True,"{'url': 'http://arxiv.org/pdf/2304.06795', 'status': None}","['Engineering', 'Computer Science']","{'volume': 'abs/2304.06795', 'name': 'ArXiv'}","[{'authorId': '2094929', 'name': 'Hainan Xu'}, {'authorId': '2187456778', 'name': 'Fei Jia'}, {'authorId': '9099952', 'name': 'Somshubra Majumdar'}, {'authorId': '2119143', 'name': 'Hengguan Huang'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '31963005', 'name': 'Boris Ginsburg'}]","A novel Token-and-Duration Transducer architecture for sequence-to-sequence tasks by jointly predicting both a token and its duration, i.e. the number of input frames covered by the emitted token."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,2567a34501c1b258c102a07e737b87e556af0809,"{'DBLP': 'conf/icassp/KanoODSMW23', 'DOI': '10.1109/ICASSP49357.2023.10095019', 'CorpusId': 258529997}",https://www.semanticscholar.org/paper/2567a34501c1b258c102a07e737b87e556af0809,Speech Summarization of Long Spoken Document: Improving Memory Efficiency of Speech/Text Encoders,"Speech summarization requires processing several minute-long speech sequences to allow exploiting the whole context of a spoken document. A conventional approach is a cascade of automatic speech recognition (ASR) and text summarization (TS). However, the cascade systems are sensitive to ASR errors. Moreover, the cascade system cannot be optimized for input speech and utilize para-linguistic information. Recently, there has been an increased interest in end-to-end (E2E) approaches optimized to output summaries directly from speech. Such systems can thus mitigate the ASR errors of cascade approaches. However, E2E speech summarization requires massive computational resources because it needs to encode long speech sequences. We propose a speech summarization system that enables E2E summarization from 100 seconds, which is the limit of the conventional method, to up to 10 minutes (i.e., the duration of typical instructional videos on YouTube). However, the modeling capability of this model for minute-long speech sequences is weaker than the conventional approach. We thus exploit auxiliary text information from ASR transcriptions to improve the modeling capabilities. The resultant system consists of a dual speech/text encoder decoder-based summarization system. We perform experiments on the How2 dataset showing the proposed system improved METEOR scores by up to 2.7 points by fully exploiting the long spoken documents.","IEEE International Conference on Acoustics, Speech, and Signal Processing",2023,29,3,0,True,,['Computer Science'],"{'pages': '1-5', 'name': 'ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)'}","[{'authorId': '3218696', 'name': 'Takatomo Kano'}, {'authorId': '2555553', 'name': 'A. Ogawa'}, {'authorId': '1690812', 'name': 'Marc Delcroix'}, {'authorId': '145521253', 'name': 'Roshan Sharma'}, {'authorId': '2054405875', 'name': 'Kohei Matsuura'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}]","This work proposes a speech summarization system that enables E2E summarization from 100 seconds, which is the limit of the conventional method, to up to 10 minutes (i.e., the duration of typical instructional videos on YouTube), and exploits auxiliary text information from ASR transcriptions to improve the modeling capabilities."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,25c399a231364f4a77d1dc4b59927585e63f5f11,"{'ArXiv': '2305.20054', 'DBLP': 'journals/corr/abs-2305-20054', 'DOI': '10.48550/arXiv.2305.20054', 'CorpusId': 258987929}",https://www.semanticscholar.org/paper/25c399a231364f4a77d1dc4b59927585e63f5f11,UNSSOR: Unsupervised Neural Speech Separation by Leveraging Over-determined Training Mixtures,"In reverberant conditions with multiple concurrent speakers, each microphone acquires a mixture signal of multiple speakers at a different location. In over-determined conditions where the microphones out-number speakers, we can narrow down the solutions to speaker images and realize unsupervised speech separation by leveraging each mixture signal as a constraint (i.e., the estimated speaker images at a microphone should add up to the mixture). Equipped with this insight, we propose UNSSOR, an algorithm for $\textbf{u}$nsupervised $\textbf{n}$eural $\textbf{s}$peech $\textbf{s}$eparation by leveraging $\textbf{o}$ver-determined training mixtu$\textbf{r}$es. At each training step, we feed an input mixture to a deep neural network (DNN) to produce an intermediate estimate for each speaker, linearly filter the estimates, and optimize a loss so that, at each microphone, the filtered estimates of all the speakers can add up to the mixture to satisfy the above constraint. We show that this loss can promote unsupervised separation of speakers. The linear filters are computed in each sub-band based on the mixture and DNN estimates through the forward convolutive prediction (FCP) algorithm. To address the frequency permutation problem incurred by using sub-band FCP, a loss term based on minimizing intra-source magnitude scattering is proposed. Although UNSSOR requires over-determined training mixtures, we can train DNNs to achieve under-determined separation (e.g., unsupervised monaural speech separation). Evaluation results on two-speaker separation in reverberant conditions show the effectiveness and potential of UNSSOR.",arXiv.org,2023,86,2,2,True,"{'url': 'http://arxiv.org/pdf/2305.20054', 'status': None}","['Computer Science', 'Engineering']","{'volume': 'abs/2305.20054', 'name': 'ArXiv'}","[{'authorId': '12229660', 'name': 'Zhong-Qiu Wang'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}]","Evaluation results on two-speaker separation in reverberant conditions show the effectiveness and potential of UNSSOR, an algorithm for over-determined training mixtures that can promote unsupervised separation of speakers."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,331af9b7193e563b021e8e6892e7cb3030decd38,"{'DBLP': 'journals/corr/abs-2309-14922', 'ArXiv': '2309.14922', 'DOI': '10.1109/ASRU57964.2023.10389796', 'CorpusId': 262825256}",https://www.semanticscholar.org/paper/331af9b7193e563b021e8e6892e7cb3030decd38,Segment-Level Vectorized Beam Search Based on Partially Autoregressive Inference,"Attention-based encoder-decoder models with autoregressive (AR) decoding have proven to be the dominant approach for automatic speech recognition (ASR) due to their superior accuracy. However, they often suffer from slow inference. This is primarily attributed to the incremental calculation of the decoder. This work proposes a partially AR framework, which employs segment-level vectorized beam search for improving the inference speed of an ASR model based on the hybrid connectionist temporal classification (CTC) attention-based architecture. It first generates an initial hypothesis using greedy CTC decoding, identifying low-confidence tokens based on their output probabilities. We then utilize the decoder to perform segment-level vectorized beam search on these tokens, re-predicting in parallel with minimal decoder calculations. Experimental results show that our method is 12 to 13 times faster in inference on the LibriSpeech corpus over AR decoding whilst preserving high accuracy.",Automatic Speech Recognition & Understanding,2023,39,0,0,True,"{'url': 'https://arxiv.org/pdf/2309.14922', 'status': None}","['Computer Science', 'Engineering']","{'pages': '1-8', 'name': '2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)'}","[{'authorId': '1387976961', 'name': 'Masao Someki'}, {'authorId': '2075058295', 'name': 'N. Eng'}, {'authorId': '46722767', 'name': 'Yosuke Higuchi'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}]","A partially AR framework, which employs segment-level vectorized beam search for improving the inference speed of an ASR model based on the hybrid connectionist temporal classification (CTC) attention-based architecture, which is 12 to 13 times faster in inference on the LibriSpeech corpus over AR decoding whilst preserving high accuracy."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,3b93dd5f2d2512a4b58f6c776af59f74a90764a5,"{'ArXiv': '2301.09099', 'DBLP': 'journals/corr/abs-2301-09099', 'DOI': '10.48550/arXiv.2301.09099', 'CorpusId': 256105724}",https://www.semanticscholar.org/paper/3b93dd5f2d2512a4b58f6c776af59f74a90764a5,Unsupervised Data Selection for TTS: Using Arabic Broadcast News as a Case Study,.,arXiv.org,2023,31,6,1,True,"{'url': 'http://arxiv.org/pdf/2301.09099', 'status': None}","['Computer Science', 'Engineering']","{'volume': 'abs/2301.09099', 'name': 'ArXiv'}","[{'authorId': '1380273855', 'name': 'Massa Baali'}, {'authorId': '3326124', 'name': 'Tomoki Hayashi'}, {'authorId': '143779235', 'name': 'Hamdy Mubarak'}, {'authorId': '31949212', 'name': 'Soumi Maiti'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '1402224224', 'name': 'W. El-Hajj'}, {'authorId': '2131153314', 'name': 'Ahmed Ali'}]",
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,3bd320ddb25886417ae90011b00f13f5d558097b,"{'ArXiv': '2307.08217', 'DBLP': 'journals/corr/abs-2307-08217', 'DOI': '10.48550/arXiv.2307.08217', 'CorpusId': 259936797}",https://www.semanticscholar.org/paper/3bd320ddb25886417ae90011b00f13f5d558097b,BASS: Block-wise Adaptation for Speech Summarization,"End-to-end speech summarization has been shown to improve performance over cascade baselines. However, such models are difficult to train on very large inputs (dozens of minutes or hours) owing to compute restrictions and are hence trained with truncated model inputs. Truncation leads to poorer models, and a solution to this problem rests in block-wise modeling, i.e., processing a portion of the input frames at a time. In this paper, we develop a method that allows one to train summarization models on very long sequences in an incremental manner. Speech summarization is realized as a streaming process, where hypothesis summaries are updated every block based on new acoustic information. We devise and test strategies to pass semantic context across the blocks. Experiments on the How2 dataset demonstrate that the proposed block-wise training method improves by 3 points absolute on ROUGE-L over a truncated input baseline.",Interspeech,2023,28,1,0,True,"{'url': 'https://arxiv.org/pdf/2307.08217', 'status': None}","['Computer Science', 'Engineering']","{'volume': 'abs/2307.08217', 'name': 'ArXiv'}","[{'authorId': '145521253', 'name': 'Roshan Sharma'}, {'authorId': '2163585699', 'name': 'Kenneth Zheng'}, {'authorId': '72401599', 'name': 'Siddhant Arora'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '153915824', 'name': 'Rita Singh'}, {'authorId': '1681921', 'name': 'B. Raj'}]",This paper develops a method that allows one to train summarization models on very long sequences in an incremental manner and devise and test strategies to pass semantic context across the blocks.
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,48c6318dbcf9908cabe0023b8817566f34d0b466,"{'DBLP': 'journals/corr/abs-2303-07624', 'ArXiv': '2303.07624', 'DOI': '10.1109/ICASSP49357.2023.10096662', 'CorpusId': 257505392}",https://www.semanticscholar.org/paper/48c6318dbcf9908cabe0023b8817566f34d0b466,I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition,"Transformer-based end-to-end speech recognition has achieved great success. However, the large footprint and computational overhead make it difficult to deploy these models in some real-world applications. Model compression techniques can reduce the model size and speed up inference, but the compressed model has a fixed architecture which might be suboptimal. We propose a novel Transformer encoder with Input-Dependent Dynamic Depth (I3D) to achieve strong performance-efficiency trade-offs. With a similar number of layers at inference time, I3D-based models outperform the vanilla Transformer and the static pruned model via iterative layer pruning. We also present interesting analysis on the gate probabilities and the input-dependency, which helps us better understand deep encoders.","IEEE International Conference on Acoustics, Speech, and Signal Processing",2023,39,8,0,True,"{'url': 'https://arxiv.org/pdf/2303.07624', 'status': None}","['Computer Science', 'Engineering']","{'pages': '1-5', 'name': 'ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)'}","[{'authorId': '2111014429', 'name': 'Yifan Peng'}, {'authorId': '3017896', 'name': 'Jaesong Lee'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}]","A novel Transformer encoder with Input-Dependent Dynamic Depth (I3D) to achieve strong performance-efficiency trade-offs and interesting analysis on the gate probabilities and the input-dependency, which helps to better understand deep encoders."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,4b8d3ede673ddeab9dfb5184da6b748d7a526754,"{'DBLP': 'conf/aaai/Chen0R23', 'ArXiv': '2302.04215', 'DOI': '10.48550/arXiv.2302.04215', 'CorpusId': 256662411}",https://www.semanticscholar.org/paper/4b8d3ede673ddeab9dfb5184da6b748d7a526754,A Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech,"Recent Text-to-Speech (TTS) systems trained on reading or acted corpora have achieved near human-level naturalness. The diversity of human speech, however, often goes beyond the coverage of these corpora. We believe the ability to handle such diversity is crucial for AI systems to achieve human-level communication. Our work explores the use of more abundant real-world data for building speech synthesizers. We train TTS systems using real-world speech from YouTube and podcasts. We observe the mismatch between training and inference alignments in mel-spectrogram based autoregressive models, leading to unintelligible synthesis, and demonstrate that learned discrete codes within multiple code groups effectively resolves this issue. We introduce our MQTTS system whose architecture is designed for multiple code generation and monotonic alignment, along with the use of a clean silence prompt to improve synthesis quality. We conduct ablation analyses to identify the efficacy of our methods. We show that MQTTS outperforms existing TTS systems in several objective and subjective measures.",AAAI Conference on Artificial Intelligence,2023,40,16,3,True,"{'url': 'http://arxiv.org/pdf/2302.04215', 'status': None}","['Computer Science', 'Engineering']","{'volume': 'abs/2302.04215', 'name': 'ArXiv'}","[{'authorId': '2119257114', 'name': 'Li-Wei Chen'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '1783635', 'name': 'Alexander I. Rudnicky'}]","This work introduces the MQTTS system, a Text-to-Speech system whose architecture is designed for multiple code generation and monotonic alignment, along with the use of a clean silence prompt to improve synthesis quality, and shows that MqTTS outperforms existing TTS systems in several objective and subjective measures."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,4d35540aaf993c8fa7e1fa5fc6a990f1eb830263,"{'DBLP': 'journals/corr/abs-2305-13331', 'ArXiv': '2305.13331', 'DOI': '10.48550/arXiv.2305.13331', 'CorpusId': 258841801}",https://www.semanticscholar.org/paper/4d35540aaf993c8fa7e1fa5fc6a990f1eb830263,A New Benchmark of Aphasia Speech Recognition and Detection Based on E-Branchformer and Multi-task Learning,"Aphasia is a language disorder that affects the speaking ability of millions of patients. This paper presents a new benchmark for Aphasia speech recognition and detection tasks using state-of-the-art speech recognition techniques with the AphsiaBank dataset. Specifically, we introduce two multi-task learning methods based on the CTC/Attention architecture to perform both tasks simultaneously. Our system achieves state-of-the-art speaker-level detection accuracy (97.3%), and a relative WER reduction of 11% for moderate Aphasia patients. In addition, we demonstrate the generalizability of our approach by applying it to another disordered speech database, the DementiaBank Pitt corpus. We will make our all-in-one recipes and pre-trained model publicly available to facilitate reproducibility. Our standardized data preprocessing pipeline and open-source recipes enable researchers to compare results directly, promoting progress in disordered speech processing.",Interspeech,2023,44,1,0,True,"{'url': 'http://arxiv.org/pdf/2305.13331', 'status': None}","['Engineering', 'Computer Science']","{'volume': 'abs/2305.13331', 'name': 'ArXiv'}","[{'authorId': '1677684712', 'name': 'Jiyang Tang'}, {'authorId': '2144302389', 'name': 'William Chen'}, {'authorId': '8776560', 'name': 'Xuankai Chang'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '2414040', 'name': 'B. MacWhinney'}]",A new benchmark for Aphasia speech recognition and detection tasks using state-of-the-art speech recognition techniques with the AphsiaBank dataset is presented and two multi-task learning methods based on the CTC/Attention architecture are introduced to perform both tasks simultaneously.
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,52d2c8d36c4ace01d8c440a44e1a7fdea04ec482,"{'PubMedCentral': '9861540', 'DOI': '10.3390/v15010244', 'CorpusId': 256055799, 'PubMed': '36680284'}",https://www.semanticscholar.org/paper/52d2c8d36c4ace01d8c440a44e1a7fdea04ec482,Antiviral Susceptibilities of Distinct Lineages of Influenza C and D Viruses,"The emergence and spread of antiviral-resistant influenza viruses are of great concern. To minimize the public health risk, it is important to monitor antiviral susceptibilities of influenza viruses. Analyses of the antiviral susceptibilities of influenza A and B viruses have been conducted globally; however, those of influenza C and D viruses are limited. Here, we determined the susceptibilities of influenza C viruses representing all six lineages (C/Taylor, C/Yamagata, C/Sao Paulo, C/Aichi, C/Kanagawa, and C/Mississippi) and influenza D viruses representing four lineages (D/OK, D/660, D/Yama2016, and D/Yama2019) to RNA polymerase inhibitors (baloxavir and favipiravir) by using a focus reduction assay. All viruses tested were susceptible to both drugs. We then performed a genetic analysis to check for amino acid substitutions associated with baloxavir and favipiravir resistance and found that none of the viruses tested possessed these substitutions. Use of the focus reduction assay with the genotypic assay has proven valuable for monitoring the antiviral susceptibilities of influenza C and D viruses as well as influenza A and B viruses. Antiviral susceptibility monitoring of all influenza virus types should continue in order to assess the public health risks posed by these viruses.",Viruses,2023,57,1,0,True,"{'url': 'https://www.mdpi.com/1999-4915/15/1/244/pdf?version=1674098063', 'status': None}",['Medicine'],"{'volume': '15', 'name': 'Viruses'}","[{'authorId': '4125173', 'name': 'E. Takashita'}, {'authorId': '2053168531', 'name': 'S. Murakami'}, {'authorId': '34776920', 'name': 'Y. Matsuzaki'}, {'authorId': '3830172', 'name': 'Seiichiro Fujisaki'}, {'authorId': '29374791', 'name': 'H. Morita'}, {'authorId': '32263706', 'name': 'Shiho Nagata'}, {'authorId': '1471243910', 'name': 'Misa Katayama'}, {'authorId': '37566144', 'name': 'K. Mizuta'}, {'authorId': '47736899', 'name': 'H. Nishimura'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '4561217', 'name': 'T. Horimoto'}, {'authorId': '1759434', 'name': 'H. Hasegawa'}]",Use of the focus reduction assay with the genotypic assay has proven valuable for monitoring the antiviral susceptibilities of influenza C and D viruses as well as influenza A and B viruses.
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,611f9ee6eef0936462cd78f371798d0699951c59,"{'ArXiv': '2302.08095', 'DBLP': 'conf/icassp/YangKBZHKWR23', 'DOI': '10.1109/ICASSP49357.2023.10096807', 'CorpusId': 256900649}",https://www.semanticscholar.org/paper/611f9ee6eef0936462cd78f371798d0699951c59,Paaploss: A Phonetic-Aligned Acoustic Parameter Loss for Speech Enhancement,"Despite rapid advancement in recent years, current speech enhancement models often produce speech that differs in perceptual quality from real clean speech. We propose a learning objective that formalizes differences in perceptual quality, by using domain knowledge of acoustic-phonetics. We identify temporal acoustic parameters – such as spectral tilt, spectral flux, shimmer, etc. – that are non-differentiable, and we develop a neural network estimator that can accurately predict their time-series values across an utterance. We also model phoneme-specific weights for each feature, as the acoustic parameters are known to show different behavior in different phonemes. We can add this criterion as an auxiliary loss to any model that produces speech, to optimize speech outputs to match the values of clean speech in these features. Experimentally we show that it improves speech enhancement workflows in both time-domain and time-frequency domain, as measured by standard evaluation metrics. We also provide an analysis of phoneme-dependent improvement on acoustic parameters, demonstrating the additional interpretability that our method provides. This analysis can suggest which features are currently the bottleneck for improvement.","IEEE International Conference on Acoustics, Speech, and Signal Processing",2023,38,3,0,True,"{'url': 'https://arxiv.org/pdf/2302.08095', 'status': None}","['Computer Science', 'Engineering']","{'pages': '1-5', 'name': 'ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)'}","[{'authorId': '72966973', 'name': 'Muqiao Yang'}, {'authorId': '2174668832', 'name': 'Joseph Konan'}, {'authorId': '2174668503', 'name': 'David Bick'}, {'authorId': '2111187803', 'name': 'YUNYANG ZENG'}, {'authorId': '2206298901', 'name': 'Shuo Han'}, {'authorId': '47311290', 'name': 'Anurag Kumar'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '1681921', 'name': 'B. Raj'}]","A learning objective is proposed that formalizes differences in perceptual quality, by using domain knowledge of acoustic-phonetics, and a neural network estimator is developed that can accurately predict their time-series values across an utterance."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,659be1ff350634f50cc066d258ee6a45e697e552,"{'DBLP': 'conf/sigmorphon/HeTR0MNL23', 'ACL': '2023.sigmorphon-1.22', 'DOI': '10.18653/v1/2023.sigmorphon-1.22', 'CorpusId': 259833803}",https://www.semanticscholar.org/paper/659be1ff350634f50cc066d258ee6a45e697e552,SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing,"In our submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), we explore approaches to data augmentation and modeling across seven low-resource languages. For data augmentation, we explore two approaches: creating artificial data from the provided training data and utilizing existing IGT resources in other languages. On the modeling side, we test an enhanced version of the provided token classification baseline as well as a pretrained multilingual seq2seq model. Additionally, we apply post-correction using a dictionary for Gitksan, the language with the smallest amount of data. We find that our token classification models are the best performing, with the highest word-level accuracy for Arapaho and highest morpheme-level accuracy for Gitksan out of all submissions. We also show that data augmentation is an effective strategy, though applying artificial data pretraining has very different effects across both models tested.",Special Interest Group on Computational Morphology and Phonology Workshop,2023,18,2,0,True,"{'url': 'https://aclanthology.org/2023.sigmorphon-1.22.pdf', 'status': None}",['Computer Science'],{'pages': '209-216'},"[{'authorId': '2107034039', 'name': 'Taiqi He'}, {'authorId': '2219036626', 'name': 'Lindia Tjuatja'}, {'authorId': '2067645226', 'name': 'Nathaniel R. Robinson'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '3407646', 'name': 'David R. Mortensen'}, {'authorId': '1700325', 'name': 'Graham Neubig'}, {'authorId': '145585627', 'name': 'L. Levin'}]","In this submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), approaches to data augmentation and modeling across seven low-resource languages are explored and token classification models are found to be the best performing."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,6c33625c7b0ffc37955921a145531d9d4eaee713,"{'DBLP': 'journals/corr/abs-2307-12231', 'ArXiv': '2307.12231', 'DOI': '10.1109/WASPAA58266.2023.10248096', 'CorpusId': 260125023}",https://www.semanticscholar.org/paper/6c33625c7b0ffc37955921a145531d9d4eaee713,Exploring the Integration of Speech Separation and Recognition with Self-Supervised Learning Representation,"Neural speech separation has made remarkable progress and its integration with automatic speech recognition (ASR) is an important direction towards realizing multi-speaker ASR. This work provides an insightful investigation of speech separation in reverberant and noisy-reverberant scenarios as an ASR front-end. In detail, we explore multi-channel separation methods, mask-based beamforming and complex spectral mapping, as well as the best features to use in the ASR back-end model. We employ the recent self-supervised learning representation (SSLR) as a feature and improve the recognition performance from the case with filterbank features. To further improve multi-speaker recognition performance, we present a carefully designed training strategy for integrating speech separation and recognition with SSLR. The proposed integration using TF-GridNet-based complex spectral mapping and WavLM-based SSLR achieves a 2.5% word error rate in reverberant WHAMR! test set, significantly outperforming an existing mask-based MVDR beamforming and filterbank integration (28.9%).",IEEE Workshop on Applications of Signal Processing to Audio and Acoustics,2023,46,1,0,True,"{'url': 'https://arxiv.org/pdf/2307.12231', 'status': None}","['Computer Science', 'Engineering']","{'pages': '1-5', 'name': '2023 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)'}","[{'authorId': '51298994', 'name': 'Yoshiki Masuyama'}, {'authorId': '8776560', 'name': 'Xuankai Chang'}, {'authorId': '2145114499', 'name': 'Wangyou Zhang'}, {'authorId': '1381145668', 'name': 'Samuele Cornell'}, {'authorId': '1732231', 'name': 'Zhongqiu Wang'}, {'authorId': '144101246', 'name': 'Nobutaka Ono'}, {'authorId': '2480051', 'name': 'Y. Qian'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}]","This work provides an insightful investigation of speech separation in reverberant and noisy-reverberant scenarios as an ASR front-end, and employs the recent self-supervised learning representation (SSLR) as a feature and improves the recognition performance from the case with filterbank features."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,786294f4008732a5dac9895a8507bc4c80450075,"{'DBLP': 'journals/corr/abs-2309-09510', 'ArXiv': '2309.09510', 'DOI': '10.48550/arXiv.2309.09510', 'CorpusId': 262046689}",https://www.semanticscholar.org/paper/786294f4008732a5dac9895a8507bc4c80450075,"Dynamic-SUPERB: Towards A Dynamic, Collaborative, and Comprehensive Instruction-Tuning Benchmark for Speech","Text language models have shown remarkable zero-shot capability in generalizing to unseen tasks when provided with well-formulated instructions. However, existing studies in speech processing primarily focus on limited or specific tasks. Moreover, the lack of standardized benchmarks hinders a fair comparison across different approaches. Thus, we present Dynamic-SUPERB, a benchmark designed for building universal speech models capable of leveraging instruction tuning to perform multiple tasks in a zero-shot fashion. To achieve comprehensive coverage of diverse speech tasks and harness instruction tuning, we invite the community to collaborate and contribute, facilitating the dynamic growth of the benchmark. To initiate, Dynamic-SUPERB features 55 evaluation instances by combining 33 tasks and 22 datasets. This spans a broad spectrum of dimensions, providing a comprehensive platform for evaluation. Additionally, we propose several approaches to establish benchmark baselines. These include the utilization of speech models, text language models, and the multimodal encoder. Evaluation results indicate that while these baselines perform reasonably on seen tasks, they struggle with unseen ones. We also conducted an ablation study to assess the robustness and seek improvements in the performance. We release all materials to the public and welcome researchers to collaborate on the project, advancing technologies in the field together.",arXiv.org,2023,43,4,0,True,"{'url': 'https://arxiv.org/pdf/2309.09510', 'status': None}","['Engineering', 'Computer Science']","{'volume': 'abs/2309.09510', 'name': 'ArXiv'}","[{'authorId': '2243803727', 'name': 'Chien-yu Huang'}, {'authorId': '2242945569', 'name': 'Ke-Han Lu'}, {'authorId': '2135571796', 'name': 'Shi Wang'}, {'authorId': '2242963687', 'name': 'Chi-Yuan Hsiao'}, {'authorId': '2243185910', 'name': 'Chun-Yi Kuan'}, {'authorId': '2243260548', 'name': 'Haibin Wu'}, {'authorId': '72401599', 'name': 'Siddhant Arora'}, {'authorId': '2782886', 'name': 'Kai-Wei Chang'}, {'authorId': '1485531923', 'name': 'Jiatong Shi'}, {'authorId': '2111014429', 'name': 'Yifan Peng'}, {'authorId': '145521253', 'name': 'Roshan Sharma'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '2243194988', 'name': 'Bhiksha Ramakrishnan'}, {'authorId': '2242892672', 'name': 'Shady Shehata'}, {'authorId': '2243359878', 'name': 'Hung-yi Lee'}]","This work presents Dynamic-SUPERB, a benchmark designed for building universal speech models capable of leveraging instruction tuning to perform multiple tasks in a zero-shot fashion, and invites the community to collaborate and contribute, facilitating the dynamic growth of the benchmark."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,7d4ad68dedff8c81e0fd9c08ea76b220a7e05d69,"{'ArXiv': '2302.06774', 'DBLP': 'conf/icassp/WuCCWGBA23', 'DOI': '10.1109/ICASSP49357.2023.10096796', 'CorpusId': 256846751}",https://www.semanticscholar.org/paper/7d4ad68dedff8c81e0fd9c08ea76b220a7e05d69,Speaker-Independent Acoustic-to-Articulatory Speech Inversion,"To build speech processing methods that can handle speech as naturally as humans, researchers have explored multiple ways of building an invertible mapping from speech to an interpretable space. The articulatory space is a promising inversion target, since this space captures the mechanics of speech production. To this end, we build an acoustic-to-articulatory inversion (AAI) model that leverages autoregression, adversarial training, and self supervision to generalize to unseen speakers. Our approach obtains 0.784 correlation on an electromagnetic articulography (EMA) dataset, improving the state-of-the-art by 12.5%. Additionally, we show the interpretability of these representations through directly com-paring the behavior of estimated representations with speech production behavior. Finally, we propose a resynthesis-based AAI evaluation metric that does not rely on articulatory labels, demonstrating its efficacy with an 18-speaker dataset.","IEEE International Conference on Acoustics, Speech, and Signal Processing",2023,40,10,1,True,"{'url': 'https://arxiv.org/pdf/2302.06774', 'status': None}","['Computer Science', 'Engineering']","{'pages': '1-5', 'name': 'ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)'}","[{'authorId': '2111194238', 'name': 'Peter Wu'}, {'authorId': '2119257114', 'name': 'Li-Wei Chen'}, {'authorId': '2064541737', 'name': 'Cheol Jun Cho'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '145965043', 'name': 'L. Goldstein'}, {'authorId': '1690706', 'name': 'A. Black'}, {'authorId': '1692246', 'name': 'G. Anumanchipalli'}]","This work builds an acoustic-to-articulatory inversion (AAI) model that leverages autoregression, adversarial training, and self supervision to generalize to unseen speakers, and proposes a resynthesis-based AAI evaluation metric that does not rely on articulatory labels."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,7f995454efda9f660d2258f59f6e19a2125e688e,"{'DBLP': 'journals/corr/abs-2309-08531', 'ArXiv': '2309.08531', 'DOI': '10.48550/arXiv.2309.08531', 'CorpusId': 262012495}",https://www.semanticscholar.org/paper/7f995454efda9f660d2258f59f6e19a2125e688e,Towards Practical and Efficient Image-to-Speech Captioning with Vision-Language Pre-training and Multi-modal Tokens,"In this paper, we propose methods to build a powerful and efficient Image-to-Speech captioning (Im2Sp) model. To this end, we start with importing the rich knowledge related to image comprehension and language modeling from a large-scale pre-trained vision-language model into Im2Sp. We set the output of the proposed Im2Sp as discretized speech units, i.e., the quantized speech features of a self-supervised speech model. The speech units mainly contain linguistic information while suppressing other characteristics of speech. This allows us to incorporate the language modeling capability of the pre-trained vision-language model into the spoken language modeling of Im2Sp. With the vision-language pre-training strategy, we set new state-of-the-art Im2Sp performances on two widely used benchmark databases, COCO and Flickr8k. Then, we further improve the efficiency of the Im2Sp model. Similar to the speech unit case, we convert the original image into image units, which are derived through vector quantization of the raw image. With these image units, we can drastically reduce the required data storage for saving image data to just 0.8% when compared to the original image data in terms of bits. Demo page: https://ms-dot-k.github.io/Image-to-Speech-Captioning.",arXiv.org,2023,50,2,0,True,"{'url': 'https://arxiv.org/pdf/2309.08531', 'status': None}","['Computer Science', 'Engineering']","{'volume': 'abs/2309.08531', 'name': 'ArXiv'}","[{'authorId': '2116506666', 'name': 'Minsu Kim'}, {'authorId': '11223968', 'name': 'J. Choi'}, {'authorId': '31949212', 'name': 'Soumi Maiti'}, {'authorId': '2161432446', 'name': 'Jeong Hun Yeo'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '2075377906', 'name': 'Y. Ro'}]","This paper starts with importing the rich knowledge related to image comprehension and language modeling from a large-scale pre-trained vision-language model into Im2Sp, and sets the output of the proposed Im2 Sp as discretized speech units, i.e., the quantized speech features of a self-supervised speech model."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,8402d64fde12cafaf8a1daa60de0acd1abedbffb,"{'DBLP': 'conf/icassp/ShiTLIWPW23', 'ArXiv': '2304.04618', 'DOI': '10.1109/ICASSP49357.2023.10095973', 'CorpusId': 258049341}",https://www.semanticscholar.org/paper/8402d64fde12cafaf8a1daa60de0acd1abedbffb,Enhancing Speech-To-Speech Translation with Multiple TTS Targets,"It has been known that direct speech-to-speech translation (S2ST) models usually suffer from the data scarcity issue because of the limited existing parallel materials for both source and target speech. Therefore to train a direct S2ST system, previous works usually utilize text-to-speech (TTS) systems to generate samples in the target language by augmenting the data from speech-to-text translation (S2TT). However, there is a limited investigation into how the synthesized target speech would affect the S2ST models. In this work, we analyze the effect of changing synthesized target speech for direct S2ST models. We find that simply combining the target speech from different TTS systems can potentially improve the S2ST performances. Following that, we also propose a multi-task framework that jointly optimizes the S2ST system with multiple targets from different TTS systems. Extensive experiments demonstrate that our proposed framework achieves consistent improvements (2.8 BLEU) over the baselines on the Fisher Spanish-English dataset.","IEEE International Conference on Acoustics, Speech, and Signal Processing",2023,38,3,0,True,"{'url': 'https://arxiv.org/pdf/2304.04618', 'status': None}","['Computer Science', 'Engineering']","{'pages': '1-5', 'name': 'ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)'}","[{'authorId': '1485531923', 'name': 'Jiatong Shi'}, {'authorId': '48066266', 'name': 'Yun Tang'}, {'authorId': '145732777', 'name': 'Ann Lee'}, {'authorId': '49276525', 'name': 'H. Inaguma'}, {'authorId': '20132361', 'name': 'Changhan Wang'}, {'authorId': '145503806', 'name': 'J. Pino'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}]","It is found that simply combining the target speech from different TTS systems can potentially improve the S2ST performances, and a multi-task framework is proposed that jointly optimizes the S1ST system with multiple targets from differentTTS systems."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,8bc617c9139648d7a92991d70c671230bac7b2e2,"{'DBLP': 'journals/corr/abs-2304-12995', 'ArXiv': '2304.12995', 'DOI': '10.48550/arXiv.2304.12995', 'CorpusId': 258309430}",https://www.semanticscholar.org/paper/8bc617c9139648d7a92991d70c671230bac7b2e2,"AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head","Large language models (LLMs) have exhibited remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. Despite the recent success, current LLMs are not capable of processing complex audio information or conducting spoken conversations (like Siri or Alexa). In this work, we propose a multi-modal AI system named AudioGPT, which complements LLMs (i.e., ChatGPT) with 1) foundation models to process complex audio information and solve numerous understanding and generation tasks; and 2) the input/output interface (ASR, TTS) to support spoken dialogue. With an increasing demand to evaluate multi-modal LLMs of human intention understanding and cooperation with foundation models, we outline the principles and processes and test AudioGPT in terms of consistency, capability, and robustness. Experimental results demonstrate the capabilities of AudioGPT in solving AI tasks with speech, music, sound, and talking head understanding and generation in multi-round dialogues, which empower humans to create rich and diverse audio content with unprecedented ease. Our system is publicly available at \url{https://github.com/AIGC-Audio/AudioGPT}.",arXiv.org,2023,46,78,5,True,"{'url': 'http://arxiv.org/pdf/2304.12995', 'status': None}","['Computer Science', 'Engineering']","{'volume': 'abs/2304.12995', 'name': 'ArXiv'}","[{'authorId': '2048021099', 'name': 'Rongjie Huang'}, {'authorId': '2112108864', 'name': 'Mingze Li'}, {'authorId': '1752879605', 'name': 'Dongchao Yang'}, {'authorId': '1485531923', 'name': 'Jiatong Shi'}, {'authorId': '8776560', 'name': 'Xuankai Chang'}, {'authorId': '1704406169', 'name': 'Zhenhui Ye'}, {'authorId': '2166452418', 'name': 'Yuning Wu'}, {'authorId': '2215274532', 'name': 'Zhiqing Hong'}, {'authorId': '3068086', 'name': 'Jia-Bin Huang'}, {'authorId': '48211720', 'name': 'Jinglin Liu'}, {'authorId': '2165186676', 'name': 'Yixiang Ren'}, {'authorId': '2156163667', 'name': 'Zhou Zhao'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}]","A multi-modal AI system named AudioGPT is proposed, which complements LLMs with 1) foundation models to process complex audio information and solve numerous understanding and generation tasks; and 2) the input/output interface (ASR, TTS) to support spoken dialogue."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,8f0a24d1678e4d0e584b0932196cd257d5c53c7d,"{'DBLP': 'journals/corr/abs-2309-17352', 'ArXiv': '2309.17352', 'DOI': '10.48550/arXiv.2309.17352', 'CorpusId': 263310763}",https://www.semanticscholar.org/paper/8f0a24d1678e4d0e584b0932196cd257d5c53c7d,"Improving Audio Captioning Models with Fine-grained Audio Features, Text Embedding Supervision, and LLM Mix-up Augmentation","Automated audio captioning (AAC) aims to generate informative descriptions for various sounds from nature and/or human activities. In recent years, AAC has quickly attracted research interest, with state-of-the-art systems now relying on a sequence-to-sequence (seq2seq) backbone powered by strong models such as Transformers. Following the macro-trend of applied machine learning research, in this work, we strive to improve the performance of seq2seq AAC models by extensively leveraging pretrained models and large language models (LLMs). Specifically, we utilize BEATs to extract fine-grained audio features. Then, we employ Instructor LLM to fetch text embeddings of captions, and infuse their language-modality knowledge into BEATs audio features via an auxiliary InfoNCE loss function. Moreover, we propose a novel data augmentation method that uses ChatGPT to produce caption mix-ups (i.e., grammatical and compact combinations of two captions) which, together with the corresponding audio mixtures, increase not only the amount but also the complexity and diversity of training data. During inference, we propose to employ nucleus sampling and a hybrid reranking algorithm, which has not been explored in AAC research. Combining our efforts, our model achieves a new state-of-the-art 32.6 SPIDEr-FL score on the Clotho evaluation split, and wins the 2023 DCASE AAC challenge.",arXiv.org,2023,39,2,1,True,"{'url': 'https://arxiv.org/pdf/2309.17352', 'status': None}","['Computer Science', 'Engineering']","{'volume': 'abs/2309.17352', 'name': 'ArXiv'}","[{'authorId': '2249540754', 'name': 'Shih-Lun Wu'}, {'authorId': '8776560', 'name': 'Xuankai Chang'}, {'authorId': '1816785', 'name': 'G. Wichern'}, {'authorId': '2241324376', 'name': 'Jee-weon Jung'}, {'authorId': '2189478002', 'name': 'Franccois G. Germain'}, {'authorId': '2067299136', 'name': 'Jonathan Le Roux'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}]",This work utilizes BEATs to extract fine-grained audio features and proposes a novel data augmentation method that uses ChatGPT to produce caption mix-ups which increase not only the amount but also the complexity and diversity of training data.
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,91a06713cbccbfb1b5e1b9f7b62a1fba348616c3,"{'DBLP': 'journals/corr/abs-2309-07937', 'ArXiv': '2309.07937', 'DOI': '10.48550/arXiv.2309.07937', 'CorpusId': 261881790}",https://www.semanticscholar.org/paper/91a06713cbccbfb1b5e1b9f7b62a1fba348616c3,Voxtlm: unified decoder-only models for consolidating speech recognition/synthesis and speech/text continuation tasks,"We propose a decoder-only language model, VoxtLM, that can perform four tasks: speech recognition, speech synthesis, text generation, and speech continuation. VoxtLM integrates text vocabulary with discrete speech tokens from self-supervised speech features and uses special tokens to enable multitask learning. Compared to a single-task model, VoxtLM exhibits a significant improvement in speech synthesis, with improvements in both speech intelligibility from 28.9 to 5.6 and objective quality from 2.68 to 3.90. VoxtLM also improves speech generation and speech recognition performance over the single-task counterpart. Further, VoxtLM is trained with publicly available data and training recipes and model checkpoints are open-sourced to make fully reproducible work.",arXiv.org,2023,40,5,0,True,"{'url': 'https://arxiv.org/pdf/2309.07937', 'status': None}","['Engineering', 'Computer Science']","{'volume': 'abs/2309.07937', 'name': 'ArXiv'}","[{'authorId': '31949212', 'name': 'Soumi Maiti'}, {'authorId': '2111014429', 'name': 'Yifan Peng'}, {'authorId': '2184409452', 'name': 'Shukjae Choi'}, {'authorId': '2241324376', 'name': 'Jee-weon Jung'}, {'authorId': '8776560', 'name': 'Xuankai Chang'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}]","A decoder-only language model that can perform four tasks: speech recognition, speech synthesis, text generation, and speech continuation, VoxtLM is proposed, which exhibits a significant improvement in speech synthesis and improves speech intelligibility and objective quality."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,95aac8fe824bd0c83de594af0bf9d259e2416f53,"{'DBLP': 'journals/corr/abs-2301-12596', 'ArXiv': '2301.12596', 'DOI': '10.48550/arXiv.2301.12596', 'CorpusId': 256390096}",https://www.semanticscholar.org/paper/95aac8fe824bd0c83de594af0bf9d259e2416f53,Learning to Speak from Text: Zero-Shot Multilingual Text-to-Speech with Unsupervised Text Pretraining,"While neural text-to-speech (TTS) has achieved human-like natural synthetic speech, multilingual TTS systems are limited to resource-rich languages due to the need for paired text and studio-quality audio data. This paper proposes a method for zero-shot multilingual TTS using text-only data for the target language. The use of text-only data allows the development of TTS systems for low-resource languages for which only textual resources are available, making TTS accessible to thousands of languages. Inspired by the strong cross-lingual transferability of multilingual language models, our framework first performs masked language model pretraining with multilingual text-only data. Then we train this model with a paired data in a supervised manner, while freezing a language-aware embedding layer. This allows inference even for languages not included in the paired data but present in the text-only data. Evaluation results demonstrate highly intelligible zero-shot TTS with a character error rate of less than 12% for an unseen language.",International Joint Conference on Artificial Intelligence,2023,68,4,1,True,"{'url': 'http://arxiv.org/pdf/2301.12596', 'status': None}","['Computer Science', 'Engineering']",{'pages': '5179-5187'},"[{'authorId': '32078983', 'name': 'Takaaki Saeki'}, {'authorId': '31949212', 'name': 'Soumi Maiti'}, {'authorId': '47058260', 'name': 'Xinjian Li'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '2424104', 'name': 'Shinnosuke Takamichi'}, {'authorId': '1685827', 'name': 'H. Saruwatari'}]","Inspired by the strong cross-lingual transferability of multilingual language models, this framework first performs masked language model pretraining with multilingual text-only data, and trains this model with a paired data in a supervised manner, while freezing a language-aware embedding layer."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,9cbd933c04218c9b642c15a49f8470d54524d9fb,"{'DBLP': 'conf/icassp/WangCCLKW23a', 'ArXiv': '2304.08707', 'DOI': '10.1109/ICASSP49357.2023.10095700', 'CorpusId': 258187590}",https://www.semanticscholar.org/paper/9cbd933c04218c9b642c15a49f8470d54524d9fb,FNeural Speech Enhancement with Very Low Algorithmic Latency and Complexity via Integrated full- and sub-band Modeling,"We propose FSB-LSTM, a novel long short-term memory (LSTM) based architecture that integrates full- and sub-band (FSB) modeling, for single- and multi-channel speech enhancement in the short-time Fourier transform (STFT) domain. The model maintains an information highway to flow an over-complete input representation through multiple FSB-LSTM modules. Each FSB-LSTM module consists of a full-band block to model spectro-temporal patterns at all frequencies and a sub-band block to model patterns within each sub-band, where each of the two blocks takes a down-sampled representation as input and returns an up-sampled discriminative representation to be added to the block input via a residual connection. The model is designed to have a low algorithmic complexity, a small run-time buffer and a very low algorithmic latency, at the same time producing a strong enhancement performance on a noisy-reverberant speech enhancement task even if the hop size is as low as 2 ms.","IEEE International Conference on Acoustics, Speech, and Signal Processing",2023,47,6,0,True,,"['Engineering', 'Computer Science']","{'pages': '1-5', 'name': 'ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)'}","[{'authorId': '1732231', 'name': 'Zhongqiu Wang'}, {'authorId': '1381145668', 'name': 'Samuele Cornell'}, {'authorId': '2184409452', 'name': 'Shukjae Choi'}, {'authorId': '18016679', 'name': 'Younglo Lee'}, {'authorId': '2109885529', 'name': 'Byeonghak Kim'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}]","The proposed FSB-LSTM model is designed to have a low algorithmic complexity, a small run-time buffer and a very lowgorithmic latency, at the same time producing a strong enhancement performance on a noisy-reverberant speech enhancement task even if the hop size is as low as 2 ms."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,9dcfb422f6057725b1585caf820e128c91d6dbb3,"{'DBLP': 'conf/icassp/ChenYSPMW23', 'ArXiv': '2302.12829', 'DOI': '10.1109/ICASSP49357.2023.10095326', 'CorpusId': 257206070}",https://www.semanticscholar.org/paper/9dcfb422f6057725b1585caf820e128c91d6dbb3,Improving Massively Multilingual ASR with Auxiliary CTC Objectives,"Multilingual Automatic Speech Recognition (ASR) models have extended the usability of speech technologies to a wide variety of languages. With how many languages these models have to handle, however, a key to understanding their imbalanced performance across different languages is to examine if the model actually knows which language it should transcribe. In this paper, we introduce our work on improving performance on FLEURS, a 102-language open ASR benchmark, by conditioning the entire model on language identity (LID). We investigate techniques inspired from recent Connectionist Temporal Classification (CTC) studies to help the model handle the large number of languages, conditioning on the LID predictions of auxiliary tasks. Our experimental results demonstrate the effectiveness of our technique over standard CTC/Attention-based hybrid models. Furthermore, our state-of-the-art systems using self-supervised models with the Conformer architecture improve over the results of prior work on FLEURS by a relative 28.4% CER. Trained models are reproducible recipes are available at https://github.com/espnet/espnet/tree/master/egs2/fleurs/asr1.","IEEE International Conference on Acoustics, Speech, and Signal Processing",2023,50,17,0,True,"{'url': 'https://arxiv.org/pdf/2302.12829', 'status': None}","['Computer Science', 'Engineering']","{'pages': '1-5', 'name': 'ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)'}","[{'authorId': '2144302389', 'name': 'William Chen'}, {'authorId': '2087059555', 'name': 'Brian Yan'}, {'authorId': '1485531923', 'name': 'Jiatong Shi'}, {'authorId': '2111014429', 'name': 'Yifan Peng'}, {'authorId': '31949212', 'name': 'Soumi Maiti'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}]","This work introduces work on improving performance on FLEURS, a 102-language open ASR benchmark, by conditioning the entire model on language identity (LID), and investigates techniques inspired from recent Connectionist Temporal Classification studies to help the model handle the large number of languages."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,a5ab124e57d1f26436821588aacd7d75b831259c,"{'ArXiv': '2309.17384', 'DBLP': 'conf/asru/ZhangSWWQ23', 'DOI': '10.1109/ASRU57964.2023.10389733', 'CorpusId': 263310398}",https://www.semanticscholar.org/paper/a5ab124e57d1f26436821588aacd7d75b831259c,Toward Universal Speech Enhancement For Diverse Input Conditions,"The past decade has witnessed substantial growth of data-driven speech enhancement (SE) techniques thanks to deep learning. While existing approaches have shown impressive performance in some common datasets, most of them are designed only for a single condition (e.g., single-channel, multi-channel, or a fixed sampling frequency) or only consider a single task (e.g., denoising or dereverberation). Currently, there is no universal SE approach that can effectively handle diverse input conditions with a single model. In this paper, we make the first attempt to investigate this line of research. First, we devise a single SE model that is independent of microphone channels, signal lengths, and sampling frequencies. Second, we design a universal SE benchmark by combining existing public corpora with multiple conditions. Our experiments on a wide range of datasets show that the proposed single model can successfully handle diverse conditions with strong performance.",Automatic Speech Recognition & Understanding,2023,46,3,0,True,"{'url': 'https://arxiv.org/pdf/2309.17384', 'status': None}","['Computer Science', 'Engineering']","{'pages': '1-6', 'name': '2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)'}","[{'authorId': '2145114499', 'name': 'Wangyou Zhang'}, {'authorId': '2242998209', 'name': 'Kohei Saijo'}, {'authorId': '12229660', 'name': 'Zhong-Qiu Wang'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '2249733239', 'name': 'Yanmin Qian'}]","This paper devise a single SE model that is independent of microphone channels, signal lengths, and sampling frequencies, and designs a universal SE benchmark by combining existing public corpora with multiple conditions."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,b4855ff933fb80846638469a1b43c1766df85d78,"{'DBLP': 'conf/icassp/FutamiHAWKPYTW23', 'ArXiv': '2305.01194', 'DOI': '10.1109/ICASSP49357.2023.10096049', 'CorpusId': 258437228}",https://www.semanticscholar.org/paper/b4855ff933fb80846638469a1b43c1766df85d78,The Pipeline System of ASR and NLU with MLM-based data Augmentation Toward Stop Low-Resource Challenge,"This paper describes our system for the low-resource domain adaptation track (Track 3) in Spoken Language Understanding Grand Challenge, which is a part of ICASSP Signal Processing Grand Challenge 2023. In the track, we adopt a pipeline approach of ASR and NLU. For ASR, we fine-tune Whisper for each domain with upsampling. For NLU, we fine-tune BART on all the Track3 data and then on low-resource domain data. We apply masked LM (MLM) -based data augmentation, where some of input tokens and corresponding target labels are replaced using MLM. We also apply a retrieval-based approach, where model input is augmented with similar training samples. As a result, we achieved exact match (EM) accuracy 63.3/75.0 (average: 69.15) for reminder/weather domain, and won the 1st place at the challenge.","IEEE International Conference on Acoustics, Speech, and Signal Processing",2023,6,2,1,True,"{'url': 'https://arxiv.org/pdf/2305.01194', 'status': None}","['Computer Science', 'Engineering']","{'pages': '1-2', 'name': 'ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)'}","[{'authorId': '1866674954', 'name': 'Hayato Futami'}, {'authorId': '50306945', 'name': 'Jessica Huynh'}, {'authorId': '72401599', 'name': 'Siddhant Arora'}, {'authorId': '1854017630', 'name': 'Shih-Lun Wu'}, {'authorId': '3165422', 'name': 'Yosuke Kashiwagi'}, {'authorId': '2111014429', 'name': 'Yifan Peng'}, {'authorId': '2087059555', 'name': 'Brian Yan'}, {'authorId': '2779505', 'name': 'E. Tsunoo'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}]","This system for the low-resource domain adaptation track (Track 3) in Spoken Language Understanding Grand Challenge, which is a part of ICASSP Signal Processing Grand Challenge 2023, adopts a pipeline approach of ASR and NLU and applies masked LM (MLM) -based data augmentation."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,b524ec331cd9708b125fad70d95d36189fa0d7b6,"{'DBLP': 'journals/corr/abs-2305-01620', 'ArXiv': '2305.01620', 'DOI': '10.1109/ICASSP49357.2023.10096175', 'CorpusId': 258437036}",https://www.semanticscholar.org/paper/b524ec331cd9708b125fad70d95d36189fa0d7b6,A Study on the Integration of Pipeline and E2E SLU Systems for Spoken Semantic Parsing Toward Stop Quality Challenge,"Recently there have been efforts to introduce new benchmark tasks for spoken language understanding (SLU), like semantic parsing. In this paper, we describe our proposed spoken semantic parsing system for the quality track (Track 1) in Spoken Language Understanding Grand Challenge which is part of ICASSP Signal Processing Grand Challenge 2023. We experiment with both end-to-end and pipeline systems for this task. Strong automatic speech recognition (ASR) models like Whisper and pretrained Language models (LM) like BART are utilized inside our SLU framework to boost performance. We also investigate the output level combination of various models to get an exact match accuracy of 80.8, which won the 1st place at the challenge.","IEEE International Conference on Acoustics, Speech, and Signal Processing",2023,5,4,1,True,"{'url': 'https://arxiv.org/pdf/2305.01620', 'status': None}","['Computer Science', 'Engineering']","{'pages': '1-2', 'name': 'ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)'}","[{'authorId': '72401599', 'name': 'Siddhant Arora'}, {'authorId': '1866674954', 'name': 'Hayato Futami'}, {'authorId': '1854017630', 'name': 'Shih-Lun Wu'}, {'authorId': '50306945', 'name': 'Jessica Huynh'}, {'authorId': '2111014429', 'name': 'Yifan Peng'}, {'authorId': '3165422', 'name': 'Yosuke Kashiwagi'}, {'authorId': '2779505', 'name': 'E. Tsunoo'}, {'authorId': '2087059555', 'name': 'Brian Yan'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}]",This paper describes the proposed spoken semantic parsing system for the quality track (Track 1) in Spoken Language Understanding Grand Challenge which is part of ICASSP Signal Processing Grand Challenge 2023.
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,b88a84fb2d35eecb5149caa3d0596942ae0a5a54,"{'PubMedCentral': '10540515', 'DOI': '10.2807/1560-7917.ES.2023.28.39.2300501', 'CorpusId': 263092306, 'PubMed': '37768560'}",https://www.semanticscholar.org/paper/b88a84fb2d35eecb5149caa3d0596942ae0a5a54,"A community cluster of influenza A(H3N2) virus infection with reduced susceptibility to baloxavir due to a PA E199G substitution in Japan, February to March 2023","A community cluster of influenza A(H3N2) caused by viruses with an E199G substitution in PA was detected in Nara, Japan, between February and March 2023. The three patients with these mutant viruses had not received antiviral treatment before specimen collection but patients in the same hospital had. The sequences of the mutant viruses were closely related, suggesting clonal spread in Nara. They showed reduced susceptibility to baloxavir in vitro; however, the clinical significance of the PA E199G substitution remains unclear.",Euro surveillance : bulletin Europeen sur les maladies transmissibles = European communicable disease bulletin,2023,18,2,0,True,"{'url': 'https://www.eurosurveillance.org/deliver/fulltext/eurosurveillance/28/39/eurosurv-28-39-1.pdf?itemId=%2Fcontent%2F10.2807%2F1560-7917.ES.2023.28.39.2300501&mimeType=pdf&containerItemId=content/eurosurveillance', 'status': None}",['Medicine'],"{'volume': '28', 'name': 'Eurosurveillance'}","[{'authorId': '4125173', 'name': 'E. Takashita'}, {'authorId': '3830172', 'name': 'Seiichiro Fujisaki'}, {'authorId': '29374791', 'name': 'H. Morita'}, {'authorId': '32263706', 'name': 'Shiho Nagata'}, {'authorId': '143940858', 'name': 'H. Miura'}, {'authorId': '2247877473', 'name': 'Yuki Matsuura'}, {'authorId': '2247828833', 'name': 'Saya Yamamoto'}, {'authorId': '2248025810', 'name': 'Shoko Chiba'}, {'authorId': '2247762905', 'name': 'Yumiko Inoue'}, {'authorId': '2248018904', 'name': 'Iori Minami'}, {'authorId': '2247954558', 'name': 'Sayaka Yoshikawa'}, {'authorId': '2248025022', 'name': 'Seiko Yamazaki'}, {'authorId': '1870898', 'name': 'N. Kishida'}, {'authorId': '2249073204', 'name': 'Kazuya Nakamura'}, {'authorId': '3965671', 'name': 'Masayuki Shirakura'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '2247942746', 'name': 'Hideki Hasegawa'}]","A community cluster of influenza A(H3N2) caused by viruses with an E199G substitution in PA was detected in Nara, Japan, between February and March 2023 and showed reduced susceptibility to baloxavir in vitro; however, the clinical significance remains unclear."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,bb4c59fc93d5be6b3d85dfde9d08e3dab80db9b7,"{'DBLP': 'journals/corr/abs-2309-15800', 'ArXiv': '2309.15800', 'DOI': '10.48550/arXiv.2309.15800', 'CorpusId': 263152563}",https://www.semanticscholar.org/paper/bb4c59fc93d5be6b3d85dfde9d08e3dab80db9b7,"Exploring Speech Recognition, Translation, and Understanding with Discrete Speech Units: A Comparative Study","Speech signals, typically sampled at rates in the tens of thousands per second, contain redundancies, evoking inefficiencies in sequence modeling. High-dimensional speech features such as spectrograms are often used as the input for the subsequent model. However, they can still be redundant. Recent investigations proposed the use of discrete speech units derived from self-supervised learning representations, which significantly compresses the size of speech data. Applying various methods, such as de-duplication and subword modeling, can further compress the speech sequence length. Hence, training time is significantly reduced while retaining notable performance. In this study, we undertake a comprehensive and systematic exploration into the application of discrete units within end-to-end speech processing models. Experiments on 12 automatic speech recognition, 3 speech translation, and 1 spoken language understanding corpora demonstrate that discrete units achieve reasonably good results in almost all the settings. We intend to release our configurations and trained models to foster future research efforts.",arXiv.org,2023,46,2,0,True,"{'url': 'https://arxiv.org/pdf/2309.15800', 'status': None}","['Computer Science', 'Engineering']","{'volume': 'abs/2309.15800', 'name': 'ArXiv'}","[{'authorId': '8776560', 'name': 'Xuankai Chang'}, {'authorId': '2087059555', 'name': 'Brian Yan'}, {'authorId': '2249554647', 'name': 'Kwanghee Choi'}, {'authorId': '2241324376', 'name': 'Jee-weon Jung'}, {'authorId': '2247958791', 'name': 'Yichen Lu'}, {'authorId': '31949212', 'name': 'Soumi Maiti'}, {'authorId': '145521253', 'name': 'Roshan Sharma'}, {'authorId': '1485531923', 'name': 'Jiatong Shi'}, {'authorId': '2247862832', 'name': 'Jinchuan Tian'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '1471364901', 'name': 'Yuya Fujita'}, {'authorId': '1816126', 'name': 'Takashi Maekaku'}, {'authorId': '2248240556', 'name': 'Pengcheng Guo'}, {'authorId': '2247967767', 'name': 'Yao-Fei Cheng'}, {'authorId': '51151648', 'name': 'Pavel Denisov'}, {'authorId': '2242998209', 'name': 'Kohei Saijo'}, {'authorId': '1390775387', 'name': 'Hsiu-Hsuan Wang'}]","This study undertake a comprehensive and systematic exploration into the application of discrete units within end-to-end speech processing models, demonstrating that discrete units achieve reasonably good results in almost all the settings."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,bc3690edd40cc9946f8162727b357b926d1127bc,"{'DBLP': 'journals/corr/abs-2305-00926', 'ArXiv': '2305.00926', 'DOI': '10.1109/ICASSP49357.2023.10095055', 'CorpusId': 258426270}",https://www.semanticscholar.org/paper/bc3690edd40cc9946f8162727b357b926d1127bc,Joint Modelling of Spoken Language Understanding Tasks with Integrated Dialog History,"Most human interactions occur in the form of spoken conversations where the semantic meaning of a given utterance depends on the context. Each utterance in spoken conversation can be represented by many semantic and speaker attributes, and there has been an interest in building Spoken Language Understanding (SLU) systems for automatically predicting these attributes. Recent work has shown that incorporating dialogue history can help advance SLU performance. However, separate models are used for each SLU task, leading to an increase in inference time and computation cost. Motivated by this, we aim to ask: can we jointly model all the SLU tasks while incorporating context to facilitate low-latency and lightweight inference? To answer this, we propose a novel model architecture that learns dialog context to jointly predict the intent, dialog act, speaker role, and emotion for the spoken utterance. Note that our joint prediction is based on an autoregressive model and we need to decide the prediction order of dialog attributes, which is not trivial. To mitigate the issue, we also propose an order agnostic training method. Our experiments show that our joint model achieves similar results to task-specific classifiers and can effectively integrate dialog context to further improve the SLU performance.1","IEEE International Conference on Acoustics, Speech, and Signal Processing",2023,43,2,0,True,"{'url': 'https://arxiv.org/pdf/2305.00926', 'status': None}","['Computer Science', 'Engineering']","{'pages': '1-5', 'name': 'ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)'}","[{'authorId': '72401599', 'name': 'Siddhant Arora'}, {'authorId': '1866674954', 'name': 'Hayato Futami'}, {'authorId': '2779505', 'name': 'E. Tsunoo'}, {'authorId': '2087059555', 'name': 'Brian Yan'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}]","A novel model architecture is proposed that learns dialog context to jointly predict the intent, dialog act, speaker role, and emotion for the spoken utterance and achieves similar results to task-specific classifiers and can effectively integrateDialog context to further improve the SLU performance."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,c2745e86ecc9bec372690cced53ccfdf44f407f8,"{'DBLP': 'journals/corr/abs-2309-15686', 'ArXiv': '2309.15686', 'DOI': '10.48550/arXiv.2309.15686', 'CorpusId': 263152687}",https://www.semanticscholar.org/paper/c2745e86ecc9bec372690cced53ccfdf44f407f8,Enhancing End-to-End Conversational Speech Translation Through Target Language Context Utilization,"Incorporating longer context has been shown to benefit machine translation, but the inclusion of context in end-to-end speech translation (E2E-ST) remains under-studied. To bridge this gap, we introduce target language context in E2E-ST, enhancing coherence and overcoming memory constraints of extended audio segments. Additionally, we propose context dropout to ensure robustness to the absence of context, and further improve performance by adding speaker information. Our proposed contextual E2E-ST outperforms the isolated utterance-based E2E-ST approach. Lastly, we demonstrate that in conversational speech, contextual information primarily contributes to capturing context style, as well as resolving anaphora and named entities.",arXiv.org,2023,38,0,0,True,"{'url': 'https://arxiv.org/pdf/2309.15686', 'status': None}","['Computer Science', 'Engineering']","{'volume': 'abs/2309.15686', 'name': 'ArXiv'}","[{'authorId': '152885017', 'name': 'A. Hussein'}, {'authorId': '2087059555', 'name': 'Brian Yan'}, {'authorId': '49513989', 'name': 'Antonios Anastasopoulos'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '2803071', 'name': 'S. Khudanpur'}]","This work introduces target language context in E2E-ST, enhancing coherence and overcoming memory constraints of extended audio segments, and proposes context dropout to ensure robustness to the absence of context, and improves performance by adding speaker information."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,c6f5da5eb57457457a49256f1434bf1db23d1898,"{'DOI': '10.5650/oleoscience.23.29', 'CorpusId': 255715394}",https://www.semanticscholar.org/paper/c6f5da5eb57457457a49256f1434bf1db23d1898,Challenges of Corporate Alliance CLOMA toward Plastic Litter,,Oleoscience,2023,1,0,0,True,"{'url': 'https://www.jstage.jst.go.jp/article/oleoscience/23/1/23_29/_pdf', 'status': None}",,{'name': 'Oleoscience'},"[{'authorId': '1746678', 'name': 'Shinji Watanabe'}]",TLDR not found
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,c823c04a6488673f936d72906130f170017288d0,"{'ArXiv': '2309.08348', 'DBLP': 'journals/corr/abs-2309-08348', 'DOI': '10.48550/arXiv.2309.08348', 'CorpusId': 262012690}",https://www.semanticscholar.org/paper/c823c04a6488673f936d72906130f170017288d0,The Multimodal Information Based Speech Processing (MISP) 2023 Challenge: Audio-Visual Target Speaker Extraction,"Previous Multimodal Information based Speech Processing (MISP) challenges mainly focused on audio-visual speech recognition (AVSR) with commendable success. However, the most advanced back-end recognition systems often hit performance limits due to the complex acoustic environments. This has prompted a shift in focus towards the Audio-Visual Target Speaker Extraction (AVTSE) task for the MISP 2023 challenge in ICASSP 2024 Signal Processing Grand Challenges. Unlike existing audio-visual speech enhance-ment challenges primarily focused on simulation data, the MISP 2023 challenge uniquely explores how front-end speech processing, combined with visual clues, impacts back-end tasks in real-world scenarios. This pioneering effort aims to set the first benchmark for the AVTSE task, offering fresh insights into enhancing the ac-curacy of back-end speech recognition systems through AVTSE in challenging and real acoustic environments. This paper delivers a thorough overview of the task setting, dataset, and baseline system of the MISP 2023 challenge. It also includes an in-depth analysis of the challenges participants may encounter. The experimental results highlight the demanding nature of this task, and we look forward to the innovative solutions participants will bring forward.",arXiv.org,2023,26,1,1,True,"{'url': 'https://arxiv.org/pdf/2309.08348', 'status': None}","['Engineering', 'Computer Science']","{'volume': 'abs/2309.08348', 'name': 'ArXiv'}","[{'authorId': '2142349204', 'name': 'Shilong Wu'}, {'authorId': '2204867112', 'name': 'Chenxi Wang'}, {'authorId': '1652999406', 'name': 'Hang Chen'}, {'authorId': '2243187679', 'name': 'Yusheng Dai'}, {'authorId': '2216401229', 'name': 'Chenyue Zhang'}, {'authorId': '2243015956', 'name': 'Ruoyu Wang'}, {'authorId': '2242713354', 'name': 'Hongbo Lan'}, {'authorId': '2243402278', 'name': 'Jun Du'}, {'authorId': '2244118958', 'name': 'Chin-Hui Lee'}, {'authorId': '47740218', 'name': 'Jingdong Chen'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '1709878', 'name': 'Sabato Marco Siniscalchi'}, {'authorId': '1700735', 'name': 'O. Scharenborg'}, {'authorId': '12229660', 'name': 'Zhong-Qiu Wang'}, {'authorId': '1391149412', 'name': 'Jia Pan'}, {'authorId': '145702494', 'name': 'Jianqing Gao'}]","A thorough overview of the task setting, dataset, and baseline system of the MISP 2023 challenge is delivered, offering fresh insights into enhancing the ac-curacy of back-end speech recognition systems through AVTSE in challenging and real acoustic environments."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,d43338451cd8676548811e1ff8f9c92ea987c5bd,"{'DBLP': 'journals/corr/abs-2309-13876', 'ArXiv': '2309.13876', 'DOI': '10.1109/ASRU57964.2023.10389676', 'CorpusId': 262465225}",https://www.semanticscholar.org/paper/d43338451cd8676548811e1ff8f9c92ea987c5bd,Reproducing Whisper-Style Training Using An Open-Source Toolkit And Publicly Available Data,"Pre-training speech models on large volumes of data has achieved remarkable success. OpenAI Whisper is a multilingual multitask model trained on 680k hours of supervised speech data. It generalizes well to various speech recognition and translation benchmarks even in a zero-shot setup. However, the full pipeline for developing such models (from data collection to training) is not publicly accessible, which makes it difficult for researchers to further improve its performance and address training-related issues such as efficiency, robustness, fairness, and bias. This work presents an Open Whisper-style Speech Model (OWSM), which reproduces Whisperstyle training using an open-source toolkit and publicly available data. OWSM even supports more translation directions and can be more efficient to train. We will publicly release all scripts used for data preparation, training, inference, and scoring as well as pretrained models and training logs to promote open science. 11https://github.com/espnet/espnet",Automatic Speech Recognition & Understanding,2023,70,1,0,True,"{'url': 'https://arxiv.org/pdf/2309.13876', 'status': None}","['Computer Science', 'Engineering']","{'pages': '1-8', 'name': '2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)'}","[{'authorId': '2111014429', 'name': 'Yifan Peng'}, {'authorId': '2087131860', 'name': 'Jinchuan Tian'}, {'authorId': '2087059555', 'name': 'Brian Yan'}, {'authorId': '2142561945', 'name': 'Dan Berrebbi'}, {'authorId': '8776560', 'name': 'Xuankai Chang'}, {'authorId': '2108191722', 'name': 'Xinjian Li'}, {'authorId': '1485531923', 'name': 'Jiatong Shi'}, {'authorId': '72401599', 'name': 'Siddhant Arora'}, {'authorId': '2144302389', 'name': 'William Chen'}, {'authorId': '145521253', 'name': 'Roshan Sharma'}, {'authorId': '1390725481', 'name': 'Wangyou Zhang'}, {'authorId': '151265408', 'name': 'Yui Sudo'}, {'authorId': '2059010326', 'name': 'Muhammad Shakeel'}, {'authorId': '31930118', 'name': 'Jee-weon Jung'}, {'authorId': '31949212', 'name': 'Soumi Maiti'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}]","This work presents an Open Whisper-style Speech Model (OWSM), which reproduces Whisperstyle training using an open-source toolkit and publicly available data and even supports more translation directions and can be more efficient to train."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,d4d5fe4a35e9de845877015075f727415e83d18f,"{'DBLP': 'journals/corr/abs-2306-13734', 'ArXiv': '2306.13734', 'DOI': '10.48550/arXiv.2306.13734', 'CorpusId': 259251557}",https://www.semanticscholar.org/paper/d4d5fe4a35e9de845877015075f727415e83d18f,The CHiME-7 DASR Challenge: Distant Meeting Transcription with Multiple Devices in Diverse Scenarios,"The CHiME challenges have played a significant role in the development and evaluation of robust automatic speech recognition (ASR) systems. We introduce the CHiME-7 distant ASR (DASR) task, within the 7th CHiME challenge. This task comprises joint ASR and diarization in far-field settings with multiple, and possibly heterogeneous, recording devices. Different from previous challenges, we evaluate systems on 3 diverse scenarios: CHiME-6, DiPCo, and Mixer 6. The goal is for participants to devise a single system that can generalize across different array geometries and use cases with no a-priori information. Another departure from earlier CHiME iterations is that participants are allowed to use open-source pre-trained models and datasets. In this paper, we describe the challenge design, motivation, and fundamental research questions in detail. We also present the baseline system, which is fully array-topology agnostic and features multi-channel diarization, channel selection, guided source separation and a robust ASR model that leverages self-supervised speech representations (SSLR).",7th International Workshop on Speech Processing in Everyday Environments (CHiME 2023),2023,53,13,4,True,"{'url': 'https://arxiv.org/pdf/2306.13734', 'status': None}","['Engineering', 'Computer Science']","{'volume': 'abs/2306.13734', 'name': 'ArXiv'}","[{'authorId': '1381145668', 'name': 'Samuele Cornell'}, {'authorId': '1500652334', 'name': 'Matthew Wiesner'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '34549139', 'name': 'Desh Raj'}, {'authorId': '8776560', 'name': 'Xuankai Chang'}, {'authorId': '1826558733', 'name': 'Paola García'}, {'authorId': '51298994', 'name': 'Yoshiki Masuyama'}, {'authorId': '12229660', 'name': 'Zhong-Qiu Wang'}, {'authorId': '1771979', 'name': 'S. Squartini'}, {'authorId': '2803071', 'name': 'S. Khudanpur'}]","The ChiME-7 distant ASR (DASR) task, within the 7th CHiME challenge, is introduced and the baseline system is presented, which is fully array-topology agnostic and features multi-channel diarization, channel selection, guided source separation and a robust ASR model that leverages self-supervised speech representations (SSLR)."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,d8728d62b238b09630309c1df723036db84bac10,"{'DBLP': 'journals/corr/abs-2309-15826', 'ArXiv': '2309.15826', 'DOI': '10.48550/arXiv.2309.15826', 'CorpusId': 263152659}",https://www.semanticscholar.org/paper/d8728d62b238b09630309c1df723036db84bac10,Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing,"Recent works in end-to-end speech-to-text translation (ST) have proposed multi-tasking methods with soft parameter sharing which leverage machine translation (MT) data via secondary encoders that map text inputs to an eventual cross-modal representation. In this work, we instead propose a ST/MT multi-tasking framework with hard parameter sharing in which all model parameters are shared cross-modally. Our method reduces the speech-text modality gap via a pre-processing stage which converts speech and text inputs into two discrete token sequences of similar length -- this allows models to indiscriminately process both modalities simply using a joint vocabulary. With experiments on MuST-C, we demonstrate that our multi-tasking framework improves attentional encoder-decoder, Connectionist Temporal Classification (CTC), transducer, and joint CTC/attention models by an average of +0.5 BLEU without any external MT data. Further, we show that this framework incorporates external MT data, yielding +0.8 BLEU, and also improves transfer learning from pre-trained textual models, yielding +1.8 BLEU.",arXiv.org,2023,55,0,0,True,"{'url': 'https://arxiv.org/pdf/2309.15826', 'status': None}","['Computer Science', 'Engineering']","{'volume': 'abs/2309.15826', 'name': 'ArXiv'}","[{'authorId': '2087059555', 'name': 'Brian Yan'}, {'authorId': '8776560', 'name': 'Xuankai Chang'}, {'authorId': '49513989', 'name': 'Antonios Anastasopoulos'}, {'authorId': '1471364901', 'name': 'Yuya Fujita'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}]",This work proposes a ST/MT multi-tasking framework with hard parameter sharing in which all model parameters are shared cross-modally and reduces the speech-text modality gap via a pre-processing stage which converts speech and text inputs into two discrete token sequences of similar length.
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,dab8e7dc79085774eea58bcb9ea2ed0ee20377eb,"{'DBLP': 'conf/acl/YanS0IPDPFBHZNH23', 'ArXiv': '2304.04596', 'ACL': '2023.acl-demo.38', 'DOI': '10.48550/arXiv.2304.04596', 'CorpusId': 258048846}",https://www.semanticscholar.org/paper/dab8e7dc79085774eea58bcb9ea2ed0ee20377eb,ESPnet-ST-v2: Multipurpose Spoken Language Translation Toolkit,"ESPnet-ST-v2 is a revamp of the open-source ESPnet-ST toolkit necessitated by the broadening interests of the spoken language translation community. ESPnet-ST-v2 supports 1) offline speech-to-text translation (ST), 2) simultaneous speech-to-text translation (SST), and 3) offline speech-to-speech translation (S2ST) – each task is supported with a wide variety of approaches, differentiating ESPnet-ST-v2 from other open source spoken language translation toolkits. This toolkit offers state-of-the-art architectures such as transducers, hybrid CTC/attention, multi-decoders with searchable intermediates, time-synchronous blockwise CTC/attention, Translatotron models, and direct discrete unit models. In this paper, we describe the overall design, example models for each task, and performance benchmarking behind ESPnet-ST-v2, which is publicly available at https://github.com/espnet/espnet.",Annual Meeting of the Association for Computational Linguistics,2023,64,8,1,True,"{'url': 'https://arxiv.org/pdf/2304.04596', 'status': None}","['Computer Science', 'Engineering']","{'volume': 'abs/2304.04596', 'name': 'ArXiv'}","[{'authorId': '2087059555', 'name': 'Brian Yan'}, {'authorId': '1485531923', 'name': 'Jiatong Shi'}, {'authorId': '2119309046', 'name': 'Yun Tang'}, {'authorId': '49276525', 'name': 'H. Inaguma'}, {'authorId': '2111014429', 'name': 'Yifan Peng'}, {'authorId': '35186886', 'name': 'Siddharth Dalmia'}, {'authorId': '2125322884', 'name': ""Peter Pol'ak""}, {'authorId': '2058640028', 'name': 'Patrick Fernandes'}, {'authorId': '2142561945', 'name': 'Dan Berrebbi'}, {'authorId': '3326124', 'name': 'Tomoki Hayashi'}, {'authorId': '2213148773', 'name': 'Xiaohui Zhang'}, {'authorId': '3877669', 'name': 'Zhaoheng Ni'}, {'authorId': '2007772583', 'name': 'Moto Hira'}, {'authorId': '31949212', 'name': 'Soumi Maiti'}, {'authorId': '145503806', 'name': 'J. Pino'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}]","The overall design, example models for each task, and performance benchmarking behind ESPnet-ST-v2 are described, which is publicly available at https://github.com/espnet/esp net."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,dd5d797b837005fac464bb19b9396bddba61c0d8,"{'DBLP': 'journals/corr/abs-2302-07928', 'ArXiv': '2302.07928', 'DOI': '10.48550/arXiv.2302.07928', 'CorpusId': 256900671}",https://www.semanticscholar.org/paper/dd5d797b837005fac464bb19b9396bddba61c0d8,Multi-Channel Target Speaker Extraction with Refinement: The WavLab Submission to the Second Clarity Enhancement Challenge,"This paper describes our submission to the Second Clarity Enhancement Challenge (CEC2), which consists of target speech enhancement for hearing-aid (HA) devices in noisy-reverberant environments with multiple interferers such as music and competing speakers. Our approach builds upon the powerful iterative neural/beamforming enhancement (iNeuBe) framework introduced in our recent work, and this paper extends it for target speaker extraction. We therefore name the proposed approach as iNeuBe-X, where the X stands for extraction. To address the challenges encountered in the CEC2 setting, we introduce four major novelties: (1) we extend the state-of-the-art TF-GridNet model, originally designed for monaural speaker separation, for multi-channel, causal speech enhancement, and large improvements are observed by replacing the TCNDenseNet used in iNeuBe with this new architecture; (2) we leverage a recent dual window size approach with future-frame prediction to ensure that iNueBe-X satisfies the 5 ms constraint on algorithmic latency required by CEC2; (3) we introduce a novel speaker-conditioning branch for TF-GridNet to achieve target speaker extraction; (4) we propose a fine-tuning step, where we compute an additional loss with respect to the target speaker signal compensated with the listener audiogram. Without using external data, on the official development set our best model reaches a hearing-aid speech perception index (HASPI) score of 0.942 and a scale-invariant signal-to-distortion ratio improvement (SI-SDRi) of 18.8 dB. These results are promising given the fact that the CEC2 data is extremely challenging (e.g., on the development set the mixture SI-SDR is -12.3 dB). A demo of our submitted system is available at WAVLab CEC2 demo.",arXiv.org,2023,14,5,0,True,"{'url': 'http://arxiv.org/pdf/2302.07928', 'status': None}","['Engineering', 'Computer Science']","{'volume': 'abs/2302.07928', 'name': 'ArXiv'}","[{'authorId': '1381145668', 'name': 'Samuele Cornell'}, {'authorId': '1732231', 'name': 'Zhongqiu Wang'}, {'authorId': '51298994', 'name': 'Yoshiki Masuyama'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '103525047', 'name': 'Manuel Pariente'}, {'authorId': '144101246', 'name': 'Nobutaka Ono'}]","The approach builds upon the powerful iterative neural/beamforming enhancement (iNeuBe) framework introduced in recent work, and this paper extends it for target speaker extraction, and is named as iNeu be-X, where the X stands for extraction."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,debb65ab30ceef2faef0e4af560a67f2abd03d14,"{'DBLP': 'conf/icassp/MaekakuFCW23', 'DOI': '10.1109/ICASSP49357.2023.10095280', 'CorpusId': 258546294}",https://www.semanticscholar.org/paper/debb65ab30ceef2faef0e4af560a67f2abd03d14,Fully Unsupervised Topic Clustering of Unlabelled Spoken Audio Using Self-Supervised Representation Learning and Topic Model,"Unsupervised topic clustering of spoken audio is an important research topic for zero-resourced unwritten languages. A classical approach is to find a set of spoken terms from only the audio based on dynamic time warping or generative modeling (e.g., hidden Markov model), and apply a topic model to classify topics. The spoken term discovery is the most important and difficult part. In this paper, we propose to combine self-supervised representation learning (SSRL) methods as a component of spoken term discovery and probabilistic topic models. Most SSRL methods pre-train a model which predicts high-quality pseudo labels generated from an audio-only corpus. These pseudo labels can be used to produce a sequence of pseudo subwords by applying deduplication and a subword model. Then, we apply a topic model based on latent Dirichlet allocation for these pseudo-subword sequences in an unsupervised manner. The clustering performance is evaluated on the Fisher corpus using normalized mutual information. We confirm the improvement of the proposed method and its effectiveness compared to an existing approach using dynamic time warping and topic models although the experimental setups are not directly comparable.","IEEE International Conference on Acoustics, Speech, and Signal Processing",2023,40,1,0,True,,['Computer Science'],"{'pages': '1-5', 'name': 'ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)'}","[{'authorId': '1816126', 'name': 'Takashi Maekaku'}, {'authorId': '1471364901', 'name': 'Yuya Fujita'}, {'authorId': '8776560', 'name': 'Xuankai Chang'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}]",This paper proposes to combine self-supervised representation learning (SSRL) methods as a component of spoken term discovery and probabilistic topic models and confirms the improvement of the proposed method and its effectiveness compared to an existing approach using dynamic time warping and topic models.
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,e146e5221c124d93f69516c5ae7e1b7b1822848e,"{'DBLP': 'journals/corr/abs-2302-08088', 'ArXiv': '2302.08088', 'DOI': '10.1109/ICASSP49357.2023.10094773', 'CorpusId': 256900782}",https://www.semanticscholar.org/paper/e146e5221c124d93f69516c5ae7e1b7b1822848e,TAPLoss: A Temporal Acoustic Parameter Loss for Speech Enhancement,"Speech enhancement models have greatly progressed in recent years, but still show limits in perceptual quality of their speech outputs. We propose an objective for perceptual quality based on temporal acoustic parameters. These are fundamental speech features that play an essential role in various applications, including speaker recognition and paralinguistic analysis. We provide a differentiable estimator for four categories of low-level acoustic descriptors involving: frequency-related parameters, energy or amplitude-related parameters, spectral balance parameters, and temporal features. Un-like prior work that looks at aggregated acoustic parameters or a few categories of acoustic parameters, our temporal acoustic parameter (TAP) loss enables auxiliary optimization and improvement of many fine-grained speech characteristics in enhancement workflows. We show that adding TAPLoss as an auxiliary objective in speech enhancement produces speech with improved perceptual quality and intelligibility. We use data from the Deep Noise Suppression 2020 Challenge to demonstrate that both time-domain models and time-frequency domain models can benefit from our method.","IEEE International Conference on Acoustics, Speech, and Signal Processing",2023,35,7,0,True,"{'url': 'https://arxiv.org/pdf/2302.08088', 'status': None}","['Computer Science', 'Engineering']","{'pages': '1-5', 'name': 'ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)'}","[{'authorId': '2111187803', 'name': 'YUNYANG ZENG'}, {'authorId': '2174668832', 'name': 'Joseph Konan'}, {'authorId': '2206298901', 'name': 'Shuo Han'}, {'authorId': '2174668503', 'name': 'David Bick'}, {'authorId': '72966973', 'name': 'Muqiao Yang'}, {'authorId': '47311290', 'name': 'Anurag Kumar'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '1681921', 'name': 'B. Raj'}]",This work shows that adding TAPLoss as an auxiliary objective in speech enhancement produces speech with improved perceptual quality and intelligibility and uses data from the Deep Noise Suppression 2020 Challenge to demonstrate that both time-domain models and time-frequency domain models can benefit from the method.
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,e25f6a60211aa74ecfde8001a5939ff206102de4,"{'DBLP': 'journals/corr/abs-2303-03329', 'ArXiv': '2303.03329', 'DOI': '10.1109/TASLP.2023.3328283', 'CorpusId': 257365554}",https://www.semanticscholar.org/paper/e25f6a60211aa74ecfde8001a5939ff206102de4,End-to-End Speech Recognition: A Survey,"In the last decade of automatic speech recognition (ASR) research, the introduction of deep learning has brought considerable reductions in word error rate of more than 50% relative, compared to modeling without deep learning. In the wake of this transition, a number of all-neural ASR architectures have been introduced. These so-called end-to-end (E2E) models provide highly integrated, completely neural ASR models, which rely strongly on general machine learning knowledge, learn more consistently from data, with lower dependence on ASR domain-specific experience. The success and enthusiastic adoption of deep learning, accompanied by more generic model architectures has led to E2E models now becoming the prominent ASR approach. The goal of this survey is to provide a taxonomy of E2E ASR models and corresponding improvements, and to discuss their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures. All relevant aspects of E2E ASR are covered in this work: modeling, training, decoding, and external language model integration, discussions of performance and deployment opportunities, as well as an outlook into potential future developments.",IEEE/ACM Transactions on Audio Speech and Language Processing,2023,350,35,2,True,"{'url': 'https://ieeexplore.ieee.org/ielx7/6570655/6633080/10301513.pdf', 'status': None}","['Computer Science', 'Engineering']","{'volume': '32', 'pages': '325-351', 'name': 'IEEE/ACM Transactions on Audio, Speech, and Language Processing'}","[{'authorId': '2557391', 'name': 'Rohit Prabhavalkar'}, {'authorId': '145443186', 'name': 'Takaaki Hori'}, {'authorId': '1784851', 'name': 'Tara N. Sainath'}, {'authorId': '121979316', 'name': 'R. Schluter'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}]","A taxonomy of E2E ASR models and corresponding improvements is provided, and their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures are discussed."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,e2826002978af39afce7529f172ffdc222342651,"{'DBLP': 'journals/corr/abs-2303-06326', 'ArXiv': '2303.06326', 'DOI': '10.1109/ICASSP49357.2023.10094836', 'CorpusId': 257496056}",https://www.semanticscholar.org/paper/e2826002978af39afce7529f172ffdc222342651,The Multimodal Information Based Speech Processing (Misp) 2022 Challenge: Audio-Visual Diarization And Recognition,"The Multi-modal Information based Speech Processing (MISP) challenge aims to extend the application of signal processing technology in specific scenarios by promoting the research into wake-up words, speaker diarization, speech recognition, and other technologies. The MISP2022 challenge has two tracks: 1) audio-visual speaker diarization (AVSD), aiming to solve ""who spoken when"" using both audio and visual data; 2) a novel audio-visual diarization and recognition (AVDR) task that focuses on addressing ""who spoken what when"" with audio-visual speaker diarization results. Both tracks focus on the Chinese language, and use far-field audio and video in real home-tv scenarios: 2-6 people communicating each other with TV noise in the background. This paper introduces the dataset, track settings, and baselines of the MISP2022 challenge. Our analyses of experiments and examples indicate the good performance of AVDR baseline system, and the potential difficulties in this challenge due to, e.g., the far-field video quality, the presence of TV noise in the background, and the indistinguishable speakers.","IEEE International Conference on Acoustics, Speech, and Signal Processing",2023,34,10,3,True,"{'url': 'https://repository.tudelft.nl/islandora/object/uuid%3A3e54aaa0-46f8-4411-a5ca-351a314d73ce/datastream/OBJ/download', 'status': None}",['Computer Science'],"{'pages': '1-5', 'name': 'ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)'}","[{'authorId': '2108196285', 'name': 'Zhe Wang'}, {'authorId': '2142349215', 'name': 'Shilong Wu'}, {'authorId': '1652999406', 'name': 'Hang Chen'}, {'authorId': '84359406', 'name': 'Maokui He'}, {'authorId': '145419855', 'name': 'Jun Du'}, {'authorId': '9391905', 'name': 'Chin-Hui Lee'}, {'authorId': '2108756112', 'name': 'Jingdong Chen'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '1709878', 'name': 'Sabato Marco Siniscalchi'}, {'authorId': '1700735', 'name': 'O. Scharenborg'}, {'authorId': '9064950', 'name': 'Diyuan Liu'}, {'authorId': '2055464704', 'name': 'Baocai Yin'}, {'authorId': '1391149412', 'name': 'Jia Pan'}, {'authorId': '145702494', 'name': 'Jianqing Gao'}, {'authorId': '2108152462', 'name': 'Cong Liu'}]","The dataset, track settings, and baselines of the MISP2022 challenge are introduced, and analyses of experiments and examples indicate the good performance of AVDR baseline system, and the potential difficulties in this challenge due to, e.g., the far-field video quality, the presence of TV noise in the background, andThe indistinguishable speakers."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,e4f2d75856ce149b994f079ae50fd33ca47245d3,"{'ArXiv': '2305.17651', 'DBLP': 'journals/corr/abs-2305-17651', 'DOI': '10.48550/arXiv.2305.17651', 'CorpusId': 258959211}",https://www.semanticscholar.org/paper/e4f2d75856ce149b994f079ae50fd33ca47245d3,DPHuBERT: Joint Distillation and Pruning of Self-Supervised Speech Models,"Self-supervised learning (SSL) has achieved notable success in many speech processing tasks, but the large model size and heavy computational cost hinder the deployment. Knowledge distillation trains a small student model to mimic the behavior of a large teacher model. However, the student architecture usually needs to be manually designed and will remain fixed during training, which requires prior knowledge and can lead to suboptimal performance. Inspired by recent success of task-specific structured pruning, we propose DPHuBERT, a novel task-agnostic compression method for speech SSL based on joint distillation and pruning. Experiments on SUPERB show that DPHuBERT outperforms pure distillation methods in almost all tasks. Moreover, DPHuBERT requires little training time and performs well with limited training data, making it suitable for resource-constrained applications. Our method can also be applied to various speech SSL models. Our code and models will be publicly available.",Interspeech,2023,42,11,1,True,"{'url': 'http://arxiv.org/pdf/2305.17651', 'status': None}","['Computer Science', 'Engineering']","{'volume': 'abs/2305.17651', 'name': 'ArXiv'}","[{'authorId': '2111014429', 'name': 'Yifan Peng'}, {'authorId': '151265408', 'name': 'Yui Sudo'}, {'authorId': '2059010326', 'name': 'Muhammad Shakeel'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}]","DPHuBERT is proposed, a novel task-agnostic compression method for speech SSL based on joint distillation and pruning that requires little training time and performs well with limited training data, making it suitable for resource-constrained applications."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,e64d4b29a4a6ccac3673b4cedbefa1e54e774c20,"{'PubMedCentral': '10011125', 'DOI': '10.3389/fimmu.2023.1129765', 'CorpusId': 257396899, 'PubMed': '36926342'}",https://www.semanticscholar.org/paper/e64d4b29a4a6ccac3673b4cedbefa1e54e774c20,An external quality assessment feasibility study; cross laboratory comparison of haemagglutination inhibition assay and microneutralization assay performance for seasonal influenza serology testing: A FLUCOP study,"Introduction External Quality Assessment (EQA) schemes are designed to provide a snapshot of laboratory proficiency, identifying issues and providing feedback to improve laboratory performance and inter-laboratory agreement in testing. Currently there are no international EQA schemes for seasonal influenza serology testing. Here we present a feasibility study for conducting an EQA scheme for influenza serology methods. Methods We invited participant laboratories from industry, contract research organizations (CROs), academia and public health institutions who regularly conduct hemagglutination inhibition (HAI) and microneutralization (MN) assays and have an interest in serology standardization. In total 16 laboratories returned data including 19 data sets for HAI assays and 9 data sets for MN assays. Results Within run analysis demonstrated good laboratory performance for HAI, with intrinsically higher levels of intra-assay variation for MN assays. Between run analysis showed laboratory and strain specific issues, particularly with B strains for HAI, whilst MN testing was consistently good across labs and strains. Inter-laboratory variability was higher for MN assays than HAI, however both assays showed a significant reduction in inter-laboratory variation when a human sera pool is used as a standard for normalization. Discussion This study has received positive feedback from participants, highlighting the benefit such an EQA scheme would have on improving laboratory performance, reducing inter laboratory variation and raising awareness of both harmonized protocol use and the benefit of biological standards for seasonal influenza serology testing.",Frontiers in Immunology,2023,15,2,0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fimmu.2023.1129765/pdf', 'status': None}",['Medicine'],"{'volume': '14', 'name': 'Frontiers in Immunology'}","[{'authorId': '122726252', 'name': 'J. Waldock'}, {'authorId': '37112552', 'name': 'C. Weiss'}, {'authorId': '2158506111', 'name': 'Wei Wang'}, {'authorId': '39296944', 'name': 'M. Levine'}, {'authorId': '48593087', 'name': 'Stacie N. Jefferson'}, {'authorId': '2078513988', 'name': 'S. Ho'}, {'authorId': '5947067', 'name': 'K. Hoschler'}, {'authorId': '3663439', 'name': 'B. Londt'}, {'authorId': '46909401', 'name': 'E. Masat'}, {'authorId': '2496392', 'name': 'Louise A. Carolan'}, {'authorId': '1435602996', 'name': 'Stephany Sánchez-Ovando'}, {'authorId': '2078697555', 'name': 'A. Fox'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '81445825', 'name': 'Miki Akimoto'}, {'authorId': '2064860844', 'name': 'Aya Sato'}, {'authorId': '1870898', 'name': 'N. Kishida'}, {'authorId': '115550262', 'name': 'A. Buys'}, {'authorId': '12530864', 'name': 'Lorens Maake'}, {'authorId': '2210943408', 'name': 'Cardia Fourie'}, {'authorId': '39059667', 'name': 'Catherine Caillet'}, {'authorId': '2122948155', 'name': 'Sandrine Raynaud'}, {'authorId': '3238452', 'name': 'R. Webby'}, {'authorId': '6495862', 'name': 'J. Debeauchamp'}, {'authorId': '32135124', 'name': 'R. Cox'}, {'authorId': '5805770', 'name': 'Sarah Lartey'}, {'authorId': '40438119', 'name': 'C. Trombetta'}, {'authorId': '47764136', 'name': 'S. Marchi'}, {'authorId': '4833168', 'name': 'E. Montomoli'}, {'authorId': '1412495959', 'name': 'I. Sanz-Muñoz'}, {'authorId': '48105866', 'name': 'J. Eiros'}, {'authorId': '2204272199', 'name': 'Javier Sánchez-Martínez'}, {'authorId': '2091145629', 'name': 'D. Duijsings'}, {'authorId': '6987753', 'name': 'O. Engelhardt'}]","A feasibility study for conducting an EQA scheme for influenza serology methods showing good laboratory performance for HAI, with intrinsically higher levels of intra-assay variation for MN assays, and a significant reduction in inter-laboratory variation when a human sera pool is used as a standard for normalization."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,ebb75ff5b5e55ba15e4239ed0ffa6ff2ad00b721,"{'DBLP': 'conf/icassp/CornellWMWPOS23', 'DOI': '10.1109/ICASSP49357.2023.10095961', 'CorpusId': 258540517}",https://www.semanticscholar.org/paper/ebb75ff5b5e55ba15e4239ed0ffa6ff2ad00b721,Multi-Channel Speaker Extraction with Adversarial Training: The Wavlab Submission to The Clarity ICASSP 2023 Grand Challenge,"In this work we detail our submission to the Clarity ICASSP 2023 grand challenge, in which participants have to develop a strong target speech enhancement system for hearing-aid (HA) devices in noisy-reverberant environments. Our system builds on our previous submission at the Second Clarity Enhancement Challenge (CEC2): iNeuBe-X, which consists in an iterative neural/conventional beamforming enhancement pipeline, guided by an enrollment utterance from the target speaker. This model, which won by a large margin the CEC2, is an extension of the state-of-the-art TF-GridNet model for multi-channel, streamable target-speaker speech enhancement. Here, this approach is extended and further improved by leveraging generative adversarial training, which we show proves especially useful when the training data is limited. Using only the official 6k training scenes data, our best model achieves 0.80 hearing-aid speech perception index (HASPI) and 0.41 hearing-aid speech quality index (HASQI) scores on the synthetic evaluation set. However, our model generalized poorly on the semi-real evaluation set. This highlights the fact that our community should focus more on real-world evaluation and less on fully synthetic datasets.","IEEE International Conference on Acoustics, Speech, and Signal Processing",2023,14,1,0,True,,['Computer Science'],"{'pages': '1-2', 'name': 'ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)'}","[{'authorId': '1381145668', 'name': 'Samuele Cornell'}, {'authorId': '1732231', 'name': 'Zhongqiu Wang'}, {'authorId': '51298994', 'name': 'Yoshiki Masuyama'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '103525047', 'name': 'Manuel Pariente'}, {'authorId': '144101246', 'name': 'Nobutaka Ono'}, {'authorId': '1771979', 'name': 'S. Squartini'}]","This work details the submission to the Clarity ICASSP 2023 grand challenge, in which participants have to develop a strong target speech enhancement system for hearing-aid (HA) devices in noisy-reverberant environments, and builds on the previous submission at the Second Clarity Enhancement Challenge (CEC2): iNeuBe-X."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,ef567580e167c3e7c546345df93d644be5d4f66f,"{'ArXiv': '2309.10787', 'DBLP': 'journals/corr/abs-2309-10787', 'DOI': '10.48550/arXiv.2309.10787', 'CorpusId': 262054269}",https://www.semanticscholar.org/paper/ef567580e167c3e7c546345df93d644be5d4f66f,AV-SUPERB: A Multi-Task Evaluation Benchmark for Audio-Visual Representation Models,"Audio-visual representation learning aims to develop systems with human-like perception by utilizing correlation between auditory and visual information. However, current models often focus on a limited set of tasks, and generalization abilities of learned representations are unclear. To this end, we propose the AV-SUPERB benchmark that enables general-purpose evaluation of unimodal audio/visual and bimodal fusion representations on 7 datasets covering 5 audio-visual tasks in speech and audio processing. We evaluate 5 recent self-supervised models and show that none of these models generalize to all tasks, emphasizing the need for future study on improving universal model performance. In addition, we show that representations may be improved with intermediate-task fine-tuning and audio event classification with AudioSet serves as a strong intermediate task. We release our benchmark with evaluation code and a model submission platform to encourage further research in audio-visual learning.",arXiv.org,2023,43,2,0,True,"{'url': 'https://arxiv.org/pdf/2309.10787', 'status': None}","['Engineering', 'Computer Science']","{'volume': 'abs/2309.10787', 'name': 'ArXiv'}","[{'authorId': '2373877', 'name': 'Yuan Tseng'}, {'authorId': '2186824098', 'name': 'Layne Berry'}, {'authorId': '2243397686', 'name': 'Yi-Ting Chen'}, {'authorId': '2243112343', 'name': 'I-Hsiang Chiu'}, {'authorId': '2243379170', 'name': 'Hsuan-Hao Lin'}, {'authorId': '2243029739', 'name': 'Max Liu'}, {'authorId': '30598090', 'name': 'Puyuan Peng'}, {'authorId': '2066408177', 'name': 'Yi-Jen Shih'}, {'authorId': '2243292029', 'name': 'Hung-Yu Wang'}, {'authorId': '2243260548', 'name': 'Haibin Wu'}, {'authorId': '2244154109', 'name': 'Po-Yao Huang'}, {'authorId': '2242872775', 'name': 'Chun-Mao Lai'}, {'authorId': '2530311', 'name': 'Shang-Wen Li'}, {'authorId': '30507748', 'name': 'David F. Harwath'}, {'authorId': '2243185330', 'name': 'Yu Tsao'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '40360972', 'name': 'Abdel-rahman Mohamed'}, {'authorId': '2244162380', 'name': 'Chi-Luen Feng'}, {'authorId': '2243359878', 'name': 'Hung-yi Lee'}]",The AV-SUPERB benchmark is proposed that enables general-purpose evaluation of unimodal audio/visual and bimodal fusion representations on 7 datasets covering 5 audio-visual tasks in speech and audio processing and shows that representations may be improved with intermediate-task fine-tuning and audio event classification with AudioSet serves as a strong intermediate task.
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,ef8b095292a8e38e9b8f56c54cbf3c67c3ed425d,"{'DBLP': 'journals/corr/abs-2305-07455', 'ArXiv': '2305.07455', 'DOI': '10.48550/arXiv.2305.07455', 'CorpusId': 258676617}",https://www.semanticscholar.org/paper/ef8b095292a8e38e9b8f56c54cbf3c67c3ed425d,Improving Cascaded Unsupervised Speech Translation with Denoising Back-translation,"Most of the speech translation models heavily rely on parallel data, which is hard to collect especially for low-resource languages. To tackle this issue, we propose to build a cascaded speech translation system without leveraging any kind of paired data. We use fully unpaired data to train our unsupervised systems and evaluate our results on CoVoST 2 and CVSS. The results show that our work is comparable with some other early supervised methods in some language pairs. While cascaded systems always suffer from severe error propagation problems, we proposed denoising back-translation (DBT), a novel approach to building robust unsupervised neural machine translation (UNMT). DBT successfully increases the BLEU score by 0.7--0.9 in all three translation directions. Moreover, we simplified the pipeline of our cascaded system to reduce inference latency and conducted a comprehensive analysis of every part of our work. We also demonstrate our unsupervised speech translation results on the established website.",arXiv.org,2023,44,3,1,True,"{'url': 'http://arxiv.org/pdf/2305.07455', 'status': None}","['Computer Science', 'Engineering']","{'volume': 'abs/2305.07455', 'name': 'ArXiv'}","[{'authorId': '2145125170', 'name': 'Yu-Kuan Fu'}, {'authorId': '2132626257', 'name': 'Liang-Hsuan Tseng'}, {'authorId': '1485531923', 'name': 'Jiatong Shi'}, {'authorId': '2186278878', 'name': 'Chen-An Li'}, {'authorId': '2057635233', 'name': 'Tsung-Yuan Hsu'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '1706104', 'name': 'Hung-yi Lee'}]","This work proposed denoising back-translation (DBT), a novel approach to building robust unsupervised neural machine translation (UNMT), which successfully increases the BLEU score by 0.7--0.9 in all three translation directions."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,f53b6f5a85f2d74deb32022795b5dab0aa753cf4,"{'ArXiv': '2307.02471', 'DOI': '10.21437/interspeech.2023-2316', 'CorpusId': 259342747}",https://www.semanticscholar.org/paper/f53b6f5a85f2d74deb32022795b5dab0aa753cf4,Deep Speech Synthesis from MRI-Based Articulatory Representations,"In this paper, we study articulatory synthesis, a speech synthesis method using human vocal tract information that offers a way to develop efficient, generalizable and interpretable synthesizers. While recent advances have enabled intelligible articulatory synthesis using electromagnetic articulography (EMA), these methods lack critical articulatory information like excitation and nasality, limiting generalization capabilities. To bridge this gap, we propose an alternative MRI-based feature set that covers a much more extensive articulatory space than EMA. We also introduce normalization and denoising procedures to enhance the generalizability of deep learning methods trained on MRI data. Moreover, we propose an MRI-to-speech model that improves both computational efficiency and speech fidelity. Finally, through a series of ablations, we show that the proposed MRI representation is more comprehensive than EMA and identify the most suitable MRI feature subset for articulatory synthesis.",Interspeech,2023,40,3,0,True,"{'url': 'https://arxiv.org/pdf/2307.02471', 'status': None}",['Engineering'],{'name': 'INTERSPEECH 2023'},"[{'authorId': '2111194238', 'name': 'Peter Wu'}, {'authorId': '116614713', 'name': 'Tingle Li'}, {'authorId': '2141540963', 'name': 'Yijingxiu Lu'}, {'authorId': '2108128313', 'name': 'Yubin Zhang'}, {'authorId': '46243665', 'name': 'Jiachen Lian'}, {'authorId': '1690706', 'name': 'A. Black'}, {'authorId': '145965043', 'name': 'L. Goldstein'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '1692246', 'name': 'G. Anumanchipalli'}]",An MRI-to-speech model that improves both computational efficiency and speech fidelity is proposed and the proposed MRI representation is more comprehensive than EMA and the most suitable MRI feature subset for articulatory synthesis is identified.
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,f7e995c3cae465963ecaa8c9b4ce8b9b4323a71b,"{'ACL': '2023.iwslt-1.1', 'DBLP': 'conf/iwslt/AgrawalABBBCCCC23', 'DOI': '10.18653/v1/2023.iwslt-1.1', 'CorpusId': 259376816}",https://www.semanticscholar.org/paper/f7e995c3cae465963ecaa8c9b4ce8b9b4323a71b,FINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN,"This paper reports on the shared tasks organized by the 20th IWSLT Conference. The shared tasks address 9 scientific challenges in spoken language translation: simultaneous and offline translation, automatic subtitling and dubbing, speech-to-speech translation, multilingual, dialect and low-resource speech translation, and formality control. The shared tasks attracted a total of 38 submissions by 31 teams. The growing interest towards spoken language translation is also witnessed by the constantly increasing number of shared task organizers and contributors to the overview paper, almost evenly distributed across industry and academia.",International Workshop on Spoken Language Translation,2023,156,22,0,True,"{'url': 'https://aclanthology.org/2023.iwslt-1.1.pdf', 'status': None}",['Computer Science'],{'pages': '1-61'},"[{'authorId': '5112699', 'name': 'Sweta Agrawal'}, {'authorId': '49513989', 'name': 'Antonios Anastasopoulos'}, {'authorId': '2486762', 'name': 'L. Bentivogli'}, {'authorId': '143832874', 'name': 'Ondrej Bojar'}, {'authorId': '2870709', 'name': 'Claudia Borg'}, {'authorId': '2954727', 'name': 'Marine Carpuat'}, {'authorId': '2145191465', 'name': 'Roldano Cattoni'}, {'authorId': '2134567113', 'name': 'Mauro Cettolo'}, {'authorId': '46221498', 'name': 'Mingda Chen'}, {'authorId': '2144302389', 'name': 'William Chen'}, {'authorId': '1678451', 'name': 'K. Choukri'}, {'authorId': '3379701', 'name': 'Alexandra Chronopoulou'}, {'authorId': '3456678', 'name': 'Anna Currey'}, {'authorId': '72836788', 'name': 'T. Declerck'}, {'authorId': '48965598', 'name': 'Qianqian Dong'}, {'authorId': '1800354', 'name': 'Kevin Duh'}, {'authorId': '1736665', 'name': 'Y. Estève'}, {'authorId': '102811815', 'name': 'Marcello Federico'}, {'authorId': '2029654236', 'name': 'Souhir Gahbiche'}, {'authorId': '2259100', 'name': 'B. Haddow'}, {'authorId': '2064231695', 'name': 'B. Hsu'}, {'authorId': '2221319128', 'name': 'Phu Mon Htut'}, {'authorId': '49276525', 'name': 'H. Inaguma'}, {'authorId': '2157427038', 'name': 'Dávid Javorský'}, {'authorId': '144955737', 'name': 'J. Judge'}, {'authorId': '2059098838', 'name': 'Yasumasa Kano'}, {'authorId': '3023507', 'name': 'Tom Ko'}, {'authorId': '2107940335', 'name': 'Rishu Kumar'}, {'authorId': '50492525', 'name': 'Peng Li'}, {'authorId': '40765198', 'name': 'Xutai Ma'}, {'authorId': '2067519818', 'name': 'Prashant Mathur'}, {'authorId': '2987437', 'name': 'E. Matusov'}, {'authorId': '145324163', 'name': 'Paul McNamee'}, {'authorId': '2221319413', 'name': 'John P. McCrae'}, {'authorId': '38730896', 'name': 'Kenton Murray'}, {'authorId': '3456844', 'name': 'Maria Nadejde'}, {'authorId': '2148246160', 'name': 'Satoshi Nakamura'}, {'authorId': '2138026', 'name': 'Matteo Negri'}, {'authorId': '8308431', 'name': 'H. Nguyen'}, {'authorId': '2920247', 'name': 'J. Niehues'}, {'authorId': '145523874', 'name': 'Xing Niu'}, {'authorId': '2221318257', 'name': 'Atul Kr. Ojha'}, {'authorId': '2172668258', 'name': 'John E. Ortega'}, {'authorId': '66380217', 'name': 'Proyag Pal'}, {'authorId': '145503806', 'name': 'J. Pino'}, {'authorId': '35100952', 'name': 'Lonneke van der Plas'}, {'authorId': '2066246895', 'name': 'Peter Polák'}, {'authorId': '2165226832', 'name': 'Elijah Matthew Rippeth'}, {'authorId': '3448427', 'name': 'Elizabeth Salesky'}, {'authorId': '1485531923', 'name': 'Jiatong Shi'}, {'authorId': '3011998', 'name': 'Matthias Sperber'}, {'authorId': '11126660', 'name': 'Sebastian Stüker'}, {'authorId': '1790811', 'name': 'Katsuhito Sudoh'}, {'authorId': '2119309046', 'name': 'Yun Tang'}, {'authorId': '137174569', 'name': 'Brian Thompson'}, {'authorId': '2748455', 'name': 'Ke M. Tran'}, {'authorId': '145862931', 'name': 'M. Turchi'}, {'authorId': '1724972', 'name': 'A. Waibel'}, {'authorId': '50468534', 'name': 'Mingxuan Wang'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '1729345257', 'name': 'Rodolfo Zevallos'}]",
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,fa5ebb425c57f6c4f1c36a7200ef1da867346e8c,"{'DBLP': 'journals/corr/abs-2309-15674', 'ArXiv': '2309.15674', 'DOI': '10.48550/arXiv.2309.15674', 'CorpusId': 263152081}",https://www.semanticscholar.org/paper/fa5ebb425c57f6c4f1c36a7200ef1da867346e8c,Speech collage: code-switched audio generation by collaging monolingual corpora,"Designing effective automatic speech recognition (ASR) systems for Code-Switching (CS) often depends on the availability of the transcribed CS resources. To address data scarcity, this paper introduces Speech Collage, a method that synthesizes CS data from monolingual corpora by splicing audio segments. We further improve the smoothness quality of audio generation using an overlap-add approach. We investigate the impact of generated data on speech recognition in two scenarios: using in-domain CS text and a zero-shot approach with synthesized CS text. Empirical results highlight up to 34.4% and 16.2% relative reductions in Mixed-Error Rate and Word-Error Rate for in-domain and zero-shot scenarios, respectively. Lastly, we demonstrate that CS augmentation bolsters the model's code-switching inclination and reduces its monolingual bias.",arXiv.org,2023,40,0,0,True,"{'url': 'https://arxiv.org/pdf/2309.15674', 'status': None}","['Computer Science', 'Engineering']","{'volume': 'abs/2309.15674', 'name': 'ArXiv'}","[{'authorId': '152885017', 'name': 'A. Hussein'}, {'authorId': '2248270267', 'name': 'Dorsa Zeinali'}, {'authorId': '3285011', 'name': 'Ondrej Klejch'}, {'authorId': '1500652334', 'name': 'Matthew Wiesner'}, {'authorId': '2087059555', 'name': 'Brian Yan'}, {'authorId': '1725417821', 'name': 'Shammur A. Chowdhury'}, {'authorId': '145907529', 'name': 'Ahmed Ali'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}, {'authorId': '2803071', 'name': 'S. Khudanpur'}]","Speech Collage is introduced, a method that synthesizes CS data from monolingual corpora by splicing audio segments that improves the smoothness quality of audio generation using an overlap-add approach and demonstrates that CS augmentation bolsters the model's code-switching inclination and reduces itsmonolingual bias."
Shinji Watanabe,1746678,Shinji Watanabe,https://www.semanticscholar.org/author/1746678,67,[],597,22222,fa75ef55e04e3b25b8af56435478c2fd17403ce8,"{'DBLP': 'journals/corr/abs-2306-01084', 'ArXiv': '2306.01084', 'DOI': '10.48550/arXiv.2306.01084', 'CorpusId': 259063686}",https://www.semanticscholar.org/paper/fa75ef55e04e3b25b8af56435478c2fd17403ce8,Exploration on HuBERT with Multiple Resolutions,"Hidden-unit BERT (HuBERT) is a widely-used self-supervised learning (SSL) model in speech processing. However, we argue that its fixed 20ms resolution for hidden representations would not be optimal for various speech-processing tasks since their attributes (e.g., speaker characteristics and semantics) are based on different time scales. To address this limitation, we propose utilizing HuBERT representations at multiple resolutions for downstream tasks. We explore two approaches, namely the parallel and hierarchical approaches, for integrating HuBERT features with different resolutions. Through experiments, we demonstrate that HuBERT with multiple resolutions outperforms the original model. This highlights the potential of utilizing multiple resolutions in SSL models like HuBERT to capture diverse information from speech signals.",Interspeech,2023,41,4,0,True,"{'url': 'http://arxiv.org/pdf/2306.01084', 'status': None}","['Computer Science', 'Engineering']","{'volume': 'abs/2306.01084', 'name': 'ArXiv'}","[{'authorId': '1485531923', 'name': 'Jiatong Shi'}, {'authorId': '2119309046', 'name': 'Yun Tang'}, {'authorId': '49276525', 'name': 'H. Inaguma'}, {'authorId': '2142518358', 'name': 'Hongyu Gong'}, {'authorId': '145503806', 'name': 'J. Pino'}, {'authorId': '1746678', 'name': 'Shinji Watanabe'}]","Through experiments, it is demonstrated that HuBERT with multiple resolutions outperforms the original model, highlighting the potential of utilizing multiple resolutions in SSL models like HuberT to capture diverse information from speech signals."
Teruko Mitamura,1706595,T. Mitamura,https://www.semanticscholar.org/author/1706595,36,[],198,4681,444737639aeea4e1e616509e368afb0bae8f89d6,"{'ACL': '2023.dialdoc-1.11', 'DOI': '10.18653/v1/2023.dialdoc-1.11', 'CorpusId': 259290499}",https://www.semanticscholar.org/paper/444737639aeea4e1e616509e368afb0bae8f89d6,Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA,"The DialDoc 2023 shared task has expanded the document-grounded dialogue task to encompass multiple languages, despite having limited annotated data. This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-agnostic approach is superior. Additionally, the study investigates the impact of query rewriting techniques using large language models, such as ChatGPT, on multilingual, document-grounded question-answering systems. The experiments conducted demonstrate that, for the examples examined, query rewriting does not enhance performance compared to the original queries. This failure is due to topic switching in final dialogue turns and irrelevant topics being considered for query rewriting.",Workshop on Document-grounded Dialogue and Conversational Question Answering,2023,23,2,0,True,"{'url': 'https://aclanthology.org/2023.dialdoc-1.11.pdf', 'status': None}",,{'name': 'Proceedings of the Third DialDoc Workshop on Document-grounded Dialogue and Conversational Question Answering'},"[{'authorId': '2220844123', 'name': 'Srinivas Gowriraj'}, {'authorId': '2090315115', 'name': 'Soham Dinesh Tiwari'}, {'authorId': '2122650064', 'name': 'Mitali Potnis'}, {'authorId': '67152985', 'name': 'Srijan Bansal'}, {'authorId': '1706595', 'name': 'T. Mitamura'}, {'authorId': '144287919', 'name': 'Eric Nyberg'}]","This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-gnostic approach is superior."
Teruko Mitamura,1706595,T. Mitamura,https://www.semanticscholar.org/author/1706595,36,[],198,4681,ff77105b2c345f54e1a87f4fbb3a701201f0c1a8,"{'DBLP': 'conf/aaai/OuPGM23', 'ArXiv': '2302.04197', 'DOI': '10.48550/arXiv.2302.04197', 'CorpusId': 256662664}",https://www.semanticscholar.org/paper/ff77105b2c345f54e1a87f4fbb3a701201f0c1a8,Hierarchical Event Grounding,"Event grounding aims at linking mention references in text corpora to events from a knowledge base (KB). Previous work on this task focused primarily on linking to a single KB event, thereby overlooking the hierarchical aspects of events. Events in documents are typically described at various levels of spatio-temporal granularity. These hierarchical relations are utilized in downstream tasks of narrative understanding and schema construction. In this work, we present an extension to the event grounding task that requires tackling hierarchical event structures from the KB. Our proposed task involves linking a mention reference to a set of event labels from a subevent hierarchy in the KB. We propose a retrieval methodology that leverages event hierarchy through an auxiliary hierarchical loss. On an automatically created multilingual dataset from Wikipedia and Wikidata, our experiments demonstrate the effectiveness of the hierarchical loss against retrieve and re-rank baselines. Furthermore, we demonstrate the systems' ability to aid hierarchical discovery among unseen events. Code is available at https://github.com/JefferyO/Hierarchical-Event-Grounding",AAAI Conference on Artificial Intelligence,2023,25,0,0,True,"{'url': 'http://arxiv.org/pdf/2302.04197', 'status': None}",['Computer Science'],"{'volume': 'abs/2302.04197', 'name': 'ArXiv'}","[{'authorId': '1657712151', 'name': 'Jiefu Ou'}, {'authorId': '51132476', 'name': 'Adithya Pratapa'}, {'authorId': '2162354140', 'name': 'Rishubh Gupta'}, {'authorId': '1706595', 'name': 'T. Mitamura'}]","This work presents an extension to the event grounding task that requires tackling hierarchical event structures from the KB, and proposes a retrieval methodology that leverages event hierarchy through an auxiliary hierarchical loss."
Taylor Berg-Kirkpatrick,1400419309,Taylor Berg-Kirkpatrick,https://www.semanticscholar.org/author/1400419309,36,[],112,5655,1527d3b661154ff7310fa2759b6dd0ddfd559492,"{'ArXiv': '2305.09859', 'DBLP': 'journals/corr/abs-2305-09859', 'DOI': '10.48550/arXiv.2305.09859', 'CorpusId': 258740888}",https://www.semanticscholar.org/paper/1527d3b661154ff7310fa2759b6dd0ddfd559492,Smaller Language Models are Better Black-box Machine-Generated Text Detectors,"With the advent of fluent generative language models that can produce convincing utterances very similar to those written by humans, distinguishing whether a piece of text is machine-generated or human-written becomes more challenging and more important, as such models could be used to spread misinformation, fake news, fake reviews and to mimic certain authors and figures. To this end, there have been a slew of methods proposed to detect machine-generated text. Most of these methods need access to the logits of the target model or need the ability to sample from the target. One such black-box detection method relies on the observation that generated text is locally optimal under the likelihood function of the generator, while human-written text is not. We find that overall, smaller and partially-trained models are better universal text detectors: they can more precisely detect text generated from both small and larger models. Interestingly, we find that whether the detector and generator were trained on the same data is not critically important to the detection success. For instance the OPT-125M model has an AUC of 0.81 in detecting ChatGPT generations, whereas a larger model from the GPT family, GPTJ-6B, has AUC of 0.45.",arXiv.org,2023,38,23,1,True,"{'url': 'http://arxiv.org/pdf/2305.09859', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.09859', 'name': 'ArXiv'}","[{'authorId': '2115471757', 'name': 'Fatemehsadat Mireshghallah'}, {'authorId': '2138547910', 'name': 'Justus Mattern'}, {'authorId': '39219411', 'name': 'Sicun Gao'}, {'authorId': '2520493', 'name': 'R. Shokri'}, {'authorId': '1400419309', 'name': 'Taylor Berg-Kirkpatrick'}]","Overall, smaller and partially-trained models are better universal text detectors: they can more precisely detect text generated from both small and larger models."
Taylor Berg-Kirkpatrick,1400419309,Taylor Berg-Kirkpatrick,https://www.semanticscholar.org/author/1400419309,36,[],112,5655,15b08595533bfc640f4dd470ca7a2273badec20a,"{'DBLP': 'conf/ismir/Shao0BD23', 'ArXiv': '2308.02723', 'DOI': '10.48550/arXiv.2308.02723', 'CorpusId': 260682482}",https://www.semanticscholar.org/paper/15b08595533bfc640f4dd470ca7a2273badec20a,Towards Improving Harmonic Sensitivity and Prediction Stability for Singing Melody Extraction,"In deep learning research, many melody extraction models rely on redesigning neural network architectures to improve performance. In this paper, we propose an input feature modification and a training objective modification based on two assumptions. First, harmonics in the spectrograms of audio data decay rapidly along the frequency axis. To enhance the model's sensitivity on the trailing harmonics, we modify the Combined Frequency and Periodicity (CFP) representation using discrete z-transform. Second, the vocal and non-vocal segments with extremely short duration are uncommon. To ensure a more stable melody contour, we design a differentiable loss function that prevents the model from predicting such segments. We apply these modifications to several models, including MSNet, FTANet, and a newly introduced model, PianoNet, modified from a piano transcription network. Our experimental results demonstrate that the proposed modifications are empirically effective for singing melody extraction.",International Society for Music Information Retrieval Conference,2023,24,0,0,True,"{'url': 'https://arxiv.org/pdf/2308.02723', 'status': None}","['Computer Science', 'Engineering']",{'pages': '657-663'},"[{'authorId': '2228382825', 'name': 'Keren Shao'}, {'authorId': '115727183', 'name': 'K. Chen'}, {'authorId': '1400419309', 'name': 'Taylor Berg-Kirkpatrick'}, {'authorId': '2204186', 'name': 'S. Dubnov'}]",This paper proposes an input feature modification and a training objective modification based on two assumptions of harmonics in the spectrograms of audio data decay rapidly along the frequency axis to enhance the model's sensitivity on the trailing harmonics.
Taylor Berg-Kirkpatrick,1400419309,Taylor Berg-Kirkpatrick,https://www.semanticscholar.org/author/1400419309,36,[],112,5655,1f1a09e59dbd178aa0988ea8f96e780e36923c8a,"{'DBLP': 'conf/www/DuncanKBM23', 'DOI': '10.1145/3543873.3584642', 'CorpusId': 258377526}",https://www.semanticscholar.org/paper/1f1a09e59dbd178aa0988ea8f96e780e36923c8a,Jointly modeling products and resource pages for task-oriented recommendation,"Modeling high-level user intent in recommender systems can improve performance, although it is often difficult to obtain a ground truth measure of this intent. In this paper, we investigate a novel way to obtain such an intent signal by leveraging resource pages associated with a particular task. We jointly model product interactions and resource page interactions to create a system which can recommend both products and resource pages to users. Our experiments consider the domain of home improvement product recommendation, where resource pages are DIY (do-it-yourself) project pages from Lowes.com. Each DIY page provides a list of tools, materials, and step-by-step instructions to complete a DIY project, such as building a deck, installing cabinets, and fixing a leaking pipe. We use this data as an indicator of the intended project, which is a natural high-level intent signal for home improvement shoppers. We then extend a state-of-the-art system to incorporate this new intent data, and show a significant improvement in the ability of the system to recommend products. We further demonstrate that our system can be used to successfully recommend DIY project pages to users. We have taken initial steps towards deploying our method for project recommendation in production on the Lowe’s website and for recommendations through marketing emails.",The Web Conference,2023,17,0,0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/3543873.3584642', 'status': None}",['Computer Science'],{'name': 'Companion Proceedings of the ACM Web Conference 2023'},"[{'authorId': '32370715', 'name': 'B. Duncan'}, {'authorId': '3378098', 'name': 'S. Kallumadi'}, {'authorId': '1400419309', 'name': 'Taylor Berg-Kirkpatrick'}, {'authorId': '35660011', 'name': 'Julian McAuley'}]","This paper jointly model product interactions and resource page interactions to create a system which can recommend both products and resource pages to users, and extends a state-of-the-art system to incorporate this new intent data, and shows a significant improvement in the ability of the system to recommend products."
Taylor Berg-Kirkpatrick,1400419309,Taylor Berg-Kirkpatrick,https://www.semanticscholar.org/author/1400419309,36,[],112,5655,464edfd902f652d3ab6a25dbb6d9fa47cc3246a9,"{'DBLP': 'journals/corr/abs-2308-01546', 'ArXiv': '2308.01546', 'DOI': '10.48550/arXiv.2308.01546', 'CorpusId': 260438807}",https://www.semanticscholar.org/paper/464edfd902f652d3ab6a25dbb6d9fa47cc3246a9,MusicLDM: Enhancing Novelty in Text-to-Music Generation Using Beat-Synchronous Mixup Strategies,"Diffusion models have shown promising results in cross-modal generation tasks, including text-to-image and text-to-audio generation. However, generating music, as a special type of audio, presents unique challenges due to limited availability of music data and sensitive issues related to copyright and plagiarism. In this paper, to tackle these challenges, we first construct a state-of-the-art text-to-music model, MusicLDM, that adapts Stable Diffusion and AudioLDM architectures to the music domain. We achieve this by retraining the contrastive language-audio pretraining model (CLAP) and the Hifi-GAN vocoder, as components of MusicLDM, on a collection of music data samples. Then, to address the limitations of training data and to avoid plagiarism, we leverage a beat tracking model and propose two different mixup strategies for data augmentation: beat-synchronous audio mixup and beat-synchronous latent mixup, which recombine training audio directly or via a latent embeddings space, respectively. Such mixup strategies encourage the model to interpolate between musical training samples and generate new music within the convex hull of the training data, making the generated music more diverse while still staying faithful to the corresponding style. In addition to popular evaluation metrics, we design several new evaluation metrics based on CLAP score to demonstrate that our proposed MusicLDM and beat-synchronous mixup strategies improve both the quality and novelty of generated music, as well as the correspondence between input text and generated music.",arXiv.org,2023,42,9,0,True,"{'url': 'https://arxiv.org/pdf/2308.01546', 'status': None}","['Computer Science', 'Engineering']","{'volume': 'abs/2308.01546', 'name': 'ArXiv'}","[{'authorId': '115727183', 'name': 'K. Chen'}, {'authorId': '2107957455', 'name': 'Yusong Wu'}, {'authorId': '151503689', 'name': 'Haohe Liu'}, {'authorId': '2174178585', 'name': 'Marianna Nezhurina'}, {'authorId': '1400419309', 'name': 'Taylor Berg-Kirkpatrick'}, {'authorId': '2204186', 'name': 'S. Dubnov'}]","A state-of-the-art text-to-music model that adapts Stable Diffusion and AudioLDM architectures to the music domain is constructed and two different mixup strategies for data augmentation are proposed: beat-synchronous audio mixup and beat- Synchronous latent mixup, which recombine training audio directly or via a latent embeddings space, respectively."
Taylor Berg-Kirkpatrick,1400419309,Taylor Berg-Kirkpatrick,https://www.semanticscholar.org/author/1400419309,36,[],112,5655,55324ec5662bbea2e226ce3d8e6258a62836e940,"{'DBLP': 'journals/corr/abs-2305-07447', 'ArXiv': '2305.07447', 'DOI': '10.48550/arXiv.2305.07447', 'CorpusId': 258676389}",https://www.semanticscholar.org/paper/55324ec5662bbea2e226ce3d8e6258a62836e940,Universal Source Separation with Weakly Labelled Data,"Universal source separation (USS) is a fundamental research task for computational auditory scene analysis, which aims to separate mono recordings into individual source tracks. There are three potential challenges awaiting the solution to the audio source separation task. First, previous audio source separation systems mainly focus on separating one or a limited number of specific sources. There is a lack of research on building a unified system that can separate arbitrary sources via a single model. Second, most previous systems require clean source data to train a separator, while clean source data are scarce. Third, there is a lack of USS system that can automatically detect and separate active sound classes in a hierarchical level. To use large-scale weakly labeled/unlabeled audio data for audio source separation, we propose a universal audio source separation framework containing: 1) an audio tagging model trained on weakly labeled data as a query net; and 2) a conditional source separation model that takes query net outputs as conditions to separate arbitrary sound sources. We investigate various query nets, source separation models, and training strategies and propose a hierarchical USS strategy to automatically detect and separate sound classes from the AudioSet ontology. By solely leveraging the weakly labelled AudioSet, our USS system is successful in separating a wide variety of sound classes, including sound event separation, music source separation, and speech enhancement. The USS system achieves an average signal-to-distortion ratio improvement (SDRi) of 5.57 dB over 527 sound classes of AudioSet; 10.57 dB on the DCASE 2018 Task 2 dataset; 8.12 dB on the MUSDB18 dataset; an SDRi of 7.28 dB on the Slakh2100 dataset; and an SSNR of 9.00 dB on the voicebank-demand dataset. We release the source code at https://github.com/bytedance/uss",arXiv.org,2023,74,6,0,True,"{'url': 'http://arxiv.org/pdf/2305.07447', 'status': None}","['Computer Science', 'Engineering']","{'volume': 'abs/2305.07447', 'name': 'ArXiv'}","[{'authorId': '8391640', 'name': 'Qiuqiang Kong'}, {'authorId': '115727183', 'name': 'K. Chen'}, {'authorId': '151503689', 'name': 'Haohe Liu'}, {'authorId': '46214809', 'name': 'Xingjian Du'}, {'authorId': '1400419309', 'name': 'Taylor Berg-Kirkpatrick'}, {'authorId': '2204186', 'name': 'S. Dubnov'}, {'authorId': '102690737', 'name': 'MarkD . Plumbley'}]","A hierarchical USS strategy to automatically detect and separate sound classes from the AudioSet ontology is proposed, which is successful in separating a wide variety of sound classes, including sound event separation, music source separation, and speech enhancement."
Taylor Berg-Kirkpatrick,1400419309,Taylor Berg-Kirkpatrick,https://www.semanticscholar.org/author/1400419309,36,[],112,5655,924036c17537adc8574a1476bf13d9d17a6eebae,"{'DBLP': 'journals/corr/abs-2301-04253', 'DOI': '10.48550/arXiv.2301.04253', 'CorpusId': 255595673}",https://www.semanticscholar.org/paper/924036c17537adc8574a1476bf13d9d17a6eebae,ClimaBench: A Benchmark Dataset For Climate Change Text Understanding in English,"The topic of Climate Change (CC) has received limited attention in NLP despite its real world urgency. Activists and policy-makers need NLP tools in order to effectively process the vast and rapidly growing textual data produced on CC. Their utility, however, primarily depends on whether the current state-of-the-art models can generalize across various tasks in the CC domain. In order to address this gap, we introduce Climate Change Benchmark (ClimaBench), a benchmark collection of existing disparate datasets for evaluating model performance across a diverse set of CC NLU tasks systematically. Further, we enhance the benchmark by releasing two large-scale labelled text classiﬁcation and question-answering datasets curated from publicly available environmental disclosures. Lastly, we provide an analysis of several generic and CC-oriented models answering whether ﬁne-tuning on domain text offers any improvements across these tasks. We hope this work provides a standard assessment tool for research on CC text data.",arXiv.org,2023,35,5,1,True,"{'url': 'https://arxiv.org/pdf/2301.04253', 'status': None}",['Computer Science'],"{'volume': 'abs/2301.04253', 'name': 'ArXiv'}","[{'authorId': '103242455', 'name': 'Tanmay Laud'}, {'authorId': '2064240141', 'name': 'Daniel M. Spokoyny'}, {'authorId': '116070555', 'name': 'Thomas W. Corringham'}, {'authorId': '1400419309', 'name': 'Taylor Berg-Kirkpatrick'}]","Climate Change Benchmark (ClimaBench) is introduced, a benchmark collection of existing disparate datasets for evaluating model performance across a diverse set of CC NLU tasks systematically and an analysis of several generic and CC-oriented models answering whether tuning on domain text offers any improvements across these tasks."
Taylor Berg-Kirkpatrick,1400419309,Taylor Berg-Kirkpatrick,https://www.semanticscholar.org/author/1400419309,36,[],112,5655,c70c11d6de5eec2677eaa87fd3112068db6fedfe,"{'DBLP': 'conf/waspaa/DongLPBPSBM23', 'ArXiv': '2306.09635', 'DOI': '10.1109/WASPAA58266.2023.10248160', 'CorpusId': 259187955}",https://www.semanticscholar.org/paper/c70c11d6de5eec2677eaa87fd3112068db6fedfe,CLIPSonic: Text-to-Audio Synthesis with Unlabeled Videos and Pretrained Language-Vision Models,"Recent work has studied text-to-audio synthesis using large amounts of paired text-audio data. However, audio recordings with high-quality text annotations can be difficult to acquire. In this work, we approach text-to-audio synthesis using unlabeled videos and pre-trained language-vision models. We propose to learn the desired text-audio correspondence by leveraging the visual modality as a bridge. We train a conditional diffusion model to generate the audio track of a video, given a video frame encoded by a pretrained contrastive language-image pretraining (CLIP) model. At test time, we first explore performing a zero-shot modality transfer and condition the diffusion model with a CLIP-encoded text query. However, we observe a noticeable performance drop with respect to image queries. To close this gap, we further adopt a pretrained diffusion prior model to generate a CLIP image embedding given a CLIP text embedding. Our results show the effectiveness of the proposed method, and that the pretrained diffusion prior can reduce the modality transfer gap. While we focus on text-to-audio synthesis, the proposed model can also generate audio from image queries, and it shows competitive performance against a state-of-the-art image-to-audio synthesis model in a subjective listening test. This study offers a new direction of approaching text-to-audio synthesis that leverages the naturally-occurring audio-visual correspondence in videos and the power of pretrained language-vision models.",IEEE Workshop on Applications of Signal Processing to Audio and Acoustics,2023,39,3,0,True,"{'url': 'https://arxiv.org/pdf/2306.09635', 'status': None}","['Computer Science', 'Engineering']","{'pages': '1-5', 'name': '2023 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)'}","[{'authorId': '2113412153', 'name': 'Hao-Wen Dong'}, {'authorId': '2111038051', 'name': 'Xiaoyu Liu'}, {'authorId': '143683184', 'name': 'Jordi Pons'}, {'authorId': '2058911648', 'name': 'Gautam Bhattacharya'}, {'authorId': '2074982546', 'name': 'Santiago Pascual'}, {'authorId': '145783638', 'name': 'J. Serrà'}, {'authorId': '1400419309', 'name': 'Taylor Berg-Kirkpatrick'}, {'authorId': '35660011', 'name': 'Julian McAuley'}]","This work proposes to learn the desired text-audio correspondence by leveraging the visual modality as a bridge in videos and pretrained language-vision models, and shows competitive performance against a state-of-the-art image-to-audio synthesis model in a subjective listening test."
Taylor Berg-Kirkpatrick,1400419309,Taylor Berg-Kirkpatrick,https://www.semanticscholar.org/author/1400419309,36,[],112,5655,cb754310302086dfbbcd098263200e2a03f65874,"{'ArXiv': '2305.18462', 'DBLP': 'conf/acl/MatternMJSSB23', 'DOI': '10.48550/arXiv.2305.18462', 'CorpusId': 258967264}",https://www.semanticscholar.org/paper/cb754310302086dfbbcd098263200e2a03f65874,Membership Inference Attacks against Language Models via Neighbourhood Comparison,"Membership Inference attacks (MIAs) aim to predict whether a data sample was present in the training data of a machine learning model or not, and are widely used for assessing the privacy risks of language models. Most existing attacks rely on the observation that models tend to assign higher probabilities to their training samples than non-training points. However, simple thresholding of the model score in isolation tends to lead to high false-positive rates as it does not account for the intrinsic complexity of a sample. Recent work has demonstrated that reference-based attacks which compare model scores to those obtained from a reference model trained on similar data can substantially improve the performance of MIAs. However, in order to train reference models, attacks of this kind make the strong and arguably unrealistic assumption that an adversary has access to samples closely resembling the original training data. Therefore, we investigate their performance in more realistic scenarios and find that they are highly fragile in relation to the data distribution used to train reference models. To investigate whether this fragility provides a layer of safety, we propose and evaluate neighbourhood attacks, which compare model scores for a given sample to scores of synthetically generated neighbour texts and therefore eliminate the need for access to the training data distribution. We show that, in addition to being competitive with reference-based attacks that have perfect knowledge about the training data distribution, our attack clearly outperforms existing reference-free attacks as well as reference-based attacks with imperfect knowledge, which demonstrates the need for a reevaluation of the threat model of adversarial attacks.",Annual Meeting of the Association for Computational Linguistics,2023,50,28,4,True,"{'url': 'https://arxiv.org/pdf/2305.18462', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.18462', 'name': 'ArXiv'}","[{'authorId': '2138547910', 'name': 'Justus Mattern'}, {'authorId': '2115471757', 'name': 'Fatemehsadat Mireshghallah'}, {'authorId': '2111472502', 'name': 'Zhijing Jin'}, {'authorId': '1707625', 'name': 'B. Scholkopf'}, {'authorId': '2790926', 'name': 'Mrinmaya Sachan'}, {'authorId': '1400419309', 'name': 'Taylor Berg-Kirkpatrick'}]","Neighbourhood attacks are proposed and evaluated, which compare model scores for a given sample to scores of synthetically generated neighbour texts and therefore eliminate the need for access to the training data distribution and clearly outperforms existing reference-free attacks as well as reference-based attacks with imperfect knowledge."
Taylor Berg-Kirkpatrick,1400419309,Taylor Berg-Kirkpatrick,https://www.semanticscholar.org/author/1400419309,36,[],112,5655,d9dc309f719233be9f2a6b6910072e537f96eec8,"{'DBLP': 'journals/corr/abs-2306-07998', 'ArXiv': '2306.07998', 'DOI': '10.48550/arXiv.2306.07998', 'CorpusId': 259165144}",https://www.semanticscholar.org/paper/d9dc309f719233be9f2a6b6910072e537f96eec8,Contrastive Attention Networks for Attribution of Early Modern Print,"In this paper, we develop machine learning techniques to identify unknown printers in early modern (c.~1500--1800) English printed books.
Specifically, we focus on matching uniquely damaged character type-imprints in anonymously printed books to works with known printers in order to provide evidence of their origins.
Until now, this work has been limited to manual investigations by analytical bibliographers.
We present a Contrastive Attention-based Metric Learning approach to identify similar damage across character image pairs, which is sensitive to very subtle differences in glyph shapes, yet robust to various confounding sources of noise associated with digitized historical books. 
To overcome the scarce amount of supervised data, we design a random data synthesis procedure that aims to simulate bends, fractures, and inking variations induced by the early printing process.
Our method successfully improves downstream damaged type-imprint matching among printed works from this period, as validated by in-domain human experts. The results of our approach on two important philosophical works from the Early Modern period demonstrate potential to extend the extant historical research about the origins and content of these books.",AAAI Conference on Artificial Intelligence,2023,49,0,0,True,"{'url': 'http://arxiv.org/pdf/2306.07998', 'status': None}",['Computer Science'],{'pages': '5285-5293'},"[{'authorId': '46623434', 'name': 'Nikolai Vogler'}, {'authorId': '37195917', 'name': 'Kartik Goyal'}, {'authorId': '2220653457', 'name': 'Kishore PV Reddy'}, {'authorId': '122063781', 'name': 'Elizaveta Pertseva'}, {'authorId': '2034956941', 'name': 'Sam Lemley'}, {'authorId': '50355374', 'name': 'Christopher N. Warren'}, {'authorId': '1456636059', 'name': ""M. G'Sell""}, {'authorId': '1400419309', 'name': 'Taylor Berg-Kirkpatrick'}]","The method successfully improves downstream damaged type-imprint matching among printed works from this period, as validated by in-domain human experts and demonstrates potential to extend the extant historical research about the origins and content of these books."
Tom Mitchell,40975594,Tom Michael Mitchell,https://www.semanticscholar.org/author/40975594,81,[],353,34877,61678a9f1d8291bb0f3d704a439ac8cd64fa6482,"{'ArXiv': '2302.04449', 'DBLP': 'journals/corr/abs-2302-04449', 'DOI': '10.48550/arXiv.2302.04449', 'CorpusId': 256697185}",https://www.semanticscholar.org/paper/61678a9f1d8291bb0f3d704a439ac8cd64fa6482,Read and Reap the Rewards: Learning to Play Atari with the Help of Instruction Manuals,"High sample complexity has long been a challenge for RL. On the other hand, humans learn to perform tasks not only from interaction or demonstrations, but also by reading unstructured text documents, e.g., instruction manuals. Instruction manuals and wiki pages are among the most abundant data that could inform agents of valuable features and policies or task-specific environmental dynamics and reward structures. Therefore, we hypothesize that the ability to utilize human-written instruction manuals to assist learning policies for specific tasks should lead to a more efficient and better-performing agent. We propose the Read and Reward framework. Read and Reward speeds up RL algorithms on Atari games by reading manuals released by the Atari game developers. Our framework consists of a QA Extraction module that extracts and summarizes relevant information from the manual and a Reasoning module that evaluates object-agent interactions based on information from the manual. An auxiliary reward is then provided to a standard A2C RL agent, when interaction is detected. Experimentally, various RL algorithms obtain significant improvement in performance and training speed when assisted by our design.",arXiv.org,2023,72,15,3,True,"{'url': 'http://arxiv.org/pdf/2302.04449', 'status': None}",['Computer Science'],"{'volume': 'abs/2302.04449', 'name': 'ArXiv'}","[{'authorId': '46220633', 'name': 'Yue Wu'}, {'authorId': '2166103953', 'name': 'Yewen Fan'}, {'authorId': '28130078', 'name': 'P. Liang'}, {'authorId': '1746466', 'name': 'A. Azaria'}, {'authorId': '152244300', 'name': 'Yuan-Fang Li'}, {'authorId': '40975594', 'name': 'Tom Michael Mitchell'}]",It is hypothesized that the ability to utilize human-written instruction manuals to assist learning policies for specific tasks should lead to a more efficient and better-performing agent in the Read and Reward framework.
Tom Mitchell,40975594,Tom Michael Mitchell,https://www.semanticscholar.org/author/40975594,81,[],353,34877,8874cd8cb99d00e133fba10454e5e5e64f38ca85,"{'DBLP': 'conf/ectel/SchmuckerPSSM23', 'DOI': '10.1007/978-3-031-42682-7_26', 'CorpusId': 261558604}",https://www.semanticscholar.org/paper/8874cd8cb99d00e133fba10454e5e5e64f38ca85,Learning to Give Useful Hints: Assistance Action Evaluation and Policy Improvements,,European Conference on Technology Enhanced Learning,2023,0,0,0,True,"{'url': 'https://link.springer.com/content/pdf/10.1007/978-3-031-42682-7_26.pdf', 'status': None}",['Computer Science'],{'pages': '383-398'},"[{'authorId': '2238003671', 'name': 'Robin Schmucker'}, {'authorId': '2135026', 'name': 'Nimish Pachapurkar'}, {'authorId': '2238001162', 'name': 'Bala Shanmugam'}, {'authorId': '2238227616', 'name': 'Miral Shah'}, {'authorId': '40975594', 'name': 'Tom Michael Mitchell'}]",TLDR not found
Tom Mitchell,40975594,Tom Michael Mitchell,https://www.semanticscholar.org/author/40975594,81,[],353,34877,e98e4af918f3ad0f6ea65f2c68e2846a5b7eb333,"{'DOI': '10.1016/j.burnso.2023.03.003', 'CorpusId': 257619852}",https://www.semanticscholar.org/paper/e98e4af918f3ad0f6ea65f2c68e2846a5b7eb333,Genitourinary Management and Follow-Up for Patients with Stevens-Johnson Syndrome/Toxic Epidermal Necrolysis,,Burns Open,2023,8,0,0,True,,,{'name': 'Burns Open'},"[{'authorId': '82705254', 'name': 'Gina T. Baaklini'}, {'authorId': '40975594', 'name': 'Tom Michael Mitchell'}, {'authorId': '34777893', 'name': 'Jordan Davis'}, {'authorId': '48690853', 'name': 'Kevin McGovern'}, {'authorId': '153276350', 'name': 'J. Aden'}, {'authorId': '2647199', 'name': 'L. Cancio'}]",TLDR not found
William Cohen,50056360,William W. Cohen,https://www.semanticscholar.org/author/50056360,88,['Google'],440,41245,2ca8e50ffd6e2e67f3fe2fbf1af57dbedb4cf493,"{'ArXiv': '2308.08661', 'DBLP': 'journals/corr/abs-2308-08661', 'DOI': '10.48550/arXiv.2308.08661', 'CorpusId': 261031074}",https://www.semanticscholar.org/paper/2ca8e50ffd6e2e67f3fe2fbf1af57dbedb4cf493,"Answering Ambiguous Questions with a Database of Questions, Answers, and Revisions","Many open-domain questions are under-specified and thus have multiple possible answers, each of which is correct under a different interpretation of the question. Answering such ambiguous questions is challenging, as it requires retrieving and then reasoning about diverse information from multiple passages. We present a new state-of-the-art for answering ambiguous questions that exploits a database of unambiguous questions generated from Wikipedia. On the challenging ASQA benchmark, which requires generating long-form answers that summarize the multiple answers to an ambiguous question, our method improves performance by 15% (relative improvement) on recall measures and 10% on measures which evaluate disambiguating questions from predicted outputs. Retrieving from the database of generated questions also gives large improvements in diverse passage retrieval (by matching user questions q to passages p indirectly, via questions q' generated from p).",arXiv.org,2023,26,1,0,True,"{'url': 'https://arxiv.org/pdf/2308.08661', 'status': None}",['Computer Science'],"{'volume': 'abs/2308.08661', 'name': 'ArXiv'}","[{'authorId': '3456820', 'name': 'Haitian Sun'}, {'authorId': '50056360', 'name': 'William W. Cohen'}, {'authorId': '145124475', 'name': 'R. Salakhutdinov'}]","A new state-of-the-art for answering ambiguous questions that exploits a database of unambiguous questions generated from Wikipedia, which improves performance by 15% (relative improvement) on recall measures and 10% on measures which evaluate disambiguating questions from predicted outputs."
William Cohen,50056360,William W. Cohen,https://www.semanticscholar.org/author/50056360,88,['Google'],440,41245,646cca9de110726000a6e44560743b241a4d7f91,"{'DBLP': 'journals/corr/abs-2308-14903', 'ArXiv': '2308.14903', 'DOI': '10.48550/arXiv.2308.14903', 'CorpusId': 261276895}",https://www.semanticscholar.org/paper/646cca9de110726000a6e44560743b241a4d7f91,MEMORY-VQ: Compression for Tractable Internet-Scale Memory,"Retrieval augmentation is a powerful but expensive method to make language models more knowledgeable about the world. Memory-based methods like LUMEN pre-compute token representations for retrieved passages to drastically speed up inference. However, memory also leads to much greater storage requirements from storing pre-computed representations. We propose MEMORY-VQ, a new method to reduce storage requirements of memory-augmented models without sacrificing performance. Our method uses a vector quantization variational autoencoder (VQ-VAE) to compress token representations. We apply MEMORY-VQ to the LUMEN model to obtain LUMEN-VQ, a memory model that achieves a 16x compression rate with comparable performance on the KILT benchmark. LUMEN-VQ enables practical retrieval augmentation even for extremely large retrieval corpora.",arXiv.org,2023,44,0,0,True,"{'url': 'https://arxiv.org/pdf/2308.14903', 'status': None}",['Computer Science'],"{'volume': 'abs/2308.14903', 'name': 'ArXiv'}","[{'authorId': '2220287479', 'name': 'Yury Zemlyanskiy'}, {'authorId': '21379393', 'name': 'Michiel de Jong'}, {'authorId': '2546951', 'name': 'L. Vilnis'}, {'authorId': '2217756237', 'name': ""Santiago Ontan'on""}, {'authorId': '50056360', 'name': 'William W. Cohen'}, {'authorId': '144074891', 'name': 'Sumit K. Sanghai'}, {'authorId': '1643737606', 'name': 'J. Ainslie'}]","This work proposes MEMORY-VQ, a new method to reduce storage requirements of memory-augmented models without sacrificing performance, which uses a vector quantization variational autoencoder (VQ-VAE) to compress token representations."
William Cohen,50056360,William W. Cohen,https://www.semanticscholar.org/author/50056360,88,['Google'],440,41245,83b8e18488d8f31dd017ec0b26531cef4b635b36,"{'DBLP': 'journals/corr/abs-2304-00186', 'ArXiv': '2304.00186', 'DOI': '10.48550/arXiv.2304.00186', 'CorpusId': 257913352}",https://www.semanticscholar.org/paper/83b8e18488d8f31dd017ec0b26531cef4b635b36,Subject-driven Text-to-Image Generation via Apprenticeship Learning,"Recent text-to-image generation models like DreamBooth have made remarkable progress in generating highly customized images of a target subject, by fine-tuning an ``expert model'' for a given subject from a few examples. However, this process is expensive, since a new expert model must be learned for each subject. In this paper, we present SuTI, a Subject-driven Text-to-Image generator that replaces subject-specific fine tuning with in-context learning. Given a few demonstrations of a new subject, SuTI can instantly generate novel renditions of the subject in different scenes, without any subject-specific optimization. SuTI is powered by apprenticeship learning, where a single apprentice model is learned from data generated by a massive number of subject-specific expert models. Specifically, we mine millions of image clusters from the Internet, each centered around a specific visual subject. We adopt these clusters to train a massive number of expert models, each specializing in a different subject. The apprentice model SuTI then learns to imitate the behavior of these fine-tuned experts. SuTI can generate high-quality and customized subject-specific images 20x faster than optimization-based SoTA methods. On the challenging DreamBench and DreamBench-v2, our human evaluation shows that SuTI significantly outperforms existing models like InstructPix2Pix, Textual Inversion, Imagic, Prompt2Prompt, Re-Imagen and DreamBooth, especially on the subject and text alignment aspects.",arXiv.org,2023,44,55,6,True,"{'url': 'https://arxiv.org/pdf/2304.00186', 'status': None}",['Computer Science'],"{'volume': 'abs/2304.00186', 'name': 'ArXiv'}","[{'authorId': '2928777', 'name': 'Wenhu Chen'}, {'authorId': '2804000', 'name': 'Hexiang Hu'}, {'authorId': '1527095795', 'name': 'Yandong Li'}, {'authorId': '2213321774', 'name': 'Nataniel Rui'}, {'authorId': '34760532', 'name': 'Xuhui Jia'}, {'authorId': '2142348146', 'name': 'Ming-Wei Chang'}, {'authorId': '50056360', 'name': 'William W. Cohen'}]","Human evaluation shows that SuTI significantly outperforms existing models like InstructPix2Pix, Textual Inversion, Imagic, Prompt2Prompt, Re-Imagen and DreamBooth, especially on the subject and text alignment aspects."
William Cohen,50056360,William W. Cohen,https://www.semanticscholar.org/author/50056360,88,['Google'],440,41245,c67099476f2b505dfd5a22c817707fad83de9994,"{'DBLP': 'journals/corr/abs-2306-10231', 'ArXiv': '2306.10231', 'DOI': '10.48550/arXiv.2306.10231', 'CorpusId': 259203489}",https://www.semanticscholar.org/paper/c67099476f2b505dfd5a22c817707fad83de9994,GLIMMER: generalized late-interaction memory reranker,"Memory-augmentation is a powerful approach for efficiently incorporating external information into language models, but leads to reduced performance relative to retrieving text. Recent work introduced LUMEN, a memory-retrieval hybrid that partially pre-computes memory and updates memory representations on the fly with a smaller live encoder. We propose GLIMMER, which improves on this approach through 1) exploiting free access to the powerful memory representations by applying a shallow reranker on top of memory to drastically improve retrieval quality at low cost, and 2) incorporating multi-task training to learn a general and higher quality memory and live encoder. GLIMMER achieves strong gains in performance at faster speeds compared to LUMEN and FiD on the KILT benchmark of knowledge-intensive tasks.",arXiv.org,2023,53,3,0,True,"{'url': 'http://arxiv.org/pdf/2306.10231', 'status': None}",['Computer Science'],"{'volume': 'abs/2306.10231', 'name': 'ArXiv'}","[{'authorId': '21379393', 'name': 'Michiel de Jong'}, {'authorId': '2220287479', 'name': 'Yury Zemlyanskiy'}, {'authorId': '143883142', 'name': 'Nicholas FitzGerald'}, {'authorId': '144074891', 'name': 'Sumit K. Sanghai'}, {'authorId': '50056360', 'name': 'William W. Cohen'}, {'authorId': '1643737606', 'name': 'J. Ainslie'}]","GLIMMER is proposed, which improves on LUMEN through exploiting free access to the powerful memory representations by applying a shallow reranker on top of memory to drastically improve retrieval quality at low cost and incorporating multi-task training to learn a general and higher quality memory and live encoder."
Yiming Yang,35729970,Yiming Yang,https://www.semanticscholar.org/author/35729970,64,[],357,47104,08a23cb1ae7b0748407146520c0630d7f2b51c4c,"{'DBLP': 'journals/corr/abs-2308-06644', 'ArXiv': '2308.06644', 'DOI': '10.48550/arXiv.2308.06644', 'CorpusId': 260887267}",https://www.semanticscholar.org/paper/08a23cb1ae7b0748407146520c0630d7f2b51c4c,Accelerating Diffusion-based Combinatorial Optimization Solvers by Progressive Distillation,"Graph-based diffusion models have shown promising results in terms of generating high-quality solutions to NP-complete (NPC) combinatorial optimization (CO) problems. However, those models are often inefficient in inference, due to the iterative evaluation nature of the denoising diffusion process. This paper proposes to use progressive distillation to speed up the inference by taking fewer steps (e.g., forecasting two steps ahead within a single step) during the denoising process. Our experimental results show that the progressively distilled model can perform inference 16 times faster with only 0.019% degradation in performance on the TSP-50 dataset.",arXiv.org,2023,22,0,0,True,"{'url': 'https://arxiv.org/pdf/2308.06644', 'status': None}",['Computer Science'],"{'volume': 'abs/2308.06644', 'name': 'ArXiv'}","[{'authorId': '2118227093', 'name': 'Junwei Huang'}, {'authorId': '48064856', 'name': 'Zhiqing Sun'}, {'authorId': '35729970', 'name': 'Yiming Yang'}]","Progressive distillation is proposed to use progressive distillation to speed up the inference by taking fewer steps (e.g., forecasting two steps ahead within a single step) during the denoising process."
Yiming Yang,35729970,Yiming Yang,https://www.semanticscholar.org/author/35729970,64,[],357,47104,0a187bee2436f4a2e98dd94d3c2f18b83281efdb,"{'PubMedCentral': '9814067', 'DOI': '10.1107/S1600577522011067', 'CorpusId': 253786249, 'PubMed': '36601935'}",https://www.semanticscholar.org/paper/0a187bee2436f4a2e98dd94d3c2f18b83281efdb,Automatic synchrotron tomographic alignment schemes based on genetic algorithms and human-in-the-loop software,A highly automatic alignment scheme is proposed to address the pressing challenge in tomographic alignment of future scanning tomography experiments. The results show that the proposed method exhibits excellent sub-pixel alignment accuracy and high time efficiency.,Journal of Synchrotron Radiation,2023,2,2,0,True,"{'url': 'https://journals.iucr.org/s/issues/2023/01/00/tv5039/tv5039.pdf', 'status': None}",['Medicine'],"{'volume': '30', 'pages': '169 - 178', 'name': 'Journal of Synchrotron Radiation'}","[{'authorId': '2144352466', 'name': 'Zhen Zhang'}, {'authorId': '2191774429', 'name': 'Xiaoxue Bi'}, {'authorId': '2164073047', 'name': 'Pengcheng Li'}, {'authorId': '2155988501', 'name': 'Chenglong Zhang'}, {'authorId': '35729970', 'name': 'Yiming Yang'}, {'authorId': '2146400396', 'name': 'Yu Liu'}, {'authorId': '2146663065', 'name': 'Gang Chen'}, {'authorId': '2165903737', 'name': 'Yuhui Dong'}, {'authorId': '2190394823', 'name': 'Gongfa Liu'}, {'authorId': '2153914727', 'name': 'Yi Zhang'}]",The results show that the proposed method exhibits excellent sub-pixel alignment accuracy and high time efficiency.
Yiming Yang,35729970,Yiming Yang,https://www.semanticscholar.org/author/35729970,64,[],357,47104,16db1c1c00ac219984c28480cb60fd09b1897bf6,"{'PubMedCentral': '10540231', 'DOI': '10.3389/fimmu.2023.1228004', 'CorpusId': 261992874, 'PubMed': '37781365'}",https://www.semanticscholar.org/paper/16db1c1c00ac219984c28480cb60fd09b1897bf6,High CD8+tumor-infiltrating lymphocytes indicate severe exhaustion and poor prognosis in angioimmunoblastic T-cell lymphoma,"Background Exhaustion of CD8+ tumor-infiltrating lymphocytes (TILs), characterized by the overexpression of immune checkpoints (IC), is a major impediment to anti-tumor immunity. However, the exhaustion status of CD8+TILs in angioimmunoblastic T cell lymphoma (AITL) remains unclear. Therefore, we aimed to elucidate the exhaustion status of CD8+TILs in AITL and its influence on prognosis. Methods The correlation between CD8+TILs and IC expression in AITL was analyzed using single-cell RNA sequencing (n = 2), flow cytometry (n = 20), and RNA sequencing (n = 20). Biological changes related to CD8+TILs exhaustion at different cytotoxic T lymphocyte (CTL) levels (mean expression levels of CD8A, CD8B, GZMA, GZMB, and PRF1) in AITL were evaluated using RNA sequencing (n = 20) and further validated using the GEO dataset (n = 51). The impact of CD8 protein expression and CTL levels on patient prognosis was analyzed using flow cytometry and RNA sequencing, respectively. Results Our findings demonstrated that the higher the infiltration of CD8+TILs, the higher was the proportion of exhausted CD8+TILs characterized by the overexpression of multiple IC. This was accompanied by extensive exhaustion-related biological changes, which suggested severe exhaustion in CD8+TILs and may be one of the main reasons for the poor prognosis of patients with high CD8+TILs and CTL. Conclusion Our study comprehensively reveals the exhaustion status of CD8+TILs and their potential negative impact on AITL prognosis, which facilitates further mechanistic studies and is valuable for guiding immunotherapy strategies.",Frontiers in Immunology,2023,35,0,0,True,"{'url': 'https://www.frontiersin.org/articles/10.3389/fimmu.2023.1228004/pdf?isPublishedV2=False', 'status': None}",['Medicine'],"{'volume': '14', 'name': 'Frontiers in Immunology'}","[{'authorId': '2152208016', 'name': 'Qiqi Zhu'}, {'authorId': '35729970', 'name': 'Yiming Yang'}, {'authorId': '81381643', 'name': 'Xueqin Deng'}, {'authorId': '2242696023', 'name': 'Ningning Chao'}, {'authorId': '15281505', 'name': 'Zihang Chen'}, {'authorId': '13854311', 'name': 'Y. Ye'}, {'authorId': '2242452044', 'name': 'Wenyan Zhang'}, {'authorId': '2243377938', 'name': 'Weiping Liu'}, {'authorId': '2243682953', 'name': 'Sha Zhao'}]","The study comprehensively reveals the exhaustion status of CD8+TILs and their potential negative impact on AITL prognosis, which facilitates further mechanistic studies and is valuable for guiding immunotherapy strategies."
Yiming Yang,35729970,Yiming Yang,https://www.semanticscholar.org/author/35729970,64,[],357,47104,2bfa8ac40c1ff8e45c298115fcadae062526310e,"{'DOI': '10.3390/met13081496', 'CorpusId': 261111753}",https://www.semanticscholar.org/paper/2bfa8ac40c1ff8e45c298115fcadae062526310e,Numerical Investigation of Fatigue Crack Propagation Behaviour of 550E High-Performance Steel,"The fatigue crack propagation behaviour of Q550E high-performance steel (HPS) is studied in this paper. Static tensile testing and fatigue crack propagation testing were carried out, and the results were compared with those of Q235. Finite element models were developed and verified against the experimental results. The impacts of the initial crack angle, crack depth ratio, stress ratio, thickness, and corrosion pitting on the fatigue crack propagation behaviour of the HPS were analysed. The results show that the fatigue life of Q550 was reduced by 18% due to the corrosion pitting, but it did not change the crack propagation path. When the stress intensity factor is higher than a certain value, the fatigue performance of Q235 is better than that of Q550E. The initial crack angle of 52.5° is the critical angle of the crack stress intensity factor. The steel tends to fracture as the crack depth ratio increases, and more attention should be paid to the effective crack length in engineering practice. An increasing stress ratio leads to a smaller stress intensity factor, and the thickness affects the stress intensity factor in the later stage. The crack stress intensity factor around the corrosion pits gradually decreases along the thickness direction, and the crack tips around the corrosion pits tend to reach the yield state initially, accelerating the fatigue fracture of the specimen and ultimately leading to a decrease in fatigue life.",Metals,2023,30,0,0,True,"{'url': 'https://www.mdpi.com/2075-4701/13/8/1496/pdf?version=1692605146', 'status': None}",,{'name': 'Metals'},"[{'authorId': '2149552454', 'name': 'Linfa Xiao'}, {'authorId': '2233437243', 'name': 'Heng Lin'}, {'authorId': '46395035', 'name': 'Yongxiang Wang'}, {'authorId': '35729970', 'name': 'Yiming Yang'}, {'authorId': '2167585974', 'name': 'Huapeng Chen'}]",TLDR not found
Yiming Yang,35729970,Yiming Yang,https://www.semanticscholar.org/author/35729970,64,[],357,47104,48bd660e0841ca990178cfafec01163ba2bb07ee,"{'PubMedCentral': '10369733', 'DOI': '10.1186/s12890-023-02574-6', 'CorpusId': 260121704, 'PubMed': '37491191'}",https://www.semanticscholar.org/paper/48bd660e0841ca990178cfafec01163ba2bb07ee,Association between albumin-to-globulin ratio and the risk of overall survival in advanced non-small cell lung cancer patients with anlotinib treatment: a retrospective cohort study,,BMC Pulmonary Medicine,2023,27,1,0,True,"{'url': 'https://bmcpulmmed.biomedcentral.com/counter/pdf/10.1186/s12890-023-02574-6', 'status': None}",['Medicine'],"{'volume': '23', 'name': 'BMC Pulmonary Medicine'}","[{'authorId': '2141121252', 'name': 'Jinzhan Chen'}, {'authorId': '1753264771', 'name': 'Cong-jun Xie'}, {'authorId': '35729970', 'name': 'Yiming Yang'}, {'authorId': '50591764', 'name': 'Shuwen Yang'}, {'authorId': '2109985490', 'name': 'Jin-xiang Huang'}, {'authorId': '2053898616', 'name': 'Feiyang Ye'}, {'authorId': '2220659403', 'name': 'Zhenyang Lin'}, {'authorId': '5578521', 'name': 'L. Tong'}, {'authorId': '2224671155', 'name': 'Jiaxin Liu'}]","AGR level is an independent protective factor for OS in advanced NSCLC patients who received anlotinib therapy, and was positively associated with OS when AGR was larger than 1.24, for every 1 unit increase in AGR, the risk of death lowered approximately by 80%."
Yiming Yang,35729970,Yiming Yang,https://www.semanticscholar.org/author/35729970,64,[],357,47104,535047a5e5845b3a05fb566d9733091448410d75,"{'PubMedCentral': '10574633', 'DOI': '10.3390/molecules28196865', 'CorpusId': 263277914, 'PubMed': '37836708'}",https://www.semanticscholar.org/paper/535047a5e5845b3a05fb566d9733091448410d75,Analysis of Volatile Components in Dried Fruits and Branch Exudates of Schisandra chinensis with Different Fruit Colors Using GC-IMS Technology,"To investigate the volatile components of Schisandra chinensis (Turcz.) Bail (commonly known as northern Schisandra) of different colors and to explore their similarities and differences, to identify the main flavor substances in the volatile components of the branch exudates of northern schisandra, and finally to establish a fingerprint map of the volatile components of the dried fruits and branch exudates of northern Schisandra of different colors, we used GC-IMS technology to analyze the volatile components of the dried fruits and branch exudates of three different colors of northern Schisandra and established a fingerprint spectra. The results showed that a total of 60 different volatile chemical components were identified in the branch exudates and dried fruits of Schisandra. The components of germplasm resources with different fruit colors were significantly different. The ion mobility spectrum and OPLS-DA results showed that white and yellow fruits were more similar compared to red fruits. The volatile components in dried fruits were significantly higher than those in branch exudates. After VIP (variable importance in projection) screening, 41 key volatile substances in dried fruits and 30 key volatile substances in branch exudates were obtained. After screening by odor activity value (OAV), there were 24 volatile components greater than 1 in both dried fruits and branch exudates. The most important contributing volatile substance was 3-methyl-butanal, and the most important contributing volatile substance in white fruit was (E)-2-hexenal.",Molecules,2023,22,2,0,True,"{'url': 'https://www.mdpi.com/1420-3049/28/19/6865/pdf?version=1695977171', 'status': None}",['Medicine'],"{'volume': '28', 'name': 'Molecules'}","[{'authorId': '2238389890', 'name': 'Yiping Yan'}, {'authorId': '2111608859', 'name': 'Wenpeng Lu'}, {'authorId': '2249269529', 'name': 'Taiping Tian'}, {'authorId': '49407053', 'name': 'Nan Shu'}, {'authorId': '35729970', 'name': 'Yiming Yang'}, {'authorId': '2238292263', 'name': 'Shutian Fan'}, {'authorId': '2249766208', 'name': 'Xianyan Han'}, {'authorId': '2249726278', 'name': 'Yunhua Ge'}, {'authorId': '2246140653', 'name': 'Peilei Xu'}]",TLDR not found
Yiming Yang,35729970,Yiming Yang,https://www.semanticscholar.org/author/35729970,64,[],357,47104,5921cc9349dfc43acfefbddc4c9b81a4b6a0b1f9,"{'PubMedCentral': '10219594', 'DOI': '10.1126/sciadv.ade0293', 'CorpusId': 258928759, 'PubMed': '37235655'}",https://www.semanticscholar.org/paper/5921cc9349dfc43acfefbddc4c9b81a4b6a0b1f9,Secreted endogenous macrosomes reduce Aβ burden and ameliorate Alzheimer’s disease,"Innovative therapeutic strategies are urgently needed for Alzheimer’s disease (AD) due to the increasing size of the aging population and the lack of effective drug treatment. Here, we report the therapeutic effects of extracellular vesicles (EVs) secreted by microglia, including macrosomes and small EVs, on AD-associated pathology. Macrosomes strongly inhibited β-amyloid (Aβ) aggregation and rescued cells from Aβ misfolding–induced cytotoxicity. Furthermore, macrosome administration reduced Aβ plaques and ameliorated cognitive impairment in mice with AD. In contrast, small EVs slightly promoted Aβ aggregation and did not improve AD pathology. Proteomic analysis of small EVs and macrosomes revealed that macrosomes harbor several important neuroprotective proteins that inhibit Aβ misfolding. In particular, the small integral membrane protein 10–like protein 2B in macrosomes has been shown to inhibit Aβ aggregation. Our observations provide an alternative therapeutic strategy for the treatment of AD over conventional ineffective drug treatments.",Science Advances,2023,64,2,0,True,"{'url': 'https://www.science.org/doi/pdf/10.1126/sciadv.ade0293?download=true', 'status': None}",['Medicine'],"{'volume': '9', 'name': 'Science Advances'}","[{'authorId': '1508456807', 'name': 'Cunli Wang'}, {'authorId': '35729970', 'name': 'Yiming Yang'}, {'authorId': '2109108293', 'name': 'Xiaoyu Zhang'}, {'authorId': '13106207', 'name': 'Zhenqiang Shi'}, {'authorId': '48690415', 'name': 'Huiling Gao'}, {'authorId': '2118603388', 'name': 'Manli Zhong'}, {'authorId': '5922145', 'name': 'Yong-gang Fan'}, {'authorId': '2108879668', 'name': 'Hongyan Zhang'}, {'authorId': '2159313547', 'name': 'Bo Liu'}, {'authorId': '2057610452', 'name': 'Guangyan Qing'}]","The therapeutic effects of extracellular vesicles secreted by microglia, including macrosomes and small EVs, on AD-associated pathology are reported and macrosomes strongly inhibited β-amyloid aggregation and rescued cells from Aβ misfolding–induced cytotoxicity."
Yiming Yang,35729970,Yiming Yang,https://www.semanticscholar.org/author/35729970,64,[],357,47104,5f90d43e6ece5c6ee6e8186e4b57d46c85377713,"{'DBLP': 'journals/corr/abs-2302-08224', 'ArXiv': '2302.08224', 'DOI': '10.48550/arXiv.2302.08224', 'CorpusId': 256900800}",https://www.semanticscholar.org/paper/5f90d43e6ece5c6ee6e8186e4b57d46c85377713,DIFUSCO: Graph-based Diffusion Solvers for Combinatorial Optimization,"Neural network-based Combinatorial Optimization (CO) methods have shown promising results in solving various NP-complete (NPC) problems without relying on hand-crafted domain knowledge. This paper broadens the current scope of neural solvers for NPC problems by introducing a new graph-based diffusion framework, namely DIFUSCO. Our framework casts NPC problems as discrete {0, 1}-vector optimization problems and leverages graph-based denoising diffusion models to generate high-quality solutions. We investigate two types of diffusion models with Gaussian and Bernoulli noise, respectively, and devise an effective inference schedule to enhance the solution quality. We evaluate our methods on two well-studied NPC combinatorial optimization problems: Traveling Salesman Problem (TSP) and Maximal Independent Set (MIS). Experimental results show that DIFUSCO strongly outperforms the previous state-of-the-art neural solvers, improving the performance gap between ground-truth and neural solvers from 1.76% to 0.46% on TSP-500, from 2.46% to 1.17% on TSP-1000, and from 3.19% to 2.58% on TSP10000. For the MIS problem, DIFUSCO outperforms the previous state-of-the-art neural solver on the challenging SATLIB benchmark.",arXiv.org,2023,129,18,3,True,"{'url': 'http://arxiv.org/pdf/2302.08224', 'status': None}",['Computer Science'],"{'volume': 'abs/2302.08224', 'name': 'ArXiv'}","[{'authorId': '48064856', 'name': 'Zhiqing Sun'}, {'authorId': '35729970', 'name': 'Yiming Yang'}]","DIFUSCO is introduced, a new graph-based diffusion framework for NPC combinatorial optimization that outperforms the previous state-of-the-art neural solvers on the challenging SATLIB benchmark and investigates two types of diffusion models with Gaussian and Bernoulli noise, respectively."
Yiming Yang,35729970,Yiming Yang,https://www.semanticscholar.org/author/35729970,64,[],357,47104,6a42f6362afa3a1a0936f7a6a8927d04a2285cc5,"{'DBLP': 'journals/corr/abs-2307-12063', 'ArXiv': '2307.12063', 'DOI': '10.1109/IJCNN54540.2023.10190993', 'CorpusId': 260125530}",https://www.semanticscholar.org/paper/6a42f6362afa3a1a0936f7a6a8927d04a2285cc5,Balancing Exploration and Exploitation in Hierarchical Reinforcement Learning via Latent Landmark Graphs,"Goal-Conditioned Hierarchical Reinforcement Learning (GCHRL) is a promising paradigm to address the exploration-exploitation dilemma in reinforcement learning. It decomposes the source task into sub goal conditional subtasks and conducts exploration and exploitation in the subgoal space. The effectiveness of GCHRL heavily relies on sub goal representation functions and sub goal selection strategy. However, existing works often overlook the temporal coherence in GCHRL when learning latent sub goal representations and lack an efficient sub goal selection strategy that balances exploration and exploitation. This paper proposes HIerarchical reinforcement learning via dynamically building Latent Landmark graphs (HILL) to overcome these limitations. HILL learns latent subgoal representations that satisfy temporal coherence using a contrastive representation learning objective. Based on these representations, HILL dynamically builds latent landmark graphs and employs a novelty measure on nodes and a utility measure on edges. Finally, HILL develops a subgoal selection strategy that balances exploration and exploitation by jointly considering both measures. Experimental results demonstrate that HILL outperforms state-of-the-art baselines on continuous control tasks with sparse rewards in sample efficiency and asymptotic performance. Our code is available at https://github.com/papercode2022/HILL.",IEEE International Joint Conference on Neural Network,2023,36,0,0,True,"{'url': 'https://arxiv.org/pdf/2307.12063', 'status': None}",['Computer Science'],"{'pages': '1-8', 'name': '2023 International Joint Conference on Neural Networks (IJCNN)'}","[{'authorId': '2120251897', 'name': 'Qingyang Zhang'}, {'authorId': '35729970', 'name': 'Yiming Yang'}, {'authorId': '2135060971', 'name': 'Jingqing Ruan'}, {'authorId': '2025270099', 'name': 'Xuantang Xiong'}, {'authorId': '144185398', 'name': 'Dengpeng Xing'}, {'authorId': '2112878667', 'name': 'Bo Xu'}]",This paper proposes HIerarchical reinforcement learning via dynamically building Latent Landmark graphs (HILL) to overcome limitations in GCHRL and develops a subgoal selection strategy that balances exploration and exploitation by jointly considering both measures.
Yiming Yang,35729970,Yiming Yang,https://www.semanticscholar.org/author/35729970,64,[],357,47104,844bb298d49ef4a07b5d4929dfdfd170f6a1d5f5,"{'ArXiv': '2309.14525', 'DBLP': 'journals/corr/abs-2309-14525', 'DOI': '10.48550/arXiv.2309.14525', 'CorpusId': 262824780}",https://www.semanticscholar.org/paper/844bb298d49ef4a07b5d4929dfdfd170f6a1d5f5,Aligning Large Multimodal Models with Factually Augmented RLHF,"Large Multimodal Models (LMM) are built across modalities and the misalignment between two modalities can result in""hallucination"", generating textual outputs that are not grounded by the multimodal information in context. To address the multimodal misalignment issue, we adapt the Reinforcement Learning from Human Feedback (RLHF) from the text domain to the task of vision-language alignment, where human annotators are asked to compare two responses and pinpoint the more hallucinated one, and the vision-language model is trained to maximize the simulated human rewards. We propose a new alignment algorithm called Factually Augmented RLHF that augments the reward model with additional factual information such as image captions and ground-truth multi-choice options, which alleviates the reward hacking phenomenon in RLHF and further improves the performance. We also enhance the GPT-4-generated training data (for vision instruction tuning) with previously available human-written image-text pairs to improve the general capabilities of our model. To evaluate the proposed approach in real-world scenarios, we develop a new evaluation benchmark MMHAL-BENCH with a special focus on penalizing hallucinations. As the first LMM trained with RLHF, our approach achieves remarkable improvement on the LLaVA-Bench dataset with the 94% performance level of the text-only GPT-4 (while previous best methods can only achieve the 87% level), and an improvement by 60% on MMHAL-BENCH over other baselines. We opensource our code, model, data at https://llava-rlhf.github.io.",arXiv.org,2023,72,48,7,True,"{'url': 'https://arxiv.org/pdf/2309.14525', 'status': None}",['Computer Science'],"{'volume': 'abs/2309.14525', 'name': 'ArXiv'}","[{'authorId': '48064856', 'name': 'Zhiqing Sun'}, {'authorId': '2191455', 'name': 'Sheng Shen'}, {'authorId': '31136675', 'name': 'Shengcao Cao'}, {'authorId': '2143856368', 'name': 'Haotian Liu'}, {'authorId': '2243126534', 'name': 'Chunyuan Li'}, {'authorId': '2714199', 'name': 'Yikang Shen'}, {'authorId': '144158271', 'name': 'Chuang Gan'}, {'authorId': '2587808', 'name': 'Liangyan Gui'}, {'authorId': '2302062', 'name': 'Yu-Xiong Wang'}, {'authorId': '35729970', 'name': 'Yiming Yang'}, {'authorId': '1732330', 'name': 'K. Keutzer'}, {'authorId': '1753210', 'name': 'Trevor Darrell'}]","A new alignment algorithm called Factually Augmented RLHF is proposed that augments the reward model with additional factual information such as image captions and ground-truth multi-choice options, which alleviates the reward hacking phenomenon in RLHF and further improves the performance."
Yiming Yang,35729970,Yiming Yang,https://www.semanticscholar.org/author/35729970,64,[],357,47104,b946ca9514be9920e5d1eff11f597facb8f7c6b7,"{'DOI': '10.3390/met13081489', 'CorpusId': 261018148}",https://www.semanticscholar.org/paper/b946ca9514be9920e5d1eff11f597facb8f7c6b7,An Experimental Study on Secondary Transfer Performances of Prestress after Anchoring Failure of Steel Wire Strands,"To understand the secondary transfer performances of residual prestress after the anchoring failure of end-anchored steel wire strands due to corrosion fracture, six steel wire strand components of post-tensioning prestress were designed and fabricated. One-side fast corrosion was applied to the steel wire strand components using the electrochemical method until anchoring failure was reached. The sphere of influence, stress changes, and the retraction and swelling effect of broken beams after failure were investigated. The influences of factors such as concrete strength, stirrup area, and the length of the component on the secondary transfer length of residual prestress were discussed. Based on the deformation relationship between prestressed steel wire strands and concrete in the stress transfer zone, a stress equation was established and solved through a bond constitutive model. A prediction model of the effective stress transfer length of prestressed steel wire strand after failure was proposed. The results demonstrated that residual prestress can have a secondary transfer after the corrosion fracture of end-anchored steel wire strands, but some effective prestress may be lost. Moreover, the loss of prestress is inversely proportional to concrete compressive strength. When the specimens are relatively short, the prestress loss increases significantly. Concrete strength has significant influences on the length of secondary transfer. The proposed simplified calculation method of the secondary transfer length of residual prestress has a relatively high accuracy, with an average error of 2.9% and a maximum error of 5.2%.",Metals,2023,0,1,0,True,"{'url': 'https://www.mdpi.com/2075-4701/13/8/1489/pdf?version=1692363837', 'status': None}",,{'name': 'Metals'},"[{'authorId': '145221662', 'name': 'Rihua Yang'}, {'authorId': '35729970', 'name': 'Yiming Yang'}, {'authorId': '2143250212', 'name': 'Xuhui Zhang'}, {'authorId': '50141642', 'name': 'Xinzhong Wang'}]",TLDR not found
Yiming Yang,35729970,Yiming Yang,https://www.semanticscholar.org/author/35729970,64,[],357,47104,f1a75a847c99ab399454c911235f0d5f7854c5a4,"{'PubMedCentral': '10541533', 'DOI': '10.2147/JHC.S422632', 'CorpusId': 263011828, 'PubMed': '37786565'}",https://www.semanticscholar.org/paper/f1a75a847c99ab399454c911235f0d5f7854c5a4,MRI Features for Predicting Microvascular Invasion and Postoperative Recurrence in Hepatocellular Carcinoma Without Peritumoral Hypointensity,"Purpose To identify MRI features of hepatocellular carcinoma (HCC) that predict microvascular invasion (MVI) and postoperative intrahepatic recurrence in patients without peritumoral hepatobiliary phase (HBP) hypointensity. Patients and Methods One hundred and thirty patients with HCC who underwent preoperative gadoxetate-enhanced MRI and curative hepatic resection were retrospectively reviewed. Two radiologists reviewed all preoperative MR images and assessed the radiological features of HCCs. The ability of peritumoral HBP hypointensity to identify MVI and intrahepatic recurrence was analyzed. We then assessed the MRI features of HCC that predicted the MVI and intrahepatic recurrence-free survival (RFS) in the subgroup without peritumoral HBP hypointensity. Finally, a two-step flowchart was constructed to assist in clinical decision-making. Results Peritumoral HBP hypointensity (odds ratio, 3.019; 95% confidence interval: 1.071–8.512; P=0.037) was an independent predictor of MVI. The sensitivity, specificity, positive predictive value, negative predictive value, and AUROC of peritumoral HBP hypointensity in predicting MVI were 23.80%, 91.04%, 71.23%, 55.96%, and 0.574, respectively. Intrahepatic RFS was significantly shorter in patients with peritumoral HBP hypointensity (P<0.001). In patients without peritumoral HBP hypointensity, the only significant difference between MVI-positive and MVI-negative HCCs was the presence of a radiological capsule (P=0.038). Satellite nodule was an independent risk factor for intrahepatic RFS (hazard ratio,3.324; 95% CI: 1.733–6.378; P<0.001). The high-risk HCC detection rate was significantly higher when using the two-step flowchart that incorporated peritumoral HBP hypointensity and satellite nodule than when using peritumoral HBP hypointensity alone (P<0.001). Conclusion In patients without peritumoral HBP hypointensity, a radiological capsule is useful for identifying MVI and satellite nodule is an independent risk factor for intrahepatic RFS.",Journal of Hepatocellular Carcinoma,2023,29,0,0,True,"{'url': 'https://www.dovepress.com/getfile.php?fileID=93036', 'status': None}",['Medicine'],"{'volume': '10', 'pages': '1595 - 1608', 'name': 'Journal of Hepatocellular Carcinoma'}","[{'authorId': '2247668758', 'name': 'Zhiyuan Chen'}, {'authorId': '2247626552', 'name': 'Xiaohuan Li'}, {'authorId': '2247680417', 'name': 'Yu Zhang'}, {'authorId': '35729970', 'name': 'Yiming Yang'}, {'authorId': '2256616659', 'name': 'Yan Zhang'}, {'authorId': '87033942', 'name': 'Dongjing Zhou'}, {'authorId': '2247920326', 'name': 'Yu Yang'}, {'authorId': '2247860726', 'name': 'Shuping Zhang'}, {'authorId': '2247850146', 'name': 'Yupin Liu'}]","In patients without peritumoral HBP hypointensity, a radiological capsule is useful for identifying MVI and satellite nodule is an independent risk factor for intrahepatic RFS, and a two-step flowchart was constructed to assist in clinical decision-making."
Yiming Yang,35729970,Yiming Yang,https://www.semanticscholar.org/author/35729970,64,[],357,47104,ff4bd0966db6a5f30fe41c8479765e9d9702a8c0,"{'DOI': '10.18402/resci.2023.06.05', 'CorpusId': 260944290}",https://www.semanticscholar.org/paper/ff4bd0966db6a5f30fe41c8479765e9d9702a8c0,Impact of local governments’ construction land allocation strategies on innovation-driven development of China,,资源科学,2023,0,0,0,True,,,{'name': '资源科学'},"[{'authorId': '2152767824', 'name': 'Jian Wang'}, {'authorId': '84159123', 'name': 'Shangui Peng'}, {'authorId': '2150672769', 'name': 'Yuhao Feng'}, {'authorId': '35729970', 'name': 'Yiming Yang'}, {'authorId': '2135321645', 'name': 'Qun Wu'}]",TLDR not found
Yiming Yang,46286308,Yiming Yang,https://www.semanticscholar.org/author/46286308,17,[],43,1532,02ce4d3f93902a94ec2b57630b77696b7f18c84a,"{'ACL': '2023.acl-long.832', 'ArXiv': '2305.14963', 'DBLP': 'journals/corr/abs-2305-14963', 'DOI': '10.48550/arXiv.2305.14963', 'CorpusId': 258865225}",https://www.semanticscholar.org/paper/02ce4d3f93902a94ec2b57630b77696b7f18c84a,PESCO: Prompt-enhanced Self Contrastive Learning for Zero-shot Text Classification,"We present PESCO, a novel contrastive learning framework that substantially improves the performance of zero-shot text classification. We formulate text classification as a neural text retrieval problem where each document is treated as a query, and the system learns the mapping from each query to the relevant class labels by (1) adding prompts to enhance label retrieval, and (2) using retrieved labels to enrich the training set in a self-training loop of contrastive learning. PESCO achieves state-of-the-art performance on four benchmark text classification datasets. On DBpedia, we achieve 98.5% accuracy without any labeled data, which is close to the fully-supervised result. Extensive experiments and analyses show all the components of PESCO are necessary for improving the performance of zero-shot text classification.",Annual Meeting of the Association for Computational Linguistics,2023,48,2,0,True,"{'url': 'http://arxiv.org/pdf/2305.14963', 'status': None}",['Computer Science'],{'pages': '14897-14911'},"[{'authorId': '46394797', 'name': 'Yau-Shian Wang'}, {'authorId': '27531332', 'name': 'Ta-Chung Chi'}, {'authorId': '46752970', 'name': 'Ruohong Zhang'}, {'authorId': '46286308', 'name': 'Yiming Yang'}]","PESCO is presented, a novel contrastive learning framework that substantially improves the performance of zero-shot text classification and achieves state-of-the-art performance on four benchmark text classification datasets."
Yiming Yang,46286308,Yiming Yang,https://www.semanticscholar.org/author/46286308,17,[],43,1532,1786a2f9140ed7211b21302977de64e948b92308,"{'ArXiv': '2302.07867', 'DBLP': 'journals/corr/abs-2302-07867', 'DOI': '10.48550/arXiv.2302.07867', 'CorpusId': 256868633}",https://www.semanticscholar.org/paper/1786a2f9140ed7211b21302977de64e948b92308,Learning Performance-Improving Code Edits,"The waning of Moore's Law has shifted the focus of the tech industry towards alternative methods for continued performance gains. While optimizing compilers are a standard tool to help increase program efficiency, programmers continue to shoulder much responsibility in crafting and refactoring code with better performance characteristics. In this paper, we investigate the ability of large language models (LLMs) to suggest functionally correct, performance improving code edits. We hypothesize that language models can suggest such edits in ways that would be impractical for static analysis alone. We investigate these questions by curating a large-scale dataset of Performance-Improving Edits, PIE. PIE contains trajectories of programs, where a programmer begins with an initial, slower version and iteratively makes changes to improve the program's performance. We use PIE to evaluate and improve the capacity of large language models. Specifically, use examples from PIE to fine-tune multiple variants of CODEGEN, a billion-scale Transformer-decoder model. Additionally, we use examples from PIE to prompt OpenAI's CODEX using a few-shot prompting. By leveraging PIE, we find that both CODEX and CODEGEN can generate performance-improving edits, with speedups of more than 2.5x for over 25% of the programs, for C++ and Python, even after the C++ programs were compiled using the O3 optimization level. Crucially, we show that PIE allows CODEGEN, an open-sourced and 10x smaller model than CODEX, to match the performance of CODEX on this challenging task. Overall, this work opens new doors for creating systems and methods that can help programmers write efficient code.",arXiv.org,2023,87,26,3,True,"{'url': 'http://arxiv.org/pdf/2302.07867', 'status': None}",['Computer Science'],"{'volume': 'abs/2302.07867', 'name': 'ArXiv'}","[{'authorId': '21626987', 'name': 'Aman Madaan'}, {'authorId': '2129995371', 'name': 'Alex Shypula'}, {'authorId': '47051926', 'name': 'Uri Alon'}, {'authorId': '33798741', 'name': 'Milad Hashemi'}, {'authorId': '1770926', 'name': 'Parthasarathy Ranganathan'}, {'authorId': '46286308', 'name': 'Yiming Yang'}, {'authorId': '1700325', 'name': 'Graham Neubig'}, {'authorId': '2112229', 'name': 'A. Yazdanbakhsh'}]","This paper investigates the ability of large language models (LLMs) to suggest functionally correct, performance improving code edits, and hypothesizes that language models can suggest such edits in ways that would be impractical for static analysis alone."
Yiming Yang,46286308,Yiming Yang,https://www.semanticscholar.org/author/46286308,17,[],43,1532,1804dc14b1cf7bbae96bf3215997e9f14425d622,"{'ArXiv': '2304.11872', 'DBLP': 'journals/corr/abs-2304-11872', 'DOI': '10.48550/arXiv.2304.11872', 'CorpusId': 258297998}",https://www.semanticscholar.org/paper/1804dc14b1cf7bbae96bf3215997e9f14425d622,Generation-driven Contrastive Self-training for Zero-shot Text Classification with Instruction-tuned GPT,"Moreover, GPT-based zero-shot classification models tend to make independent predictions over test instances, which can be sub-optimal as the instance correlations and the decision boundaries in the target space are ignored. To address these difficulties and limitations, we propose a new approach to zero-shot text classification, namely \ourmodelshort, which leverages the strong generative power of GPT to assist in training a smaller, more adaptable, and efficient sentence encoder classifier with contrastive self-training. Specifically, GenCo applies GPT in two ways: firstly, it generates multiple augmented texts for each input instance to enhance the semantic embedding of the instance and improve the mapping to relevant labels; secondly, it generates augmented texts conditioned on the predicted label during self-training, which makes the generative process tailored to the decision boundaries in the target space. In our experiments, GenCo outperforms previous state-of-the-art methods on multiple benchmark datasets, even when only limited in-domain text data is available.",arXiv.org,2023,24,4,1,True,"{'url': 'http://arxiv.org/pdf/2304.11872', 'status': None}",['Computer Science'],"{'volume': 'abs/2304.11872', 'name': 'ArXiv'}","[{'authorId': '46752970', 'name': 'Ruohong Zhang'}, {'authorId': '46394797', 'name': 'Yau-Shian Wang'}, {'authorId': '46286308', 'name': 'Yiming Yang'}]","This work proposes a new approach to zero-shot text classification, namely \ourmodelshort, which leverages the strong generative power of GPT to assist in training a smaller, more adaptable, and efficient sentence encoder classifier with contrastive self-training."
Yiming Yang,46286308,Yiming Yang,https://www.semanticscholar.org/author/46286308,17,[],43,1532,3aaf6a2cbad5850ad81ab5c163599cb3d523436f,"{'DBLP': 'journals/corr/abs-2303-17651', 'ArXiv': '2303.17651', 'DOI': '10.48550/arXiv.2303.17651', 'CorpusId': 257900871}",https://www.semanticscholar.org/paper/3aaf6a2cbad5850ad81ab5c163599cb3d523436f,Self-Refine: Iterative Refinement with Self-Feedback,"Like humans, large language models (LLMs) do not always generate the best output on their first try. Motivated by how humans refine their written text, we introduce Self-Refine, an approach for improving initial outputs from LLMs through iterative feedback and refinement. The main idea is to generate an initial output using an LLMs; then, the same LLMs provides feedback for its output and uses it to refine itself, iteratively. Self-Refine does not require any supervised training data, additional training, or reinforcement learning, and instead uses a single LLM as the generator, refiner, and feedback provider. We evaluate Self-Refine across 7 diverse tasks, ranging from dialog response generation to mathematical reasoning, using state-of-the-art (GPT-3.5, ChatGPT, and GPT-4) LLMs. Across all evaluated tasks, outputs generated with Self-Refine are preferred by humans and automatic metrics over those generated with the same LLM using conventional one-step generation, improving by ~20% absolute on average in task performance. Our work demonstrates that even state-of-the-art LLMs like GPT-4 can be further improved at test time using our simple, standalone approach.",arXiv.org,2023,52,383,25,True,"{'url': 'http://arxiv.org/pdf/2303.17651', 'status': None}",['Computer Science'],"{'volume': 'abs/2303.17651', 'name': 'ArXiv'}","[{'authorId': '21626987', 'name': 'Aman Madaan'}, {'authorId': '1721168', 'name': 'Niket Tandon'}, {'authorId': '1491232062', 'name': 'Prakhar Gupta'}, {'authorId': '1474550731', 'name': 'Skyler Hallinan'}, {'authorId': '49715441', 'name': 'Luyu Gao'}, {'authorId': '35823986', 'name': 'Sarah Wiegreffe'}, {'authorId': '47051926', 'name': 'Uri Alon'}, {'authorId': '46217681', 'name': 'Nouha Dziri'}, {'authorId': '9358910', 'name': 'Shrimai Prabhumoye'}, {'authorId': '46286308', 'name': 'Yiming Yang'}, {'authorId': '2129663', 'name': 'S. Welleck'}, {'authorId': '3165738', 'name': 'Bodhisattwa Prasad Majumder'}, {'authorId': '2152953535', 'name': 'Shashank Gupta'}, {'authorId': '2112229', 'name': 'A. Yazdanbakhsh'}, {'authorId': '48323507', 'name': 'Peter Clark'}]","Self-Refine is introduced, an approach for improving initial outputs from LLMs through iterative feedback and refinement that demonstrates that even state-of-the-art LLMs like GPT-4 can be further improved at test time using this simple, standalone approach."
Yiming Yang,46286308,Yiming Yang,https://www.semanticscholar.org/author/46286308,17,[],43,1532,3c92fd24ea2a49aeba4b368abe3ef13cbce40987,"{'DBLP': 'conf/eacl/ZhangWYYVL23', 'ACL': '2023.findings-eacl.81', 'DOI': '10.18653/v1/2023.findings-eacl.81', 'CorpusId': 258378221}",https://www.semanticscholar.org/paper/3c92fd24ea2a49aeba4b368abe3ef13cbce40987,Long-tailed Extreme Multi-label Text Classification by the Retrieval of Generated Pseudo Label Descriptions,"Extreme Multi-label Text Classification (XMTC) has been a tough challenge in machine learning research and applications due to the sheer sizes of the label spaces and the severe data scarcity problem associated with the long tail of rare labels in highly skewed distributions. This paper addresses the challenge of tail label prediction by leveraging the power of dense neural retrieval model in mapping input documents (as queries) to relevant label descriptions. To further enhance the quality of label descriptions, we propose to generate pseudo label descriptions from a trained bag-of-words (BoW) classifier, which demonstrates better classification performance under severe scarce data conditions.The proposed approach achieves the state-of-the-art (SOTA) performance of overall label prediction on XMTC benchmark datasets and especially outperforms the SOTA models in the tail label prediction. We also provide a theoretical analysis for relating the BoW and neural models w.r.t. performance lower bound.",Findings,2023,29,2,0,True,"{'url': 'https://aclanthology.org/2023.findings-eacl.81.pdf', 'status': None}",['Computer Science'],{'pages': '1062-1076'},"[{'authorId': '46752970', 'name': 'Ruohong Zhang'}, {'authorId': '46394797', 'name': 'Yau-Shian Wang'}, {'authorId': '46286308', 'name': 'Yiming Yang'}, {'authorId': '15121583', 'name': 'Donghan Yu'}, {'authorId': '2161340676', 'name': 'Tom Vu'}, {'authorId': '2066699630', 'name': 'Li Lei'}]","This paper addresses the challenge of tail label prediction by leveraging the power of dense neural retrieval model in mapping input documents to relevant label descriptions and generates pseudo label descriptions from a trained bag-of-words (BoW) classifier, which demonstrates better classification performance under severe scarce data conditions."
Yiming Yang,46286308,Yiming Yang,https://www.semanticscholar.org/author/46286308,17,[],43,1532,4ce987d4f8ae0f4680808c318980d42a82b9aa89,"{'DBLP': 'journals/corr/abs-2302-01925', 'ArXiv': '2302.01925', 'DOI': '10.48550/arXiv.2302.01925', 'CorpusId': 256598356}",https://www.semanticscholar.org/paper/4ce987d4f8ae0f4680808c318980d42a82b9aa89,Learning a Fourier Transform for Linear Relative Positional Encodings in Transformers,"We propose a new class of linear Transformers called FourierLearner-Transformers (FLTs), which incorporate a wide range of relative positional encoding mechanisms (RPEs). These include regular RPE techniques applied for nongeometric data, as well as novel RPEs operating on the sequences of tokens embedded in higher-dimensional Euclidean spaces (e.g. point clouds). FLTs construct the optimal RPE mechanism implicitly by learning its spectral representation. As opposed to other architectures combining efficient low-rank linear attention with RPEs, FLTs remain practical in terms of their memory usage and do not require additional assumptions about the structure of the RPE-mask. FLTs allow also for applying certain structural inductive bias techniques to specify masking strategies, e.g. they provide a way to learn the so-called local RPEs introduced in this paper and providing accuracy gains as compared with several other linear Transformers for language modeling. We also thoroughly tested FLTs on other data modalities and tasks, such as: image classification and 3D molecular modeling. For 3D-data FLTs are, to the best of our knowledge, the first Transformers architectures providing RPE-enhanced linear attention.",arXiv.org,2023,60,5,1,True,"{'url': 'http://arxiv.org/pdf/2302.01925', 'status': None}",['Computer Science'],"{'volume': 'abs/2302.01925', 'name': 'ArXiv'}","[{'authorId': '1805203', 'name': 'K. Choromanski'}, {'authorId': '2119028865', 'name': 'Shanda Li'}, {'authorId': '52314889', 'name': 'Valerii Likhosherstov'}, {'authorId': '89890133', 'name': 'Kumar Avinava Dubey'}, {'authorId': '2108801920', 'name': 'Shengjie Luo'}, {'authorId': '1391126980', 'name': 'Di He'}, {'authorId': '46286308', 'name': 'Yiming Yang'}, {'authorId': '2227764', 'name': 'Tamás Sarlós'}, {'authorId': '2151791144', 'name': 'Thomas Weingarten'}, {'authorId': '145689461', 'name': 'Adrian Weller'}]",FLTs are the first Transformers architectures providing RPE-enhanced linear attention and provide a way to learn the so-called local RPEs introduced in this paper and providing accuracy gains as compared with several other linear Transformers for language modeling.
Yiming Yang,46286308,Yiming Yang,https://www.semanticscholar.org/author/46286308,17,[],43,1532,846f60ef3b98590c7ad1d84727c66a08cc2258c8,"{'DBLP': 'journals/corr/abs-2308-03725', 'ArXiv': '2308.03725', 'DOI': '10.48550/arXiv.2308.03725', 'CorpusId': 260681733}",https://www.semanticscholar.org/paper/846f60ef3b98590c7ad1d84727c66a08cc2258c8,Efficient Temporal Sentence Grounding in Videos with Multi-Teacher Knowledge Distillation,"Temporal Sentence Grounding in Videos (TSGV) aims to detect the event timestamps described by the natural language query from untrimmed videos. This paper discusses the challenge of achieving efficient computation in TSGV models while maintaining high performance. Most existing approaches exquisitely design complex architectures to improve accuracy with extra layers and loss, suffering from inefficiency and heaviness. Although some works have noticed that, they only make an issue of feature fusion layers, which can hardly enjoy the highspeed merit in the whole clunky network. To tackle this problem, we propose a novel efficient multi-teacher model (EMTM) based on knowledge distillation to transfer diverse knowledge from both heterogeneous and isomorphic networks. Specifically, We first unify different outputs of the heterogeneous models into one single form. Next, a Knowledge Aggregation Unit (KAU) is built to acquire high-quality integrated soft labels from multiple teachers. After that, the KAU module leverages the multi-scale video and global query information to adaptively determine the weights of different teachers. A Shared Encoder strategy is then proposed to solve the problem that the student shallow layers hardly benefit from teachers, in which an isomorphic teacher is collaboratively trained with the student to align their hidden states. Extensive experimental results on three popular TSGV benchmarks demonstrate that our method is both effective and efficient without bells and whistles.",arXiv.org,2023,31,7,0,True,"{'url': 'https://arxiv.org/pdf/2308.03725', 'status': None}",['Computer Science'],"{'volume': 'abs/2308.03725', 'name': 'ArXiv'}","[{'authorId': '2070441728', 'name': 'Renjie Liang'}, {'authorId': '46286308', 'name': 'Yiming Yang'}, {'authorId': '2212706205', 'name': 'Hui Lu'}, {'authorId': '2160115945', 'name': 'Li Li'}]","A novel efficient multi-teacher model (EMTM) based on knowledge distillation to transfer diverse knowledge from both heterogeneous and isomorphic networks is proposed, which is both effective and efficient without bells and whistles."
Yiming Yang,46286308,Yiming Yang,https://www.semanticscholar.org/author/46286308,17,[],43,1532,88884b8806262a4095036041e3567d450dba39f7,"{'DBLP': 'journals/corr/abs-2305-06983', 'ArXiv': '2305.06983', 'DOI': '10.48550/arXiv.2305.06983', 'CorpusId': 258615731}",https://www.semanticscholar.org/paper/88884b8806262a4095036041e3567d450dba39f7,Active Retrieval Augmented Generation,"Despite the remarkable ability of large language models (LMs) to comprehend and generate language, they have a tendency to hallucinate and create factually inaccurate output. Augmenting LMs by retrieving information from external knowledge resources is one promising solution. Most existing retrieval augmented LMs employ a retrieve-and-generate setup that only retrieves information once based on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout generation is essential. In this work, we provide a generalized view of active retrieval augmented generation, methods that actively decide when and what to retrieve across the course of the generation. We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens. We test FLARE along with baselines comprehensively over 4 long-form knowledge-intensive generation tasks/datasets. FLARE achieves superior or competitive performance on all tasks, demonstrating the effectiveness of our method. Code and datasets are available at https://github.com/jzbjyb/FLARE.",Conference on Empirical Methods in Natural Language Processing,2023,78,46,6,True,"{'url': 'http://arxiv.org/pdf/2305.06983', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.06983', 'name': 'ArXiv'}","[{'authorId': '2669515', 'name': 'Zhengbao Jiang'}, {'authorId': '40027632', 'name': 'Frank F. Xu'}, {'authorId': '49715441', 'name': 'Luyu Gao'}, {'authorId': '48064856', 'name': 'Zhiqing Sun'}, {'authorId': '1409707585', 'name': 'Qian Liu'}, {'authorId': '2173509991', 'name': 'Jane Dwivedi-Yu'}, {'authorId': '46286308', 'name': 'Yiming Yang'}, {'authorId': '144987107', 'name': 'Jamie Callan'}, {'authorId': '1700325', 'name': 'Graham Neubig'}]","This work proposes Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens."
Yiming Yang,46286308,Yiming Yang,https://www.semanticscholar.org/author/46286308,17,[],43,1532,938d2951ba3aa26f3752d489c3c044ae67d5e809,"{'DBLP': 'conf/sigir/YuY23', 'DOI': '10.1145/3539618.3592052', 'CorpusId': 259949733}",https://www.semanticscholar.org/paper/938d2951ba3aa26f3752d489c3c044ae67d5e809,Retrieval-Enhanced Generative Model for Large-Scale Knowledge Graph Completion,"The task of knowledge graph completion (KGC) is of great importance. To achieve scalability when dealing with large-scale knowledge graphs, recent works formulate KGC as a sequence-to-sequence process, where the incomplete triplet (input) and the missing entity (output) are both verbalized as text sequences. However, inference with these methods relies solely on the model parameters for implicit reasoning and neglects the use of KG itself, which limits the performance since the model lacks the capacity to memorize a vast number of triplets. To tackle this issue, we introduce ReSKGC, a Retrieval-enhanced Seq2seq KGC model, which selects semantically relevant triplets from the KG and uses them as evidence to guide output generation with explicit reasoning. Our method has demonstrated state-of-the-art performance on benchmark datasets Wikidata5M and WikiKG90Mv2, which contain about 5M and 90M entities, respectively.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2023,34,0,0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/3539618.3592052', 'status': None}",['Computer Science'],{'name': 'Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval'},"[{'authorId': '2111506236', 'name': 'Donghan Yu'}, {'authorId': '46286308', 'name': 'Yiming Yang'}]","ReSKGC is introduced, a Retrieval-enhanced Seq2seq KGC model, which selects semantically relevant triplets from the KG and uses them as evidence to guide output generation with explicit reasoning, and has demonstrated state-of-the-art performance on benchmark datasets Wikidata5M and WikiKG90Mv2."
Yiming Yang,46286308,Yiming Yang,https://www.semanticscholar.org/author/46286308,17,[],43,1532,b4a6c010724f0459c9791018e34a982cf96987cf,"{'ArXiv': '2305.11860', 'DBLP': 'conf/emnlp/AggarwalY23', 'DOI': '10.18653/v1/2023.emnlp-main.761', 'CorpusId': 258823191}",https://www.semanticscholar.org/paper/b4a6c010724f0459c9791018e34a982cf96987cf,Let's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning and Coding with LLMs,"A popular approach for improving the correctness of output from large language models (LLMs) is Self-Consistency - poll the LLM multiple times and output the most frequent solution. Existing Self-Consistency techniques always generate a constant number of samples per question, where a better approach will be to non-uniformly distribute the available budget based on the amount of agreement in the samples generated so far. In response, we introduce Adaptive-Consistency, a cost-efficient, model-agnostic technique that dynamically adjusts the number of samples per question using a lightweight stopping criterion. Our experiments over 17 reasoning and code generation datasets and three LLMs demonstrate that Adaptive-Consistency reduces sample budget by up to 7.9 times with an average accuracy drop of less than 0.1%. Our code and data are available at https://www.sample-step-by-step.info",Conference on Empirical Methods in Natural Language Processing,2023,54,9,1,True,"{'url': 'https://aclanthology.org/2023.emnlp-main.761.pdf', 'status': None}",['Computer Science'],{'pages': '12375-12396'},"[{'authorId': '2114841965', 'name': 'Pranjal Aggarwal'}, {'authorId': '21626987', 'name': 'Aman Madaan'}, {'authorId': '46286308', 'name': 'Yiming Yang'}, {'authorId': '2674444', 'name': 'Mausam'}]","Adaptive-Consistency is introduced, a cost-efficient, model-agnostic technique that dynamically adjusts the number of samples per question using a lightweight stopping criterion that reduces sample budget by up to 7.9 times with an average accuracy drop of less than 0.1%."
Yiming Yang,46286308,Yiming Yang,https://www.semanticscholar.org/author/46286308,17,[],43,1532,e01515c6138bc525f7aec30fc85f2adf028d4156,"{'DBLP': 'journals/corr/abs-2305-03047', 'ArXiv': '2305.03047', 'DOI': '10.48550/arXiv.2305.03047', 'CorpusId': 258479665}",https://www.semanticscholar.org/paper/e01515c6138bc525f7aec30fc85f2adf028d4156,Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision,"Recent AI-assistant agents, such as ChatGPT, predominantly rely on supervised fine-tuning (SFT) with human annotations and reinforcement learning from human feedback (RLHF) to align the output of large language models (LLMs) with human intentions, ensuring they are helpful, ethical, and reliable. However, this dependence can significantly constrain the true potential of AI-assistant agents due to the high cost of obtaining human supervision and the related issues on quality, reliability, diversity, self-consistency, and undesirable biases. To address these challenges, we propose a novel approach called SELF-ALIGN, which combines principle-driven reasoning and the generative power of LLMs for the self-alignment of AI agents with minimal human supervision. Our approach encompasses four stages: first, we use an LLM to generate synthetic prompts, and a topic-guided method to augment the prompt diversity; second, we use a small set of human-written principles for AI models to follow, and guide the LLM through in-context learning from demonstrations (of principles application) to produce helpful, ethical, and reliable responses to user's queries; third, we fine-tune the original LLM with the high-quality self-aligned responses so that the resulting model can generate desirable responses for each query directly without the principle set and the demonstrations anymore; and finally, we offer a refinement step to address the issues of overly-brief or indirect responses. Applying SELF-ALIGN to the LLaMA-65b base language model, we develop an AI assistant named Dromedary. With fewer than 300 lines of human annotations (including<200 seed prompts, 16 generic principles, and 5 exemplars for in-context learning). Dromedary significantly surpasses the performance of several state-of-the-art AI systems, including Text-Davinci-003 and Alpaca, on benchmark datasets with various settings.",arXiv.org,2023,79,109,13,True,"{'url': 'http://arxiv.org/pdf/2305.03047', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.03047', 'name': 'ArXiv'}","[{'authorId': '48064856', 'name': 'Zhiqing Sun'}, {'authorId': '2714199', 'name': 'Yikang Shen'}, {'authorId': '2107604346', 'name': 'Qinhong Zhou'}, {'authorId': '2118083343', 'name': 'Hongxin Zhang'}, {'authorId': '2111329651', 'name': 'Zhenfang Chen'}, {'authorId': '2064715218', 'name': 'David D. Cox'}, {'authorId': '46286308', 'name': 'Yiming Yang'}, {'authorId': '2056157586', 'name': 'Chuang Gan'}]","An AI assistant named Dromedary is developed, which combines principle-driven reasoning and the generative power of LLMs for the self-alignment of AI agents with minimal human supervision and significantly surpasses the performance of several state-of-the-art AI systems on benchmark datasets with various settings."
Yiming Yang,46286308,Yiming Yang,https://www.semanticscholar.org/author/46286308,17,[],43,1532,fe9fe9f15f24fbbb19b62bcd9a3418511a699b84,"{'DBLP': 'journals/corr/abs-2305-13122', 'ArXiv': '2305.13122', 'DOI': '10.48550/arXiv.2305.13122', 'CorpusId': 258832463}",https://www.semanticscholar.org/paper/fe9fe9f15f24fbbb19b62bcd9a3418511a699b84,Policy Representation via Diffusion Probability Model for Reinforcement Learning,"Popular reinforcement learning (RL) algorithms tend to produce a unimodal policy distribution, which weakens the expressiveness of complicated policy and decays the ability of exploration. The diffusion probability model is powerful to learn complicated multimodal distributions, which has shown promising and potential applications to RL. In this paper, we formally build a theoretical foundation of policy representation via the diffusion probability model and provide practical implementations of diffusion policy for online model-free RL. Concretely, we character diffusion policy as a stochastic process, which is a new approach to representing a policy. Then we present a convergence guarantee for diffusion policy, which provides a theory to understand the multimodality of diffusion policy. Furthermore, we propose the DIPO which is an implementation for model-free online RL with DIffusion POlicy. To the best of our knowledge, DIPO is the first algorithm to solve model-free online RL problems with the diffusion model. Finally, extensive empirical results show the effectiveness and superiority of DIPO on the standard continuous control Mujoco benchmark.",arXiv.org,2023,97,4,0,True,"{'url': 'http://arxiv.org/pdf/2305.13122', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.13122', 'name': 'ArXiv'}","[{'authorId': '150196660', 'name': 'Long Yang'}, {'authorId': '2218293583', 'name': 'Zhixiong Huang'}, {'authorId': '2218119181', 'name': 'Fenghao Lei'}, {'authorId': '2218100325', 'name': 'Yucun Zhong'}, {'authorId': '46286308', 'name': 'Yiming Yang'}, {'authorId': '47967033', 'name': 'Cong Fang'}, {'authorId': '2992234', 'name': 'Shiting Wen'}, {'authorId': '2218029625', 'name': 'Binbin Zhou'}, {'authorId': '33383055', 'name': 'Zhouchen Lin'}]","A theoretical foundation of policy representation via the diffusion probability model is formally built, a convergence guarantee for diffusion policy is presented, and the DIPO is proposed, which is an implementation for model-free online RL with DIffusion POlicy."
Yonatan Bisk,3312309,Yonatan Bisk,https://www.semanticscholar.org/author/3312309,33,['Carnegie Mellon University'],98,7048,376f494126d1ea4f571ea0263c43ac2b6331800a,"{'ArXiv': '2306.17842', 'DBLP': 'journals/corr/abs-2306-17842', 'DOI': '10.48550/arXiv.2306.17842', 'CorpusId': 259308960}",https://www.semanticscholar.org/paper/376f494126d1ea4f571ea0263c43ac2b6331800a,SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs,"In this work, we introduce Semantic Pyramid AutoEncoder (SPAE) for enabling frozen LLMs to perform both understanding and generation tasks involving non-linguistic modalities such as images or videos. SPAE converts between raw pixels and interpretable lexical tokens (or words) extracted from the LLM's vocabulary. The resulting tokens capture both the semantic meaning and the fine-grained details needed for visual reconstruction, effectively translating the visual content into a language comprehensible to the LLM, and empowering it to perform a wide array of multimodal tasks. Our approach is validated through in-context learning experiments with frozen PaLM 2 and GPT 3.5 on a diverse set of image understanding and generation tasks. Our method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.",arXiv.org,2023,52,9,1,True,"{'url': 'http://arxiv.org/pdf/2306.17842', 'status': None}",['Computer Science'],"{'volume': 'abs/2306.17842', 'name': 'ArXiv'}","[{'authorId': '8547960', 'name': 'Lijun Yu'}, {'authorId': '2109716647', 'name': 'Yong Cheng'}, {'authorId': '1390877035', 'name': 'Zhiruo Wang'}, {'authorId': '2107989922', 'name': 'Vivek Kumar'}, {'authorId': '3153147', 'name': 'Wolfgang Macherey'}, {'authorId': '2145438541', 'name': 'Yanping Huang'}, {'authorId': '144711958', 'name': 'David A. Ross'}, {'authorId': '145955800', 'name': 'Irfan Essa'}, {'authorId': '3312309', 'name': 'Yonatan Bisk'}, {'authorId': '152790163', 'name': 'Ming Yang'}, {'authorId': '1702318', 'name': 'K. Murphy'}, {'authorId': '145788702', 'name': 'A. Hauptmann'}, {'authorId': '39978626', 'name': 'Lu Jiang'}]","This method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%."
Yonatan Bisk,3312309,Yonatan Bisk,https://www.semanticscholar.org/author/3312309,33,['Carnegie Mellon University'],98,7048,3b0c02955e88f5862e61b560c7f70ba8cf235b1d,"{'DBLP': 'journals/corr/abs-2306-11565', 'ArXiv': '2306.11565', 'DOI': '10.48550/arXiv.2306.11565', 'CorpusId': 259203746}",https://www.semanticscholar.org/paper/3b0c02955e88f5862e61b560c7f70ba8cf235b1d,HomeRobot: Open-Vocabulary Mobile Manipulation,"HomeRobot (noun): An affordable compliant robot that navigates homes and manipulates a wide range of objects in order to complete everyday tasks. Open-Vocabulary Mobile Manipulation (OVMM) is the problem of picking any object in any unseen environment, and placing it in a commanded location. This is a foundational challenge for robots to be useful assistants in human environments, because it involves tackling sub-problems from across robotics: perception, language understanding, navigation, and manipulation are all essential to OVMM. In addition, integration of the solutions to these sub-problems poses its own substantial challenges. To drive research in this area, we introduce the HomeRobot OVMM benchmark, where an agent navigates household environments to grasp novel objects and place them on target receptacles. HomeRobot has two components: a simulation component, which uses a large and diverse curated object set in new, high-quality multi-room home environments; and a real-world component, providing a software stack for the low-cost Hello Robot Stretch to encourage replication of real-world experiments across labs. We implement both reinforcement learning and heuristic (model-based) baselines and show evidence of sim-to-real transfer. Our baselines achieve a 20% success rate in the real world; our experiments identify ways future research work improve performance. See videos on our website: https://ovmm.github.io/.",Conference on Robot Learning,2023,115,16,1,True,"{'url': 'http://arxiv.org/pdf/2306.11565', 'status': None}",['Computer Science'],"{'volume': 'abs/2306.11565', 'name': 'ArXiv'}","[{'authorId': '2088846095', 'name': 'Sriram Yenamandra'}, {'authorId': '1410121720', 'name': 'A. Ramachandran'}, {'authorId': '1838683872', 'name': 'Karmesh Yadav'}, {'authorId': '32451493', 'name': 'Austin S. Wang'}, {'authorId': '2066532783', 'name': 'Mukul Khanna'}, {'authorId': '81588783', 'name': 'Théophile Gervet'}, {'authorId': '2220329333', 'name': 'Tsung-Yen Yang'}, {'authorId': '2061364783', 'name': 'Vidhi Jain'}, {'authorId': '30933599', 'name': 'Alexander Clegg'}, {'authorId': '2115151351', 'name': 'John Turner'}, {'authorId': '145276578', 'name': 'Z. Kira'}, {'authorId': '2295141', 'name': 'M. Savva'}, {'authorId': '145830541', 'name': 'Angel X. Chang'}, {'authorId': '2142753065', 'name': 'Devendra Singh Chaplot'}, {'authorId': '1746610', 'name': 'Dhruv Batra'}, {'authorId': '3012475', 'name': 'Roozbeh Mottaghi'}, {'authorId': '3312309', 'name': 'Yonatan Bisk'}, {'authorId': '1977464', 'name': 'Chris Paxton'}]","The HomeRobot OVMM benchmark is introduced, where an agent navigates household environments to grasp novel objects and place them on target receptacles, and baselines achieve a 20% success rate in the real world; the experiments identify ways future research work improve performance."
Yonatan Bisk,3312309,Yonatan Bisk,https://www.semanticscholar.org/author/3312309,33,['Carnegie Mellon University'],98,7048,5ce2f1dff23a5620f77f9b11f1e534422ab8ff3f,"{'DBLP': 'journals/corr/abs-2305-02412', 'ArXiv': '2305.02412', 'DOI': '10.48550/arXiv.2305.02412', 'CorpusId': 258480064}",https://www.semanticscholar.org/paper/5ce2f1dff23a5620f77f9b11f1e534422ab8ff3f,"Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents","Pre-trained large language models (LLMs) capture procedural knowledge about the world. Recent work has leveraged LLM's ability to generate abstract plans to simplify challenging control tasks, either by action scoring, or action modeling (fine-tuning). However, the transformer architecture inherits several constraints that make it difficult for the LLM to directly serve as the agent: e.g. limited input lengths, fine-tuning inefficiency, bias from pre-training, and incompatibility with non-text environments. To maintain compatibility with a low-level trainable actor, we propose to instead use the knowledge in LLMs to simplify the control problem, rather than solving it. We propose the Plan, Eliminate, and Track (PET) framework. The Plan module translates a task description into a list of high-level sub-tasks. The Eliminate module masks out irrelevant objects and receptacles from the observation for the current sub-task. Finally, the Track module determines whether the agent has accomplished each sub-task. On the AlfWorld instruction following benchmark, the PET framework leads to a significant 15% improvement over SOTA for generalization to human goal specifications.",arXiv.org,2023,41,16,0,True,"{'url': 'http://arxiv.org/pdf/2305.02412', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.02412', 'name': 'ArXiv'}","[{'authorId': '46220633', 'name': 'Yue Wu'}, {'authorId': '2008204295', 'name': 'So Yeon Min'}, {'authorId': '3312309', 'name': 'Yonatan Bisk'}, {'authorId': '145124475', 'name': 'R. Salakhutdinov'}, {'authorId': '1746466', 'name': 'A. Azaria'}, {'authorId': '152244300', 'name': 'Yuan-Fang Li'}, {'authorId': '144135485', 'name': 'Tom M. Mitchell'}, {'authorId': '9358910', 'name': 'Shrimai Prabhumoye'}]","A framework to use the knowledge in LLMs to simplify the control problem, rather than solving it is proposed, which leads to a significant 15% improvement over SOTA for generalization to human goal specifications."
Yonatan Bisk,3312309,Yonatan Bisk,https://www.semanticscholar.org/author/3312309,33,['Carnegie Mellon University'],98,7048,69b8cd15966c4c9c3e44e71769e557f1c87fb3f9,"{'DBLP': 'journals/corr/abs-2309-08508', 'ArXiv': '2309.08508', 'DOI': '10.48550/arXiv.2309.08508', 'CorpusId': 262012665}",https://www.semanticscholar.org/paper/69b8cd15966c4c9c3e44e71769e557f1c87fb3f9,MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception,"A holistic understanding of object properties across diverse sensory modalities (e.g., visual, audio, and haptic) is essential for tasks ranging from object categorization to complex manipulation. Drawing inspiration from cognitive science studies that emphasize the significance of multi-sensory integration in human perception, we introduce MOSAIC (Multi-modal Object property learning with Self-Attention and Integrated Comprehension), a novel framework designed to facilitate the learning of unified multi-sensory object property representations. While it is undeniable that visual information plays a prominent role, we acknowledge that many fundamental object properties extend beyond the visual domain to encompass attributes like texture, mass distribution, or sounds, which significantly influence how we interact with objects. In MOSAIC, we leverage this profound insight by distilling knowledge from the extensive pre-trained Contrastive Language-Image Pre-training (CLIP) model, aligning these representations not only across vision but also haptic and auditory sensory modalities. Through extensive experiments on a dataset where a humanoid robot interacts with 100 objects across 10 exploratory behaviors, we demonstrate the versatility of MOSAIC in two task families: object categorization and object-fetching tasks. Our results underscore the efficacy of MOSAIC's unified representations, showing competitive performance in category recognition through a simple linear probe setup and excelling in the fetch object task under zero-shot transfer conditions. This work pioneers the application of CLIP-based sensory grounding in robotics, promising a significant leap in multi-sensory perception capabilities for autonomous systems. We have released the code, datasets, and additional results: https://github.com/gtatiya/MOSAIC.",arXiv.org,2023,35,1,0,True,"{'url': 'https://arxiv.org/pdf/2309.08508', 'status': None}",['Computer Science'],"{'volume': 'abs/2309.08508', 'name': 'ArXiv'}","[{'authorId': '1394711029', 'name': 'Gyan Tatiya'}, {'authorId': '26253744', 'name': 'Jonathan M Francis'}, {'authorId': '2243295123', 'name': 'Ho-Hsiang Wu'}, {'authorId': '3312309', 'name': 'Yonatan Bisk'}, {'authorId': '1715858', 'name': 'J. Sinapov'}]","This work pioneers the application of CLIP-based sensory grounding in robotics, promising a significant leap in multi-sensory perception capabilities for autonomous systems."
Yonatan Bisk,3312309,Yonatan Bisk,https://www.semanticscholar.org/author/3312309,33,['Carnegie Mellon University'],98,7048,8035a247980cb18abf2bb7b9d96e7d4c63622ef2,"{'ArXiv': '2309.10103', 'DBLP': 'journals/corr/abs-2309-10103', 'DOI': '10.48550/arXiv.2309.10103', 'CorpusId': 261945162}",https://www.semanticscholar.org/paper/8035a247980cb18abf2bb7b9d96e7d4c63622ef2,Reasoning about the Unseen for Efficient Outdoor Object Navigation,"Robots should exist anywhere humans do: indoors, outdoors, and even unmapped environments. In contrast, the focus of recent advancements in Object Goal Navigation(OGN) has targeted navigating in indoor environments by leveraging spatial and semantic cues that do not generalize outdoors. While these contributions provide valuable insights into indoor scenarios, the broader spectrum of real-world robotic applications often extends to outdoor settings. As we transition to the vast and complex terrains of outdoor environments, new challenges emerge. Unlike the structured layouts found indoors, outdoor environments lack clear spatial delineations and are riddled with inherent semantic ambiguities. Despite this, humans navigate with ease because we can reason about the unseen. We introduce a new task OUTDOOR, a new mechanism for Large Language Models (LLMs) to accurately hallucinate possible futures, and a new computationally aware success metric for pushing research forward in this more complex domain. Additionally, we show impressive results on both a simulated drone and physical quadruped in outdoor environments. Our agent has no premapping and our formalism outperforms naive LLM-based approaches",arXiv.org,2023,36,1,1,True,"{'url': 'https://arxiv.org/pdf/2309.10103', 'status': None}",['Computer Science'],"{'volume': 'abs/2309.10103', 'name': 'ArXiv'}","[{'authorId': '2242010169', 'name': 'Quanting Xie'}, {'authorId': '2238206121', 'name': 'Tianyi Zhang'}, {'authorId': '2243950262', 'name': 'Kedi Xu'}, {'authorId': '1389944402', 'name': 'M. Johnson-Roberson'}, {'authorId': '3312309', 'name': 'Yonatan Bisk'}]","A new task OUTDOOR is introduced, a new mechanism for Large Language Models (LLMs) to accurately hallucinate possible futures, and a new computationally aware success metric for pushing research forward in this more complex domain are introduced."
Yonatan Bisk,3312309,Yonatan Bisk,https://www.semanticscholar.org/author/3312309,33,['Carnegie Mellon University'],98,7048,b777aa86b5a1d49ce8eababc5c2ee56d3562801e,"{'DBLP': 'journals/corr/abs-2302-06117', 'ArXiv': '2302.06117', 'DOI': '10.48550/arXiv.2302.06117', 'CorpusId': 256826923}",https://www.semanticscholar.org/paper/b777aa86b5a1d49ce8eababc5c2ee56d3562801e,The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment,"Increased focus on the computational efficiency of NLP systems has motivated the design of efficient model architectures and improvements to underlying hardware accelerators. However, the resulting increases in computational throughput and reductions in floating point operations have not directly translated to improvements in wall-clock inference latency. We demonstrate that these discrepancies can be largely attributed to bottlenecks introduced by deep learning frameworks. We denote this phenomenon as the \textit{framework tax}, and observe that the disparity is growing as hardware speed increases over time. In this work, we examine this phenomenon through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency. Code is available at https://github.com/JaredFern/Framework-Tax.",Conference on Empirical Methods in Natural Language Processing,2023,64,2,0,True,"{'url': 'http://arxiv.org/pdf/2302.06117', 'status': None}",['Computer Science'],"{'volume': 'abs/2302.06117', 'name': 'ArXiv'}","[{'authorId': '152793333', 'name': 'Jared Fernandez'}, {'authorId': '39960571', 'name': 'Jacob Kahn'}, {'authorId': '2166313248', 'name': 'Clara Na'}, {'authorId': '3312309', 'name': 'Yonatan Bisk'}, {'authorId': '2268272', 'name': 'Emma Strubell'}]","This work examines the effects of model design decisions, framework paradigms, and hardware platforms on total model latency through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency."
Yonatan Bisk,3312309,Yonatan Bisk,https://www.semanticscholar.org/author/3312309,33,['Carnegie Mellon University'],98,7048,e41482f4ee984f17382f6cdd900df094d928be06,"{'ArXiv': '2307.13854', 'DBLP': 'journals/corr/abs-2307-13854', 'DOI': '10.48550/arXiv.2307.13854', 'CorpusId': 260164780}",https://www.semanticscholar.org/paper/e41482f4ee984f17382f6cdd900df094d928be06,WebArena: A Realistic Web Environment for Building Autonomous Agents,"With advances in generative AI, there is now potential for autonomous agents to manage daily tasks via natural language commands. However, current agents are primarily created and tested in simplified synthetic environments, leading to a disconnect with real-world scenarios. In this paper, we build an environment for language-guided agents that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on the web, and create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our environment is enriched with tools (e.g., a map) and external knowledge bases (e.g., user manuals) to encourage human-like task-solving. Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and designed to emulate tasks that humans routinely perform on the internet. We experiment with several baseline agents, integrating recent techniques such as reasoning before acting. The results demonstrate that solving complex tasks is challenging: our best GPT-4-based agent only achieves an end-to-end task success rate of 14.41%, significantly lower than the human performance of 78.24%. These results highlight the need for further development of robust agents, that current state-of-the-art large language models are far from perfect performance in these real-life tasks, and that WebArena can be used to measure such progress.",arXiv.org,2023,63,60,7,True,"{'url': 'https://arxiv.org/pdf/2307.13854', 'status': None}",['Computer Science'],"{'volume': 'abs/2307.13854', 'name': 'ArXiv'}","[{'authorId': '2149163534', 'name': 'Shuyan Zhou'}, {'authorId': '40027632', 'name': 'Frank F. Xu'}, {'authorId': '2115313911', 'name': 'Hao Zhu'}, {'authorId': '144101734', 'name': 'Xuhui Zhou'}, {'authorId': '145250604', 'name': 'Robert Lo'}, {'authorId': '66820957', 'name': 'Abishek Sridhar'}, {'authorId': '144691454', 'name': 'Xianyi Cheng'}, {'authorId': '3312309', 'name': 'Yonatan Bisk'}, {'authorId': '47070750', 'name': 'Daniel Fried'}, {'authorId': '47051926', 'name': 'Uri Alon'}, {'authorId': '1700325', 'name': 'Graham Neubig'}]","This paper builds an environment for language-guided agents that is highly realistic and reproducible, and creates an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management."
Yonatan Bisk,3312309,Yonatan Bisk,https://www.semanticscholar.org/author/3312309,33,['Carnegie Mellon University'],98,7048,e7b3b692b0816821aafc0d354749bc3802cbf6ac,"{'DBLP': 'journals/corr/abs-2303-01502', 'ArXiv': '2303.01502', 'DOI': '10.48550/arXiv.2303.01502', 'CorpusId': 257280165}",https://www.semanticscholar.org/paper/e7b3b692b0816821aafc0d354749bc3802cbf6ac,Computational Language Acquisition with Theory of Mind,"Unlike current state-of-the-art language models, young children actively acquire language through interactions with their surrounding environment and caretakers. One mechanism that has been argued to be critical to language learning is the ability to infer the mental states of other agents in social environments, coined Theory of Mind (ToM) by Premack&Woodruff (1978). Drawing inspiration from the modern operationalized versions of ToM implemented in Rabinowitz et al. (2018) and Zhu et al. (2021), we build language-learning agents equipped with ToM, and measure its effects on the learning process. We model ToM by giving the speaker agent an internal listener model that is trained alongside the speaker and used to rerank potential utterances. We experiment with varying task difficulty, hypothesizing that models will acquire more complex language to adapt to stronger environmental pressures. We find that training speakers with a highly weighted ToM listener component leads to performance gains in our image referential game setting. We also find some evidence that increasing task difficulty in the training process results in more fluent and precise utterances in evaluation. This suggests the potential utility of further incorporating ToM, as well as other insights from child language acquisition, into computational models of language acquisition.",International Conference on Learning Representations,2023,35,6,0,True,"{'url': 'http://arxiv.org/pdf/2303.01502', 'status': None}",['Computer Science'],"{'volume': 'abs/2303.01502', 'name': 'ArXiv'}","[{'authorId': '46263614', 'name': 'Andy T. Liu'}, {'authorId': '2115314674', 'name': 'Hao Zhu'}, {'authorId': '1381444447', 'name': 'Emmy Liu'}, {'authorId': '3312309', 'name': 'Yonatan Bisk'}, {'authorId': '1700325', 'name': 'Graham Neubig'}]","It is found that training speakers with a highly weighted ToM listener component leads to performance gains in the authors' image referential game setting, and suggests the potential utility of further incorporating ToM, as well as other insights from child language acquisition, into computational models of language acquisition."
Yulia Tsvetkov,145317727,Yulia Tsvetkov,https://www.semanticscholar.org/author/145317727,33,['Carnegie Mellon University'],92,4659,12902f724619344dfeae330043c4b7b1c9d99bd0,"{'ACL': '2023.eacl-tutorials.4', 'DOI': '10.18653/v1/2023.eacl-tutorials.4', 'CorpusId': 258378232}",https://www.semanticscholar.org/paper/12902f724619344dfeae330043c4b7b1c9d99bd0,Understanding Ethics in NLP Authoring and Reviewing,"With NLP research now quickly being transferred into real-world applications, it is important to be aware of and think through the consequences of our scientific investigation. Such ethical considerations are important in both authoring and reviewing. This tutorial will equip participants with basic guidelines for thinking deeply about ethical issues and review common considerations that recur in NLP research. The methodology is interactive and participatory, including case studies and working in groups. Importantly, the participants will be co-building the tutorial outcomes and will be working to create further tutorial materials to share as public outcomes.",Conference of the European Chapter of the Association for Computational Linguistics,2023,37,0,0,True,"{'url': 'https://aclanthology.org/2023.eacl-tutorials.4.pdf', 'status': None}",,{'name': 'Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics: Tutorial Abstracts'},"[{'authorId': '2066254822', 'name': 'Luciana Benotti'}, {'authorId': '3196675', 'name': 'Karën Fort'}, {'authorId': '37596605', 'name': 'Min-Yen Kan'}, {'authorId': '145317727', 'name': 'Yulia Tsvetkov'}]",This tutorial will equip participants with basic guidelines for thinking deeply about ethical issues and review common considerations that recur in NLP research.
Yulia Tsvetkov,2073587169,Yulia Tsvetkov,https://www.semanticscholar.org/author/2073587169,17,[],48,1382,17605c43ca3eb982c99642052ddc21a93d116594,"{'DBLP': 'conf/emnlp/SongK0FOWACTAN23', 'ArXiv': '2305.14716', 'DOI': '10.48550/arXiv.2305.14716', 'CorpusId': 258866051}",https://www.semanticscholar.org/paper/17605c43ca3eb982c99642052ddc21a93d116594,GlobalBench: A Benchmark for Global Progress in Natural Language Processing,"Despite the major advances in NLP, significant disparities in NLP system performance across languages still exist. Arguably, these are due to uneven resource allocation and sub-optimal incentives to work on less resourced languages. To track and further incentivize the global development of equitable language technology, we introduce GlobalBench. Prior multilingual benchmarks are static and have focused on a limited number of tasks and languages. In contrast, GlobalBench is an ever-expanding collection that aims to dynamically track progress on all NLP datasets in all languages. Rather than solely measuring accuracy, GlobalBench also tracks the estimated per-speaker utility and equity of technology across all languages, providing a multi-faceted view of how language technology is serving people of the world. Furthermore, GlobalBench is designed to identify the most under-served languages, and rewards research efforts directed towards those languages. At present, the most under-served languages are the ones with a relatively high population, but nonetheless overlooked by composite multilingual benchmarks (like Punjabi, Portuguese, and Wu Chinese). Currently, GlobalBench covers 966 datasets in 190 languages, and has 1,128 system submissions spanning 62 languages.",Conference on Empirical Methods in Natural Language Processing,2023,45,1,0,True,"{'url': 'http://arxiv.org/pdf/2305.14716', 'status': None}",['Computer Science'],{'pages': '14157-14171'},"[{'authorId': '148310739', 'name': 'Yueqi Song'}, {'authorId': '2218206121', 'name': 'Catherine Cui'}, {'authorId': '1452678825', 'name': 'Simran Khanuja'}, {'authorId': '144118452', 'name': 'Pengfei Liu'}, {'authorId': '48556979', 'name': 'FAHIM FAISAL'}, {'authorId': '1475670743', 'name': 'Alissa Ostapenko'}, {'authorId': '9162688', 'name': 'Genta Indra Winata'}, {'authorId': '8129718', 'name': 'Alham Fikri Aji'}, {'authorId': '66986482', 'name': 'Samuel Cahyawijaya'}, {'authorId': '2073587169', 'name': 'Yulia Tsvetkov'}, {'authorId': '49513989', 'name': 'Antonios Anastasopoulos'}, {'authorId': '1700325', 'name': 'Graham Neubig'}]","This work introduces GlobalBench, an ever-expanding collection that aims to dynamically track progress on all NLP datasets in all languages and tracks the estimated per-speaker utility and equity of technology across all languages, providing a multi-faceted view of how language technology is serving people of the world."
Yulia Tsvetkov,2073587169,Yulia Tsvetkov,https://www.semanticscholar.org/author/2073587169,17,[],48,1382,17fbffb05fa14e21d1c506fd5f0f568b955fe983,"{'DBLP': 'conf/emnlp/Ahia0GKMST23', 'ArXiv': '2305.13707', 'DOI': '10.48550/arXiv.2305.13707', 'CorpusId': 258841465}",https://www.semanticscholar.org/paper/17fbffb05fa14e21d1c506fd5f0f568b955fe983,Do All Languages Cost the Same? Tokenization in the Era of Commercial Language Models,"Language models have graduated from being research prototypes to commercialized products offered as web APIs, and recent works have highlighted the multilingual capabilities of these products. The API vendors charge their users based on usage, more specifically on the number of ``tokens'' processed or generated by the underlying language models. What constitutes a token, however, is training data and model dependent with a large variance in the number of tokens required to convey the same information in different languages. In this work, we analyze the effect of this non-uniformity on the fairness of an API's pricing policy across languages. We conduct a systematic analysis of the cost and utility of OpenAI's language model API on multilingual benchmarks in 22 typologically diverse languages. We show evidence that speakers of a large number of the supported languages are overcharged while obtaining poorer results. These speakers tend to also come from regions where the APIs are less affordable to begin with. Through these analyses, we aim to increase transparency around language model APIs' pricing policies and encourage the vendors to make them more equitable.",Conference on Empirical Methods in Natural Language Processing,2023,82,11,2,True,"{'url': 'http://arxiv.org/pdf/2305.13707', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.13707', 'name': 'ArXiv'}","[{'authorId': '1452686038', 'name': 'Orevaoghene Ahia'}, {'authorId': '51467955', 'name': 'Sachin Kumar'}, {'authorId': '1821892', 'name': 'Hila Gonen'}, {'authorId': '11348687', 'name': 'Jungo Kasai'}, {'authorId': '3407646', 'name': 'David R. Mortensen'}, {'authorId': '144365875', 'name': 'Noah A. Smith'}, {'authorId': '2073587169', 'name': 'Yulia Tsvetkov'}]",This work conducts a systematic analysis of the cost and utility of OpenAI's language model API on multilingual benchmarks in 22 typologically diverse languages and shows evidence that speakers of a large number of the supported languages are overcharged while obtaining poorer results.
Yulia Tsvetkov,2073587169,Yulia Tsvetkov,https://www.semanticscholar.org/author/2073587169,17,[],48,1382,1bc0dc96d745325d89ec5bee1da1541255e6d1eb,"{'DBLP': 'journals/corr/abs-2302-00381', 'DOI': '10.48550/arXiv.2302.00381', 'CorpusId': 256459902}",https://www.semanticscholar.org/paper/1bc0dc96d745325d89ec5bee1da1541255e6d1eb,BotPercent: Estimating Twitter Bot Populations from Groups to Crowds,"Twitter bot detection has become increasingly important in combating misinformation, identifying malicious online cam-paigns, and protecting the integrity of social media discourse. While existing bot detection literature mostly focuses on identifying individual bots, it remains underexplored how to estimate the proportion of bots within speciﬁc communities and social networks, which has great implications for both content moderators and day-to-day users. In this work, we propose community-level bot detection , a novel approach to estimating the amount of malicious interference in online communities by estimating the percentage of bot accounts. Speciﬁcally, we introduce BotPercent , an amalgamation of Twitter bot-detection datasets and feature, text, and graph-based models that overcome generalization issues in existing individual-level models, resulting in a more accurate community-level bot estimation. Experiments demonstrate that BotPercent achieves state-of-the-art community-level bot detection performance on the TwiBot-22 benchmark while showing great robustness towards the tampering of speciﬁc user features. Armed with BotPercent , we analyze bot rates in different Twitter groups and communities, such as all active Twitter users, users that interact with partisan news media, users that participate in Elon Musk’s content moderation votes, and the political communities in different countries and regions. Our experimental results demonstrate that the existence of Twitter bots is not homogeneous, but rather a spatial-temporal distribution whose heterogeneity should be taken into account for content moderation, social media policy making, and more. The BotPercent implementation is available at https://github.com/TamSiuhin/BotPercent",arXiv.org,2023,79,13,1,True,"{'url': 'http://arxiv.org/pdf/2302.00381', 'status': None}",['Computer Science'],"{'volume': 'abs/2302.00381', 'name': 'ArXiv'}","[{'authorId': '2093186816', 'name': 'Zhaoxuan Tan'}, {'authorId': '2114887261', 'name': 'Shangbin Feng'}, {'authorId': '1947172233', 'name': 'Melanie Sclar'}, {'authorId': '2114831715', 'name': 'Herun Wan'}, {'authorId': '3326677', 'name': 'Minnan Luo'}, {'authorId': '1699545', 'name': 'Yejin Choi'}, {'authorId': '2073587169', 'name': 'Yulia Tsvetkov'}]","The experimental results demonstrate that the existence of Twitter bots is not homogeneous, but rather a spatial-temporal distribution whose heterogeneity should be taken into account for content moderation, social media policy making, and more."
Yulia Tsvetkov,2073587169,Yulia Tsvetkov,https://www.semanticscholar.org/author/2073587169,17,[],48,1382,346e4f35a5a81ef893792133ec1fec18f23c1768,"{'DBLP': 'conf/fat/FieldCGCPST23', 'ArXiv': '2305.19409', 'DOI': '10.1145/3593013.3594094', 'CorpusId': 258987867}",https://www.semanticscholar.org/paper/346e4f35a5a81ef893792133ec1fec18f23c1768,Examining risks of racial biases in NLP tools for child protective services,"Although much literature has established the presence of demographic bias in natural language processing (NLP) models, most work relies on curated bias metrics that may not be reflective of real-world applications. At the same time, practitioners are increasingly using algorithmic tools in high-stakes settings, with particular recent interest in NLP. In this work, we focus on one such setting: child protective services (CPS). CPS workers often write copious free-form text notes about families they are working with, and CPS agencies are actively seeking to deploy NLP models to leverage these data. Given well-established racial bias in this setting, we investigate possible ways deployed NLP is liable to increase racial disparities. We specifically examine word statistics within notes and algorithmic fairness in risk prediction, coreference resolution, and named entity recognition (NER). We document consistent algorithmic unfairness in NER models, possible algorithmic unfairness in coreference resolution models, and little evidence of exacerbated racial bias in risk prediction. While there is existing pronounced criticism of risk prediction, our results expose previously undocumented risks of racial bias in realistic information extraction systems, highlighting potential concerns in deploying them, even though they may appear more benign. Our work serves as a rare realistic examination of NLP algorithmic fairness in a potential deployed setting and a timely investigation of a specific risk associated with deploying NLP in CPS settings.","Conference on Fairness, Accountability and Transparency",2023,68,2,0,True,"{'url': 'https://dl.acm.org/doi/pdf/10.1145/3593013.3594094', 'status': None}",['Computer Science'],"{'name': 'Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency'}","[{'authorId': '49713890', 'name': 'Anjalie Field'}, {'authorId': '48577290', 'name': 'Amanda Coston'}, {'authorId': '47404598', 'name': 'Nupoor Gandhi'}, {'authorId': '2082393', 'name': 'A. Chouldechova'}, {'authorId': '1398859796', 'name': 'Emily Putnam-Hornstein'}, {'authorId': '2082303978', 'name': 'David Steier'}, {'authorId': '2073587169', 'name': 'Yulia Tsvetkov'}]","This work investigates possible ways deployed NLP is liable to increase racial disparities and examines word statistics within notes and algorithmic fairness in risk prediction, coreference resolution, and named entity recognition (NER)."
Yulia Tsvetkov,2073587169,Yulia Tsvetkov,https://www.semanticscholar.org/author/2073587169,17,[],48,1382,36f7bc27c9a37eb337c35df4ae86f148e13d4e9a,"{'ACL': '2023.acl-long.708', 'DBLP': 'conf/acl/HanSMTCW23', 'ArXiv': '2306.15091', 'DOI': '10.48550/arXiv.2306.15091', 'CorpusId': 259262608}",https://www.semanticscholar.org/paper/36f7bc27c9a37eb337c35df4ae86f148e13d4e9a,Understanding In-Context Learning via Supportive Pretraining Data,"In-context learning (ICL) improves language models’ performance on a variety of NLP tasks by simply demonstrating a handful of examples at inference time. It is not well understood why ICL ability emerges, as the model has never been specifically trained on such demonstrations. Unlike prior work that explores implicit mechanisms behind ICL, we study ICL via investigating the pretraining data. Specifically, we first adapt an iterative, gradient-based approach to find a small subset of pretraining data that supports ICL. We observe that a continued pretraining on this small subset significantly improves the model’s ICL ability, by up to 18%. We then compare the supportive subset constrastively with random subsets of pretraining data and discover: (1) The supportive pretraining data to ICL do not have a higher domain relevance to downstream tasks. (2) The supportive pretraining data have a higher mass of rarely occurring, long-tail tokens. (3) The supportive pretraining data are challenging examples where the information gain from long-range context is below average, indicating learning to incorporate difficult long-range context encourages ICL. Our work takes a first step towards understanding ICL via analyzing instance-level pretraining data. Our insights have a potential to enhance the ICL ability of language models by actively guiding the construction of pretraining data in the future.",Annual Meeting of the Association for Computational Linguistics,2023,44,8,0,True,"{'url': 'http://arxiv.org/pdf/2306.15091', 'status': None}",['Computer Science'],{'pages': '12660-12673'},"[{'authorId': '40500540', 'name': 'Xiaochuang Han'}, {'authorId': '2082239112', 'name': 'Daniel Simig'}, {'authorId': '39980906', 'name': 'Todor Mihaylov'}, {'authorId': '2073587169', 'name': 'Yulia Tsvetkov'}, {'authorId': '1709797', 'name': 'Asli Celikyilmaz'}, {'authorId': '1785372925', 'name': 'Tianlu Wang'}]","This work first adapts an iterative, gradient-based approach to find a small subset of pretraining data that supports ICL and observes that a continued pretraining on this small subset significantly improves the model’s ICL ability, by up to 18%."
Yulia Tsvetkov,2073587169,Yulia Tsvetkov,https://www.semanticscholar.org/author/2073587169,17,[],48,1382,49f1fa0d609ff06564b46270cbc022b7d9d195f4,"{'ArXiv': '2303.18190', 'DBLP': 'journals/corr/abs-2303-18190', 'DOI': '10.48550/arXiv.2303.18190', 'CorpusId': 257900638}",https://www.semanticscholar.org/paper/49f1fa0d609ff06564b46270cbc022b7d9d195f4,Assessing Language Model Deployment with Risk Cards,"This paper introduces RiskCards, a framework for structured assessment and documentation of risks associated with an application of language models. As with all language, text generated by language models can be harmful, or used to bring about harm. Automating language generation adds both an element of scale and also more subtle or emergent undesirable tendencies to the generated text. Prior work establishes a wide variety of language model harms to many different actors: existing taxonomies identify categories of harms posed by language models; benchmarks establish automated tests of these harms; and documentation standards for models, tasks and datasets encourage transparent reporting. However, there is no risk-centric framework for documenting the complexity of a landscape in which some risks are shared across models and contexts, while others are specific, and where certain conditions may be required for risks to manifest as harms. RiskCards address this methodological gap by providing a generic framework for assessing the use of a given language model in a given scenario. Each RiskCard makes clear the routes for the risk to manifest harm, their placement in harm taxonomies, and example prompt-output pairs. While RiskCards are designed to be open-source, dynamic and participatory, we present a""starter set""of RiskCards taken from a broad literature survey, each of which details a concrete risk presentation. Language model RiskCards initiate a community knowledge base which permits the mapping of risks and harms to a specific model or its application scenario, ultimately contributing to a better, safer and shared understanding of the risk landscape.",arXiv.org,2023,66,17,0,True,"{'url': 'http://arxiv.org/pdf/2303.18190', 'status': None}",['Computer Science'],"{'volume': 'abs/2303.18190', 'name': 'ArXiv'}","[{'authorId': '113320522', 'name': 'Leon Derczynski'}, {'authorId': '90729626', 'name': 'Hannah Rose Kirk'}, {'authorId': '143820870', 'name': 'Vidhisha Balachandran'}, {'authorId': '51467955', 'name': 'Sachin Kumar'}, {'authorId': '2073587169', 'name': 'Yulia Tsvetkov'}, {'authorId': '119004240', 'name': 'M. Leiser'}, {'authorId': '2057036852', 'name': 'Saif Mohammad'}]","Language model RiskCards initiate a community knowledge base which permits the mapping of risks and harms to a specific model or its application scenario, ultimately contributing to a better, safer and shared understanding of the risk landscape."
Yulia Tsvetkov,2073587169,Yulia Tsvetkov,https://www.semanticscholar.org/author/2073587169,17,[],48,1382,5471114e37448bea2457b74894b1ecb92bbcfdf6,"{'ArXiv': '2305.08283', 'ACL': '2023.acl-long.656', 'DBLP': 'conf/acl/FengPLT23', 'DOI': '10.48550/arXiv.2305.08283', 'CorpusId': 258686693}",https://www.semanticscholar.org/paper/5471114e37448bea2457b74894b1ecb92bbcfdf6,From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models,"Language models (LMs) are pretrained on diverse data sources—news, discussion forums, books, online encyclopedias. A significant portion of this data includes facts and opinions which, on one hand, celebrate democracy and diversity of ideas, and on the other hand are inherently socially biased. Our work develops new methods to (1) measure media biases in LMs trained on such corpora, along social and economic axes, and (2) measure the fairness of downstream NLP models trained on top of politically biased LMs. We focus on hate speech and misinformation detection, aiming to empirically quantify the effects of political (social, economic) biases in pretraining data on the fairness of high-stakes social-oriented tasks. Our findings reveal that pretrained LMs do have political leanings which reinforce the polarization present in pretraining corpora, propagating social biases into hate speech predictions and media biases into misinformation detectors. We discuss the implications of our findings for NLP research and propose future directions to mitigate unfairness.",Annual Meeting of the Association for Computational Linguistics,2023,135,54,4,True,"{'url': 'https://arxiv.org/pdf/2305.08283', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.08283', 'name': 'ArXiv'}","[{'authorId': '2114887261', 'name': 'Shangbin Feng'}, {'authorId': '50487261', 'name': 'Chan Young Park'}, {'authorId': '2169159066', 'name': 'Yuhan Liu'}, {'authorId': '2073587169', 'name': 'Yulia Tsvetkov'}]","The findings reveal that pretrained LMs do have political leanings which reinforce the polarization present in pretraining corpora, propagating social biases into hate speech predictions and media biases into misinformation detectors."
Yulia Tsvetkov,2073587169,Yulia Tsvetkov,https://www.semanticscholar.org/author/2073587169,17,[],48,1382,663d743272e9ab04f54d9105a3c3a3f6e22dd1dd,"{'DBLP': 'conf/emnlp/FengBBT23', 'ArXiv': '2305.08281', 'DOI': '10.48550/arXiv.2305.08281', 'CorpusId': 258685429}",https://www.semanticscholar.org/paper/663d743272e9ab04f54d9105a3c3a3f6e22dd1dd,FactKB: Generalizable Factuality Evaluation using Language Models Enhanced with Factual Knowledge,"Evaluating the factual consistency of automatically generated summaries is essential for the progress and adoption of reliable summarization systems. Despite recent advances, existing factuality evaluation models are not robust, being especially prone to entity and relation errors in new domains. We propose FactKB, a simple new approach to factuality evaluation that is generalizable across domains, in particular with respect to entities and relations. FactKB is based on language models pretrained using facts extracted from external knowledge bases. We introduce three types of complementary factuality pretraining objectives based on direct entity facts, facts grounded in auxiliary knowledge about entities, and facts constructed compositionally through knowledge base walks. The resulting factuality evaluation model achieves state-of-the-art performance on two in-domain news summarization benchmarks as well as on three out-of-domain scientific literature datasets. Further analysis of FactKB shows improved ability to detect erroneous entities and relations in summaries and is robust and generalizable across domains.",Conference on Empirical Methods in Natural Language Processing,2023,114,14,1,True,"{'url': 'http://arxiv.org/pdf/2305.08281', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.08281', 'name': 'ArXiv'}","[{'authorId': '2114887261', 'name': 'Shangbin Feng'}, {'authorId': '143820870', 'name': 'Vidhisha Balachandran'}, {'authorId': '2170130468', 'name': 'Yuyang Bai'}, {'authorId': '2073587169', 'name': 'Yulia Tsvetkov'}]","FactKB is a simple new approach to factuality evaluation that is generalizable across domains, in particular with respect to entities and relations and shows improved ability to detect erroneous entities and relation in summaries."
Yulia Tsvetkov,2073587169,Yulia Tsvetkov,https://www.semanticscholar.org/author/2073587169,17,[],48,1382,926dece297434dc535733814efca28759b94ab82,"{'DBLP': 'conf/emnlp/NjooPSTCT23', 'ArXiv': '2305.14326', 'DOI': '10.18653/v1/2023.findings-emnlp.625', 'CorpusId': 258841861}",https://www.semanticscholar.org/paper/926dece297434dc535733814efca28759b94ab82,TalkUp: Paving the Way for Understanding Empowering Language,"Empowering language is important in many real-world contexts, from education to workplace dynamics to healthcare. Though language technologies are growing more prevalent in these contexts, empowerment has seldom been studied in NLP, and moreover, it is inherently challenging to operationalize because of its implicit nature. This work builds from linguistic and social psychology literature to explore what characterizes empowering language. We then crowdsource a novel dataset of Reddit posts labeled for empowerment, reasons why these posts are empowering to readers, and the social relationships between posters and readers. Our preliminary analyses show that this dataset, which we call TalkUp, can be used to train language models that capture empowering and disempowering language. More broadly, TalkUp provides an avenue to explore implication, presuppositions, and how social context influences the meaning of language.",Conference on Empirical Methods in Natural Language Processing,2023,48,0,0,True,"{'url': 'https://aclanthology.org/2023.findings-emnlp.625.pdf', 'status': None}",['Computer Science'],{'pages': '9334-9354'},"[{'authorId': '79336318', 'name': 'Lucille Njoo'}, {'authorId': '50487261', 'name': 'Chan Young Park'}, {'authorId': '2218440660', 'name': 'Octavia Stappart'}, {'authorId': '46189691', 'name': 'Marvin Thielk'}, {'authorId': '2070015461', 'name': 'Yi Chu'}, {'authorId': '2073587169', 'name': 'Yulia Tsvetkov'}]","This work builds from linguistic and social psychology literature to explore what characterizes empowering language, and crowdsource a novel dataset of Reddit posts labeled for empowerment, reasons why these posts are empowering to readers, and the social relationships between posters and readers."
Yulia Tsvetkov,2073587169,Yulia Tsvetkov,https://www.semanticscholar.org/author/2073587169,17,[],48,1382,984d4a1d41bfc8184fb77b8aa0eb8e96d536d048,"{'DBLP': 'journals/corr/abs-2305-14739', 'ArXiv': '2305.14739', 'DOI': '10.48550/arXiv.2305.14739', 'CorpusId': 258866080}",https://www.semanticscholar.org/paper/984d4a1d41bfc8184fb77b8aa0eb8e96d536d048,Trusting Your Evidence: Hallucinate Less with Context-aware Decoding,"Language models (LMs) often struggle to pay enough attention to the input context, and generate texts that are unfaithful or contain hallucinations. To mitigate this issue, we present context-aware decoding (CAD), which follows a contrastive output distribution that amplifies the difference between the output probabilities when a model is used with and without context. Our experiments show that CAD, without additional training, significantly improves the faithfulness of different LM families, including OPT, GPT, LLaMA and FLAN-T5 for summarization tasks (e.g., 14.3% gain for LLaMA in factuality metrics). Furthermore, CAD is particularly effective in overriding a model's prior knowledge when it contradicts the provided context, leading to substantial improvements in tasks where resolving the knowledge conflict is essential.",arXiv.org,2023,33,41,6,True,"{'url': 'http://arxiv.org/pdf/2305.14739', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.14739', 'name': 'ArXiv'}","[{'authorId': '3040379', 'name': 'Weijia Shi'}, {'authorId': '40500540', 'name': 'Xiaochuang Han'}, {'authorId': '35084211', 'name': 'M. Lewis'}, {'authorId': '2073587169', 'name': 'Yulia Tsvetkov'}, {'authorId': '1982950', 'name': 'Luke Zettlemoyer'}, {'authorId': '3156075', 'name': 'S. Yih'}]","Context-aware decoding (CAD), which follows a contrastive output distribution that amplifies the difference between the output probabilities when a model is used with and without context, improves the faithfulness of different LM families."
Yulia Tsvetkov,2073587169,Yulia Tsvetkov,https://www.semanticscholar.org/author/2073587169,17,[],48,1382,ad454e24bd32408559512b4bac4cd5237794210f,"{'DBLP': 'journals/corr/abs-2305-14857', 'ArXiv': '2305.14857', 'DOI': '10.48550/arXiv.2305.14857', 'CorpusId': 258865558}",https://www.semanticscholar.org/paper/ad454e24bd32408559512b4bac4cd5237794210f,BUFFET: Benchmarking Large Language Models for Few-shot Cross-lingual Transfer,"Despite remarkable advancements in few-shot generalization in natural language processing, most models are developed and evaluated primarily in English. To facilitate research on few-shot cross-lingual transfer, we introduce a new benchmark, called BUFFET, which unifies 15 diverse tasks across 54 languages in a sequence-to-sequence format and provides a fixed set of few-shot examples and instructions. BUFFET is designed to establish a rigorous and equitable evaluation framework for few-shot cross-lingual transfer across a broad range of tasks and languages. Using BUFFET, we perform thorough evaluations of state-of-the-art multilingual large language models with different transfer methods, namely in-context learning and fine-tuning. Our findings reveal significant room for improvement in few-shot in-context cross-lingual transfer. In particular, ChatGPT with in-context learning often performs worse than much smaller mT5-base models fine-tuned on English task data and few-shot in-language examples. Our analysis suggests various avenues for future research in few-shot cross-lingual transfer, such as improved pretraining, understanding, and future evaluations.",arXiv.org,2023,70,15,4,True,"{'url': 'http://arxiv.org/pdf/2305.14857', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.14857', 'name': 'ArXiv'}","[{'authorId': '35584853', 'name': 'Akari Asai'}, {'authorId': '35871436', 'name': 'Sneha Kudugunta'}, {'authorId': '2118211280', 'name': 'Xinyan Velocity Yu'}, {'authorId': '3443287', 'name': 'Terra Blevins'}, {'authorId': '1821892', 'name': 'Hila Gonen'}, {'authorId': '1557386977', 'name': 'Machel Reid'}, {'authorId': '2073587169', 'name': 'Yulia Tsvetkov'}, {'authorId': '2124014463', 'name': 'Sebastian Ruder'}, {'authorId': '2548384', 'name': 'Hannaneh Hajishirzi'}]","This work introduces a new benchmark, called BUFFET, which unifies 15 diverse tasks across 54 languages in a sequence-to-sequence format and provides a fixed set of few- shot examples and instructions and suggests various avenues for future research in few-shot cross-lingual transfer, such as improved pretraining, understanding, and future evaluations."
Yulia Tsvetkov,2073587169,Yulia Tsvetkov,https://www.semanticscholar.org/author/2073587169,17,[],48,1382,cb0335107f12d331ace2cbf220eb3c7bdcf653c5,"{'DOI': '10.18653/v1/2023.emnlp-tutorial.5', 'CorpusId': 266181225}",https://www.semanticscholar.org/paper/cb0335107f12d331ace2cbf220eb3c7bdcf653c5,Mitigating Societal Harms in Large Language Models,",",Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts,2023,66,0,0,True,"{'url': 'https://aclanthology.org/2023.emnlp-tutorial.5.pdf', 'status': None}",,{'name': 'Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts'},"[{'authorId': '51467955', 'name': 'Sachin Kumar'}, {'authorId': '143820870', 'name': 'Vidhisha Balachandran'}, {'authorId': '79336318', 'name': 'Lucille Njoo'}, {'authorId': '2273733474', 'name': 'Antonios Anastasopoulos'}, {'authorId': '2073587169', 'name': 'Yulia Tsvetkov'}]",
Yulia Tsvetkov,2073587169,Yulia Tsvetkov,https://www.semanticscholar.org/author/2073587169,17,[],48,1382,d7a3f5c612930a3c08f1632b88934252edc66d67,"{'ACL': '2023.acl-long.780', 'DBLP': 'conf/acl/SclarKWS0T23', 'ArXiv': '2306.00924', 'DOI': '10.48550/arXiv.2306.00924', 'CorpusId': 258999153}",https://www.semanticscholar.org/paper/d7a3f5c612930a3c08f1632b88934252edc66d67,Minding Language Models’ (Lack of) Theory of Mind: A Plug-and-Play Multi-Character Belief Tracker,"Theory of Mind (ToM)—the ability to reason about the mental states of other people—is a key element of our social intelligence. Yet, despite their ever more impressive performance, large-scale neural language models still lack basic theory of mind capabilities out-of-the-box. We posit that simply scaling up models will not imbue them with theory of mind due to the inherently symbolic and implicit nature of the phenomenon, and instead investigate an alternative: can we design a decoding-time algorithm that enhances theory of mind of off-the-shelf neural language models without explicit supervision? We present SymbolicToM, a plug-and-play approach to reason about the belief states of multiple characters in reading comprehension tasks via explicit symbolic representation. More concretely, our approach tracks each entity’s beliefs, their estimation of other entities’ beliefs, and higher-order levels of reasoning, all through graphical representations, allowing for more precise and interpretable reasoning than previous approaches. Empirical results on the well-known ToMi benchmark (Le et al., 2019) demonstrate that SymbolicToM dramatically enhances off-the-shelf neural networks’ theory of mind in a zero-shot setting while showing robust out-of-distribution performance compared to supervised baselines. Our work also reveals spurious patterns in existing theory of mind benchmarks, emphasizing the importance of out-of-distribution evaluation and methods that do not overfit a particular dataset.",Annual Meeting of the Association for Computational Linguistics,2023,53,22,1,True,"{'url': 'http://arxiv.org/pdf/2306.00924', 'status': None}",['Computer Science'],{'pages': '13960-13980'},"[{'authorId': '1947172233', 'name': 'Melanie Sclar'}, {'authorId': '51467955', 'name': 'Sachin Kumar'}, {'authorId': '119659229', 'name': 'Peter West'}, {'authorId': '32849969', 'name': 'Alane Suhr'}, {'authorId': '1699545', 'name': 'Yejin Choi'}, {'authorId': '2073587169', 'name': 'Yulia Tsvetkov'}]","SymbolicToM is presented, a plug-and-play approach to reason about the belief states of multiple characters in reading comprehension tasks via explicit symbolic representation that dramatically enhances off-the-shelf neural networks’ theory of mind in a zero-shot setting while showing robust out-of-distribution performance compared to supervised baselines."
Yulia Tsvetkov,2073587169,Yulia Tsvetkov,https://www.semanticscholar.org/author/2073587169,17,[],48,1382,df2beaae63e4d68ef8e762bcd4704c9f11f856d9,"{'ArXiv': '2305.10037', 'DBLP': 'journals/corr/abs-2305-10037', 'DOI': '10.48550/arXiv.2305.10037', 'CorpusId': 258740923}",https://www.semanticscholar.org/paper/df2beaae63e4d68ef8e762bcd4704c9f11f856d9,Can Language Models Solve Graph Problems in Natural Language?,"Large language models (LLMs) are increasingly adopted for a variety of tasks with implicit graphical structures, such as planning in robotics, multi-hop question answering or knowledge probing, structured commonsense reasoning, and more. While LLMs have advanced the state-of-the-art on these tasks with structure implications, whether LLMs could explicitly process textual descriptions of graphs and structures, map them to grounded conceptual spaces, and perform structured operations remains underexplored. To this end, we propose NLGraph (Natural Language Graph), a comprehensive benchmark of graph-based problem solving designed in natural language. NLGraph contains 29,370 problems, covering eight graph reasoning tasks with varying complexity from simple tasks such as connectivity and shortest path up to complex problems such as maximum flow and simulating graph neural networks. We evaluate LLMs (GPT-3/4) with various prompting approaches on the NLGraph benchmark and find that 1) language models do demonstrate preliminary graph reasoning abilities, 2) the benefit of advanced prompting and in-context learning diminishes on more complex graph problems, while 3) LLMs are also (un)surprisingly brittle in the face of spurious correlations in graph and problem settings. We then propose Build-a-Graph Prompting and Algorithmic Prompting, two instruction-based approaches to enhance LLMs in solving natural language graph problems. Build-a-Graph and Algorithmic prompting improve the performance of LLMs on NLGraph by 3.07% to 16.85% across multiple tasks and settings, while how to solve the most complicated graph reasoning tasks in our setup with language models remains an open research question. The NLGraph benchmark and evaluation code are available at https://github.com/Arthur-Heng/NLGraph.",arXiv.org,2023,40,46,9,True,"{'url': 'http://arxiv.org/pdf/2305.10037', 'status': None}",['Computer Science'],"{'volume': 'abs/2305.10037', 'name': 'ArXiv'}","[{'authorId': '2256778370', 'name': 'Heng Wang'}, {'authorId': '2114887261', 'name': 'Shangbin Feng'}, {'authorId': '3083253', 'name': 'Tianxing He'}, {'authorId': '2093186816', 'name': 'Zhaoxuan Tan'}, {'authorId': '40500540', 'name': 'Xiaochuang Han'}, {'authorId': '2073587169', 'name': 'Yulia Tsvetkov'}]","This work evaluates LLMs (GPT-3/4) with various prompting approaches on the NLGraph benchmark and finds that language models do demonstrate preliminary graph reasoning abilities, but the benefit of advanced prompting and in-context learning diminishes on more complex graph problems, while LLMs are also (un)surprisingly brittle in the face of spurious correlations in graph and problem settings."
Yulia Tsvetkov,2073587169,Yulia Tsvetkov,https://www.semanticscholar.org/author/2073587169,17,[],48,1382,f9a5af5b21563b9bdd09630a8dec62d515479678,"{'ACL': '2023.starsem-1.19', 'DBLP': 'conf/starsem/AhiaGBTS23', 'DOI': '10.18653/v1/2023.starsem-1.19', 'CorpusId': 260063220}",https://www.semanticscholar.org/paper/f9a5af5b21563b9bdd09630a8dec62d515479678,LEXPLAIN: Improving Model Explanations via Lexicon Supervision,"Model explanations that shed light on the model’s predictions are becoming a desired additional output of NLP models, alongside their predictions. Challenges in creating these explanations include making them trustworthy and faithful to the model’s predictions. In this work, we propose a novel framework for guiding model explanations by supervising them explicitly. To this end, our method, LEXplain, uses task-related lexicons to directly supervise model explanations. This approach consistently improves the model’s explanations without sacrificing performance on the task, as we demonstrate on sentiment analysis and toxicity detection. Our analyses show that our method also demotes spurious correlations (i.e., with respect to African American English dialect) when performing the task, improving fairness.",STARSEM,2023,40,0,0,True,"{'url': 'https://aclanthology.org/2023.starsem-1.19.pdf', 'status': None}",['Computer Science'],{'pages': '207-216'},"[{'authorId': '1452686038', 'name': 'Orevaoghene Ahia'}, {'authorId': '1821892', 'name': 'Hila Gonen'}, {'authorId': '143820870', 'name': 'Vidhisha Balachandran'}, {'authorId': '2073587169', 'name': 'Yulia Tsvetkov'}, {'authorId': '144365875', 'name': 'Noah A. Smith'}]","This work proposes a novel framework for guiding model explanations by supervising them explicitly by using task-related lexicons to directly supervise model explanations, which consistently improves the model’s explanations without sacrificing performance on the task, as well as demonstrating on sentiment analysis and toxicity detection."
