Question,Answer,Document,Notes
What is the author ID of Alexander Hauptmann?,145788702,data/paper_jsons/A. Hauptmann_145788702.json,
What are the papers of Alexander Hauptmann?,"Zero-Shot and Few-Shot Stance Detection on Varied Topics via Conditional Generation, SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs, STMT: A Spatial-Temporal Mesh Transformer for MoCap-Based Action Recognition, DocumentNet: Bridging the Data Gap in Document Pre-training",data/paper_jsons/A. Hauptmann_145788702.json,
What is the H-index of Alexander Hauptmann?,27,data/paper_jsons/A. Hauptmann_145788702.json,
What is the author citation count of Alexander Hauptmann?,2295,data/paper_jsons/A. Hauptmann_145788702.json,
What journals has Alexander Hauptmann published in?,"ArXiv, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",data/paper_jsons/A. Hauptmann_145788702.json,
What are the journals and how many papers has Alexander Hauptmann published in each?,"{'ArXiv': 1, '2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)': 1}",data/paper_jsons/A. Hauptmann_145788702.json,
What are the fields of study of Alexander Hauptmann?,Computer Science,data/paper_jsons/A. Hauptmann_145788702.json,
How many papers has Alexander Hauptmann published in open access journals?,4,data/paper_jsons/A. Hauptmann_145788702.json,
What venues has Alexander Hauptmann published in?,"Annual Meeting of the Association for Computational Linguistics, arXiv.org, Computer Vision and Pattern Recognition, Conference on Empirical Methods in Natural Language Processing",data/paper_jsons/A. Hauptmann_145788702.json,
What is the most cited paper from Alexander Hauptmann?,SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs,data/paper_jsons/A. Hauptmann_145788702.json,
What is the url of the most cited paper from Alexander Hauptmann?,http://arxiv.org/pdf/2306.17842,data/paper_jsons/A. Hauptmann_145788702.json,
Who are the authors of the most cited paper from Alexander Hauptmann?,"Lijun Yu, Yong Cheng, Zhiruo Wang, Vivek Kumar, Wolfgang Macherey, Yanping Huang, David A. Ross, Irfan Essa, Yonatan Bisk, Ming Yang, K. Murphy, A. Hauptmann, Lu Jiang",data/paper_jsons/A. Hauptmann_145788702.json,
TLDR of the most cited paper from Alexander Hauptmann?,"This method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.",data/paper_jsons/A. Hauptmann_145788702.json,
Abstract of the most cited paper from Alexander Hauptmann?,"In this work, we introduce Semantic Pyramid AutoEncoder (SPAE) for enabling frozen LLMs to perform both understanding and generation tasks involving non-linguistic modalities such as images or videos. SPAE converts between raw pixels and interpretable lexical tokens (or words) extracted from the LLM's vocabulary. The resulting tokens capture both the semantic meaning and the fine-grained details needed for visual reconstruction, effectively translating the visual content into a language comprehensible to the LLM, and empowering it to perform a wide array of multimodal tasks. Our approach is validated through in-context learning experiments with frozen PaLM 2 and GPT 3.5 on a diverse set of image understanding and generation tasks. Our method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.",data/paper_jsons/A. Hauptmann_145788702.json,
"What journal was the paper ""DocumentNet: Bridging the Data Gap in Document Pre-training"" published in?",,A. Hauptmann_145788702.json,
"What venue was the paper ""DocumentNet: Bridging the Data Gap in Document Pre-training"" published in?",Conference on Empirical Methods in Natural Language Processing,A. Hauptmann_145788702.json,
"How many citations does the paper ""DocumentNet: Bridging the Data Gap in Document Pre-training"" have?",1,A. Hauptmann_145788702.json,
"Who are the authors of the paper ""DocumentNet: Bridging the Data Gap in Document Pre-training""?","Lijun Yu, Jin Miao, Xiaoyu Sun, Jiayi Chen, A. Hauptmann, H. Dai, Wei Wei",A. Hauptmann_145788702.json,
"Who is the first author of the paper ""DocumentNet: Bridging the Data Gap in Document Pre-training""?",Lijun Yu,A. Hauptmann_145788702.json,
"What is the paper ID of the paper ""DocumentNet: Bridging the Data Gap in Document Pre-training""?",8ccda6de0223bcd897d5dc0efc8f33222a899d0d,A. Hauptmann_145788702.json,
What paper has the paper ID 8ccda6de0223bcd897d5dc0efc8f33222a899d0d?,DocumentNet: Bridging the Data Gap in Document Pre-training,A. Hauptmann_145788702.json,
What is the TLDR of the paper 'DocumentNet: Bridging the Data Gap in Document Pre-training'?,"This paper proposes a method to collect massive-scale and weakly labeled data from the web to benefit the training of VDER models, and provides a large data source to extend their multi-modal capabilities for VDER.",A. Hauptmann_145788702.json,
What is the abstract of the paper 'DocumentNet: Bridging the Data Gap in Document Pre-training'?,"Document understanding tasks, in particular, Visually-rich Document Entity Retrieval (VDER), have gained significant attention in recent years thanks to their broad applications in enterprise AI. However, publicly available data have been scarce for these tasks due to strict privacy constraints and high annotation costs. To make things worse, the non-overlapping entity spaces from different datasets hinder the knowledge transfer between document types. In this paper, we propose a method to collect massive-scale and weakly labeled data from the web to benefit the training of VDER models. The collected dataset, named DocumentNet, does not depend on specific document types or entity sets, making it universally applicable to all VDER tasks. The current DocumentNet consists of 30M documents spanning nearly 400 document types organized in a four-level ontology. Experiments on a set of broadly adopted VDER tasks show significant improvements when DocumentNet is incorporated into the pre-training for both classic and few-shot learning settings. With the recent emergence of large language models (LLMs), DocumentNet provides a large data source to extend their multi-modal capabilities for VDER.",A. Hauptmann_145788702.json,
"What journal was the paper ""Zero-Shot and Few-Shot Stance Detection on Varied Topics via Conditional Generation"" published in?",,A. Hauptmann_145788702.json,
"What venue was the paper ""Zero-Shot and Few-Shot Stance Detection on Varied Topics via Conditional Generation"" published in?",Annual Meeting of the Association for Computational Linguistics,A. Hauptmann_145788702.json,
"How many citations does the paper ""Zero-Shot and Few-Shot Stance Detection on Varied Topics via Conditional Generation"" have?",2,A. Hauptmann_145788702.json,
"Who are the authors of the paper ""Zero-Shot and Few-Shot Stance Detection on Varied Topics via Conditional Generation""?","Haoyang Wen, A. Hauptmann",A. Hauptmann_145788702.json,
"Who is the first author of the paper ""Zero-Shot and Few-Shot Stance Detection on Varied Topics via Conditional Generation""?",Haoyang Wen,A. Hauptmann_145788702.json,
"What is the paper ID of the paper ""Zero-Shot and Few-Shot Stance Detection on Varied Topics via Conditional Generation""?",2107b867cb8f8afa30a9a940288d7c8b657f8aa5,A. Hauptmann_145788702.json,
What paper has the paper ID 2107b867cb8f8afa30a9a940288d7c8b657f8aa5?,Zero-Shot and Few-Shot Stance Detection on Varied Topics via Conditional Generation,A. Hauptmann_145788702.json,
What is the TLDR of the paper 'Zero-Shot and Few-Shot Stance Detection on Varied Topics via Conditional Generation'?,"This paper utilizes a conditional generation framework and formulates the zero-shot and few-shot stance detection problem as denoising from partially-filled templates, which can better utilize the semantics among input, label, and target texts.",A. Hauptmann_145788702.json,
What is the abstract of the paper 'Zero-Shot and Few-Shot Stance Detection on Varied Topics via Conditional Generation'?,"Zero-shot and few-shot stance detection identify the polarity of text with regard to a certain target when we have only limited or no training resources for the target. Previous work generally formulates the problem into a classification setting, ignoring the potential use of label text. In this paper, we instead utilize a conditional generation framework and formulate the problem as denoising from partially-filled templates, which can better utilize the semantics among input, label, and target texts. We further propose to jointly train an auxiliary task, target prediction, and to incorporate manually constructed incorrect samples with unlikelihood training to improve the representations for both target and label texts. We also verify the effectiveness of target-related Wikipedia knowledge with the generation framework. Experiments show that our proposed method significantly outperforms several strong baselines on VAST, and achieves new state-of-the-art performance.",A. Hauptmann_145788702.json,
"What journal was the paper ""SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs"" published in?",ArXiv,A. Hauptmann_145788702.json,
"What venue was the paper ""SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs"" published in?",arXiv.org,A. Hauptmann_145788702.json,
"How many citations does the paper ""SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs"" have?",9,A. Hauptmann_145788702.json,
"Who are the authors of the paper ""SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs""?","Lijun Yu, Yong Cheng, Zhiruo Wang, Vivek Kumar, Wolfgang Macherey, Yanping Huang, David A. Ross, Irfan Essa, Yonatan Bisk, Ming Yang, K. Murphy, A. Hauptmann, Lu Jiang",A. Hauptmann_145788702.json,
"Who is the first author of the paper ""SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs""?",Lijun Yu,A. Hauptmann_145788702.json,
"What is the paper ID of the paper ""SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs""?",376f494126d1ea4f571ea0263c43ac2b6331800a,A. Hauptmann_145788702.json,
What paper has the paper ID 376f494126d1ea4f571ea0263c43ac2b6331800a?,SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs,A. Hauptmann_145788702.json,
What is the TLDR of the paper 'SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs'?,"This method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.",A. Hauptmann_145788702.json,
What is the abstract of the paper 'SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs'?,"In this work, we introduce Semantic Pyramid AutoEncoder (SPAE) for enabling frozen LLMs to perform both understanding and generation tasks involving non-linguistic modalities such as images or videos. SPAE converts between raw pixels and interpretable lexical tokens (or words) extracted from the LLM's vocabulary. The resulting tokens capture both the semantic meaning and the fine-grained details needed for visual reconstruction, effectively translating the visual content into a language comprehensible to the LLM, and empowering it to perform a wide array of multimodal tasks. Our approach is validated through in-context learning experiments with frozen PaLM 2 and GPT 3.5 on a diverse set of image understanding and generation tasks. Our method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.",A. Hauptmann_145788702.json,
What is the author ID of Alon Lavie?,1784914,data/paper_jsons/A. Lavie_1784914.json,
What are the papers of Alon Lavie?,"The Inside Story: Towards Better Understanding of Machine Translation Neural Evaluation Metrics, Towards Multilingual Automatic Dialogue Evaluation, Results of WMT23 Metrics Shared Task: Metrics Might Be Guilty but References Are Not Innocent, Appropriateness is all you need!, Towards Multilingual Automatic Open-Domain Dialogue Evaluation, Simple LLM Prompting is State-of-the-Art for Robust and Multilingual Dialogue Evaluation",data/paper_jsons/A. Lavie_1784914.json,
What is the H-index of Alon Lavie?,47,data/paper_jsons/A. Lavie_1784914.json,
What is the author citation count of Alon Lavie?,14491,data/paper_jsons/A. Lavie_1784914.json,
What journals has Alon Lavie published in?,ArXiv,data/paper_jsons/A. Lavie_1784914.json,
What are the journals and how many papers has Alon Lavie published in each?,{'ArXiv': 3},data/paper_jsons/A. Lavie_1784914.json,
What are the fields of study of Alon Lavie?,Computer Science,data/paper_jsons/A. Lavie_1784914.json,
How many papers has Alon Lavie published in open access journals?,6,data/paper_jsons/A. Lavie_1784914.json,
What venues has Alon Lavie published in?,"Annual Meeting of the Association for Computational Linguistics, arXiv.org, Conference on Machine Translation, SIGDIAL Conferences, DSTC",data/paper_jsons/A. Lavie_1784914.json,
What is the most cited paper from Alon Lavie?,The Inside Story: Towards Better Understanding of Machine Translation Neural Evaluation Metrics,data/paper_jsons/A. Lavie_1784914.json,
What is the url of the most cited paper from Alon Lavie?,http://arxiv.org/pdf/2305.11806,data/paper_jsons/A. Lavie_1784914.json,
Who are the authors of the most cited paper from Alon Lavie?,"Ricardo Rei, Nuno M. Guerreiro, Marcos Vinícius Treviso, Luísa Coheur, A. Lavie, André Martins",data/paper_jsons/A. Lavie_1784914.json,
TLDR of the most cited paper from Alon Lavie?,"This study reveals that neural explainability metrics leverage token-level information that can be directly attributed to translation errors, as assessed through comparison of token- level neural saliency maps with Multidimensional Quality Metrics annotations and with synthetically-generated critical translation errors.",data/paper_jsons/A. Lavie_1784914.json,
Abstract of the most cited paper from Alon Lavie?,"Neural metrics for machine translation evaluation, such as COMET, exhibit significant improvements in their correlation with human judgments, as compared to traditional metrics based on lexical overlap, such as BLEU. Yet, neural metrics are, to a great extent, “black boxes” returning a single sentence-level score without transparency about the decision-making process. In this work, we develop and compare several neural explainability methods and demonstrate their effectiveness for interpreting state-of-the-art fine-tuned neural metrics. Our study reveals that these metrics leverage token-level information that can be directly attributed to translation errors, as assessed through comparison of token-level neural saliency maps with Multidimensional Quality Metrics (MQM) annotations and with synthetically-generated critical translation errors. To ease future research, we release our code at: https://github.com/Unbabel/COMET/tree/explainable-metrics",data/paper_jsons/A. Lavie_1784914.json,
"What journal was the paper ""Towards Multilingual Automatic Open-Domain Dialogue Evaluation"" published in?",,A. Lavie_1784914.json,
"What venue was the paper ""Towards Multilingual Automatic Open-Domain Dialogue Evaluation"" published in?",SIGDIAL Conferences,A. Lavie_1784914.json,
"How many citations does the paper ""Towards Multilingual Automatic Open-Domain Dialogue Evaluation"" have?",0,A. Lavie_1784914.json,
"Who are the authors of the paper ""Towards Multilingual Automatic Open-Domain Dialogue Evaluation""?","John Mendonça, A. Lavie, I. Trancoso",A. Lavie_1784914.json,
"Who is the first author of the paper ""Towards Multilingual Automatic Open-Domain Dialogue Evaluation""?",John Mendonça,A. Lavie_1784914.json,
"What is the paper ID of the paper ""Towards Multilingual Automatic Open-Domain Dialogue Evaluation""?",9e8f125ef479af7e95ee5b8949b24e750c7df367,A. Lavie_1784914.json,
What paper has the paper ID 9e8f125ef479af7e95ee5b8949b24e750c7df367?,Towards Multilingual Automatic Open-Domain Dialogue Evaluation,A. Lavie_1784914.json,
What is the TLDR of the paper 'Towards Multilingual Automatic Open-Domain Dialogue Evaluation'?,It is empirically show that the naive approach of finetuning a pretrained multilingual encoder model with translated data is insufficient to outperform the strong baseline of finETuning a multilingual model with only source data.,A. Lavie_1784914.json,
What is the abstract of the paper 'Towards Multilingual Automatic Open-Domain Dialogue Evaluation'?,"The main limiting factor in the development of robust multilingual open-domain dialogue evaluation metrics is the lack of multilingual data and the limited availability of open-sourced multilingual dialogue systems. In this work, we propose a workaround for this lack of data by leveraging a strong multilingual pretrained encoder-based Language Model and augmenting existing English dialogue data using Machine Translation. We empirically show that the naive approach of finetuning a pretrained multilingual encoder model with translated data is insufficient to outperform the strong baseline of finetuning a multilingual model with only source data. Instead, the best approach consists in the careful curation of translated data using MT Quality Estimation metrics, excluding low quality translations that hinder its performance.",A. Lavie_1784914.json,
"What journal was the paper ""Simple LLM Prompting is State-of-the-Art for Robust and Multilingual Dialogue Evaluation"" published in?",ArXiv,A. Lavie_1784914.json,
"What venue was the paper ""Simple LLM Prompting is State-of-the-Art for Robust and Multilingual Dialogue Evaluation"" published in?",DSTC,A. Lavie_1784914.json,
"How many citations does the paper ""Simple LLM Prompting is State-of-the-Art for Robust and Multilingual Dialogue Evaluation"" have?",4,A. Lavie_1784914.json,
"Who are the authors of the paper ""Simple LLM Prompting is State-of-the-Art for Robust and Multilingual Dialogue Evaluation""?","J. Mendoncca, Patrícia Pereira, Joao Paulo Carvalho, A. Lavie, I. Trancoso",A. Lavie_1784914.json,
"Who is the first author of the paper ""Simple LLM Prompting is State-of-the-Art for Robust and Multilingual Dialogue Evaluation""?",J. Mendoncca,A. Lavie_1784914.json,
"What is the paper ID of the paper ""Simple LLM Prompting is State-of-the-Art for Robust and Multilingual Dialogue Evaluation""?",bcefc74b20649fd41ea05d87a3fa512d2559fc8d,A. Lavie_1784914.json,
What paper has the paper ID bcefc74b20649fd41ea05d87a3fa512d2559fc8d?,Simple LLM Prompting is State-of-the-Art for Robust and Multilingual Dialogue Evaluation,A. Lavie_1784914.json,
What is the TLDR of the paper 'Simple LLM Prompting is State-of-the-Art for Robust and Multilingual Dialogue Evaluation'?,A novel framework that takes advantage of the strengths of current evaluation models with the newly-established paradigm of prompting Large Language Models (LLMs) to achieve the desired properties of robustness and multilinguality for dialogue evaluation metrics.,A. Lavie_1784914.json,
What is the abstract of the paper 'Simple LLM Prompting is State-of-the-Art for Robust and Multilingual Dialogue Evaluation'?,"Despite significant research effort in the development of automatic dialogue evaluation metrics, little thought is given to evaluating dialogues other than in English. At the same time, ensuring metrics are invariant to semantically similar responses is also an overlooked topic. In order to achieve the desired properties of robustness and multilinguality for dialogue evaluation metrics, we propose a novel framework that takes advantage of the strengths of current evaluation models with the newly-established paradigm of prompting Large Language Models (LLMs). Empirical results show our framework achieves state of the art results in terms of mean Spearman correlation scores across several benchmarks and ranks first place on both the Robust and Multilingual tasks of the DSTC11 Track 4 “Automatic Evaluation Metrics for Open-Domain Dialogue Systems”, proving the evaluation capabilities of prompted LLMs.",A. Lavie_1784914.json,
"What journal was the paper ""Towards Multilingual Automatic Dialogue Evaluation"" published in?",ArXiv,A. Lavie_1784914.json,
"What venue was the paper ""Towards Multilingual Automatic Dialogue Evaluation"" published in?",arXiv.org,A. Lavie_1784914.json,
"How many citations does the paper ""Towards Multilingual Automatic Dialogue Evaluation"" have?",0,A. Lavie_1784914.json,
"Who are the authors of the paper ""Towards Multilingual Automatic Dialogue Evaluation""?","John Mendonça, A. Lavie, Isabel Trancoso",A. Lavie_1784914.json,
"Who is the first author of the paper ""Towards Multilingual Automatic Dialogue Evaluation""?",John Mendonça,A. Lavie_1784914.json,
"What is the paper ID of the paper ""Towards Multilingual Automatic Dialogue Evaluation""?",5579d38636b898c6a67ad67a16a80dd83be0f8d4,A. Lavie_1784914.json,
What paper has the paper ID 5579d38636b898c6a67ad67a16a80dd83be0f8d4?,Towards Multilingual Automatic Dialogue Evaluation,A. Lavie_1784914.json,
What is the TLDR of the paper 'Towards Multilingual Automatic Dialogue Evaluation'?,TLDR not found,A. Lavie_1784914.json,
What is the abstract of the paper 'Towards Multilingual Automatic Dialogue Evaluation'?,,A. Lavie_1784914.json,
What is the author ID of Alexander Rudnicky?,3156164,data/paper_jsons/A. Rudnicky_3156164.json,
What are the papers of Alexander Rudnicky?,"Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings, Transformer Working Memory Enables Regular Language Reasoning and Natural Language Length Extrapolation",data/paper_jsons/A. Rudnicky_3156164.json,
What is the H-index of Alexander Rudnicky?,8,data/paper_jsons/A. Rudnicky_3156164.json,
What is the author citation count of Alexander Rudnicky?,309,data/paper_jsons/A. Rudnicky_3156164.json,
What journals has Alexander Rudnicky published in?,,data/paper_jsons/A. Rudnicky_3156164.json,
What are the journals and how many papers has Alexander Rudnicky published in each?,{},data/paper_jsons/A. Rudnicky_3156164.json,
What are the fields of study of Alexander Rudnicky?,Computer Science,data/paper_jsons/A. Rudnicky_3156164.json,
How many papers has Alexander Rudnicky published in open access journals?,2,data/paper_jsons/A. Rudnicky_3156164.json,
What venues has Alexander Rudnicky published in?,"Annual Meeting of the Association for Computational Linguistics, Conference on Empirical Methods in Natural Language Processing",data/paper_jsons/A. Rudnicky_3156164.json,
What is the most cited paper from Alexander Rudnicky?,Transformer Working Memory Enables Regular Language Reasoning and Natural Language Length Extrapolation,data/paper_jsons/A. Rudnicky_3156164.json,
What is the url of the most cited paper from Alexander Rudnicky?,http://arxiv.org/pdf/2305.03796,data/paper_jsons/A. Rudnicky_3156164.json,
Who are the authors of the most cited paper from Alexander Rudnicky?,"Ta-Chung Chi, Ting-Han Fan, A. Rudnicky, P. Ramadge",data/paper_jsons/A. Rudnicky_3156164.json,
TLDR of the most cited paper from Alexander Rudnicky?,"Inspired by the notion of working memory, a new Transformer variant named RegularGPT is proposed, which constructs working memory along the depth dimension, thereby enabling efficient and successful modeling of regular languages such as PARITY.",data/paper_jsons/A. Rudnicky_3156164.json,
Abstract of the most cited paper from Alexander Rudnicky?,"Unlike recurrent models, conventional wisdom has it that Transformers cannot perfectly model regular languages. Inspired by the notion of working memory, we propose a new Transformer variant named RegularGPT. With its novel combination of Weight-Sharing, Adaptive-Depth, and Sliding-Dilated-Attention, RegularGPT constructs working memory along the depth dimension, thereby enabling efficient and successful modeling of regular languages such as PARITY. We further test RegularGPT on the task of natural language length extrapolation and surprisingly find that it rediscovers the local windowed attention effect deemed necessary in prior work for length extrapolation.",data/paper_jsons/A. Rudnicky_3156164.json,
"What journal was the paper ""Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings"" published in?",,A. Rudnicky_3156164.json,
"What venue was the paper ""Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings"" published in?",Annual Meeting of the Association for Computational Linguistics,A. Rudnicky_3156164.json,
"How many citations does the paper ""Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings"" have?",1,A. Rudnicky_3156164.json,
"Who are the authors of the paper ""Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings""?","Ta-Chung Chi, Ting-Han Fan, Li-Wei Chen, A. Rudnicky, P. Ramadge",A. Rudnicky_3156164.json,
"Who is the first author of the paper ""Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings""?",Ta-Chung Chi,A. Rudnicky_3156164.json,
"What is the paper ID of the paper ""Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings""?",161bf3f0705ef8e088f53b383363338daac9af44,A. Rudnicky_3156164.json,
What paper has the paper ID 161bf3f0705ef8e088f53b383363338daac9af44?,Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings,A. Rudnicky_3156164.json,
What is the TLDR of the paper 'Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings'?,"This work demonstrates that a randomly initialized and frozen transformer language model, devoid of positional embeddings, inherently encodes strong positional information through the shrinkage of self-attention variance, and derives the underlying distribution of each step within a transformer layer.",A. Rudnicky_3156164.json,
What is the abstract of the paper 'Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings'?,"The use of positional embeddings in transformer language models is widely accepted. However, recent research has called into question the necessity of such embeddings. We further extend this inquiry by demonstrating that a randomly initialized and frozen transformer language model, devoid of positional embeddings, inherently encodes strong positional information through the shrinkage of self-attention variance. To quantify this variance, we derive the underlying distribution of each step within a transformer layer. Through empirical validation using a fully pretrained model, we show that the variance shrinkage effect still persists after extensive gradient updates. Our findings serve to justify the decision to discard positional embeddings and thus facilitate more efficient pretraining of transformer language models.",A. Rudnicky_3156164.json,
"What journal was the paper ""Transformer Working Memory Enables Regular Language Reasoning and Natural Language Length Extrapolation"" published in?",,A. Rudnicky_3156164.json,
"What venue was the paper ""Transformer Working Memory Enables Regular Language Reasoning and Natural Language Length Extrapolation"" published in?",Conference on Empirical Methods in Natural Language Processing,A. Rudnicky_3156164.json,
"How many citations does the paper ""Transformer Working Memory Enables Regular Language Reasoning and Natural Language Length Extrapolation"" have?",4,A. Rudnicky_3156164.json,
"Who are the authors of the paper ""Transformer Working Memory Enables Regular Language Reasoning and Natural Language Length Extrapolation""?","Ta-Chung Chi, Ting-Han Fan, A. Rudnicky, P. Ramadge",A. Rudnicky_3156164.json,
"Who is the first author of the paper ""Transformer Working Memory Enables Regular Language Reasoning and Natural Language Length Extrapolation""?",Ta-Chung Chi,A. Rudnicky_3156164.json,
"What is the paper ID of the paper ""Transformer Working Memory Enables Regular Language Reasoning and Natural Language Length Extrapolation""?",465ec2212d865e875e64638b3dd1ecaac21c5ddd,A. Rudnicky_3156164.json,
What paper has the paper ID 465ec2212d865e875e64638b3dd1ecaac21c5ddd?,Transformer Working Memory Enables Regular Language Reasoning and Natural Language Length Extrapolation,A. Rudnicky_3156164.json,
What is the TLDR of the paper 'Transformer Working Memory Enables Regular Language Reasoning and Natural Language Length Extrapolation'?,"Inspired by the notion of working memory, a new Transformer variant named RegularGPT is proposed, which constructs working memory along the depth dimension, thereby enabling efficient and successful modeling of regular languages such as PARITY.",A. Rudnicky_3156164.json,
What is the abstract of the paper 'Transformer Working Memory Enables Regular Language Reasoning and Natural Language Length Extrapolation'?,"Unlike recurrent models, conventional wisdom has it that Transformers cannot perfectly model regular languages. Inspired by the notion of working memory, we propose a new Transformer variant named RegularGPT. With its novel combination of Weight-Sharing, Adaptive-Depth, and Sliding-Dilated-Attention, RegularGPT constructs working memory along the depth dimension, thereby enabling efficient and successful modeling of regular languages such as PARITY. We further test RegularGPT on the task of natural language length extrapolation and surprisingly find that it rediscovers the local windowed attention effect deemed necessary in prior work for length extrapolation.",A. Rudnicky_3156164.json,
What is the author ID of Alexander Waibel?,1724972,data/paper_jsons/A. Waibel_1724972.json,
What are the papers of Alexander Waibel?,"SYNTACC : Synthesizing Multi-Accent Speech By Weight Factorization, KIT’s Multilingual Speech Translation System for IWSLT 2023, Convoifilter: A case study of doing cocktail party speech recognition, Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff, End-to-End Evaluation for Low-Latency Simultaneous Speech Translation, FINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN",data/paper_jsons/A. Waibel_1724972.json,
What is the H-index of Alexander Waibel?,80,data/paper_jsons/A. Waibel_1724972.json,
What is the author citation count of Alexander Waibel?,27573,data/paper_jsons/A. Waibel_1724972.json,
What journals has Alexander Waibel published in?,"ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), ArXiv",data/paper_jsons/A. Waibel_1724972.json,
What are the journals and how many papers has Alexander Waibel published in each?,"{'ArXiv': 3, 'ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)': 1}",data/paper_jsons/A. Waibel_1724972.json,
What are the fields of study of Alexander Waibel?,"Computer Science, Engineering",data/paper_jsons/A. Waibel_1724972.json,
How many papers has Alexander Waibel published in open access journals?,6,data/paper_jsons/A. Waibel_1724972.json,
What venues has Alexander Waibel published in?,"IEEE International Conference on Acoustics, Speech, and Signal Processing, International Workshop on Spoken Language Translation, arXiv.org, Interspeech, Conference on Empirical Methods in Natural Language Processing",data/paper_jsons/A. Waibel_1724972.json,
What is the most cited paper from Alexander Waibel?,FINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN,data/paper_jsons/A. Waibel_1724972.json,
What is the url of the most cited paper from Alexander Waibel?,https://aclanthology.org/2023.iwslt-1.1.pdf,data/paper_jsons/A. Waibel_1724972.json,
Who are the authors of the most cited paper from Alexander Waibel?,"Sweta Agrawal, Antonios Anastasopoulos, L. Bentivogli, Ondrej Bojar, Claudia Borg, Marine Carpuat, Roldano Cattoni, Mauro Cettolo, Mingda Chen, William Chen, K. Choukri, Alexandra Chronopoulou, Anna Currey, T. Declerck, Qianqian Dong, Kevin Duh, Y. Estève, Marcello Federico, Souhir Gahbiche, B. Haddow, B. Hsu, Phu Mon Htut, H. Inaguma, Dávid Javorský, J. Judge, Yasumasa Kano, Tom Ko, Rishu Kumar, Peng Li, Xutai Ma, Prashant Mathur, E. Matusov, Paul McNamee, John P. McCrae, Kenton Murray, Maria Nadejde, Satoshi Nakamura, Matteo Negri, H. Nguyen, J. Niehues, Xing Niu, Atul Kr. Ojha, John E. Ortega, Proyag Pal, J. Pino, Lonneke van der Plas, Peter Polák, Elijah Matthew Rippeth, Elizabeth Salesky, Jiatong Shi, Matthias Sperber, Sebastian Stüker, Katsuhito Sudoh, Yun Tang, Brian Thompson, Ke M. Tran, M. Turchi, A. Waibel, Mingxuan Wang, Shinji Watanabe, Rodolfo Zevallos",data/paper_jsons/A. Waibel_1724972.json,
TLDR of the most cited paper from Alexander Waibel?,,data/paper_jsons/A. Waibel_1724972.json,
Abstract of the most cited paper from Alexander Waibel?,"This paper reports on the shared tasks organized by the 20th IWSLT Conference. The shared tasks address 9 scientific challenges in spoken language translation: simultaneous and offline translation, automatic subtitling and dubbing, speech-to-speech translation, multilingual, dialect and low-resource speech translation, and formality control. The shared tasks attracted a total of 38 submissions by 31 teams. The growing interest towards spoken language translation is also witnessed by the constantly increasing number of shared task organizers and contributors to the overview paper, almost evenly distributed across industry and academia.",data/paper_jsons/A. Waibel_1724972.json,
"What journal was the paper ""FINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN"" published in?",,A. Waibel_1724972.json,
"What venue was the paper ""FINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN"" published in?",International Workshop on Spoken Language Translation,A. Waibel_1724972.json,
"How many citations does the paper ""FINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN"" have?",22,A. Waibel_1724972.json,
"Who are the authors of the paper ""FINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN""?","Sweta Agrawal, Antonios Anastasopoulos, L. Bentivogli, Ondrej Bojar, Claudia Borg, Marine Carpuat, Roldano Cattoni, Mauro Cettolo, Mingda Chen, William Chen, K. Choukri, Alexandra Chronopoulou, Anna Currey, T. Declerck, Qianqian Dong, Kevin Duh, Y. Estève, Marcello Federico, Souhir Gahbiche, B. Haddow, B. Hsu, Phu Mon Htut, H. Inaguma, Dávid Javorský, J. Judge, Yasumasa Kano, Tom Ko, Rishu Kumar, Peng Li, Xutai Ma, Prashant Mathur, E. Matusov, Paul McNamee, John P. McCrae, Kenton Murray, Maria Nadejde, Satoshi Nakamura, Matteo Negri, H. Nguyen, J. Niehues, Xing Niu, Atul Kr. Ojha, John E. Ortega, Proyag Pal, J. Pino, Lonneke van der Plas, Peter Polák, Elijah Matthew Rippeth, Elizabeth Salesky, Jiatong Shi, Matthias Sperber, Sebastian Stüker, Katsuhito Sudoh, Yun Tang, Brian Thompson, Ke M. Tran, M. Turchi, A. Waibel, Mingxuan Wang, Shinji Watanabe, Rodolfo Zevallos",A. Waibel_1724972.json,
"Who is the first author of the paper ""FINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN""?",Sweta Agrawal,A. Waibel_1724972.json,
"What is the paper ID of the paper ""FINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN""?",f7e995c3cae465963ecaa8c9b4ce8b9b4323a71b,A. Waibel_1724972.json,
What paper has the paper ID f7e995c3cae465963ecaa8c9b4ce8b9b4323a71b?,FINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN,A. Waibel_1724972.json,
What is the TLDR of the paper 'FINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN'?,,A. Waibel_1724972.json,
What is the abstract of the paper 'FINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN'?,"This paper reports on the shared tasks organized by the 20th IWSLT Conference. The shared tasks address 9 scientific challenges in spoken language translation: simultaneous and offline translation, automatic subtitling and dubbing, speech-to-speech translation, multilingual, dialect and low-resource speech translation, and formality control. The shared tasks attracted a total of 38 submissions by 31 teams. The growing interest towards spoken language translation is also witnessed by the constantly increasing number of shared task organizers and contributors to the overview paper, almost evenly distributed across industry and academia.",A. Waibel_1724972.json,
"What journal was the paper ""Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff"" published in?",ArXiv,A. Waibel_1724972.json,
"What venue was the paper ""Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff"" published in?",Interspeech,A. Waibel_1724972.json,
"How many citations does the paper ""Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff"" have?",4,A. Waibel_1724972.json,
"Who are the authors of the paper ""Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff""?","Peter Polák, Brian Yan, Shinji Watanabe, A. Waibel, Ondrej Bojar",A. Waibel_1724972.json,
"Who is the first author of the paper ""Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff""?",Peter Polák,A. Waibel_1724972.json,
"What is the paper ID of the paper ""Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff""?",d24d60719e90e69749a75c160cb760d1d9fca44a,A. Waibel_1724972.json,
What paper has the paper ID d24d60719e90e69749a75c160cb760d1d9fca44a?,Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff,A. Waibel_1724972.json,
What is the TLDR of the paper 'Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff'?,A modified incremental blockwise beam search incorporating local agreement or hold-$n$ policies for quality-latency control is proposed and applied to models trained for online or offline translation and it is demonstrated that both types can be effectively used in online mode.,A. Waibel_1724972.json,
What is the abstract of the paper 'Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff'?,"Blockwise self-attentional encoder models have recently emerged as one promising end-to-end approach to simultaneous speech translation. These models employ a blockwise beam search with hypothesis reliability scoring to determine when to wait for more input speech before translating further. However, this method maintains multiple hypotheses until the entire speech input is consumed -- this scheme cannot directly show a single \textit{incremental} translation to users. Further, this method lacks mechanisms for \textit{controlling} the quality vs. latency tradeoff. We propose a modified incremental blockwise beam search incorporating local agreement or hold-$n$ policies for quality-latency control. We apply our framework to models trained for online or offline translation and demonstrate that both types can be effectively used in online mode. Experimental results on MuST-C show 0.6-3.6 BLEU improvement without changing latency or 0.8-1.4 s latency improvement without changing quality.",A. Waibel_1724972.json,
"What journal was the paper ""KIT’s Multilingual Speech Translation System for IWSLT 2023"" published in?",ArXiv,A. Waibel_1724972.json,
"What venue was the paper ""KIT’s Multilingual Speech Translation System for IWSLT 2023"" published in?",International Workshop on Spoken Language Translation,A. Waibel_1724972.json,
"How many citations does the paper ""KIT’s Multilingual Speech Translation System for IWSLT 2023"" have?",2,A. Waibel_1724972.json,
"Who are the authors of the paper ""KIT’s Multilingual Speech Translation System for IWSLT 2023""?","Danni Liu, T. Nguyen, Sai Koneru, Enes Yavuz Ugan, Ngoc-Quan Pham, Tuan-Nam Nguyen, Tu Anh Dinh, Carlos Mullov, A. Waibel, J. Niehues",A. Waibel_1724972.json,
"Who is the first author of the paper ""KIT’s Multilingual Speech Translation System for IWSLT 2023""?",Danni Liu,A. Waibel_1724972.json,
"What is the paper ID of the paper ""KIT’s Multilingual Speech Translation System for IWSLT 2023""?",610d9958390ab83515d0d81e19f8e5264faf8e9b,A. Waibel_1724972.json,
What paper has the paper ID 610d9958390ab83515d0d81e19f8e5264faf8e9b?,KIT’s Multilingual Speech Translation System for IWSLT 2023,A. Waibel_1724972.json,
What is the TLDR of the paper 'KIT’s Multilingual Speech Translation System for IWSLT 2023'?,"This paper describes the speech translation system for the multilingual track of IWSLT 2023, which focuses on the translation of scientific conference talks, and observes that cascaded systems are more easily adaptable towards specific target domains, due to their separate modules.",A. Waibel_1724972.json,
What is the abstract of the paper 'KIT’s Multilingual Speech Translation System for IWSLT 2023'?,"Many existing speech translation benchmarks focus on native-English speech in high-quality recording conditions, which often do not match the conditions in real-life use-cases. In this paper, we describe our speech translation system for the multilingual track of IWSLT 2023, which focuses on the translation of scientific conference talks. The test condition features accented input speech and terminology-dense contents. The tasks requires translation into 10 languages of varying amounts of resources. In absence of training data from the target domain, we use a retrieval-based approach (kNN-MT) for effective adaptation (+0.8 BLEU for speech translation). We also use adapters to easily integrate incremental training data from data augmentation, and show that it matches the performance of re-training. We observe that cascaded systems are more easily adaptable towards specific target domains, due to their separate modules. Our cascaded speech system outperforms its end-to-end counterpart on scientific talk translation, although their performance remains similar on TED talks.",A. Waibel_1724972.json,
What is the author ID of Alexander Waibel?,2064429921,data/paper_jsons/A. Waibel_2064429921.json,
What are the papers of Alexander Waibel?,"AdapITN: A Fast, Reliable, and Dynamic Adaptive Inverse Text Normalization, Train Global, Tailor Local: Minimalist Multilingual Translation into Endangered Languages, Towards Efficient Simultaneous Speech Translation: CUNI-KIT System for Simultaneous Track at IWSLT 2023",data/paper_jsons/A. Waibel_2064429921.json,
What is the H-index of Alexander Waibel?,6,data/paper_jsons/A. Waibel_2064429921.json,
What is the author citation count of Alexander Waibel?,69,data/paper_jsons/A. Waibel_2064429921.json,
What journals has Alexander Waibel published in?,"ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), ArXiv",data/paper_jsons/A. Waibel_2064429921.json,
What are the journals and how many papers has Alexander Waibel published in each?,"{'ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)': 1, 'ArXiv': 1}",data/paper_jsons/A. Waibel_2064429921.json,
What are the fields of study of Alexander Waibel?,Computer Science,data/paper_jsons/A. Waibel_2064429921.json,
How many papers has Alexander Waibel published in open access journals?,3,data/paper_jsons/A. Waibel_2064429921.json,
What venues has Alexander Waibel published in?,"IEEE International Conference on Acoustics, Speech, and Signal Processing, LORESMT, International Workshop on Spoken Language Translation",data/paper_jsons/A. Waibel_2064429921.json,
What is the most cited paper from Alexander Waibel?,Towards Efficient Simultaneous Speech Translation: CUNI-KIT System for Simultaneous Track at IWSLT 2023,data/paper_jsons/A. Waibel_2064429921.json,
What is the url of the most cited paper from Alexander Waibel?,https://aclanthology.org/2023.iwslt-1.37.pdf,data/paper_jsons/A. Waibel_2064429921.json,
Who are the authors of the most cited paper from Alexander Waibel?,"Peter Polák, Danni Liu, Ngoc-Quan Pham, J. Niehues, A. Waibel, Ondrej Bojar",data/paper_jsons/A. Waibel_2064429921.json,
TLDR of the most cited paper from Alexander Waibel?,"This year's submission to the Simultaneous Track at IWSLT 2023 is described, and a novel online policy for attentional encoder-decoder models is proposed that prevents the model to generate translation beyond the current speech input by using an auxiliary CTC output layer.",data/paper_jsons/A. Waibel_2064429921.json,
Abstract of the most cited paper from Alexander Waibel?,"In this paper, we describe our submission to the Simultaneous Track at IWSLT 2023. This year, we continue with the successful setup from the last year, however, we adopt the latest methods that further improve the translation quality. Additionally, we propose a novel online policy for attentional encoder-decoder models. The policy prevents the model to generate translation beyond the current speech input by using an auxiliary CTC output layer. We show that the proposed simultaneous policy can be applied to both streaming blockwise models and offline encoder-decoder models. We observe significant improvements in quality (up to 1.1 BLEU) and the computational footprint (up to 45% relative RTF).",data/paper_jsons/A. Waibel_2064429921.json,
"What journal was the paper ""Towards Efficient Simultaneous Speech Translation: CUNI-KIT System for Simultaneous Track at IWSLT 2023"" published in?",,A. Waibel_2064429921.json,
"What venue was the paper ""Towards Efficient Simultaneous Speech Translation: CUNI-KIT System for Simultaneous Track at IWSLT 2023"" published in?",International Workshop on Spoken Language Translation,A. Waibel_2064429921.json,
"How many citations does the paper ""Towards Efficient Simultaneous Speech Translation: CUNI-KIT System for Simultaneous Track at IWSLT 2023"" have?",5,A. Waibel_2064429921.json,
"Who are the authors of the paper ""Towards Efficient Simultaneous Speech Translation: CUNI-KIT System for Simultaneous Track at IWSLT 2023""?","Peter Polák, Danni Liu, Ngoc-Quan Pham, J. Niehues, A. Waibel, Ondrej Bojar",A. Waibel_2064429921.json,
"Who is the first author of the paper ""Towards Efficient Simultaneous Speech Translation: CUNI-KIT System for Simultaneous Track at IWSLT 2023""?",Peter Polák,A. Waibel_2064429921.json,
"What is the paper ID of the paper ""Towards Efficient Simultaneous Speech Translation: CUNI-KIT System for Simultaneous Track at IWSLT 2023""?",f547c7ec86cbc0989e87f0e23f7e0b2cfc5259c3,A. Waibel_2064429921.json,
What paper has the paper ID f547c7ec86cbc0989e87f0e23f7e0b2cfc5259c3?,Towards Efficient Simultaneous Speech Translation: CUNI-KIT System for Simultaneous Track at IWSLT 2023,A. Waibel_2064429921.json,
What is the TLDR of the paper 'Towards Efficient Simultaneous Speech Translation: CUNI-KIT System for Simultaneous Track at IWSLT 2023'?,"This year's submission to the Simultaneous Track at IWSLT 2023 is described, and a novel online policy for attentional encoder-decoder models is proposed that prevents the model to generate translation beyond the current speech input by using an auxiliary CTC output layer.",A. Waibel_2064429921.json,
What is the abstract of the paper 'Towards Efficient Simultaneous Speech Translation: CUNI-KIT System for Simultaneous Track at IWSLT 2023'?,"In this paper, we describe our submission to the Simultaneous Track at IWSLT 2023. This year, we continue with the successful setup from the last year, however, we adopt the latest methods that further improve the translation quality. Additionally, we propose a novel online policy for attentional encoder-decoder models. The policy prevents the model to generate translation beyond the current speech input by using an auxiliary CTC output layer. We show that the proposed simultaneous policy can be applied to both streaming blockwise models and offline encoder-decoder models. We observe significant improvements in quality (up to 1.1 BLEU) and the computational footprint (up to 45% relative RTF).",A. Waibel_2064429921.json,
"What journal was the paper ""Train Global, Tailor Local: Minimalist Multilingual Translation into Endangered Languages"" published in?",ArXiv,A. Waibel_2064429921.json,
"What venue was the paper ""Train Global, Tailor Local: Minimalist Multilingual Translation into Endangered Languages"" published in?",LORESMT,A. Waibel_2064429921.json,
"How many citations does the paper ""Train Global, Tailor Local: Minimalist Multilingual Translation into Endangered Languages"" have?",0,A. Waibel_2064429921.json,
"Who are the authors of the paper ""Train Global, Tailor Local: Minimalist Multilingual Translation into Endangered Languages""?","Zhong Zhou, J. Niehues, A. Waibel",A. Waibel_2064429921.json,
"Who is the first author of the paper ""Train Global, Tailor Local: Minimalist Multilingual Translation into Endangered Languages""?",Zhong Zhou,A. Waibel_2064429921.json,
"What is the paper ID of the paper ""Train Global, Tailor Local: Minimalist Multilingual Translation into Endangered Languages""?",f3e237e794bc4cd8df7f3e31d0caa2f7ee8cd06b,A. Waibel_2064429921.json,
What paper has the paper ID f3e237e794bc4cd8df7f3e31d0caa2f7ee8cd06b?,"Train Global, Tailor Local: Minimalist Multilingual Translation into Endangered Languages",A. Waibel_2064429921.json,
"What is the TLDR of the paper 'Train Global, Tailor Local: Minimalist Multilingual Translation into Endangered Languages'?","This work examines two approaches to best selection of seed sentences to jump start translations in a new language in view of best generalization to the remainder of a larger targeted text(s), and it finds that adapting large pretrained multilingual models to the domain/text first and then to the severely low resource language works best.",A. Waibel_2064429921.json,
"What is the abstract of the paper 'Train Global, Tailor Local: Minimalist Multilingual Translation into Endangered Languages'?","In many humanitarian scenarios, translation into severely low resource languages often does not require a universal translation engine, but a dedicated text-specific translation engine. For example, healthcare records, hygienic procedures, government communication, emergency procedures and religious texts are all limited texts. While generic translation engines for all languages do not exist, translation of multilingually known limited texts into new, endangered languages may be possible and reduce human translation effort. We attempt to leverage translation resources from rich resource languages to efficiently produce best possible translation quality for well known texts, which is available in multiple languages, in a new, severely low resource language. We examine two approaches: 1.) best selection of seed sentences to jump start translations in a new language in view of best generalization to the remainder of a larger targeted text(s), and 2.) we adapt large general multilingual translation engines from many other languages to focus on a specific text in a new, unknown language. We find that adapting large pretrained multilingual models to the domain/text first and then to the severely low resource language works best. If we also select a best set of seed sentences, we can improve average chrF performance on new test languages from a baseline of 21.9 to 50.7, while reducing the number of seed sentences to only ∼1,000 in the new, unknown language.",A. Waibel_2064429921.json,
"What journal was the paper ""AdapITN: A Fast, Reliable, and Dynamic Adaptive Inverse Text Normalization"" published in?","ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",A. Waibel_2064429921.json,
"What venue was the paper ""AdapITN: A Fast, Reliable, and Dynamic Adaptive Inverse Text Normalization"" published in?","IEEE International Conference on Acoustics, Speech, and Signal Processing",A. Waibel_2064429921.json,
"How many citations does the paper ""AdapITN: A Fast, Reliable, and Dynamic Adaptive Inverse Text Normalization"" have?",1,A. Waibel_2064429921.json,
"Who are the authors of the paper ""AdapITN: A Fast, Reliable, and Dynamic Adaptive Inverse Text Normalization""?","T. Nguyen, Le Duc Minh Nhat, Quang Minh Nguyen, Quoc Truong Do, C. Luong, A. Waibel",A. Waibel_2064429921.json,
"Who is the first author of the paper ""AdapITN: A Fast, Reliable, and Dynamic Adaptive Inverse Text Normalization""?",T. Nguyen,A. Waibel_2064429921.json,
"What is the paper ID of the paper ""AdapITN: A Fast, Reliable, and Dynamic Adaptive Inverse Text Normalization""?",aab2ed83bc3739a20e90ae1d97dcf45f3bc8e508,A. Waibel_2064429921.json,
What paper has the paper ID aab2ed83bc3739a20e90ae1d97dcf45f3bc8e508?,"AdapITN: A Fast, Reliable, and Dynamic Adaptive Inverse Text Normalization",A. Waibel_2064429921.json,
"What is the TLDR of the paper 'AdapITN: A Fast, Reliable, and Dynamic Adaptive Inverse Text Normalization'?","A novel end2end model that can handle both semiotic phrases (SEP) and phonetization phrases (PHP), named AdapITN is introduced, named ""Adap"" because it allows for handling unseen PHP.",A. Waibel_2064429921.json,
"What is the abstract of the paper 'AdapITN: A Fast, Reliable, and Dynamic Adaptive Inverse Text Normalization'?","Inverse text normalization (ITN) is the task that transforms text in spoken-form into written-form. While automatic speech recognition (ASR) produces text in spoken-form, human and natural language understanding systems prefer to consume text in written-form. ITN generally deals with semiotic phrases (e.g., numbers, date, time). However, lack of studies to deal with phonetization phrases, which is ASR’s output when it handles unseen data (e.g., foreign-named entities, domain names), although these exist in the same form in the spoken-form text. The reason is that phonetization phrases are infinite patterns and language-dependent. In this study, we introduce a novel end2end model that can handle both semiotic phrases (SEP) and phonetization phrases (PHP), named AdapITN. We call it ""Adap"" because it allows for handling unseen PHP. The model performs only when necessary by providing a mechanism to narrow normalized regions and external query knowledge, reducing the runtime significantly.",A. Waibel_2064429921.json,
What is the author ID of Alexander Hauptmann?,7661726,data/paper_jsons/Alexander Hauptmann_7661726.json,
What are the papers of Alexander Hauptmann?,Towards Open-Domain Twitter User Profile Inference,data/paper_jsons/Alexander Hauptmann_7661726.json,
What is the H-index of Alexander Hauptmann?,81,data/paper_jsons/Alexander Hauptmann_7661726.json,
What is the author citation count of Alexander Hauptmann?,25325,data/paper_jsons/Alexander Hauptmann_7661726.json,
What journals has Alexander Hauptmann published in?,,data/paper_jsons/Alexander Hauptmann_7661726.json,
What are the journals and how many papers has Alexander Hauptmann published in each?,{},data/paper_jsons/Alexander Hauptmann_7661726.json,
What are the fields of study of Alexander Hauptmann?,Computer Science,data/paper_jsons/Alexander Hauptmann_7661726.json,
How many papers has Alexander Hauptmann published in open access journals?,1,data/paper_jsons/Alexander Hauptmann_7661726.json,
What venues has Alexander Hauptmann published in?,Annual Meeting of the Association for Computational Linguistics,data/paper_jsons/Alexander Hauptmann_7661726.json,
What is the most cited paper from Alexander Hauptmann?,Towards Open-Domain Twitter User Profile Inference,data/paper_jsons/Alexander Hauptmann_7661726.json,
What is the url of the most cited paper from Alexander Hauptmann?,https://aclanthology.org/2023.findings-acl.198.pdf,data/paper_jsons/Alexander Hauptmann_7661726.json,
Who are the authors of the most cited paper from Alexander Hauptmann?,"Haoyang Wen, Zhenxin Xiao, E. Hovy, Alexander Hauptmann",data/paper_jsons/Alexander Hauptmann_7661726.json,
TLDR of the most cited paper from Alexander Hauptmann?,,data/paper_jsons/Alexander Hauptmann_7661726.json,
Abstract of the most cited paper from Alexander Hauptmann?,",",data/paper_jsons/Alexander Hauptmann_7661726.json,
"What journal was the paper ""Towards Open-Domain Twitter User Profile Inference"" published in?",,Alexander Hauptmann_7661726.json,
"What venue was the paper ""Towards Open-Domain Twitter User Profile Inference"" published in?",Annual Meeting of the Association for Computational Linguistics,Alexander Hauptmann_7661726.json,
"How many citations does the paper ""Towards Open-Domain Twitter User Profile Inference"" have?",0,Alexander Hauptmann_7661726.json,
"Who are the authors of the paper ""Towards Open-Domain Twitter User Profile Inference""?","Haoyang Wen, Zhenxin Xiao, E. Hovy, Alexander Hauptmann",Alexander Hauptmann_7661726.json,
"Who is the first author of the paper ""Towards Open-Domain Twitter User Profile Inference""?",Haoyang Wen,Alexander Hauptmann_7661726.json,
"What is the paper ID of the paper ""Towards Open-Domain Twitter User Profile Inference""?",72cce47fd053bf916314d89a8174726c58c05e02,Alexander Hauptmann_7661726.json,
What paper has the paper ID 72cce47fd053bf916314d89a8174726c58c05e02?,Towards Open-Domain Twitter User Profile Inference,Alexander Hauptmann_7661726.json,
What is the TLDR of the paper 'Towards Open-Domain Twitter User Profile Inference'?,,Alexander Hauptmann_7661726.json,
What is the abstract of the paper 'Towards Open-Domain Twitter User Profile Inference'?,",",Alexander Hauptmann_7661726.json,
What is the author ID of Alexander Rudnicky?,1783635,data/paper_jsons/Alexander I. Rudnicky_1783635.json,
What are the papers of Alexander Rudnicky?,"Advancing Regular Language Reasoning in Linear Recurrent Neural Networks, Structured Dialogue Discourse Parsing, A Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech, Overview of Robust and Multilingual Automatic Evaluation Metrics

for Open-Domain Dialogue Systems at DSTC 11 Track 4, Learning to Ask Questions for Zero-shot Dialogue State Tracking",data/paper_jsons/Alexander I. Rudnicky_1783635.json,
What is the H-index of Alexander Rudnicky?,42,data/paper_jsons/Alexander I. Rudnicky_1783635.json,
What is the author citation count of Alexander Rudnicky?,7639,data/paper_jsons/Alexander I. Rudnicky_1783635.json,
What journals has Alexander Rudnicky published in?,"ArXiv, Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval",data/paper_jsons/Alexander I. Rudnicky_1783635.json,
What are the journals and how many papers has Alexander Rudnicky published in each?,"{'ArXiv': 4, 'Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval': 1}",data/paper_jsons/Alexander I. Rudnicky_1783635.json,
What are the fields of study of Alexander Rudnicky?,"Computer Science, Engineering",data/paper_jsons/Alexander I. Rudnicky_1783635.json,
How many papers has Alexander Rudnicky published in open access journals?,5,data/paper_jsons/Alexander I. Rudnicky_1783635.json,
What venues has Alexander Rudnicky published in?,"arXiv.org, SIGDIAL Conferences, AAAI Conference on Artificial Intelligence, DSTC, Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",data/paper_jsons/Alexander I. Rudnicky_1783635.json,
What is the most cited paper from Alexander Rudnicky?,A Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech,data/paper_jsons/Alexander I. Rudnicky_1783635.json,
What is the url of the most cited paper from Alexander Rudnicky?,http://arxiv.org/pdf/2302.04215,data/paper_jsons/Alexander I. Rudnicky_1783635.json,
Who are the authors of the most cited paper from Alexander Rudnicky?,"Li-Wei Chen, Shinji Watanabe, Alexander I. Rudnicky",data/paper_jsons/Alexander I. Rudnicky_1783635.json,
TLDR of the most cited paper from Alexander Rudnicky?,"This work introduces the MQTTS system, a Text-to-Speech system whose architecture is designed for multiple code generation and monotonic alignment, along with the use of a clean silence prompt to improve synthesis quality, and shows that MqTTS outperforms existing TTS systems in several objective and subjective measures.",data/paper_jsons/Alexander I. Rudnicky_1783635.json,
Abstract of the most cited paper from Alexander Rudnicky?,"Recent Text-to-Speech (TTS) systems trained on reading or acted corpora have achieved near human-level naturalness. The diversity of human speech, however, often goes beyond the coverage of these corpora. We believe the ability to handle such diversity is crucial for AI systems to achieve human-level communication. Our work explores the use of more abundant real-world data for building speech synthesizers. We train TTS systems using real-world speech from YouTube and podcasts. We observe the mismatch between training and inference alignments in mel-spectrogram based autoregressive models, leading to unintelligible synthesis, and demonstrate that learned discrete codes within multiple code groups effectively resolves this issue. We introduce our MQTTS system whose architecture is designed for multiple code generation and monotonic alignment, along with the use of a clean silence prompt to improve synthesis quality. We conduct ablation analyses to identify the efficacy of our methods. We show that MQTTS outperforms existing TTS systems in several objective and subjective measures.",data/paper_jsons/Alexander I. Rudnicky_1783635.json,
"What journal was the paper ""Advancing Regular Language Reasoning in Linear Recurrent Neural Networks"" published in?",ArXiv,Alexander I. Rudnicky_1783635.json,
"What venue was the paper ""Advancing Regular Language Reasoning in Linear Recurrent Neural Networks"" published in?",arXiv.org,Alexander I. Rudnicky_1783635.json,
"How many citations does the paper ""Advancing Regular Language Reasoning in Linear Recurrent Neural Networks"" have?",0,Alexander I. Rudnicky_1783635.json,
"Who are the authors of the paper ""Advancing Regular Language Reasoning in Linear Recurrent Neural Networks""?","Ting-Han Fan, Ta-Chung Chi, Alexander I. Rudnicky",Alexander I. Rudnicky_1783635.json,
"Who is the first author of the paper ""Advancing Regular Language Reasoning in Linear Recurrent Neural Networks""?",Ting-Han Fan,Alexander I. Rudnicky_1783635.json,
"What is the paper ID of the paper ""Advancing Regular Language Reasoning in Linear Recurrent Neural Networks""?",06a8f2e3c4266196b008851f1ec7ef9f340809da,Alexander I. Rudnicky_1783635.json,
What paper has the paper ID 06a8f2e3c4266196b008851f1ec7ef9f340809da?,Advancing Regular Language Reasoning in Linear Recurrent Neural Networks,Alexander I. Rudnicky_1783635.json,
What is the TLDR of the paper 'Advancing Regular Language Reasoning in Linear Recurrent Neural Networks'?,"This work theoretically analyze some existing LRNNs and proposes a new LRNN equipped with a block-diagonal and input-dependent transition matrix that is the only LRNN that can perform length extrapolation on regular language tasks such as Sum, Even Pair, and Modular Arithmetic.",Alexander I. Rudnicky_1783635.json,
What is the abstract of the paper 'Advancing Regular Language Reasoning in Linear Recurrent Neural Networks'?,"In recent studies, linear recurrent neural networks (LRNNs) have achieved Transformer-level performance in natural language modeling and long-range modeling while offering rapid parallel training and constant inference costs. With the resurged interest in LRNNs, we study whether they can learn the hidden rules in training sequences, such as the grammatical structures of regular language. We theoretically analyze some existing LRNNs and discover their limitations on regular language. Motivated by the analysis, we propose a new LRNN equipped with a block-diagonal and input-dependent transition matrix. Experiments suggest that the proposed model is the only LRNN that can perform length extrapolation on regular language tasks such as Sum, Even Pair, and Modular Arithmetic.",Alexander I. Rudnicky_1783635.json,
"What journal was the paper ""A Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech"" published in?",ArXiv,Alexander I. Rudnicky_1783635.json,
"What venue was the paper ""A Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech"" published in?",AAAI Conference on Artificial Intelligence,Alexander I. Rudnicky_1783635.json,
"How many citations does the paper ""A Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech"" have?",16,Alexander I. Rudnicky_1783635.json,
"Who are the authors of the paper ""A Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech""?","Li-Wei Chen, Shinji Watanabe, Alexander I. Rudnicky",Alexander I. Rudnicky_1783635.json,
"Who is the first author of the paper ""A Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech""?",Li-Wei Chen,Alexander I. Rudnicky_1783635.json,
"What is the paper ID of the paper ""A Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech""?",4b8d3ede673ddeab9dfb5184da6b748d7a526754,Alexander I. Rudnicky_1783635.json,
What paper has the paper ID 4b8d3ede673ddeab9dfb5184da6b748d7a526754?,A Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech,Alexander I. Rudnicky_1783635.json,
What is the TLDR of the paper 'A Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech'?,"This work introduces the MQTTS system, a Text-to-Speech system whose architecture is designed for multiple code generation and monotonic alignment, along with the use of a clean silence prompt to improve synthesis quality, and shows that MqTTS outperforms existing TTS systems in several objective and subjective measures.",Alexander I. Rudnicky_1783635.json,
What is the abstract of the paper 'A Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech'?,"Recent Text-to-Speech (TTS) systems trained on reading or acted corpora have achieved near human-level naturalness. The diversity of human speech, however, often goes beyond the coverage of these corpora. We believe the ability to handle such diversity is crucial for AI systems to achieve human-level communication. Our work explores the use of more abundant real-world data for building speech synthesizers. We train TTS systems using real-world speech from YouTube and podcasts. We observe the mismatch between training and inference alignments in mel-spectrogram based autoregressive models, leading to unintelligible synthesis, and demonstrate that learned discrete codes within multiple code groups effectively resolves this issue. We introduce our MQTTS system whose architecture is designed for multiple code generation and monotonic alignment, along with the use of a clean silence prompt to improve synthesis quality. We conduct ablation analyses to identify the efficacy of our methods. We show that MQTTS outperforms existing TTS systems in several objective and subjective measures.",Alexander I. Rudnicky_1783635.json,
"What journal was the paper ""Overview of Robust and Multilingual Automatic Evaluation Metrics

for Open-Domain Dialogue Systems at DSTC 11 Track 4"" published in?",ArXiv,Alexander I. Rudnicky_1783635.json,
"What venue was the paper ""Overview of Robust and Multilingual Automatic Evaluation Metrics

for Open-Domain Dialogue Systems at DSTC 11 Track 4"" published in?",DSTC,Alexander I. Rudnicky_1783635.json,
"How many citations does the paper ""Overview of Robust and Multilingual Automatic Evaluation Metrics

for Open-Domain Dialogue Systems at DSTC 11 Track 4"" have?",3,Alexander I. Rudnicky_1783635.json,
"Who are the authors of the paper ""Overview of Robust and Multilingual Automatic Evaluation Metrics

for Open-Domain Dialogue Systems at DSTC 11 Track 4""?","Mario Rodr'iguez-Cantelar, Chen Zhang, Chengguang Tang, Ke Shi, Sarik Ghazarian, João Sedoc, L. F. D’Haro, Alexander I. Rudnicky",Alexander I. Rudnicky_1783635.json,
"Who is the first author of the paper ""Overview of Robust and Multilingual Automatic Evaluation Metrics

for Open-Domain Dialogue Systems at DSTC 11 Track 4""?",Mario Rodr'iguez-Cantelar,Alexander I. Rudnicky_1783635.json,
"What is the paper ID of the paper ""Overview of Robust and Multilingual Automatic Evaluation Metrics

for Open-Domain Dialogue Systems at DSTC 11 Track 4""?",9799c17fd287bb9e8d231fe032c6dbf9c0c9d675,Alexander I. Rudnicky_1783635.json,
What paper has the paper ID 9799c17fd287bb9e8d231fe032c6dbf9c0c9d675?,"Overview of Robust and Multilingual Automatic Evaluation Metrics

for Open-Domain Dialogue Systems at DSTC 11 Track 4",Alexander I. Rudnicky_1783635.json,
"What is the TLDR of the paper 'Overview of Robust and Multilingual Automatic Evaluation Metrics

for Open-Domain Dialogue Systems at DSTC 11 Track 4'?","The datasets and baselines provided to participants are described and the submission and result details of the two proposed subtasks are discussed, which promote robust and multilingual automatic evaluation metrics.",Alexander I. Rudnicky_1783635.json,
"What is the abstract of the paper 'Overview of Robust and Multilingual Automatic Evaluation Metrics

for Open-Domain Dialogue Systems at DSTC 11 Track 4'?","The advent and fast development of neural networks have revolutionized the research on dialogue systems and subsequently have triggered various challenges regarding their automatic evaluation. Automatic evaluation of open-domain dialogue systems as an open challenge has been the center of the attention of many researchers. Despite the consistent efforts to improve automatic metrics’ correlations with human evaluation, there have been very few attempts to assess their robustness over multiple domains and dimensions. Also, their focus is mainly on the English language. All of these challenges prompt the development of automatic evaluation metrics that are reliable in various domains, dimensions, and languages. This track in the 11th Dialogue System Technology Challenge (DSTC11) is part of the ongoing effort to promote robust and multilingual automatic evaluation metrics. This article describes the datasets and baselines provided to participants and discusses the submission and result details of the two proposed subtasks.",Alexander I. Rudnicky_1783635.json,
What is the author ID of Brian MacWhinney?,2414040,data/paper_jsons/B. MacWhinney_2414040.json,
What are the papers of Brian MacWhinney?,"Assessment and Therapy Goal Planning Using Free Computerized Language Analysis Software., Automation of Language Sample Analysis, The role of novelty stimuli in second language acquisition: evidence from the optimized training by the Pinyin Tutor at TalkBank, Using diagnostic feedback to enhance the development of phonetic knowledge of an L2: a CALL design based on the unified competition model and the implementation with the Pinyin Tutor, A New Benchmark of Aphasia Speech Recognition and Detection Based on E-Branchformer and Multi-task Learning, Collaborative Commentary for Understanding Communication Disorders., Establishing the DementiaBank Delaware Corpus: An Online Multimedia Database for the Study of Language and Cognition in Dementia, Evaluating Picture Description Speech for Dementia Detection using Image-text Alignment, Multilingual Alzheimer’s Dementia Recognition through Spontaneous Speech: A Signal Processing Grand Challenge, DementiaBank: Theoretical Rationale, Protocol, and Illustrative Analyses",data/paper_jsons/B. MacWhinney_2414040.json,
What is the H-index of Brian MacWhinney?,75,data/paper_jsons/B. MacWhinney_2414040.json,
What is the author citation count of Brian MacWhinney?,27192,data/paper_jsons/B. MacWhinney_2414040.json,
What journals has Brian MacWhinney published in?,"Perspectives of the ASHA special interest groups, Journal of Speech, Language, and Hearing Research : JSLHR, Smart Learning Environments, Language Testing in Asia, ArXiv, American journal of speech-language pathology, Alzheimer's & Dementia, ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), American Journal of Speech-Language Pathology",data/paper_jsons/B. MacWhinney_2414040.json,
What are the journals and how many papers has Brian MacWhinney published in each?,"{'ArXiv': 2, 'Perspectives of the ASHA special interest groups': 1, 'Journal of Speech, Language, and Hearing Research : JSLHR': 1, 'Smart Learning Environments': 1, 'Language Testing in Asia': 1, 'American journal of speech-language pathology': 1, ""Alzheimer's & Dementia"": 1, 'ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)': 1, 'American Journal of Speech-Language Pathology': 1}",data/paper_jsons/B. MacWhinney_2414040.json,
What are the fields of study of Brian MacWhinney?,"Medicine, Computer Science, Engineering",data/paper_jsons/B. MacWhinney_2414040.json,
How many papers has Brian MacWhinney published in open access journals?,10,data/paper_jsons/B. MacWhinney_2414040.json,
What venues has Brian MacWhinney published in?,"Perspectives of the ASHA Special Interest Groups, Journal of Speech, Language and Hearing Research, Smart Learning Environments, Language Testing in Asia, Interspeech, American Journal of Speech-Language Pathology, Alzheimer's &amp; Dementia, arXiv.org, IEEE International Conference on Acoustics, Speech, and Signal Processing",data/paper_jsons/B. MacWhinney_2414040.json,
What is the most cited paper from Brian MacWhinney?,Multilingual Alzheimer’s Dementia Recognition through Spontaneous Speech: A Signal Processing Grand Challenge,data/paper_jsons/B. MacWhinney_2414040.json,
What is the url of the most cited paper from Brian MacWhinney?,https://arxiv.org/pdf/2301.05562,data/paper_jsons/B. MacWhinney_2414040.json,
Who are the authors of the most cited paper from Brian MacWhinney?,"S. Luz, F. Haider, Davida Fromm, Ioulietta Lazarou, Y. Kompatsiaris, B. MacWhinney",data/paper_jsons/B. MacWhinney_2414040.json,
TLDR of the most cited paper from Brian MacWhinney?,"This Signal Processing Grand Challenge (SPGC) targets a difficult automatic prediction problem of societal and medical relevance, namely, the detection of Alzheimer’s Dementia, and aims to assess the extent to which predictive models built based on speech in one language generalise to another language.",data/paper_jsons/B. MacWhinney_2414040.json,
Abstract of the most cited paper from Brian MacWhinney?,"This Signal Processing Grand Challenge (SPGC) targets a difficult automatic prediction problem of societal and medical relevance, namely, the detection of Alzheimer’s Dementia (AD). Participants were invited to employ signal processing and machine learning methods to create predictive models based on spontaneous speech data. The Challenge has been designed to assess the extent to which predictive models built based on speech in one language (English) generalise to another language (Greek). To the best of our knowledge no work has investigated acoustic features of the speech signal in multilingual AD detection. Our baseline system used conventional machine learning algorithms with Active Data Representation of acoustic features, achieving accuracy of 73.91% on AD detection, and 4.95 root mean squared error on cognitive score prediction.",data/paper_jsons/B. MacWhinney_2414040.json,
"What journal was the paper ""Collaborative Commentary for Understanding Communication Disorders."" published in?",American journal of speech-language pathology,B. MacWhinney_2414040.json,
"What venue was the paper ""Collaborative Commentary for Understanding Communication Disorders."" published in?",American Journal of Speech-Language Pathology,B. MacWhinney_2414040.json,
"How many citations does the paper ""Collaborative Commentary for Understanding Communication Disorders."" have?",0,B. MacWhinney_2414040.json,
"Who are the authors of the paper ""Collaborative Commentary for Understanding Communication Disorders.""?","B. MacWhinney, Davida Fromm",B. MacWhinney_2414040.json,
"Who is the first author of the paper ""Collaborative Commentary for Understanding Communication Disorders.""?",B. MacWhinney,B. MacWhinney_2414040.json,
"What is the paper ID of the paper ""Collaborative Commentary for Understanding Communication Disorders.""?",52b48ab5d7d87642395818bea1ff804ff6dd0bd3,B. MacWhinney_2414040.json,
What paper has the paper ID 52b48ab5d7d87642395818bea1ff804ff6dd0bd3?,Collaborative Commentary for Understanding Communication Disorders.,B. MacWhinney_2414040.json,
What is the TLDR of the paper 'Collaborative Commentary for Understanding Communication Disorders.'?,"CC can contribute to a better understanding of connected speech features in aphasia, dementia, right hemisphere disorder, and traumatic brain injury and is being used currently in five research projects and eight classes.",B. MacWhinney_2414040.json,
What is the abstract of the paper 'Collaborative Commentary for Understanding Communication Disorders.'?,"PURPOSE
The goal of the Collaborative Commentary (CC) system is to make the TalkBank adult clinical databases-including AphasiaBank, DementiaBank, RHDBank, and TBIBank-open to commentary and analysis from the full community of researchers, instructors, students, and clinicians.


METHOD
CC allows a group leader to establish a commentary group and invite colleagues or students to join as members of the group. Members can then browse through the transcript database using the TalkBank Browser. When they wish to insert a comment, they click on the utterance line number or drag the cursor across a range of utterances and a window opens to receive the comment. The comment can include open text along with codes selected from a predefined set of codes created by that commentary group.


RESULTS
CC was released for public use in August 2022. It is being used currently in five research projects and eight classes. An important feature of CC is its ability to evaluate the reliability of coding systems and to sharpen analytic categories. By familiarizing instructors and researchers with the capabilities of CC, we expect to see an increasing usage of CC for a variety of clinical and research applications.


CONCLUSIONS
CC can contribute to a better understanding of connected speech features in aphasia, dementia, right hemisphere disorder, and traumatic brain injury. CC represents an extreme innovation not only for the study of adult neurogenic communication disorders but also for the study of spoken language generally.",B. MacWhinney_2414040.json,
"What journal was the paper ""Automation of Language Sample Analysis"" published in?","Journal of Speech, Language, and Hearing Research : JSLHR",B. MacWhinney_2414040.json,
"What venue was the paper ""Automation of Language Sample Analysis"" published in?","Journal of Speech, Language and Hearing Research",B. MacWhinney_2414040.json,
"How many citations does the paper ""Automation of Language Sample Analysis"" have?",0,B. MacWhinney_2414040.json,
"Who are the authors of the paper ""Automation of Language Sample Analysis""?","Houjun Liu, B. MacWhinney, Davida Fromm, Alyssa M. Lanzi",B. MacWhinney_2414040.json,
"Who is the first author of the paper ""Automation of Language Sample Analysis""?",Houjun Liu,B. MacWhinney_2414040.json,
"What is the paper ID of the paper ""Automation of Language Sample Analysis""?",0773228ecc4c1f2d729c0ae5764c77c1c9bb9573,B. MacWhinney_2414040.json,
What paper has the paper ID 0773228ecc4c1f2d729c0ae5764c77c1c9bb9573?,Automation of Language Sample Analysis,B. MacWhinney_2414040.json,
What is the TLDR of the paper 'Automation of Language Sample Analysis'?,"An automated pipeline that takes raw audio and creates full transcripts in Codes for the Human Analysis of Talk (CHAT) transcription format, complete with utterance- and word-level time alignments and morphosyntactic analysis, provides an output superior to that typically generated by human transcribers.",B. MacWhinney_2414040.json,
What is the abstract of the paper 'Automation of Language Sample Analysis'?,"Purpose: A major barrier to the wider use of language sample analysis (LSA) is the fact that transcription is very time intensive. Methods that can reduce the required time and effort could help in promoting the use of LSA for clinical practice and research. Method: This article describes an automated pipeline, called Batchalign, that takes raw audio and creates full transcripts in Codes for the Human Analysis of Talk (CHAT) transcription format, complete with utterance- and word-level time alignments and morphosyntactic analysis. The pipeline only requires major human intervention for final checking. It combines a series of existing tools with additional novel reformatting processes. The steps in the pipeline are (a) automatic speech recognition, (b) utterance tokenization, (c) automatic corrections, (d) speaker ID assignment, (e) forced alignment, (f) user adjustments, and (g) automatic morphosyntactic and profiling analyses. Results: For work with recordings from adults with language disorders, six major results were obtained: (a) The word error rate was between 2.4% for controls and 3.4% for patients, (b) utterance tokenization accuracy was at the level reported for speakers without language disorders, (c) word-level diarization accuracy was at 93% for control participants and 83% for participants with language disorders, (d) utterance-level diarization accuracy based on word-level diarization was high, (e) adherence to CHAT format was fully accurate, and (f) human transcriber time was reduced by up to 75%. Conclusion: The pipeline dramatically shortens the time gap between data collection and data analysis and provides an output superior to that typically generated by human transcribers.",B. MacWhinney_2414040.json,
"What journal was the paper ""A New Benchmark of Aphasia Speech Recognition and Detection Based on E-Branchformer and Multi-task Learning"" published in?",ArXiv,B. MacWhinney_2414040.json,
"What venue was the paper ""A New Benchmark of Aphasia Speech Recognition and Detection Based on E-Branchformer and Multi-task Learning"" published in?",Interspeech,B. MacWhinney_2414040.json,
"How many citations does the paper ""A New Benchmark of Aphasia Speech Recognition and Detection Based on E-Branchformer and Multi-task Learning"" have?",1,B. MacWhinney_2414040.json,
"Who are the authors of the paper ""A New Benchmark of Aphasia Speech Recognition and Detection Based on E-Branchformer and Multi-task Learning""?","Jiyang Tang, William Chen, Xuankai Chang, Shinji Watanabe, B. MacWhinney",B. MacWhinney_2414040.json,
"Who is the first author of the paper ""A New Benchmark of Aphasia Speech Recognition and Detection Based on E-Branchformer and Multi-task Learning""?",Jiyang Tang,B. MacWhinney_2414040.json,
"What is the paper ID of the paper ""A New Benchmark of Aphasia Speech Recognition and Detection Based on E-Branchformer and Multi-task Learning""?",4d35540aaf993c8fa7e1fa5fc6a990f1eb830263,B. MacWhinney_2414040.json,
What paper has the paper ID 4d35540aaf993c8fa7e1fa5fc6a990f1eb830263?,A New Benchmark of Aphasia Speech Recognition and Detection Based on E-Branchformer and Multi-task Learning,B. MacWhinney_2414040.json,
What is the TLDR of the paper 'A New Benchmark of Aphasia Speech Recognition and Detection Based on E-Branchformer and Multi-task Learning'?,A new benchmark for Aphasia speech recognition and detection tasks using state-of-the-art speech recognition techniques with the AphsiaBank dataset is presented and two multi-task learning methods based on the CTC/Attention architecture are introduced to perform both tasks simultaneously.,B. MacWhinney_2414040.json,
What is the abstract of the paper 'A New Benchmark of Aphasia Speech Recognition and Detection Based on E-Branchformer and Multi-task Learning'?,"Aphasia is a language disorder that affects the speaking ability of millions of patients. This paper presents a new benchmark for Aphasia speech recognition and detection tasks using state-of-the-art speech recognition techniques with the AphsiaBank dataset. Specifically, we introduce two multi-task learning methods based on the CTC/Attention architecture to perform both tasks simultaneously. Our system achieves state-of-the-art speaker-level detection accuracy (97.3%), and a relative WER reduction of 11% for moderate Aphasia patients. In addition, we demonstrate the generalizability of our approach by applying it to another disordered speech database, the DementiaBank Pitt corpus. We will make our all-in-one recipes and pre-trained model publicly available to facilitate reproducibility. Our standardized data preprocessing pipeline and open-source recipes enable researchers to compare results directly, promoting progress in disordered speech processing.",B. MacWhinney_2414040.json,
What is the author ID of Bhiksha Raj?,1681921,data/paper_jsons/B. Raj_1681921.json,
What are the papers of Bhiksha Raj?,"FREDOM: Fairness Domain Adaptation Approach to Semantic Scene Understanding, UTOPIA: Unconstrained Tracking Objects without Preliminary Examination via Cross-Domain Adaptation, SoftMatch: Addressing the Quantity-Quality Trade-off in Semi-supervised Learning, Fixed Inter-Neuron Covariability Induces Adversarial Robustness, Understanding political polarization using language models: A dataset and method, Prolonged school closure during the pandemic time in successive waves of COVID-19- vulnerability of children to sexual abuses – A case study in Tamil Nadu, India, BASS: Block-wise Adaptation for Speech Summarization, Understanding Political Polarisation using Language Models: A dataset and method, An Approach to Ontological Learning from Weak Labels, Rethinking Voice-Face Correlation: A Geometry View, Paaploss: A Phonetic-Aligned Acoustic Parameter Loss for Speech Enhancement, Improving Perceptual Quality, Intelligibility, and Acoustics on VoIP Platforms, Approach to Learning Generalized Audio Representation Through Batch Embedding Covariance Regularization and Constant-Q Transforms, Training on Foveated Images Improves Robustness to Adversarial Attacks, Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations, The Hidden Dance of Phonemes and Visage: Unveiling the Enigmatic Link between Phonemes and Facial Features, Fairness Continual Learning Approach to Semantic Scene Understanding in Open-World Environments, PaintSeg: Training-free Segmentation via Painting, TAPLoss: A Temporal Acoustic Parameter Loss for Speech Enhancement, Synergy between human and machine approaches to sound/scene recognition and processing: An overview of ICASSP special session",data/paper_jsons/B. Raj_1681921.json,
What is the H-index of Bhiksha Raj?,54,data/paper_jsons/B. Raj_1681921.json,
What is the author citation count of Bhiksha Raj?,14485,data/paper_jsons/B. Raj_1681921.json,
What journals has Bhiksha Raj published in?,"2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), ArXiv, AI Mag., Heliyon, ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Proceedings of the 31st ACM International Conference on Multimedia",data/paper_jsons/B. Raj_1681921.json,
What are the journals and how many papers has Bhiksha Raj published in each?,"{'ArXiv': 13, 'ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)': 3, '2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)': 1, 'AI Mag.': 1, 'Heliyon': 1, 'Proceedings of the 31st ACM International Conference on Multimedia': 1}",data/paper_jsons/B. Raj_1681921.json,
What are the fields of study of Bhiksha Raj?,"Computer Science, Medicine, Engineering",data/paper_jsons/B. Raj_1681921.json,
How many papers has Bhiksha Raj published in open access journals?,20,data/paper_jsons/B. Raj_1681921.json,
What venues has Bhiksha Raj published in?,"Computer Vision and Pattern Recognition, arXiv.org, International Conference on Learning Representations, The AI Magazine, Heliyon, Interspeech, IEEE International Conference on Acoustics, Speech, and Signal Processing, ACM Multimedia",data/paper_jsons/B. Raj_1681921.json,
What is the most cited paper from Bhiksha Raj?,SoftMatch: Addressing the Quantity-Quality Trade-off in Semi-supervised Learning,data/paper_jsons/B. Raj_1681921.json,
What is the url of the most cited paper from Bhiksha Raj?,http://arxiv.org/pdf/2301.10921,data/paper_jsons/B. Raj_1681921.json,
Who are the authors of the most cited paper from Bhiksha Raj?,"Hao Chen, R. Tao, Yue Fan, Yidong Wang, Jindong Wang, B. Schiele, Xingxu Xie, B. Raj, M. Savvides",data/paper_jsons/B. Raj_1681921.json,
TLDR of the most cited paper from Bhiksha Raj?,"This paper revisits the popular pseudo-labeling methods via a unified sample weighting formulation and demonstrates the inherent quantity-quality trade-off problem of pseudo-labels with thresholding, which may prohibit learning.",data/paper_jsons/B. Raj_1681921.json,
Abstract of the most cited paper from Bhiksha Raj?,"The critical challenge of Semi-Supervised Learning (SSL) is how to effectively leverage the limited labeled data and massive unlabeled data to improve the model's generalization performance. In this paper, we first revisit the popular pseudo-labeling methods via a unified sample weighting formulation and demonstrate the inherent quantity-quality trade-off problem of pseudo-labeling with thresholding, which may prohibit learning. To this end, we propose SoftMatch to overcome the trade-off by maintaining both high quantity and high quality of pseudo-labels during training, effectively exploiting the unlabeled data. We derive a truncated Gaussian function to weight samples based on their confidence, which can be viewed as a soft version of the confidence threshold. We further enhance the utilization of weakly-learned classes by proposing a uniform alignment approach. In experiments, SoftMatch shows substantial improvements across a wide variety of benchmarks, including image, text, and imbalanced classification.",data/paper_jsons/B. Raj_1681921.json,
"What journal was the paper ""Synergy between human and machine approaches to sound/scene recognition and processing: An overview of ICASSP special session"" published in?",ArXiv,B. Raj_1681921.json,
"What venue was the paper ""Synergy between human and machine approaches to sound/scene recognition and processing: An overview of ICASSP special session"" published in?",arXiv.org,B. Raj_1681921.json,
"How many citations does the paper ""Synergy between human and machine approaches to sound/scene recognition and processing: An overview of ICASSP special session"" have?",8,B. Raj_1681921.json,
"Who are the authors of the paper ""Synergy between human and machine approaches to sound/scene recognition and processing: An overview of ICASSP special session""?","L. Heller, Benjamin Elizalde, B. Raj, Soham Deshmukh",B. Raj_1681921.json,
"Who is the first author of the paper ""Synergy between human and machine approaches to sound/scene recognition and processing: An overview of ICASSP special session""?",L. Heller,B. Raj_1681921.json,
"What is the paper ID of the paper ""Synergy between human and machine approaches to sound/scene recognition and processing: An overview of ICASSP special session""?",feecd2cfb7871a818ba514e8b4b3f9da482f17bc,B. Raj_1681921.json,
What paper has the paper ID feecd2cfb7871a818ba514e8b4b3f9da482f17bc?,Synergy between human and machine approaches to sound/scene recognition and processing: An overview of ICASSP special session,B. Raj_1681921.json,
What is the TLDR of the paper 'Synergy between human and machine approaches to sound/scene recognition and processing: An overview of ICASSP special session'?,"Advances in the development of hybrid approaches to Machine Listening models that are informed by models of peripheral (human) auditory processes, to those that employ or derive semantic information encoded in relations between sounds are summarized.",B. Raj_1681921.json,
What is the abstract of the paper 'Synergy between human and machine approaches to sound/scene recognition and processing: An overview of ICASSP special session'?,"Machine Listening, as usually formalized, attempts to perform a task that is, from our perspective, fundamentally human-performable, and performed by humans. Current automated models of Machine Listening vary from purely data-driven approaches to approaches imitating human systems. In recent years, the most promising approaches have been hybrid in that they have used data-driven approaches informed by models of the perceptual, cognitive, and semantic processes of the human system. Not only does the guidance provided by models of human perception and domain knowledge enable better, and more generalizable Machine Listening, in the converse, the lessons learned from these models may be used to verify or improve our models of human perception themselves. This paper summarizes advances in the development of such hybrid approaches, ranging from Machine Listening models that are informed by models of peripheral (human) auditory processes, to those that employ or derive semantic information encoded in relations between sounds. The research described herein was presented in a special session on""Synergy between human and machine approaches to sound/scene recognition and processing""at the 2023 ICASSP meeting.",B. Raj_1681921.json,
"What journal was the paper ""BASS: Block-wise Adaptation for Speech Summarization"" published in?",ArXiv,B. Raj_1681921.json,
"What venue was the paper ""BASS: Block-wise Adaptation for Speech Summarization"" published in?",Interspeech,B. Raj_1681921.json,
"How many citations does the paper ""BASS: Block-wise Adaptation for Speech Summarization"" have?",1,B. Raj_1681921.json,
"Who are the authors of the paper ""BASS: Block-wise Adaptation for Speech Summarization""?","Roshan Sharma, Kenneth Zheng, Siddhant Arora, Shinji Watanabe, Rita Singh, B. Raj",B. Raj_1681921.json,
"Who is the first author of the paper ""BASS: Block-wise Adaptation for Speech Summarization""?",Roshan Sharma,B. Raj_1681921.json,
"What is the paper ID of the paper ""BASS: Block-wise Adaptation for Speech Summarization""?",3bd320ddb25886417ae90011b00f13f5d558097b,B. Raj_1681921.json,
What paper has the paper ID 3bd320ddb25886417ae90011b00f13f5d558097b?,BASS: Block-wise Adaptation for Speech Summarization,B. Raj_1681921.json,
What is the TLDR of the paper 'BASS: Block-wise Adaptation for Speech Summarization'?,This paper develops a method that allows one to train summarization models on very long sequences in an incremental manner and devise and test strategies to pass semantic context across the blocks.,B. Raj_1681921.json,
What is the abstract of the paper 'BASS: Block-wise Adaptation for Speech Summarization'?,"End-to-end speech summarization has been shown to improve performance over cascade baselines. However, such models are difficult to train on very large inputs (dozens of minutes or hours) owing to compute restrictions and are hence trained with truncated model inputs. Truncation leads to poorer models, and a solution to this problem rests in block-wise modeling, i.e., processing a portion of the input frames at a time. In this paper, we develop a method that allows one to train summarization models on very long sequences in an incremental manner. Speech summarization is realized as a streaming process, where hypothesis summaries are updated every block based on new acoustic information. We devise and test strategies to pass semantic context across the blocks. Experiments on the How2 dataset demonstrate that the proposed block-wise training method improves by 3 points absolute on ROUGE-L over a truncated input baseline.",B. Raj_1681921.json,
"What journal was the paper ""FREDOM: Fairness Domain Adaptation Approach to Semantic Scene Understanding"" published in?",2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),B. Raj_1681921.json,
"What venue was the paper ""FREDOM: Fairness Domain Adaptation Approach to Semantic Scene Understanding"" published in?",Computer Vision and Pattern Recognition,B. Raj_1681921.json,
"How many citations does the paper ""FREDOM: Fairness Domain Adaptation Approach to Semantic Scene Understanding"" have?",8,B. Raj_1681921.json,
"Who are the authors of the paper ""FREDOM: Fairness Domain Adaptation Approach to Semantic Scene Understanding""?","Thanh-Dat Truong, Ngan T. H. Le, B. Raj, J. Cothren, Khoa Luu",B. Raj_1681921.json,
"Who is the first author of the paper ""FREDOM: Fairness Domain Adaptation Approach to Semantic Scene Understanding""?",Thanh-Dat Truong,B. Raj_1681921.json,
"What is the paper ID of the paper ""FREDOM: Fairness Domain Adaptation Approach to Semantic Scene Understanding""?",078f86c6a691806cc71bbef1e734f75690db0ffc,B. Raj_1681921.json,
What paper has the paper ID 078f86c6a691806cc71bbef1e734f75690db0ffc?,FREDOM: Fairness Domain Adaptation Approach to Semantic Scene Understanding,B. Raj_1681921.json,
What is the TLDR of the paper 'FREDOM: Fairness Domain Adaptation Approach to Semantic Scene Understanding'?,"This paper proposes a novel Fairness Domain Adaptation (FREDOM) approach to semantic scene segmentation, where a new adaptation framework will be introduced based on the fair treatment of class distributions to generally model the context of structural dependency.",B. Raj_1681921.json,
What is the abstract of the paper 'FREDOM: Fairness Domain Adaptation Approach to Semantic Scene Understanding'?,"Although Domain Adaptation in Semantic Scene Segmentation has shown impressive improvement in recent years, the fairness concerns in the domain adaptation have yet to be well defined and addressed. In addition, fairness is one of the most critical aspects when deploying the segmentation models into human-related real-world applications, e.g., autonomous driving, as any unfair predictions could influence human safety. In this paper, we propose a novel Fairness Domain Adaptation (FREDOM) approach to semantic scene segmentation. In particular, from the proposed formulated fairness objective, a new adaptation framework will be introduced based on the fair treatment of class distributions. Moreover, to generally model the context of structural dependency, a new conditional structural constraint is introduced to impose the consistency of predicted segmentation. Thanks to the proposed Conditional Structure Network, the self-attention mechanism has sufficiently modeled the structural information of segmentation. Through the ablation studies, the proposed method has shown the performance improvement of the segmentation models and promoted fairness in the model predictions. The experimental results on the two standard benchmarks, i.e., SYNTHIA $\rightarrow$ Cityscapes and GTA5 $\rightarrow$ Cityscapes, have shown that our method achieved State-of-the-Art (SOTA) performance11The implementation of FREDOM is available at https://github.com/uark-cviu/FREDOM",B. Raj_1681921.json,
What is the author ID of Carolyn Rose?,35959897,data/paper_jsons/C. Rosé_35959897.json,
What are the papers of Carolyn Rose?,"High school students’ data modeling practices and processes: from modeling unstructured data to evaluating automated decisions, Linguistic representations for fewer-shot relation extraction across domains, Using counterfactual contrast to improve compositional generalization for multi-step quantitative reasoning, Towards Extracting and Understanding the Implicit Rubrics of Transformer Based Automatic Essay Scoring Models, Exploring Artificial Intelligence in English Language Arts with StoryQ",data/paper_jsons/C. Rosé_35959897.json,
What is the H-index of Carolyn Rose?,54,data/paper_jsons/C. Rosé_35959897.json,
What is the author citation count of Carolyn Rose?,11882,data/paper_jsons/C. Rosé_35959897.json,
What journals has Carolyn Rose published in?,"Learning, Media and Technology, ArXiv",data/paper_jsons/C. Rosé_35959897.json,
What are the journals and how many papers has Carolyn Rose published in each?,"{'Learning, Media and Technology': 1, 'ArXiv': 1}",data/paper_jsons/C. Rosé_35959897.json,
What are the fields of study of Carolyn Rose?,Computer Science,data/paper_jsons/C. Rosé_35959897.json,
How many papers has Carolyn Rose published in open access journals?,5,data/paper_jsons/C. Rosé_35959897.json,
What venues has Carolyn Rose published in?,"Journal of Educational Media, Annual Meeting of the Association for Computational Linguistics, Workshop on Innovative Use of NLP for Building Educational Applications, AAAI Conference on Artificial Intelligence",data/paper_jsons/C. Rosé_35959897.json,
What is the most cited paper from Carolyn Rose?,High school students’ data modeling practices and processes: from modeling unstructured data to evaluating automated decisions,data/paper_jsons/C. Rosé_35959897.json,
What is the url of the most cited paper from Carolyn Rose?,https://www.tandfonline.com/doi/pdf/10.1080/17439884.2023.2189735?needAccess=true&role=button,data/paper_jsons/C. Rosé_35959897.json,
Who are the authors of the most cited paper from Carolyn Rose?,"Shiyan Jiang, Hengtao Tang, Can Tatar, C. Rosé, J. Chao",data/paper_jsons/C. Rosé_35959897.json,
TLDR of the most cited paper from Carolyn Rose?,It’s critical to foster artificial intelligence literacy for high school students to understand working mechanism of data-driven AI technologies and critically evaluate automated decisions from predictive models.,data/paper_jsons/C. Rosé_35959897.json,
Abstract of the most cited paper from Carolyn Rose?,"ABSTRACT It’s critical to foster artificial intelligence (AI) literacy for high school students, the first generation to grow up surrounded by AI, to understand working mechanism of data-driven AI technologies and critically evaluate automated decisions from predictive models. While efforts have been made to engage youth in understanding AI through developing machine learning models, few provided in-depth insights into the nuanced learning processes. In this study, we examined high school students’ data modeling practices and processes. Twenty-eight students developed machine learning models with text data for classifying negative and positive reviews of ice cream stores. We identified nine data modeling practices that describe students’ processes of model exploration, development, and testing and two themes about evaluating automated decisions from data technologies. The results provide implications for designing accessible data modeling experiences for students to understand data justice as well as the role and responsibility of data modelers in creating AI technologies.",data/paper_jsons/C. Rosé_35959897.json,
"What journal was the paper ""Exploring Artificial Intelligence in English Language Arts with StoryQ"" published in?",,C. Rosé_35959897.json,
"What venue was the paper ""Exploring Artificial Intelligence in English Language Arts with StoryQ"" published in?",AAAI Conference on Artificial Intelligence,C. Rosé_35959897.json,
"How many citations does the paper ""Exploring Artificial Intelligence in English Language Arts with StoryQ"" have?",0,C. Rosé_35959897.json,
"Who are the authors of the paper ""Exploring Artificial Intelligence in English Language Arts with StoryQ""?","J. Chao, Rebecca Ellis, Shiyan Jiang, C. Rosé, W. Finzer, Can Tatar, James Fiacco, Kenia Wiedemann",C. Rosé_35959897.json,
"Who is the first author of the paper ""Exploring Artificial Intelligence in English Language Arts with StoryQ""?",J. Chao,C. Rosé_35959897.json,
"What is the paper ID of the paper ""Exploring Artificial Intelligence in English Language Arts with StoryQ""?",27ca2d927421035e10b48c96a96db32224f1f8e6,C. Rosé_35959897.json,
What paper has the paper ID 27ca2d927421035e10b48c96a96db32224f1f8e6?,Exploring Artificial Intelligence in English Language Arts with StoryQ,C. Rosé_35959897.json,
What is the TLDR of the paper 'Exploring Artificial Intelligence in English Language Arts with StoryQ'?,,C. Rosé_35959897.json,
What is the abstract of the paper 'Exploring Artificial Intelligence in English Language Arts with StoryQ'?,"Exploring Artificial Intelligence (AI) in English Language Arts (ELA) with StoryQ is a 10-hour curriculum module designed for high school ELA classes. The module introduces students to fundamental AI concepts and essential machine learning workflow using StoryQ, a web-based GUI environment for Grades 6-12 learners. In this module, students work with unstructured text data and learn to train, test, and improve text classification models such as intent recognition, clickbait filter, and sentiment analysis. As they interact with machine-learning language models deeply, students also gain a nuanced understanding of language and how to wield it, not just as a data structure, but as a tool in our human-human encounters as well. The current version contains eight lessons, all delivered through a full-featured online learning and teaching platform. Computers and Internet access are required to implement the module. The module was piloted in an ELA class in the Spring of 2022, and the student learning outcomes were positive. The module is currently undergoing revision and will be further tested and improved in Fall 2022.",C. Rosé_35959897.json,
"What journal was the paper ""Using counterfactual contrast to improve compositional generalization for multi-step quantitative reasoning"" published in?",,C. Rosé_35959897.json,
"What venue was the paper ""Using counterfactual contrast to improve compositional generalization for multi-step quantitative reasoning"" published in?",Annual Meeting of the Association for Computational Linguistics,C. Rosé_35959897.json,
"How many citations does the paper ""Using counterfactual contrast to improve compositional generalization for multi-step quantitative reasoning"" have?",0,C. Rosé_35959897.json,
"Who are the authors of the paper ""Using counterfactual contrast to improve compositional generalization for multi-step quantitative reasoning""?","Armineh Nourbakhsh, Sameena Shah, C. Rosé",C. Rosé_35959897.json,
"Who is the first author of the paper ""Using counterfactual contrast to improve compositional generalization for multi-step quantitative reasoning""?",Armineh Nourbakhsh,C. Rosé_35959897.json,
"What is the paper ID of the paper ""Using counterfactual contrast to improve compositional generalization for multi-step quantitative reasoning""?",117e1323677cb5d78ece0fd07b5cfa81618f4866,C. Rosé_35959897.json,
What paper has the paper ID 117e1323677cb5d78ece0fd07b5cfa81618f4866?,Using counterfactual contrast to improve compositional generalization for multi-step quantitative reasoning,C. Rosé_35959897.json,
What is the TLDR of the paper 'Using counterfactual contrast to improve compositional generalization for multi-step quantitative reasoning'?,"This paper proposes CounterComp, a method that uses counterfactual scenarios to generate samples with compositional contrast based on metric learning, which allows for direct sampling from the training set and circumvents the need for additional human labels.",C. Rosé_35959897.json,
What is the abstract of the paper 'Using counterfactual contrast to improve compositional generalization for multi-step quantitative reasoning'?,"In quantitative question answering, compositional generalization is one of the main challenges of state of the art models, especially when longer sequences of reasoning steps are required. In this paper we propose CounterComp, a method that uses counterfactual scenarios to generate samples with compositional contrast. Instead of a data augmentation approach, CounterComp is based on metric learning, which allows for direct sampling from the training set and circumvents the need for additional human labels. Our proposed auxiliary metric learning loss improves the performance of three state of the art models on four recently released datasets. We also show how the approach can improve OOD performance on unseen domains, as well as unseen compositions. Lastly, we demonstrate how the method can lead to better compositional attention patterns during training.",C. Rosé_35959897.json,
"What journal was the paper ""Linguistic representations for fewer-shot relation extraction across domains"" published in?",ArXiv,C. Rosé_35959897.json,
"What venue was the paper ""Linguistic representations for fewer-shot relation extraction across domains"" published in?",Annual Meeting of the Association for Computational Linguistics,C. Rosé_35959897.json,
"How many citations does the paper ""Linguistic representations for fewer-shot relation extraction across domains"" have?",1,C. Rosé_35959897.json,
"Who are the authors of the paper ""Linguistic representations for fewer-shot relation extraction across domains""?","Sireesh Gururaja, Ritam Dutt, Ting-gen Liao, C. Rosé",C. Rosé_35959897.json,
"Who is the first author of the paper ""Linguistic representations for fewer-shot relation extraction across domains""?",Sireesh Gururaja,C. Rosé_35959897.json,
"What is the paper ID of the paper ""Linguistic representations for fewer-shot relation extraction across domains""?",0c0d8ea1c1745e7b56bc3b1513a715ae3df30c44,C. Rosé_35959897.json,
What paper has the paper ID 0c0d8ea1c1745e7b56bc3b1513a715ae3df30c44?,Linguistic representations for fewer-shot relation extraction across domains,C. Rosé_35959897.json,
What is the TLDR of the paper 'Linguistic representations for fewer-shot relation extraction across domains'?,"This work explores the impact of linguistic representations on cross-domain performance in a few-shot transfer setting, and investigates whether earlier findings, e.g. that semantic representations can be more helpful than syntactic ones, extend to relation extraction in multiple domains.",C. Rosé_35959897.json,
What is the abstract of the paper 'Linguistic representations for fewer-shot relation extraction across domains'?,"Recent work has demonstrated the positive impact of incorporating linguistic representations as additional context and scaffolds on the in-domain performance of several NLP tasks. We extend this work by exploring the impact of linguistic representations on cross-domain performance in a few-shot transfer setting. An important question is whether linguistic representations enhance generalizability by providing features that function as cross-domain pivots. We focus on the task of relation extraction on three datasets of procedural text in two domains, cooking and materials science. Our approach augments a popular transformer-based architecture by alternately incorporating syntactic and semantic graphs constructed by freely available off-the-shelf tools. We examine their utility for enhancing generalization, and investigate whether earlier findings, e.g. that semantic representations can be more helpful than syntactic ones, extend to relation extraction in multiple domains. We find that while the inclusion of these graphs results in significantly higher performance in few-shot transfer, both types of graph exhibit roughly equivalent utility.",C. Rosé_35959897.json,
What is the author ID of Chenyan Xiong?,144628574,data/paper_jsons/Chenyan Xiong_144628574.json,
What are the papers of Chenyan Xiong?,"Text Matching Improves Sequential Recommendation by Reducing Popularity Biases, Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval, OpenMatch-v2: An All-in-one Multi-Modality PLM-based Information Retrieval Toolkit",data/paper_jsons/Chenyan Xiong_144628574.json,
What is the H-index of Chenyan Xiong?,35,data/paper_jsons/Chenyan Xiong_144628574.json,
What is the author citation count of Chenyan Xiong?,5048,data/paper_jsons/Chenyan Xiong_144628574.json,
What journals has Chenyan Xiong published in?,"Proceedings of the 32nd ACM International Conference on Information and Knowledge Management, ArXiv, Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval",data/paper_jsons/Chenyan Xiong_144628574.json,
What are the journals and how many papers has Chenyan Xiong published in each?,"{'Proceedings of the 32nd ACM International Conference on Information and Knowledge Management': 1, 'ArXiv': 1, 'Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval': 1}",data/paper_jsons/Chenyan Xiong_144628574.json,
What are the fields of study of Chenyan Xiong?,Computer Science,data/paper_jsons/Chenyan Xiong_144628574.json,
How many papers has Chenyan Xiong published in open access journals?,3,data/paper_jsons/Chenyan Xiong_144628574.json,
What venues has Chenyan Xiong published in?,"International Conference on Information and Knowledge Management, arXiv.org, Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",data/paper_jsons/Chenyan Xiong_144628574.json,
What is the most cited paper from Chenyan Xiong?,OpenMatch-v2: An All-in-one Multi-Modality PLM-based Information Retrieval Toolkit,data/paper_jsons/Chenyan Xiong_144628574.json,
What is the url of the most cited paper from Chenyan Xiong?,https://dl.acm.org/doi/pdf/10.1145/3539618.3591813,data/paper_jsons/Chenyan Xiong_144628574.json,
Who are the authors of the most cited paper from Chenyan Xiong?,"Shi Yu, Zhenghao Liu, Chenyan Xiong, Zhiyuan Liu",data/paper_jsons/Chenyan Xiong_144628574.json,
TLDR of the most cited paper from Chenyan Xiong?,"As a full upgrade of OpenMatch proposed in 2021, OpenMatch-v2 incorporates the most recent advancements of PLM-based IR research, providing support for new, cross-modality models and enhanced domain adaptation techniques with a streamlined, optimized infrastructure.",data/paper_jsons/Chenyan Xiong_144628574.json,
Abstract of the most cited paper from Chenyan Xiong?,"Pre-trained language models (PLMs) have emerged as the foundation of the most advanced Information Retrieval (IR) models. Powered by PLMs, the latest IR research has proposed novel models, new domain adaptation algorithms as well as enlarged datasets. In this paper, we present a Python-based IR toolkit OpenMatch-v2. As a full upgrade of OpenMatch proposed in 2021, OpenMatch-v2 incorporates the most recent advancements of PLM-based IR research, providing support for new, cross-modality models and enhanced domain adaptation techniques with a streamlined, optimized infrastructure. The code of OpenMatch is publicly available at https://github.com/OpenMatch/OpenMatch.",data/paper_jsons/Chenyan Xiong_144628574.json,
"What journal was the paper ""OpenMatch-v2: An All-in-one Multi-Modality PLM-based Information Retrieval Toolkit"" published in?",Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval,Chenyan Xiong_144628574.json,
"What venue was the paper ""OpenMatch-v2: An All-in-one Multi-Modality PLM-based Information Retrieval Toolkit"" published in?",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,Chenyan Xiong_144628574.json,
"How many citations does the paper ""OpenMatch-v2: An All-in-one Multi-Modality PLM-based Information Retrieval Toolkit"" have?",6,Chenyan Xiong_144628574.json,
"Who are the authors of the paper ""OpenMatch-v2: An All-in-one Multi-Modality PLM-based Information Retrieval Toolkit""?","Shi Yu, Zhenghao Liu, Chenyan Xiong, Zhiyuan Liu",Chenyan Xiong_144628574.json,
"Who is the first author of the paper ""OpenMatch-v2: An All-in-one Multi-Modality PLM-based Information Retrieval Toolkit""?",Shi Yu,Chenyan Xiong_144628574.json,
"What is the paper ID of the paper ""OpenMatch-v2: An All-in-one Multi-Modality PLM-based Information Retrieval Toolkit""?",cdfd0926ad26c3c95a02db2ae891b7d4a457429c,Chenyan Xiong_144628574.json,
What paper has the paper ID cdfd0926ad26c3c95a02db2ae891b7d4a457429c?,OpenMatch-v2: An All-in-one Multi-Modality PLM-based Information Retrieval Toolkit,Chenyan Xiong_144628574.json,
What is the TLDR of the paper 'OpenMatch-v2: An All-in-one Multi-Modality PLM-based Information Retrieval Toolkit'?,"As a full upgrade of OpenMatch proposed in 2021, OpenMatch-v2 incorporates the most recent advancements of PLM-based IR research, providing support for new, cross-modality models and enhanced domain adaptation techniques with a streamlined, optimized infrastructure.",Chenyan Xiong_144628574.json,
What is the abstract of the paper 'OpenMatch-v2: An All-in-one Multi-Modality PLM-based Information Retrieval Toolkit'?,"Pre-trained language models (PLMs) have emerged as the foundation of the most advanced Information Retrieval (IR) models. Powered by PLMs, the latest IR research has proposed novel models, new domain adaptation algorithms as well as enlarged datasets. In this paper, we present a Python-based IR toolkit OpenMatch-v2. As a full upgrade of OpenMatch proposed in 2021, OpenMatch-v2 incorporates the most recent advancements of PLM-based IR research, providing support for new, cross-modality models and enhanced domain adaptation techniques with a streamlined, optimized infrastructure. The code of OpenMatch is publicly available at https://github.com/OpenMatch/OpenMatch.",Chenyan Xiong_144628574.json,
"What journal was the paper ""Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval"" published in?",ArXiv,Chenyan Xiong_144628574.json,
"What venue was the paper ""Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval"" published in?",arXiv.org,Chenyan Xiong_144628574.json,
"How many citations does the paper ""Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval"" have?",2,Chenyan Xiong_144628574.json,
"Who are the authors of the paper ""Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval""?","S. Yu, Cheng-Chung Fan, Chenyan Xiong, David Jin, Zhiyuan Liu, Zhenghao Liu Tsinghua University, Huazhong University of Science, Technology, Microsoft Research, M. I. O. Technology, N. University",Chenyan Xiong_144628574.json,
"Who is the first author of the paper ""Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval""?",S. Yu,Chenyan Xiong_144628574.json,
"What is the paper ID of the paper ""Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval""?",275da3802142fc42f6fab2ce2104223b2e0ef40d,Chenyan Xiong_144628574.json,
What paper has the paper ID 275da3802142fc42f6fab2ce2104223b2e0ef40d?,Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval,Chenyan Xiong_144628574.json,
What is the TLDR of the paper 'Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval'?,"A novel re-ranker named Fusion-in-T5 (FiT5), which integrates document text information, retrieval features, and global document information into a single unified model using templated-based input and global attention, is proposed.",Chenyan Xiong_144628574.json,
What is the abstract of the paper 'Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval'?,"Common IR pipelines are typically cascade systems that may involve multiple rankers and/or fusion models to integrate different information step-by-step. In this paper, we propose a novel re-ranker named Fusion-in-T5 (FiT5), which integrates document text information, retrieval features, and global document information into a single unified model using templated-based input and global attention. Experiments on passage ranking benchmarks MS MARCO and TREC DL show that FiT5 significantly improves ranking performance over prior pipelines. Analyses find that through global attention, FiT5 is able to jointly utilize the ranking features via gradually attending to related documents, and thus improve the detection of subtle nuances between them. Our code will be open-sourced.",Chenyan Xiong_144628574.json,
"What journal was the paper ""Text Matching Improves Sequential Recommendation by Reducing Popularity Biases"" published in?",Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,Chenyan Xiong_144628574.json,
"What venue was the paper ""Text Matching Improves Sequential Recommendation by Reducing Popularity Biases"" published in?",International Conference on Information and Knowledge Management,Chenyan Xiong_144628574.json,
"How many citations does the paper ""Text Matching Improves Sequential Recommendation by Reducing Popularity Biases"" have?",3,Chenyan Xiong_144628574.json,
"Who are the authors of the paper ""Text Matching Improves Sequential Recommendation by Reducing Popularity Biases""?","Zhenghao Liu, Senkun Mei, Chenyan Xiong, Xiaohua Li, Shi Yu, Zhiyuan Liu, Yu Gu, Ge Yu",Chenyan Xiong_144628574.json,
"Who is the first author of the paper ""Text Matching Improves Sequential Recommendation by Reducing Popularity Biases""?",Zhenghao Liu,Chenyan Xiong_144628574.json,
"What is the paper ID of the paper ""Text Matching Improves Sequential Recommendation by Reducing Popularity Biases""?",159100c8323fc558e4073a3a006f3f243aca3a60,Chenyan Xiong_144628574.json,
What paper has the paper ID 159100c8323fc558e4073a3a006f3f243aca3a60?,Text Matching Improves Sequential Recommendation by Reducing Popularity Biases,Chenyan Xiong_144628574.json,
What is the TLDR of the paper 'Text Matching Improves Sequential Recommendation by Reducing Popularity Biases'?,,Chenyan Xiong_144628574.json,
What is the abstract of the paper 'Text Matching Improves Sequential Recommendation by Reducing Popularity Biases'?,"This paper proposes Text mAtching based SequenTial rEcommenda-tion model (TASTE), which maps items and users in an embedding space and recommends items by matching their text representations. TASTE verbalizes items and user-item interactions using identifiers and attributes of items. To better characterize user behaviors, TASTE additionally proposes an attention sparsity method, which enables TASTE to model longer user-item interactions by reducing the self-attention computations during encoding. Our experiments show that TASTE outperforms the state-of-the-art methods on widely used sequential recommendation datasets. TASTE alleviates the cold start problem by representing long-tail items using full-text modeling and bringing the benefits of pretrained language models to recommendation systems. Our further analyses illustrate that TASTE significantly improves the recommendation accuracy by reducing the popularity bias of previous item id based recommendation models and returning more appropriate and text-relevant items to satisfy users. All codes are available at https://github.com/OpenMatch/TASTE.",Chenyan Xiong_144628574.json,
What is the author ID of Chenyan Xiong?,2139787803,data/paper_jsons/Chenyan Xiong_2139787803.json,
What are the papers of Chenyan Xiong?,"Improving Multitask Retrieval by Promoting Task Specialization, Unsupervised Dense Retrieval Training with Web Anchors, Augmentation-Adapted Retriever Improves Generalization of Language Models as Generic Plug-In, Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers, Structure-Aware Language Model Pretraining Improves Dense Retrieval on Structured Data, Toolink: Linking Toolkit Creation and Using through Chain-of-Solving on Open-Source Model, Augmenting Zero-Shot Dense Retrievers with Plug-in Mixture-of-Memories",data/paper_jsons/Chenyan Xiong_2139787803.json,
What is the H-index of Chenyan Xiong?,7,data/paper_jsons/Chenyan Xiong_2139787803.json,
What is the author citation count of Chenyan Xiong?,222,data/paper_jsons/Chenyan Xiong_2139787803.json,
What journals has Chenyan Xiong published in?,"Transactions of the Association for Computational Linguistics, Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval, ArXiv",data/paper_jsons/Chenyan Xiong_2139787803.json,
What are the journals and how many papers has Chenyan Xiong published in each?,"{'ArXiv': 3, 'Transactions of the Association for Computational Linguistics': 1, 'Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval': 1}",data/paper_jsons/Chenyan Xiong_2139787803.json,
What are the fields of study of Chenyan Xiong?,Computer Science,data/paper_jsons/Chenyan Xiong_2139787803.json,
How many papers has Chenyan Xiong published in open access journals?,7,data/paper_jsons/Chenyan Xiong_2139787803.json,
What venues has Chenyan Xiong published in?,"Transactions of the Association for Computational Linguistics, Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, Annual Meeting of the Association for Computational Linguistics, arXiv.org, Conference on Empirical Methods in Natural Language Processing",data/paper_jsons/Chenyan Xiong_2139787803.json,
What is the most cited paper from Chenyan Xiong?,Augmentation-Adapted Retriever Improves Generalization of Language Models as Generic Plug-In,data/paper_jsons/Chenyan Xiong_2139787803.json,
What is the url of the most cited paper from Chenyan Xiong?,http://arxiv.org/pdf/2305.17331,data/paper_jsons/Chenyan Xiong_2139787803.json,
Who are the authors of the most cited paper from Chenyan Xiong?,"Zichun Yu, Chenyan Xiong, S. Yu, Zhiyuan Liu",data/paper_jsons/Chenyan Xiong_2139787803.json,
TLDR of the most cited paper from Chenyan Xiong?,"This paper proposes augmentation-adapted retriever (AAR), which learns LM’s preferences obtained from a known source LM to assist target LMs that may not be known beforehand or are unable to be fine-tuned together in a generic retrieval plug-in.",data/paper_jsons/Chenyan Xiong_2139787803.json,
Abstract of the most cited paper from Chenyan Xiong?,"Retrieval augmentation can aid language models (LMs) in knowledge-intensive tasks by supplying them with external information. Prior works on retrieval augmentation usually jointly fine-tune the retriever and the LM, making them closely coupled. In this paper, we explore the scheme of generic retrieval plug-in: the retriever is to assist target LMs that may not be known beforehand or are unable to be fine-tuned together. To retrieve useful documents for unseen target LMs, we propose augmentation-adapted retriever (AAR), which learns LM’s preferences obtained from a known source LM. Experiments on the MMLU and PopQA datasets demonstrate that our AAR trained with a small source LM is able to significantly improve the zero-shot generalization of larger target LMs ranging from 250M Flan-T5 to 175B InstructGPT. Further analysis indicates that the preferences of different LMs overlap, enabling AAR trained with a single source LM to serve as a generic plug-in for various target LMs. Our code is open-sourced at https://github.com/OpenMatch/Augmentation-Adapted-Retriever.",data/paper_jsons/Chenyan Xiong_2139787803.json,
"What journal was the paper ""Improving Multitask Retrieval by Promoting Task Specialization"" published in?",Transactions of the Association for Computational Linguistics,Chenyan Xiong_2139787803.json,
"What venue was the paper ""Improving Multitask Retrieval by Promoting Task Specialization"" published in?",Transactions of the Association for Computational Linguistics,Chenyan Xiong_2139787803.json,
"How many citations does the paper ""Improving Multitask Retrieval by Promoting Task Specialization"" have?",0,Chenyan Xiong_2139787803.json,
"Who are the authors of the paper ""Improving Multitask Retrieval by Promoting Task Specialization""?","Wenzheng Zhang, Chenyan Xiong, K. Stratos, Arnold Overwijk",Chenyan Xiong_2139787803.json,
"Who is the first author of the paper ""Improving Multitask Retrieval by Promoting Task Specialization""?",Wenzheng Zhang,Chenyan Xiong_2139787803.json,
"What is the paper ID of the paper ""Improving Multitask Retrieval by Promoting Task Specialization""?",105759bdb5e3bddc1d3244df2eff2d5c997a1d84,Chenyan Xiong_2139787803.json,
What paper has the paper ID 105759bdb5e3bddc1d3244df2eff2d5c997a1d84?,Improving Multitask Retrieval by Promoting Task Specialization,Chenyan Xiong_2139787803.json,
What is the TLDR of the paper 'Improving Multitask Retrieval by Promoting Task Specialization'?,"It is shown that it is possible to train a multitask retriever that outperforms task-specific retrievers by promoting task specialization, and the model indeed learns parameters that are more task-specialized compared to naive multitasking without prompting or adaptive learning.",Chenyan Xiong_2139787803.json,
What is the abstract of the paper 'Improving Multitask Retrieval by Promoting Task Specialization'?,"Abstract In multitask retrieval, a single retriever is trained to retrieve relevant contexts for multiple tasks. Despite its practical appeal, naive multitask retrieval lags behind task-specific retrieval, in which a separate retriever is trained for each task. We show that it is possible to train a multitask retriever that outperforms task-specific retrievers by promoting task specialization. The main ingredients are: (1) a better choice of pretrained model—one that is explicitly optimized for multitasking—along with compatible prompting, and (2) a novel adaptive learning method that encourages each parameter to specialize in a particular task. The resulting multitask retriever is highly performant on the KILT benchmark. Upon analysis, we find that the model indeed learns parameters that are more task-specialized compared to naive multitasking without prompting or adaptive learning.1",Chenyan Xiong_2139787803.json,
"What journal was the paper ""Toolink: Linking Toolkit Creation and Using through Chain-of-Solving on Open-Source Model"" published in?",ArXiv,Chenyan Xiong_2139787803.json,
"What venue was the paper ""Toolink: Linking Toolkit Creation and Using through Chain-of-Solving on Open-Source Model"" published in?",arXiv.org,Chenyan Xiong_2139787803.json,
"How many citations does the paper ""Toolink: Linking Toolkit Creation and Using through Chain-of-Solving on Open-Source Model"" have?",3,Chenyan Xiong_2139787803.json,
"Who are the authors of the paper ""Toolink: Linking Toolkit Creation and Using through Chain-of-Solving on Open-Source Model""?","Cheng Qian, Chenyan Xiong, Zhenghao Liu, Zhiyuan Liu",Chenyan Xiong_2139787803.json,
"Who is the first author of the paper ""Toolink: Linking Toolkit Creation and Using through Chain-of-Solving on Open-Source Model""?",Cheng Qian,Chenyan Xiong_2139787803.json,
"What is the paper ID of the paper ""Toolink: Linking Toolkit Creation and Using through Chain-of-Solving on Open-Source Model""?",b9e8b62bcc019f47a0a015568f70039b3b7c1196,Chenyan Xiong_2139787803.json,
What paper has the paper ID b9e8b62bcc019f47a0a015568f70039b3b7c1196?,Toolink: Linking Toolkit Creation and Using through Chain-of-Solving on Open-Source Model,Chenyan Xiong_2139787803.json,
What is the TLDR of the paper 'Toolink: Linking Toolkit Creation and Using through Chain-of-Solving on Open-Source Model'?,"This paper introduces Toolink, a comprehensive framework that performs task-solving by first creating a toolkit and then integrating the planning and calling of tools through a chain-of-s solving (CoS) approach, and results in LLaMA-CoS, a powerful open-source model with advanced tool-planning and tool-calling capabilities.",Chenyan Xiong_2139787803.json,
What is the abstract of the paper 'Toolink: Linking Toolkit Creation and Using through Chain-of-Solving on Open-Source Model'?,"Large Language Models (LLMs) have demonstrated remarkable progress in utilizing tools, but their closed-source nature and high inference costs pose limitations on their adaptability, necessitating a valid method that leverages smaller, open-sourced models. In this paper, we introduce Toolink, a comprehensive framework that performs task-solving by first creating a toolkit and then integrating the planning and calling of tools through a chain-of-solving (CoS) approach. We first validate the efficacy of Toolink in harnessing the model's creativity and CoS ability on ChatGPT. Subsequently, we curate CoS-GPT, a chain-of-solving dataset designed for tool-using, and finetune the LLaMA-7B model. It results in LLaMA-CoS, a powerful open-source model with advanced tool-planning and tool-calling capabilities. Evaluation on diverse tasks from BIG-bench demonstrates its CoS ability matches that of ChatGPT while its performance surpasses the chain-of-thought approach. Further studies highlight the generalization of LLaMA-CoS to unseen tasks and showcase its capability in using toolkits not explicitly tailored for the target task, affirming its robustness in real-world scenarios. All codes and data are released.",Chenyan Xiong_2139787803.json,
"What journal was the paper ""Unsupervised Dense Retrieval Training with Web Anchors"" published in?",Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval,Chenyan Xiong_2139787803.json,
"What venue was the paper ""Unsupervised Dense Retrieval Training with Web Anchors"" published in?",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,Chenyan Xiong_2139787803.json,
"How many citations does the paper ""Unsupervised Dense Retrieval Training with Web Anchors"" have?",2,Chenyan Xiong_2139787803.json,
"Who are the authors of the paper ""Unsupervised Dense Retrieval Training with Web Anchors""?","Yiqing Xie, X. Liu, Chenyan Xiong",Chenyan Xiong_2139787803.json,
"Who is the first author of the paper ""Unsupervised Dense Retrieval Training with Web Anchors""?",Yiqing Xie,Chenyan Xiong_2139787803.json,
"What is the paper ID of the paper ""Unsupervised Dense Retrieval Training with Web Anchors""?",1fe3a802efdc4f1a3e5c8187547f38a3ec65750b,Chenyan Xiong_2139787803.json,
What paper has the paper ID 1fe3a802efdc4f1a3e5c8187547f38a3ec65750b?,Unsupervised Dense Retrieval Training with Web Anchors,Chenyan Xiong_2139787803.json,
What is the TLDR of the paper 'Unsupervised Dense Retrieval Training with Web Anchors'?,"This work trains an unsupervised dense retriever, Anchor-DR, with a contrastive learning task that matches the anchor text and the linked document, and presents a novel filtering technique to only select anchors that contain similar types of information as search queries.",Chenyan Xiong_2139787803.json,
What is the abstract of the paper 'Unsupervised Dense Retrieval Training with Web Anchors'?,"In this work, we present an unsupervised retrieval method with contrastive learning on web anchors. The anchor text describes the content that is referenced from the linked page. This shows similarities to search queries that aim to retrieve pertinent information from relevant documents. Based on their commonalities, we train an unsupervised dense retriever, Anchor-DR, with a contrastive learning task that matches the anchor text and the linked document. To filter out uninformative anchors (such as ""homepage"" or other functional anchors), we present a novel filtering technique to only select anchors that contain similar types of information as search queries. Experiments show that Anchor-DR outperforms state-of-the-art methods on unsupervised dense retrieval by a large margin (e.g., by 5.3% NDCG@10 on MSMARCO). The gain of our method is especially significant for search and question answering tasks. Our analysis further reveals that the pattern of anchor-document pairs is similar to that of search query-document pairs. Code available at https://github.com/Veronicium/AnchorDR.",Chenyan Xiong_2139787803.json,
What is the author ID of Daniel Fried?,47070750,data/paper_jsons/Daniel Fried_47070750.json,
What are the papers of Daniel Fried?,"Pragmatic Inference with a CLIP Listener for Contrastive Captioning, SantaCoder: don't reach for the stars!, Grounding Language Models to Images for Multimodal Generation, StarCoder: may the source be with you!, Generating Images with Multimodal Language Models, WebArena: A Realistic Web Environment for Building Autonomous Agents",data/paper_jsons/Daniel Fried_47070750.json,
What is the H-index of Daniel Fried?,26,data/paper_jsons/Daniel Fried_47070750.json,
What is the author citation count of Daniel Fried?,2668,data/paper_jsons/Daniel Fried_47070750.json,
What journals has Daniel Fried published in?,ArXiv,data/paper_jsons/Daniel Fried_47070750.json,
What are the journals and how many papers has Daniel Fried published in each?,{'ArXiv': 6},data/paper_jsons/Daniel Fried_47070750.json,
What are the fields of study of Daniel Fried?,Computer Science,data/paper_jsons/Daniel Fried_47070750.json,
How many papers has Daniel Fried published in open access journals?,6,data/paper_jsons/Daniel Fried_47070750.json,
What venues has Daniel Fried published in?,"Annual Meeting of the Association for Computational Linguistics, arXiv.org",data/paper_jsons/Daniel Fried_47070750.json,
What is the most cited paper from Daniel Fried?,StarCoder: may the source be with you!,data/paper_jsons/Daniel Fried_47070750.json,
What is the url of the most cited paper from Daniel Fried?,http://arxiv.org/pdf/2305.06161,data/paper_jsons/Daniel Fried_47070750.json,
Who are the authors of the most cited paper from Daniel Fried?,"Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, Qian Liu, Evgenii Zheltonozhskii, Terry Yue Zhuo, Thomas Wang, Olivier Dehaene, Mishig Davaadorj, J. Lamy-Poirier, João Monteiro, Oleh Shliazhko, Nicolas Gontier, Nicholas Meade, Armel Zebaze, Ming-Ho Yee, Logesh Kumar Umapathi, Jian Zhu, Benjamin Lipkin, Muhtasham Oblokulov, Zhiruo Wang, Rudra Murthy, J. Stillerman, S. Patel, Dmitry Abulkhanov, Marco Zocca, Manan Dey, Zhihan Zhang, N. Fahmy, Urvashi Bhattacharyya, W. Yu, Swayam Singh, Sasha Luccioni, Paulo Villegas, M. Kunakov, Fedor Zhdanov, Manuel Romero, Tony Lee, Nadav Timor, Jennifer Ding, Claire Schlesinger, Hailey Schoelkopf, Jana Ebert, Tri Dao, Mayank Mishra, A. Gu, Jennifer Robinson, Carolyn Jane Anderson, Brendan Dolan-Gavitt, Danish Contractor, Siva Reddy, Daniel Fried, Dzmitry Bahdanau, Yacine Jernite, Carlos Muñoz Ferrandis, Sean M. Hughes, Thomas Wolf, Arjun Guha, Leandro von Werra, Harm de Vries",data/paper_jsons/Daniel Fried_47070750.json,
TLDR of the most cited paper from Daniel Fried?,This work performs the most comprehensive evaluation of Code LLMs to date and shows that StarCoderBase outperforms every open Code LLM that supports multiple programming languages and matches or outperforms the OpenAI code-cushman-001 model.,data/paper_jsons/Daniel Fried_47070750.json,
Abstract of the most cited paper from Daniel Fried?,"The BigCode community, an open-scientific collaboration working on the responsible development of Large Language Models for Code (Code LLMs), introduces StarCoder and StarCoderBase: 15.5B parameter models with 8K context length, infilling capabilities and fast large-batch inference enabled by multi-query attention. StarCoderBase is trained on 1 trillion tokens sourced from The Stack, a large collection of permissively licensed GitHub repositories with inspection tools and an opt-out process. We fine-tuned StarCoderBase on 35B Python tokens, resulting in the creation of StarCoder. We perform the most comprehensive evaluation of Code LLMs to date and show that StarCoderBase outperforms every open Code LLM that supports multiple programming languages and matches or outperforms the OpenAI code-cushman-001 model. Furthermore, StarCoder outperforms every model that is fine-tuned on Python, can be prompted to achieve 40\% pass@1 on HumanEval, and still retains its performance on other programming languages. We take several important steps towards a safe open-access model release, including an improved PII redaction pipeline and a novel attribution tracing tool, and make the StarCoder models publicly available under a more commercially viable version of the Open Responsible AI Model license.",data/paper_jsons/Daniel Fried_47070750.json,
"What journal was the paper ""Grounding Language Models to Images for Multimodal Generation"" published in?",ArXiv,Daniel Fried_47070750.json,
"What venue was the paper ""Grounding Language Models to Images for Multimodal Generation"" published in?",arXiv.org,Daniel Fried_47070750.json,
"How many citations does the paper ""Grounding Language Models to Images for Multimodal Generation"" have?",60,Daniel Fried_47070750.json,
"Who are the authors of the paper ""Grounding Language Models to Images for Multimodal Generation""?","Jing Yu Koh, R. Salakhutdinov, Daniel Fried",Daniel Fried_47070750.json,
"Who is the first author of the paper ""Grounding Language Models to Images for Multimodal Generation""?",Jing Yu Koh,Daniel Fried_47070750.json,
"What is the paper ID of the paper ""Grounding Language Models to Images for Multimodal Generation""?",2b2d9ee18507aa89a7f1ecba0bf68844c7d9aa75,Daniel Fried_47070750.json,
What paper has the paper ID 2b2d9ee18507aa89a7f1ecba0bf68844c7d9aa75?,Grounding Language Models to Images for Multimodal Generation,Daniel Fried_47070750.json,
What is the TLDR of the paper 'Grounding Language Models to Images for Multimodal Generation'?,"An ef-fective, general solution for leveraging pretrained language models in visually grounded settings, enabling them to process and generate arbitrarily interleaved image-and-text data.",Daniel Fried_47070750.json,
What is the abstract of the paper 'Grounding Language Models to Images for Multimodal Generation'?,"We propose an efﬁcient method to ground pre-trained text-only language models to the visual domain, enabling them to process and generate arbitrarily interleaved image-and-text data. Our method leverages the abilities of language models learnt from large scale text-only pretraining, such as in-context learning and free-form text generation. We keep the language model frozen, and ﬁnetune input and output linear layers to enable cross-modality interactions. This allows our model to process arbitrarily interleaved image-and-text inputs, and generate free-form text interleaved with retrieved images. We achieve strong zero-shot performance on grounded tasks such as contextual image retrieval and multimodal dialogue, and showcase compelling interactive abilities. Our approach works with any off-the-shelf language model and paves the way towards an ef-fective, general solution for leveraging pretrained language models in visually grounded settings.",Daniel Fried_47070750.json,
"What journal was the paper ""WebArena: A Realistic Web Environment for Building Autonomous Agents"" published in?",ArXiv,Daniel Fried_47070750.json,
"What venue was the paper ""WebArena: A Realistic Web Environment for Building Autonomous Agents"" published in?",arXiv.org,Daniel Fried_47070750.json,
"How many citations does the paper ""WebArena: A Realistic Web Environment for Building Autonomous Agents"" have?",60,Daniel Fried_47070750.json,
"Who are the authors of the paper ""WebArena: A Realistic Web Environment for Building Autonomous Agents""?","Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, Graham Neubig",Daniel Fried_47070750.json,
"Who is the first author of the paper ""WebArena: A Realistic Web Environment for Building Autonomous Agents""?",Shuyan Zhou,Daniel Fried_47070750.json,
"What is the paper ID of the paper ""WebArena: A Realistic Web Environment for Building Autonomous Agents""?",e41482f4ee984f17382f6cdd900df094d928be06,Daniel Fried_47070750.json,
What paper has the paper ID e41482f4ee984f17382f6cdd900df094d928be06?,WebArena: A Realistic Web Environment for Building Autonomous Agents,Daniel Fried_47070750.json,
What is the TLDR of the paper 'WebArena: A Realistic Web Environment for Building Autonomous Agents'?,"This paper builds an environment for language-guided agents that is highly realistic and reproducible, and creates an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management.",Daniel Fried_47070750.json,
What is the abstract of the paper 'WebArena: A Realistic Web Environment for Building Autonomous Agents'?,"With advances in generative AI, there is now potential for autonomous agents to manage daily tasks via natural language commands. However, current agents are primarily created and tested in simplified synthetic environments, leading to a disconnect with real-world scenarios. In this paper, we build an environment for language-guided agents that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on the web, and create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our environment is enriched with tools (e.g., a map) and external knowledge bases (e.g., user manuals) to encourage human-like task-solving. Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and designed to emulate tasks that humans routinely perform on the internet. We experiment with several baseline agents, integrating recent techniques such as reasoning before acting. The results demonstrate that solving complex tasks is challenging: our best GPT-4-based agent only achieves an end-to-end task success rate of 14.41%, significantly lower than the human performance of 78.24%. These results highlight the need for further development of robust agents, that current state-of-the-art large language models are far from perfect performance in these real-life tasks, and that WebArena can be used to measure such progress.",Daniel Fried_47070750.json,
"What journal was the paper ""SantaCoder: don't reach for the stars!"" published in?",ArXiv,Daniel Fried_47070750.json,
"What venue was the paper ""SantaCoder: don't reach for the stars!"" published in?",arXiv.org,Daniel Fried_47070750.json,
"How many citations does the paper ""SantaCoder: don't reach for the stars!"" have?",83,Daniel Fried_47070750.json,
"Who are the authors of the paper ""SantaCoder: don't reach for the stars!""?","Loubna Ben Allal, Raymond Li, Denis Kocetkov, Chenghao Mou, Christopher Akiki, Carlos Muñoz Ferrandis, Niklas Muennighoff, Mayank Mishra, A. Gu, Manan Dey, Logesh Kumar Umapathi, Carolyn Jane Anderson, Yangtian Zi, J. Poirier, Hailey Schoelkopf, S. Troshin, Dmitry Abulkhanov, M. Romero, M. Lappert, F. Toni, Bernardo Garc'ia del R'io, Qian Liu, Shamik Bose, Urvashi Bhattacharyya, Terry Yue Zhuo, I. Yu, Paulo Villegas, Marco Zocca, Sourab Mangrulkar, D. Lansky, Huu Nguyen, Danish Contractor, Luisa Villa, Jia Li, Dzmitry Bahdanau, Yacine Jernite, S. Hughes, Daniel Fried, Arjun Guha, Harm de Vries, Leandro von Werra",Daniel Fried_47070750.json,
"Who is the first author of the paper ""SantaCoder: don't reach for the stars!""?",Loubna Ben Allal,Daniel Fried_47070750.json,
"What is the paper ID of the paper ""SantaCoder: don't reach for the stars!""?",1bf21dabbdfc81fd4f9e92b1201ecce744cabb6a,Daniel Fried_47070750.json,
What paper has the paper ID 1bf21dabbdfc81fd4f9e92b1201ecce744cabb6a?,SantaCoder: don't reach for the stars!,Daniel Fried_47070750.json,
What is the TLDR of the paper 'SantaCoder: don't reach for the stars!'?,"The current state of the Personally Identifiable Information (PII) redaction pipeline is outlined, the experiments conducted to de-risk the model architecture, and the experiments investigating better preprocessing methods for the training data are outlined.",Daniel Fried_47070750.json,
What is the abstract of the paper 'SantaCoder: don't reach for the stars!'?,"The BigCode project is an open-scientific collaboration working on the responsible development of large language models for code. This tech report describes the progress of the collaboration until December 2022, outlining the current state of the Personally Identifiable Information (PII) redaction pipeline, the experiments conducted to de-risk the model architecture, and the experiments investigating better preprocessing methods for the training data. We train 1.1B parameter models on the Java, JavaScript, and Python subsets of The Stack and evaluate them on the MultiPL-E text-to-code benchmark. We find that more aggressive filtering of near-duplicates can further boost performance and, surprisingly, that selecting files from repositories with 5+ GitHub stars deteriorates performance significantly. Our best model outperforms previous open-source multilingual code generation models (InCoder-6.7B and CodeGen-Multi-2.7B) in both left-to-right generation and infilling on the Java, JavaScript, and Python portions of MultiPL-E, despite being a substantially smaller model. All models are released under an OpenRAIL license at https://hf.co/bigcode.",Daniel Fried_47070750.json,
What is the author ID of Daphne Ippolito?,7975935,data/paper_jsons/Daphne Ippolito_7975935.json,
What are the papers of Daphne Ippolito?,"Reverse-Engineering Decoding Strategies Given Blackbox Access to a Language Generation System, A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity, Extracting Training Data from Diffusion Models, Are aligned neural networks adversarially aligned?",data/paper_jsons/Daphne Ippolito_7975935.json,
What is the H-index of Daphne Ippolito?,25,data/paper_jsons/Daphne Ippolito_7975935.json,
What is the author citation count of Daphne Ippolito?,6460,data/paper_jsons/Daphne Ippolito_7975935.json,
What journals has Daphne Ippolito published in?,ArXiv,data/paper_jsons/Daphne Ippolito_7975935.json,
What are the journals and how many papers has Daphne Ippolito published in each?,{'ArXiv': 3},data/paper_jsons/Daphne Ippolito_7975935.json,
What are the fields of study of Daphne Ippolito?,Computer Science,data/paper_jsons/Daphne Ippolito_7975935.json,
How many papers has Daphne Ippolito published in open access journals?,4,data/paper_jsons/Daphne Ippolito_7975935.json,
What venues has Daphne Ippolito published in?,"International Conference on Natural Language Generation, arXiv.org, USENIX Security Symposium",data/paper_jsons/Daphne Ippolito_7975935.json,
What is the most cited paper from Daphne Ippolito?,Extracting Training Data from Diffusion Models,data/paper_jsons/Daphne Ippolito_7975935.json,
What is the url of the most cited paper from Daphne Ippolito?,http://arxiv.org/pdf/2301.13188,data/paper_jsons/Daphne Ippolito_7975935.json,
Who are the authors of the most cited paper from Daphne Ippolito?,"Nicholas Carlini, Jamie Hayes, Milad Nasr, Matthew Jagielski, Vikash Sehwag, Florian Tramèr, B. Balle, Daphne Ippolito, Eric Wallace",data/paper_jsons/Daphne Ippolito_7975935.json,
TLDR of the most cited paper from Daphne Ippolito?,"The results show that diffusion models are much less private than prior generative models such as GANs, and that mitigating these vulnerabilities may require new advances in privacy-preserving training.",data/paper_jsons/Daphne Ippolito_7975935.json,
Abstract of the most cited paper from Daphne Ippolito?,"Image diffusion models such as DALL-E 2, Imagen, and Stable Diffusion have attracted significant attention due to their ability to generate high-quality synthetic images. In this work, we show that diffusion models memorize individual images from their training data and emit them at generation time. With a generate-and-filter pipeline, we extract over a thousand training examples from state-of-the-art models, ranging from photographs of individual people to trademarked company logos. We also train hundreds of diffusion models in various settings to analyze how different modeling and data decisions affect privacy. Overall, our results show that diffusion models are much less private than prior generative models such as GANs, and that mitigating these vulnerabilities may require new advances in privacy-preserving training.",data/paper_jsons/Daphne Ippolito_7975935.json,
"What journal was the paper ""Are aligned neural networks adversarially aligned?"" published in?",ArXiv,Daphne Ippolito_7975935.json,
"What venue was the paper ""Are aligned neural networks adversarially aligned?"" published in?",arXiv.org,Daphne Ippolito_7975935.json,
"How many citations does the paper ""Are aligned neural networks adversarially aligned?"" have?",67,Daphne Ippolito_7975935.json,
"Who are the authors of the paper ""Are aligned neural networks adversarially aligned?""?","Nicholas Carlini, Milad Nasr, Christopher A. Choquette-Choo, Matthew Jagielski, Irena Gao, Anas Awadalla, Pang Wei Koh, Daphne Ippolito, Katherine Lee, Florian Tramèr, Ludwig Schmidt",Daphne Ippolito_7975935.json,
"Who is the first author of the paper ""Are aligned neural networks adversarially aligned?""?",Nicholas Carlini,Daphne Ippolito_7975935.json,
"What is the paper ID of the paper ""Are aligned neural networks adversarially aligned?""?",8724579d3f126e753a0451d98ff57b165f722e72,Daphne Ippolito_7975935.json,
What paper has the paper ID 8724579d3f126e753a0451d98ff57b165f722e72?,Are aligned neural networks adversarially aligned?,Daphne Ippolito_7975935.json,
What is the TLDR of the paper 'Are aligned neural networks adversarially aligned?'?,"It is shown that existing NLP-based optimization attacks are insufficiently powerful to reliably attack aligned text models, and conjecture that improved NLP attacks may demonstrate this same level of adversarial control over text-only models.",Daphne Ippolito_7975935.json,
What is the abstract of the paper 'Are aligned neural networks adversarially aligned?'?,"Large language models are now tuned to align with the goals of their creators, namely to be""helpful and harmless.""These models should respond helpfully to user questions, but refuse to answer requests that could cause harm. However, adversarial users can construct inputs which circumvent attempts at alignment. In this work, we study to what extent these models remain aligned, even when interacting with an adversarial user who constructs worst-case inputs (adversarial examples). These inputs are designed to cause the model to emit harmful content that would otherwise be prohibited. We show that existing NLP-based optimization attacks are insufficiently powerful to reliably attack aligned text models: even when current NLP-based attacks fail, we can find adversarial inputs with brute force. As a result, the failure of current attacks should not be seen as proof that aligned text models remain aligned under adversarial inputs. However the recent trend in large-scale ML models is multimodal models that allow users to provide images that influence the text that is generated. We show these models can be easily attacked, i.e., induced to perform arbitrary un-aligned behavior through adversarial perturbation of the input image. We conjecture that improved NLP attacks may demonstrate this same level of adversarial control over text-only models.",Daphne Ippolito_7975935.json,
"What journal was the paper ""Extracting Training Data from Diffusion Models"" published in?",ArXiv,Daphne Ippolito_7975935.json,
"What venue was the paper ""Extracting Training Data from Diffusion Models"" published in?",USENIX Security Symposium,Daphne Ippolito_7975935.json,
"How many citations does the paper ""Extracting Training Data from Diffusion Models"" have?",222,Daphne Ippolito_7975935.json,
"Who are the authors of the paper ""Extracting Training Data from Diffusion Models""?","Nicholas Carlini, Jamie Hayes, Milad Nasr, Matthew Jagielski, Vikash Sehwag, Florian Tramèr, B. Balle, Daphne Ippolito, Eric Wallace",Daphne Ippolito_7975935.json,
"Who is the first author of the paper ""Extracting Training Data from Diffusion Models""?",Nicholas Carlini,Daphne Ippolito_7975935.json,
"What is the paper ID of the paper ""Extracting Training Data from Diffusion Models""?",2e965b5d97c2d6fb4af284307735be39283792ba,Daphne Ippolito_7975935.json,
What paper has the paper ID 2e965b5d97c2d6fb4af284307735be39283792ba?,Extracting Training Data from Diffusion Models,Daphne Ippolito_7975935.json,
What is the TLDR of the paper 'Extracting Training Data from Diffusion Models'?,"The results show that diffusion models are much less private than prior generative models such as GANs, and that mitigating these vulnerabilities may require new advances in privacy-preserving training.",Daphne Ippolito_7975935.json,
What is the abstract of the paper 'Extracting Training Data from Diffusion Models'?,"Image diffusion models such as DALL-E 2, Imagen, and Stable Diffusion have attracted significant attention due to their ability to generate high-quality synthetic images. In this work, we show that diffusion models memorize individual images from their training data and emit them at generation time. With a generate-and-filter pipeline, we extract over a thousand training examples from state-of-the-art models, ranging from photographs of individual people to trademarked company logos. We also train hundreds of diffusion models in various settings to analyze how different modeling and data decisions affect privacy. Overall, our results show that diffusion models are much less private than prior generative models such as GANs, and that mitigating these vulnerabilities may require new advances in privacy-preserving training.",Daphne Ippolito_7975935.json,
"What journal was the paper ""A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity"" published in?",ArXiv,Daphne Ippolito_7975935.json,
"What venue was the paper ""A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity"" published in?",arXiv.org,Daphne Ippolito_7975935.json,
"How many citations does the paper ""A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity"" have?",32,Daphne Ippolito_7975935.json,
"Who are the authors of the paper ""A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity""?","S. Longpre, Gregory Yauney, Emily Reif, Katherine Lee, Adam Roberts, Barret Zoph, Denny Zhou, Jason Wei, Kevin Robinson, David M. Mimno, Daphne Ippolito",Daphne Ippolito_7975935.json,
"Who is the first author of the paper ""A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity""?",S. Longpre,Daphne Ippolito_7975935.json,
"What is the paper ID of the paper ""A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity""?",1567bcac0ab09269c9d0ff33c9a406132417fab9,Daphne Ippolito_7975935.json,
What paper has the paper ID 1567bcac0ab09269c9d0ff33c9a406132417fab9?,"A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity",Daphne Ippolito_7975935.json,
"What is the TLDR of the paper 'A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity'?","These findings constitute the largest set of experiments to validate, quantify, and expose many undocumented intuitions about text pretraining, which are hoped to help support more informed data-centric decisions in LM development.",Daphne Ippolito_7975935.json,
"What is the abstract of the paper 'A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity'?","Pretraining is the preliminary and fundamental step in developing capable language models (LM). Despite this, pretraining data design is critically under-documented and often guided by empirically unsupported intuitions. To address this, we pretrain 28 1.5B parameter decoder-only models, training on data curated (1) at different times, (2) with varying toxicity and quality filters, and (3) with different domain compositions. First, we quantify the effect of pretraining data age. A temporal shift between evaluation data and pretraining data leads to performance degradation, which is not overcome by finetuning. Second, we explore the effect of quality and toxicity filters, showing a trade-off between performance on standard benchmarks and risk of toxic generations. Our findings indicate there does not exist a one-size-fits-all solution to filtering training data. We also find that the effects of different types of filtering are not predictable from text domain characteristics. Lastly, we empirically validate that the inclusion of heterogeneous data sources, like books and web, is broadly beneficial and warrants greater prioritization. These findings constitute the largest set of experiments to validate, quantify, and expose many undocumented intuitions about text pretraining, which we hope will help support more informed data-centric decisions in LM development.",Daphne Ippolito_7975935.json,
What is the author ID of David R Mortensen?,3407646,data/paper_jsons/David R. Mortensen_3407646.json,
What are the papers of David R Mortensen?,"ChatGPT MT: Competitive for High- (but Not Low-) Resource Languages, Do All Languages Cost the Same? Tokenization in the Era of Commercial Language Models, SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing, Construction Grammar Provides Unique Insight into Neural Language Models, Generalized Glossing Guidelines: An Explicit, Human- and Machine-Readable, Item-and-Process Convention for Morphological Annotation, Transformed Protoform Reconstruction, PWESuite: Phonetic Word Embeddings and Tasks They Facilitate",data/paper_jsons/David R. Mortensen_3407646.json,
What is the H-index of David R Mortensen?,15,data/paper_jsons/David R. Mortensen_3407646.json,
What is the author citation count of David R Mortensen?,1049,data/paper_jsons/David R. Mortensen_3407646.json,
What journals has David R Mortensen published in?,ArXiv,data/paper_jsons/David R. Mortensen_3407646.json,
What are the journals and how many papers has David R Mortensen published in each?,{'ArXiv': 4},data/paper_jsons/David R. Mortensen_3407646.json,
What are the fields of study of David R Mortensen?,Computer Science,data/paper_jsons/David R. Mortensen_3407646.json,
How many papers has David R Mortensen published in open access journals?,7,data/paper_jsons/David R. Mortensen_3407646.json,
What venues has David R Mortensen published in?,"Conference on Machine Translation, Conference on Empirical Methods in Natural Language Processing, Special Interest Group on Computational Morphology and Phonology Workshop, CXGSNLP, Annual Meeting of the Association for Computational Linguistics, arXiv.org",data/paper_jsons/David R. Mortensen_3407646.json,
What is the most cited paper from David R Mortensen?,Do All Languages Cost the Same? Tokenization in the Era of Commercial Language Models,data/paper_jsons/David R. Mortensen_3407646.json,
What is the url of the most cited paper from David R Mortensen?,http://arxiv.org/pdf/2305.13707,data/paper_jsons/David R. Mortensen_3407646.json,
Who are the authors of the most cited paper from David R Mortensen?,"Orevaoghene Ahia, Sachin Kumar, Hila Gonen, Jungo Kasai, David R. Mortensen, Noah A. Smith, Yulia Tsvetkov",data/paper_jsons/David R. Mortensen_3407646.json,
TLDR of the most cited paper from David R Mortensen?,This work conducts a systematic analysis of the cost and utility of OpenAI's language model API on multilingual benchmarks in 22 typologically diverse languages and shows evidence that speakers of a large number of the supported languages are overcharged while obtaining poorer results.,data/paper_jsons/David R. Mortensen_3407646.json,
Abstract of the most cited paper from David R Mortensen?,"Language models have graduated from being research prototypes to commercialized products offered as web APIs, and recent works have highlighted the multilingual capabilities of these products. The API vendors charge their users based on usage, more specifically on the number of ``tokens'' processed or generated by the underlying language models. What constitutes a token, however, is training data and model dependent with a large variance in the number of tokens required to convey the same information in different languages. In this work, we analyze the effect of this non-uniformity on the fairness of an API's pricing policy across languages. We conduct a systematic analysis of the cost and utility of OpenAI's language model API on multilingual benchmarks in 22 typologically diverse languages. We show evidence that speakers of a large number of the supported languages are overcharged while obtaining poorer results. These speakers tend to also come from regions where the APIs are less affordable to begin with. Through these analyses, we aim to increase transparency around language model APIs' pricing policies and encourage the vendors to make them more equitable.",data/paper_jsons/David R. Mortensen_3407646.json,
"What journal was the paper ""SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing"" published in?",,David R. Mortensen_3407646.json,
"What venue was the paper ""SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing"" published in?",Special Interest Group on Computational Morphology and Phonology Workshop,David R. Mortensen_3407646.json,
"How many citations does the paper ""SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing"" have?",2,David R. Mortensen_3407646.json,
"Who are the authors of the paper ""SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing""?","Taiqi He, Lindia Tjuatja, Nathaniel R. Robinson, Shinji Watanabe, David R. Mortensen, Graham Neubig, L. Levin",David R. Mortensen_3407646.json,
"Who is the first author of the paper ""SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing""?",Taiqi He,David R. Mortensen_3407646.json,
"What is the paper ID of the paper ""SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing""?",659be1ff350634f50cc066d258ee6a45e697e552,David R. Mortensen_3407646.json,
What paper has the paper ID 659be1ff350634f50cc066d258ee6a45e697e552?,SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing,David R. Mortensen_3407646.json,
What is the TLDR of the paper 'SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing'?,"In this submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), approaches to data augmentation and modeling across seven low-resource languages are explored and token classification models are found to be the best performing.",David R. Mortensen_3407646.json,
What is the abstract of the paper 'SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing'?,"In our submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), we explore approaches to data augmentation and modeling across seven low-resource languages. For data augmentation, we explore two approaches: creating artificial data from the provided training data and utilizing existing IGT resources in other languages. On the modeling side, we test an enhanced version of the provided token classification baseline as well as a pretrained multilingual seq2seq model. Additionally, we apply post-correction using a dictionary for Gitksan, the language with the smallest amount of data. We find that our token classification models are the best performing, with the highest word-level accuracy for Arapaho and highest morpheme-level accuracy for Gitksan out of all submissions. We also show that data augmentation is an effective strategy, though applying artificial data pretraining has very different effects across both models tested.",David R. Mortensen_3407646.json,
"What journal was the paper ""Transformed Protoform Reconstruction"" published in?",,David R. Mortensen_3407646.json,
"What venue was the paper ""Transformed Protoform Reconstruction"" published in?",Annual Meeting of the Association for Computational Linguistics,David R. Mortensen_3407646.json,
"How many citations does the paper ""Transformed Protoform Reconstruction"" have?",1,David R. Mortensen_3407646.json,
"Who are the authors of the paper ""Transformed Protoform Reconstruction""?","Young Min Kim, Kalvin Chang, Chenxuan Cui, David R. Mortensen",David R. Mortensen_3407646.json,
"Who is the first author of the paper ""Transformed Protoform Reconstruction""?",Young Min Kim,David R. Mortensen_3407646.json,
"What is the paper ID of the paper ""Transformed Protoform Reconstruction""?",c5c6d006e399386c99068daba138021a62d6cc17,David R. Mortensen_3407646.json,
What paper has the paper ID c5c6d006e399386c99068daba138021a62d6cc17?,Transformed Protoform Reconstruction,David R. Mortensen_3407646.json,
What is the TLDR of the paper 'Transformed Protoform Reconstruction'?,"The Meloni et al (2021) model is updated with the state-of-the-art seq2seq model: the Transformer, which outperforms their model on a suite of different metrics on two different datasets: their Romance data of 8,000 cognate spanning 5 languages and a Chinese dataset (Hou 2004) of 800+ cognates spanning 39 varieties.",David R. Mortensen_3407646.json,
What is the abstract of the paper 'Transformed Protoform Reconstruction'?,"Protoform reconstruction is the task of inferring what morphemes or words appeared like in the ancestral languages of a set of daughter languages. Meloni et al (2021) achieved the state-of-the-art on Latin protoform reconstruction with an RNN-based encoder-decoder with attention model. We update their model with the state-of-the-art seq2seq model: the Transformer. Our model outperforms their model on a suite of different metrics on two different datasets: their Romance data of 8,000 cognates spanning 5 languages and a Chinese dataset (Hou 2004) of 800+ cognates spanning 39 varieties. We also probe our model for potential phylogenetic signal contained in the model. Our code is publicly available at https://github.com/cmu-llab/acl-2023.",David R. Mortensen_3407646.json,
"What journal was the paper ""Construction Grammar Provides Unique Insight into Neural Language Models"" published in?",ArXiv,David R. Mortensen_3407646.json,
"What venue was the paper ""Construction Grammar Provides Unique Insight into Neural Language Models"" published in?",CXGSNLP,David R. Mortensen_3407646.json,
"How many citations does the paper ""Construction Grammar Provides Unique Insight into Neural Language Models"" have?",7,David R. Mortensen_3407646.json,
"Who are the authors of the paper ""Construction Grammar Provides Unique Insight into Neural Language Models""?","Leonie Weissweiler, Taiqi He, Naoki Otani, David R. Mortensen, L. Levin, Hinrich Schütze",David R. Mortensen_3407646.json,
"Who is the first author of the paper ""Construction Grammar Provides Unique Insight into Neural Language Models""?",Leonie Weissweiler,David R. Mortensen_3407646.json,
"What is the paper ID of the paper ""Construction Grammar Provides Unique Insight into Neural Language Models""?",7a08051aac75a809737096e39820bf836908d4e1,David R. Mortensen_3407646.json,
What paper has the paper ID 7a08051aac75a809737096e39820bf836908d4e1?,Construction Grammar Provides Unique Insight into Neural Language Models,David R. Mortensen_3407646.json,
What is the TLDR of the paper 'Construction Grammar Provides Unique Insight into Neural Language Models'?,"The view of the most important challenges and research questions that this promising new field of research faces is provided, and an analysis of selected previous work in detail is provided.",David R. Mortensen_3407646.json,
What is the abstract of the paper 'Construction Grammar Provides Unique Insight into Neural Language Models'?,"Construction Grammar (CxG) has recently been used as the basis for probing studies that have investigated the performance of large pretrained language models (PLMs) with respect to the structure and meaning of constructions. In this position paper, we make suggestions for the continuation and augmentation of this line of research. We look at probing methodology that was not designed with CxG in mind, as well as probing methodology that was designed for specific constructions. We analyse selected previous work in detail, and provide our view of the most important challenges and research questions that this promising new field faces.",David R. Mortensen_3407646.json,
What is the author ID of Eric P. Xing?,143977260,data/paper_jsons/E. Xing_143977260.json,
What are the papers of Eric P. Xing?,"Identification of Nonlinear Latent Hierarchical Models, StyleRF: Zero-Shot 3D Style Transfer of Neural Radiance Fields, Judging LLM-as-a-judge with MT-Bench and Chatbot Arena, Understanding Masked Autoencoders via Hierarchical Latent Variable Models",data/paper_jsons/E. Xing_143977260.json,
What is the H-index of Eric P. Xing?,103,data/paper_jsons/E. Xing_143977260.json,
What is the author citation count of Eric P. Xing?,46108,data/paper_jsons/E. Xing_143977260.json,
What journals has Eric P. Xing published in?,"ArXiv, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",data/paper_jsons/E. Xing_143977260.json,
What are the journals and how many papers has Eric P. Xing published in each?,"{'ArXiv': 2, '2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)': 2}",data/paper_jsons/E. Xing_143977260.json,
What are the fields of study of Eric P. Xing?,"Computer Science, Mathematics",data/paper_jsons/E. Xing_143977260.json,
How many papers has Eric P. Xing published in open access journals?,4,data/paper_jsons/E. Xing_143977260.json,
What venues has Eric P. Xing published in?,"arXiv.org, Computer Vision and Pattern Recognition",data/paper_jsons/E. Xing_143977260.json,
What is the most cited paper from Eric P. Xing?,Judging LLM-as-a-judge with MT-Bench and Chatbot Arena,data/paper_jsons/E. Xing_143977260.json,
What is the url of the most cited paper from Eric P. Xing?,https://arxiv.org/pdf/2306.05685,data/paper_jsons/E. Xing_143977260.json,
Who are the authors of the most cited paper from Eric P. Xing?,"Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, E. Xing, Haotong Zhang, Joseph Gonzalez, I. Stoica",data/paper_jsons/E. Xing_143977260.json,
TLDR of the most cited paper from Eric P. Xing?,"The results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80% agreement, the same level of agreement between humans, and LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain.",data/paper_jsons/E. Xing_143977260.json,
Abstract of the most cited paper from Eric P. Xing?,"Evaluating large language model (LLM) based chat assistants is challenging due to their broad capabilities and the inadequacy of existing benchmarks in measuring human preferences. To address this, we explore using strong LLMs as judges to evaluate these models on more open-ended questions. We examine the usage and limitations of LLM-as-a-judge, including position, verbosity, and self-enhancement biases, as well as limited reasoning ability, and propose solutions to mitigate some of them. We then verify the agreement between LLM judges and human preferences by introducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80% agreement, the same level of agreement between humans. Hence, LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain. Additionally, we show our benchmark and traditional benchmarks complement each other by evaluating several variants of LLaMA and Vicuna. The MT-bench questions, 3K expert votes, and 30K conversations with human preferences are publicly available at https://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge.",data/paper_jsons/E. Xing_143977260.json,
"What journal was the paper ""Judging LLM-as-a-judge with MT-Bench and Chatbot Arena"" published in?",ArXiv,E. Xing_143977260.json,
"What venue was the paper ""Judging LLM-as-a-judge with MT-Bench and Chatbot Arena"" published in?",arXiv.org,E. Xing_143977260.json,
"How many citations does the paper ""Judging LLM-as-a-judge with MT-Bench and Chatbot Arena"" have?",690,E. Xing_143977260.json,
"Who are the authors of the paper ""Judging LLM-as-a-judge with MT-Bench and Chatbot Arena""?","Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, E. Xing, Haotong Zhang, Joseph Gonzalez, I. Stoica",E. Xing_143977260.json,
"Who is the first author of the paper ""Judging LLM-as-a-judge with MT-Bench and Chatbot Arena""?",Lianmin Zheng,E. Xing_143977260.json,
"What is the paper ID of the paper ""Judging LLM-as-a-judge with MT-Bench and Chatbot Arena""?",a0a79dad89857a96f8f71b14238e5237cbfc4787,E. Xing_143977260.json,
What paper has the paper ID a0a79dad89857a96f8f71b14238e5237cbfc4787?,Judging LLM-as-a-judge with MT-Bench and Chatbot Arena,E. Xing_143977260.json,
What is the TLDR of the paper 'Judging LLM-as-a-judge with MT-Bench and Chatbot Arena'?,"The results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80% agreement, the same level of agreement between humans, and LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain.",E. Xing_143977260.json,
What is the abstract of the paper 'Judging LLM-as-a-judge with MT-Bench and Chatbot Arena'?,"Evaluating large language model (LLM) based chat assistants is challenging due to their broad capabilities and the inadequacy of existing benchmarks in measuring human preferences. To address this, we explore using strong LLMs as judges to evaluate these models on more open-ended questions. We examine the usage and limitations of LLM-as-a-judge, including position, verbosity, and self-enhancement biases, as well as limited reasoning ability, and propose solutions to mitigate some of them. We then verify the agreement between LLM judges and human preferences by introducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80% agreement, the same level of agreement between humans. Hence, LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain. Additionally, we show our benchmark and traditional benchmarks complement each other by evaluating several variants of LLaMA and Vicuna. The MT-bench questions, 3K expert votes, and 30K conversations with human preferences are publicly available at https://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge.",E. Xing_143977260.json,
"What journal was the paper ""Understanding Masked Autoencoders via Hierarchical Latent Variable Models"" published in?",2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),E. Xing_143977260.json,
"What venue was the paper ""Understanding Masked Autoencoders via Hierarchical Latent Variable Models"" published in?",Computer Vision and Pattern Recognition,E. Xing_143977260.json,
"How many citations does the paper ""Understanding Masked Autoencoders via Hierarchical Latent Variable Models"" have?",8,E. Xing_143977260.json,
"Who are the authors of the paper ""Understanding Masked Autoencoders via Hierarchical Latent Variable Models""?","Lingjing Kong, Martin Q. Ma, Guan-Hong Chen, E. Xing, Yuejie Chi, Louis-Philippe Morency, Kun Zhang",E. Xing_143977260.json,
"Who is the first author of the paper ""Understanding Masked Autoencoders via Hierarchical Latent Variable Models""?",Lingjing Kong,E. Xing_143977260.json,
"What is the paper ID of the paper ""Understanding Masked Autoencoders via Hierarchical Latent Variable Models""?",dcb4f2b9b0e6da0d629878d1ad0469aee3df2020,E. Xing_143977260.json,
What paper has the paper ID dcb4f2b9b0e6da0d629878d1ad0469aee3df2020?,Understanding Masked Autoencoders via Hierarchical Latent Variable Models,E. Xing_143977260.json,
What is the TLDR of the paper 'Understanding Masked Autoencoders via Hierarchical Latent Variable Models'?,"This work formally characterize and justify existing empirical in-sights and provide theoretical guarantees of MAE, and formulate the underlying data-generating process as a hierarchical latent variable model, and shows that under reasonable assumptions, MAE provably identifies a set of latent variables in the hierarchical model.",E. Xing_143977260.json,
What is the abstract of the paper 'Understanding Masked Autoencoders via Hierarchical Latent Variable Models'?,"Masked autoencoder (MAE), a simple and effective self-supervised learning framework based on the reconstruction of masked image regions, has recently achieved prominent success in a variety of vision tasks. Despite the emergence of intriguing empirical observations on MAE, a theoretically principled understanding is still lacking. In this work, we formally characterize and justify existing empirical in-sights and provide theoretical guarantees of MAE. We formulate the underlying data-generating process as a hierarchical latent variable model, and show that under reasonable assumptions, MAE provably identifies a set of latent variables in the hierarchical model, explaining why MAE can extract high-level information from pixels. Further, we show how key hyperparameters in MAE (the masking ratio and the patch size) determine which true latent variables to be recovered, therefore influencing the level of semantic information in the representation. Specifically, extremely large or small masking ratios inevitably lead to low-level representations. Our theory offers coherent explanations of existing empirical observations and provides insights for potential empirical improvements and fundamental limitations of the masked-reconstruction paradigm. We conduct extensive experiments to validate our theoretical insights.",E. Xing_143977260.json,
"What journal was the paper ""StyleRF: Zero-Shot 3D Style Transfer of Neural Radiance Fields"" published in?",2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),E. Xing_143977260.json,
"What venue was the paper ""StyleRF: Zero-Shot 3D Style Transfer of Neural Radiance Fields"" published in?",Computer Vision and Pattern Recognition,E. Xing_143977260.json,
"How many citations does the paper ""StyleRF: Zero-Shot 3D Style Transfer of Neural Radiance Fields"" have?",12,E. Xing_143977260.json,
"Who are the authors of the paper ""StyleRF: Zero-Shot 3D Style Transfer of Neural Radiance Fields""?","Kunhao Liu, Fangneng Zhan, Yiwen Chen, Jiahui Zhang, Yingchen Yu, Abdulmotaleb El Saddik, Shijian Lu, E. Xing",E. Xing_143977260.json,
"Who is the first author of the paper ""StyleRF: Zero-Shot 3D Style Transfer of Neural Radiance Fields""?",Kunhao Liu,E. Xing_143977260.json,
"What is the paper ID of the paper ""StyleRF: Zero-Shot 3D Style Transfer of Neural Radiance Fields""?",8cc1cd002bfc36a8cba8bcbe63d32eacc656097f,E. Xing_143977260.json,
What paper has the paper ID 8cc1cd002bfc36a8cba8bcbe63d32eacc656097f?,StyleRF: Zero-Shot 3D Style Transfer of Neural Radiance Fields,E. Xing_143977260.json,
What is the TLDR of the paper 'StyleRF: Zero-Shot 3D Style Transfer of Neural Radiance Fields'?,"StyleRF (Style Radiance Fields), an innovative 3D style transfer technique that resolves the three-way dilemma by performing style transformation within the feature space of a radiance field, achieves superior 3D stylization quality with precise geometry reconstruction and it can generalize to various new styles in a zero-shot manner.",E. Xing_143977260.json,
What is the abstract of the paper 'StyleRF: Zero-Shot 3D Style Transfer of Neural Radiance Fields'?,"3D style transfer aims to render stylized novel views of a 3D scene with multiview consistency. However, most existing work suffers from a three-way dilemma over accurate geometry reconstruction, high-quality stylization, and being generalizable to arbitrary new styles. We propose StyleRF (Style Radiance Fields), an innovative 3D style transfer technique that resolves the three-way dilemma by performing style transformation within the feature space of a radiance field. StyleRF employs an explicit grid of high-level features to represent 3D scenes, with which highfidelity geometry can be reliably restored via volume rendering. In addition, it transforms the grid features according to the reference style which directly leads to high-quality zero-shot style transfer. StyleRF consists of two innovative designs. The first is sampling-invariant content transformation that makes the transformation invariant to the holistic statistics of the sampled 3D points and accordingly ensures multi-view consistency. The second is deferred style transformation of 2D feature maps which is equivalent to the transformation of 3D points but greatly reduces memory footprint without degrading multi-view consistency. Extensive experiments show that StyleRF achieves superior 3D stylization quality with precise geometry reconstruction and it can generalize to various new styles in a zero-shot manner. Project website: https://kunhao-liu.github.io/StyleRF/",E. Xing_143977260.json,
What is the author ID of Emma Strubell?,2268272,data/paper_jsons/Emma Strubell_2268272.json,
What are the papers of Emma Strubell?,"To Build Our Future, We Must Know Our Past: Contextualizing Paradigm Shifts in Natural Language Processing, Understanding the Effect of Model Compression on Social Bias in Large Language Models, Surveying (Dis)Parities and Concerns of Compute Hungry NLP Research, On the Interactions of Structural Constraints and Data Resources for Structured Prediction, Efficiency Pentathlon: A Standardized Arena for Efficiency Evaluation, Queer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Models, Making Scalable Meta Learning Practical, Regularizing Self-training for Unsupervised Domain Adaptation via Structural Constraints, The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment, Data-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training",data/paper_jsons/Emma Strubell_2268272.json,
What is the H-index of Emma Strubell?,17,data/paper_jsons/Emma Strubell_2268272.json,
What is the author citation count of Emma Strubell?,4143,data/paper_jsons/Emma Strubell_2268272.json,
What journals has Emma Strubell published in?,ArXiv,data/paper_jsons/Emma Strubell_2268272.json,
What are the journals and how many papers has Emma Strubell published in each?,{'ArXiv': 7},data/paper_jsons/Emma Strubell_2268272.json,
What are the fields of study of Emma Strubell?,Computer Science,data/paper_jsons/Emma Strubell_2268272.json,
How many papers has Emma Strubell published in open access journals?,10,data/paper_jsons/Emma Strubell_2268272.json,
What venues has Emma Strubell published in?,"Conference on Empirical Methods in Natural Language Processing, arXiv.org, SUSTAINLP",data/paper_jsons/Emma Strubell_2268272.json,
What is the most cited paper from Emma Strubell?,Efficiency Pentathlon: A Standardized Arena for Efficiency Evaluation,data/paper_jsons/Emma Strubell_2268272.json,
What is the url of the most cited paper from Emma Strubell?,https://arxiv.org/pdf/2307.09701,data/paper_jsons/Emma Strubell_2268272.json,
Who are the authors of the most cited paper from Emma Strubell?,"Hao Peng, Qingqing Cao, Jesse Dodge, Matthew E. Peters, Jared Fernandez, Tom Sherborne, Kyle Lo, Sam Skjonsberg, Emma Strubell, Darrell Plessas, Iz Beltagy, Pete Walsh, Noah A. Smith, Hannaneh Hajishirzi",data/paper_jsons/Emma Strubell_2268272.json,
TLDR of the most cited paper from Emma Strubell?,"Pentathlon is a benchmark for holistic and realistic evaluation of model efficiency, which focuses on inference, which accounts for a majority of the compute in a model's lifecycle, and is designed to mirror real-world applications scenarios.",data/paper_jsons/Emma Strubell_2268272.json,
Abstract of the most cited paper from Emma Strubell?,"Rising computational demands of modern natural language processing (NLP) systems have increased the barrier to entry for cutting-edge research while posing serious environmental concerns. Yet, progress on model efficiency has been impeded by practical challenges in model evaluation and comparison. For example, hardware is challenging to control due to disparate levels of accessibility across different institutions. Moreover, improvements in metrics such as FLOPs often fail to translate to progress in real-world applications. In response, we introduce Pentathlon, a benchmark for holistic and realistic evaluation of model efficiency. Pentathlon focuses on inference, which accounts for a majority of the compute in a model's lifecycle. It offers a strictly-controlled hardware platform, and is designed to mirror real-world applications scenarios. It incorporates a suite of metrics that target different aspects of efficiency, including latency, throughput, memory overhead, and energy consumption. Pentathlon also comes with a software library that can be seamlessly integrated into any codebase and enable evaluation. As a standardized and centralized evaluation platform, Pentathlon can drastically reduce the workload to make fair and reproducible efficiency comparisons. While initially focused on natural language processing (NLP) models, Pentathlon is designed to allow flexible extension to other fields. We envision Pentathlon will stimulate algorithmic innovations in building efficient models, and foster an increased awareness of the social and environmental implications in the development of future-generation NLP models.",data/paper_jsons/Emma Strubell_2268272.json,
"What journal was the paper ""Surveying (Dis)Parities and Concerns of Compute Hungry NLP Research"" published in?",ArXiv,Emma Strubell_2268272.json,
"What venue was the paper ""Surveying (Dis)Parities and Concerns of Compute Hungry NLP Research"" published in?",arXiv.org,Emma Strubell_2268272.json,
"How many citations does the paper ""Surveying (Dis)Parities and Concerns of Compute Hungry NLP Research"" have?",2,Emma Strubell_2268272.json,
"Who are the authors of the paper ""Surveying (Dis)Parities and Concerns of Compute Hungry NLP Research""?","Ji-Ung Lee, Haritz Puerto, Betty van Aken, Yuki Arase, J. Forde, Leon Derczynski, Andreas Ruckl'e, Iryna Gurevych, Roy Schwartz, Emma Strubell, Jesse Dodge",Emma Strubell_2268272.json,
"Who is the first author of the paper ""Surveying (Dis)Parities and Concerns of Compute Hungry NLP Research""?",Ji-Ung Lee,Emma Strubell_2268272.json,
"What is the paper ID of the paper ""Surveying (Dis)Parities and Concerns of Compute Hungry NLP Research""?",667ba2e8f1933b6c32e9672012526904b4c5dc31,Emma Strubell_2268272.json,
What paper has the paper ID 667ba2e8f1933b6c32e9672012526904b4c5dc31?,Surveying (Dis)Parities and Concerns of Compute Hungry NLP Research,Emma Strubell_2268272.json,
What is the TLDR of the paper 'Surveying (Dis)Parities and Concerns of Compute Hungry NLP Research'?,"This work captures existing (dis)parities between different and within groups with respect to seniority, academia, and industry; and their impact on the peer reviewing process; and provides an analysis and devise recommendations to mitigate found disparities.",Emma Strubell_2268272.json,
What is the abstract of the paper 'Surveying (Dis)Parities and Concerns of Compute Hungry NLP Research'?,"Many recent improvements in NLP stem from the development and use of large pre-trained language models (PLMs) with billions of parameters. Large model sizes makes computational cost one of the main limiting factors for training and evaluating such models; and has raised severe concerns about the sustainability, reproducibility, and inclusiveness for researching PLMs. These concerns are often based on personal experiences and observations. However, there had not been any large-scale surveys that investigate them. In this work, we provide a first attempt to quantify these concerns regarding three topics, namely, environmental impact, equity, and impact on peer reviewing. By conducting a survey with 312 participants from the NLP community, we capture existing (dis)parities between different and within groups with respect to seniority, academia, and industry; and their impact on the peer reviewing process. For each topic, we provide an analysis and devise recommendations to mitigate found disparities, some of which already successfully implemented. Finally, we discuss additional concerns raised by many participants in free-text responses.",Emma Strubell_2268272.json,
"What journal was the paper ""Understanding the Effect of Model Compression on Social Bias in Large Language Models"" published in?",ArXiv,Emma Strubell_2268272.json,
"What venue was the paper ""Understanding the Effect of Model Compression on Social Bias in Large Language Models"" published in?",Conference on Empirical Methods in Natural Language Processing,Emma Strubell_2268272.json,
"How many citations does the paper ""Understanding the Effect of Model Compression on Social Bias in Large Language Models"" have?",2,Emma Strubell_2268272.json,
"Who are the authors of the paper ""Understanding the Effect of Model Compression on Social Bias in Large Language Models""?","Gustavo Gonçalves, Emma Strubell",Emma Strubell_2268272.json,
"Who is the first author of the paper ""Understanding the Effect of Model Compression on Social Bias in Large Language Models""?",Gustavo Gonçalves,Emma Strubell_2268272.json,
"What is the paper ID of the paper ""Understanding the Effect of Model Compression on Social Bias in Large Language Models""?",45e50baac4d341f0cf1a40af096bfa9c3f555235,Emma Strubell_2268272.json,
What paper has the paper ID 45e50baac4d341f0cf1a40af096bfa9c3f555235?,Understanding the Effect of Model Compression on Social Bias in Large Language Models,Emma Strubell_2268272.json,
What is the TLDR of the paper 'Understanding the Effect of Model Compression on Social Bias in Large Language Models'?,"A carefully controlled study of the impact of model compression via quantization and knowledge distillation on measures of social bias in LLMs finds that longer pretraining and larger models led to higher social bias, and quantization showed a regularizer effect with its best trade-off around 20% of the original pretraining time.",Emma Strubell_2268272.json,
What is the abstract of the paper 'Understanding the Effect of Model Compression on Social Bias in Large Language Models'?,"Large Language Models (LLMs) trained with self-supervision on vast corpora of web text fit to the social biases of that text. Without intervention, these social biases persist in the model's predictions in downstream tasks, leading to representational harm. Many strategies have been proposed to mitigate the effects of inappropriate social biases learned during pretraining. Simultaneously, methods for model compression have become increasingly popular to reduce the computational burden of LLMs. Despite the popularity and need for both approaches, little work has been done to explore the interplay between these two. We perform a carefully controlled study of the impact of model compression via quantization and knowledge distillation on measures of social bias in LLMs. Longer pretraining and larger models led to higher social bias, and quantization showed a regularizer effect with its best trade-off around 20% of the original pretraining time.",Emma Strubell_2268272.json,
"What journal was the paper ""The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment"" published in?",ArXiv,Emma Strubell_2268272.json,
"What venue was the paper ""The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment"" published in?",Conference on Empirical Methods in Natural Language Processing,Emma Strubell_2268272.json,
"How many citations does the paper ""The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment"" have?",2,Emma Strubell_2268272.json,
"Who are the authors of the paper ""The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment""?","Jared Fernandez, Jacob Kahn, Clara Na, Yonatan Bisk, Emma Strubell",Emma Strubell_2268272.json,
"Who is the first author of the paper ""The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment""?",Jared Fernandez,Emma Strubell_2268272.json,
"What is the paper ID of the paper ""The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment""?",b777aa86b5a1d49ce8eababc5c2ee56d3562801e,Emma Strubell_2268272.json,
What paper has the paper ID b777aa86b5a1d49ce8eababc5c2ee56d3562801e?,The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment,Emma Strubell_2268272.json,
What is the TLDR of the paper 'The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment'?,"This work examines the effects of model design decisions, framework paradigms, and hardware platforms on total model latency through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency.",Emma Strubell_2268272.json,
What is the abstract of the paper 'The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment'?,"Increased focus on the computational efficiency of NLP systems has motivated the design of efficient model architectures and improvements to underlying hardware accelerators. However, the resulting increases in computational throughput and reductions in floating point operations have not directly translated to improvements in wall-clock inference latency. We demonstrate that these discrepancies can be largely attributed to bottlenecks introduced by deep learning frameworks. We denote this phenomenon as the \textit{framework tax}, and observe that the disparity is growing as hardware speed increases over time. In this work, we examine this phenomenon through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency. Code is available at https://github.com/JaredFern/Framework-Tax.",Emma Strubell_2268272.json,
What is the author ID of Eric Nyberg?,144287919,data/paper_jsons/Eric Nyberg_144287919.json,
What are the papers of Eric Nyberg?,"GameQA: Gamified Mobile App Platform for Building Multiple-Domain Question-Answering Datasets, InPars-Light: Cost-Effective Unsupervised Training of Efficient Rankers, Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA, Chain-of-Skills: A Configurable Model for Open-Domain Question Answering",data/paper_jsons/Eric Nyberg_144287919.json,
What is the H-index of Eric Nyberg?,38,data/paper_jsons/Eric Nyberg_144287919.json,
What is the author citation count of Eric Nyberg?,6031,data/paper_jsons/Eric Nyberg_144287919.json,
What journals has Eric Nyberg published in?,"ArXiv, Proceedings of the Third DialDoc Workshop on Document-grounded Dialogue and Conversational Question Answering",data/paper_jsons/Eric Nyberg_144287919.json,
What are the journals and how many papers has Eric Nyberg published in each?,"{'ArXiv': 1, 'Proceedings of the Third DialDoc Workshop on Document-grounded Dialogue and Conversational Question Answering': 1}",data/paper_jsons/Eric Nyberg_144287919.json,
What are the fields of study of Eric Nyberg?,Computer Science,data/paper_jsons/Eric Nyberg_144287919.json,
How many papers has Eric Nyberg published in open access journals?,4,data/paper_jsons/Eric Nyberg_144287919.json,
What venues has Eric Nyberg published in?,"Conference of the European Chapter of the Association for Computational Linguistics, arXiv.org, Workshop on Document-grounded Dialogue and Conversational Question Answering, Annual Meeting of the Association for Computational Linguistics",data/paper_jsons/Eric Nyberg_144287919.json,
What is the most cited paper from Eric Nyberg?,InPars-Light: Cost-Effective Unsupervised Training of Efficient Rankers,data/paper_jsons/Eric Nyberg_144287919.json,
What is the url of the most cited paper from Eric Nyberg?,http://arxiv.org/pdf/2301.02998,data/paper_jsons/Eric Nyberg_144287919.json,
Who are the authors of the most cited paper from Eric Nyberg?,"Leonid Boytsov, Preksha Patel, Vivek Sourabh, Riddhi Nisar, Sayan Kundu, R. Ramanathan, Eric Nyberg",data/paper_jsons/Eric Nyberg_144287919.json,
TLDR of the most cited paper from Eric Nyberg?,InPars-light is the first truly cost-effective prompt-based unsupervised recipe to train and deploy neural ranking models that outperform BM25.,data/paper_jsons/Eric Nyberg_144287919.json,
Abstract of the most cited paper from Eric Nyberg?,"We carried out a reproducibility study of InPars, which is a method for unsupervised training of neural rankers (Bonifacio et al., 2022). As a by-product, we developed InPars-light, which is a simple-yet-effective modification of InPars. Unlike InPars, InPars-light uses 7x-100x smaller ranking models and only a freely available language model BLOOM, which -- as we found out -- produced more accurate rankers compared to a proprietary GPT-3 model. On all five English retrieval collections (used in the original InPars study) we obtained substantial (7%-30%) and statistically significant improvements over BM25 (in nDCG and MRR) using only a 30M parameter six-layer MiniLM-30M ranker and a single three-shot prompt. In contrast, in the InPars study only a 100x larger monoT5-3B model consistently outperformed BM25, whereas their smaller monoT5-220M model (which is still 7x larger than our MiniLM ranker) outperformed BM25 only on MS MARCO and TREC DL 2020. In the same three-shot prompting scenario, our 435M parameter DeBERTA v3 ranker was at par with the 7x larger monoT5-3B (average gain over BM25 of 1.3 vs 1.32): In fact, on three out of five datasets, DeBERTA slightly outperformed monoT5-3B. Finally, these good results were achieved by re-ranking only 100 candidate documents compared to 1000 used by Bonifacio et al. (2022). We believe that InPars-light is the first truly cost-effective prompt-based unsupervised recipe to train and deploy neural ranking models that outperform BM25. Our code and data is publicly available. https://github.com/searchivarius/inpars_light/",data/paper_jsons/Eric Nyberg_144287919.json,
"What journal was the paper ""GameQA: Gamified Mobile App Platform for Building Multiple-Domain Question-Answering Datasets"" published in?",,Eric Nyberg_144287919.json,
"What venue was the paper ""GameQA: Gamified Mobile App Platform for Building Multiple-Domain Question-Answering Datasets"" published in?",Conference of the European Chapter of the Association for Computational Linguistics,Eric Nyberg_144287919.json,
"How many citations does the paper ""GameQA: Gamified Mobile App Platform for Building Multiple-Domain Question-Answering Datasets"" have?",0,Eric Nyberg_144287919.json,
"Who are the authors of the paper ""GameQA: Gamified Mobile App Platform for Building Multiple-Domain Question-Answering Datasets""?","Njall Skarphedinsson, Breki Gudmundsson, Steinar Smari, M. Lárusdóttir, H. Einarsson, Abuzar Khan, Eric Nyberg, H. Loftsson",Eric Nyberg_144287919.json,
"Who is the first author of the paper ""GameQA: Gamified Mobile App Platform for Building Multiple-Domain Question-Answering Datasets""?",Njall Skarphedinsson,Eric Nyberg_144287919.json,
"What is the paper ID of the paper ""GameQA: Gamified Mobile App Platform for Building Multiple-Domain Question-Answering Datasets""?",0f008e07d601e8f21d1df5db3d36e85484840083,Eric Nyberg_144287919.json,
What paper has the paper ID 0f008e07d601e8f21d1df5db3d36e85484840083?,GameQA: Gamified Mobile App Platform for Building Multiple-Domain Question-Answering Datasets,Eric Nyberg_144287919.json,
What is the TLDR of the paper 'GameQA: Gamified Mobile App Platform for Building Multiple-Domain Question-Answering Datasets'?,This work developed a novel crowd-sourcing platform to gather multiple-domain QA data for low-resource languages and successfully released the app for Icelandic to build a dataset which rivals large QA datasets for high- resource languages both in terms of size and ratio of answered questions.,Eric Nyberg_144287919.json,
What is the abstract of the paper 'GameQA: Gamified Mobile App Platform for Building Multiple-Domain Question-Answering Datasets'?,"The methods used to create many of the well-known Question-Answering (QA) datasets are hard to replicate for low-resource languages. A commonality amongst these methods is hiring annotators to source answers from the internet by querying a single answer source, such as Wikipedia. Applying these methods for low-resource languages can be problematic since there is no single large answer source for these languages. Consequently, this can result in a high ratio of unanswered questions, since the amount of information in any single source is limited. To address this problem, we developed a novel crowd-sourcing platform to gather multiple-domain QA data for low-resource languages. Our platform, which consists of a mobile app and a web API, gamifies the data collection process. We successfully released the app for Icelandic (a low-resource language with about 350,000 native speakers) to build a dataset which rivals large QA datasets for high-resource languages both in terms of size and ratio of answered questions. We have made the platform open source with instructions on how to localize and deploy it to gather data for other low-resource languages.",Eric Nyberg_144287919.json,
"What journal was the paper ""Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA"" published in?",Proceedings of the Third DialDoc Workshop on Document-grounded Dialogue and Conversational Question Answering,Eric Nyberg_144287919.json,
"What venue was the paper ""Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA"" published in?",Workshop on Document-grounded Dialogue and Conversational Question Answering,Eric Nyberg_144287919.json,
"How many citations does the paper ""Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA"" have?",2,Eric Nyberg_144287919.json,
"Who are the authors of the paper ""Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA""?","Srinivas Gowriraj, Soham Dinesh Tiwari, Mitali Potnis, Srijan Bansal, T. Mitamura, Eric Nyberg",Eric Nyberg_144287919.json,
"Who is the first author of the paper ""Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA""?",Srinivas Gowriraj,Eric Nyberg_144287919.json,
"What is the paper ID of the paper ""Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA""?",444737639aeea4e1e616509e368afb0bae8f89d6,Eric Nyberg_144287919.json,
What paper has the paper ID 444737639aeea4e1e616509e368afb0bae8f89d6?,Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA,Eric Nyberg_144287919.json,
What is the TLDR of the paper 'Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA'?,"This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-gnostic approach is superior.",Eric Nyberg_144287919.json,
What is the abstract of the paper 'Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA'?,"The DialDoc 2023 shared task has expanded the document-grounded dialogue task to encompass multiple languages, despite having limited annotated data. This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-agnostic approach is superior. Additionally, the study investigates the impact of query rewriting techniques using large language models, such as ChatGPT, on multilingual, document-grounded question-answering systems. The experiments conducted demonstrate that, for the examples examined, query rewriting does not enhance performance compared to the original queries. This failure is due to topic switching in final dialogue turns and irrelevant topics being considered for query rewriting.",Eric Nyberg_144287919.json,
"What journal was the paper ""Chain-of-Skills: A Configurable Model for Open-Domain Question Answering"" published in?",,Eric Nyberg_144287919.json,
"What venue was the paper ""Chain-of-Skills: A Configurable Model for Open-Domain Question Answering"" published in?",Annual Meeting of the Association for Computational Linguistics,Eric Nyberg_144287919.json,
"How many citations does the paper ""Chain-of-Skills: A Configurable Model for Open-Domain Question Answering"" have?",6,Eric Nyberg_144287919.json,
"Who are the authors of the paper ""Chain-of-Skills: A Configurable Model for Open-Domain Question Answering""?","Kaixin Ma, Hao Cheng, Yu Zhang, Xiaodong Liu, Eric Nyberg, Jianfeng Gao",Eric Nyberg_144287919.json,
"Who is the first author of the paper ""Chain-of-Skills: A Configurable Model for Open-Domain Question Answering""?",Kaixin Ma,Eric Nyberg_144287919.json,
"What is the paper ID of the paper ""Chain-of-Skills: A Configurable Model for Open-Domain Question Answering""?",61354e45bca908ad08f24e44bd507b4e1c958e6f,Eric Nyberg_144287919.json,
What paper has the paper ID 61354e45bca908ad08f24e44bd507b4e1c958e6f?,Chain-of-Skills: A Configurable Model for Open-Domain Question Answering,Eric Nyberg_144287919.json,
What is the TLDR of the paper 'Chain-of-Skills: A Configurable Model for Open-Domain Question Answering'?,"This work proposes a modular retriever where individual modules correspond to key skills that can be reused across datasets and achieves state-of-the-art fine-tuned retrieval performance on NQ, HotpotQA and OTT-QA.",Eric Nyberg_144287919.json,
What is the abstract of the paper 'Chain-of-Skills: A Configurable Model for Open-Domain Question Answering'?,"The retrieval model is an indispensable component for real-world knowledge-intensive tasks, e.g., open-domain question answering (ODQA). As separate retrieval skills are annotated for different datasets, recent work focuses on customized methods, limiting the model transfer- ability and scalability. In this work, we propose a modular retriever where individual modules correspond to key skills that can be reused across datasets. Our approach supports flexible skill configurations based on the target domain to boost performance. To mitigate task interference, we design a novel modularization parameterization inspired by sparse Transformer. We demonstrate that our model can benefit from self-supervised pretraining on Wikipedia and fine-tuning using multiple ODQA datasets, both in a multi-task fashion. Our approach outperforms recent self-supervised retrievers in zero-shot evaluations and achieves state-of-the-art fine-tuned retrieval performance on NQ, HotpotQA and OTT-QA.",Eric Nyberg_144287919.json,
What is the author ID of Fernando-Diaz?,145472333,data/paper_jsons/Fernando Diaz_145472333.json,
What are the papers of Fernando-Diaz?,"Best-Case Retrieval Evaluation: Improving the Sensitivity of Reciprocal Rank with Lexicographic Precision, Fairness Through Domain Awareness: Mitigating Popularity Bias For Music Discovery, Overview of the TREC 2021 Fair Ranking Track",data/paper_jsons/Fernando Diaz_145472333.json,
What is the H-index of Fernando-Diaz?,45,data/paper_jsons/Fernando Diaz_145472333.json,
What is the author citation count of Fernando-Diaz?,7996,data/paper_jsons/Fernando Diaz_145472333.json,
What journals has Fernando-Diaz published in?,ArXiv,data/paper_jsons/Fernando Diaz_145472333.json,
What are the journals and how many papers has Fernando-Diaz published in each?,{'ArXiv': 3},data/paper_jsons/Fernando Diaz_145472333.json,
What are the fields of study of Fernando-Diaz?,Computer Science,data/paper_jsons/Fernando Diaz_145472333.json,
How many papers has Fernando-Diaz published in open access journals?,3,data/paper_jsons/Fernando Diaz_145472333.json,
What venues has Fernando-Diaz published in?,"arXiv.org, Text Retrieval Conference",data/paper_jsons/Fernando Diaz_145472333.json,
What is the most cited paper from Fernando-Diaz?,Overview of the TREC 2021 Fair Ranking Track,data/paper_jsons/Fernando Diaz_145472333.json,
What is the url of the most cited paper from Fernando-Diaz?,http://arxiv.org/pdf/2302.10856,data/paper_jsons/Fernando Diaz_145472333.json,
Who are the authors of the most cited paper from Fernando-Diaz?,"Asia J. Biega, Fernando Diaz, Michael D. Ekstrand, Sebastian Kohlmeier",data/paper_jsons/Fernando Diaz_145472333.json,
TLDR of the most cited paper from Fernando-Diaz?,"The 2021 Fair Ranking track aimed to ensure that documents that are about, or somehow represent, certain protected characteristics receive a fair exposure to the Wikipedia editors, so that the documents have an fair opportunity of being improved and, therefore, be well-represented in Wikipedia.",data/paper_jsons/Fernando Diaz_145472333.json,
Abstract of the most cited paper from Fernando-Diaz?,"The TREC Fair Ranking Track aims to provide a platform for participants to develop and evaluate novel retrieval algorithms that can provide a fair exposure to a mixture of demographics or attributes, such as ethnicity, that are represented by relevant documents in response to a search query. For example, particular demographics or attributes can be represented by the documents' topical content or authors. The 2021 Fair Ranking Track adopted a resource allocation task. The task focused on supporting Wikipedia editors who are looking to improve the encyclopedia's coverage of topics under the purview of a WikiProject. WikiProject coordinators and/or Wikipedia editors search for Wikipedia documents that are in need of editing to improve the quality of the article. The 2021 Fair Ranking track aimed to ensure that documents that are about, or somehow represent, certain protected characteristics receive a fair exposure to the Wikipedia editors, so that the documents have an fair opportunity of being improved and, therefore, be well-represented in Wikipedia. The under-representation of particular protected characteristics in Wikipedia can result in systematic biases that can have a negative human, social, and economic impact, particularly for disadvantaged or protected societal groups.",data/paper_jsons/Fernando Diaz_145472333.json,
"What journal was the paper ""Overview of the TREC 2021 Fair Ranking Track"" published in?",ArXiv,Fernando Diaz_145472333.json,
"What venue was the paper ""Overview of the TREC 2021 Fair Ranking Track"" published in?",Text Retrieval Conference,Fernando Diaz_145472333.json,
"How many citations does the paper ""Overview of the TREC 2021 Fair Ranking Track"" have?",28,Fernando Diaz_145472333.json,
"Who are the authors of the paper ""Overview of the TREC 2021 Fair Ranking Track""?","Asia J. Biega, Fernando Diaz, Michael D. Ekstrand, Sebastian Kohlmeier",Fernando Diaz_145472333.json,
"Who is the first author of the paper ""Overview of the TREC 2021 Fair Ranking Track""?",Asia J. Biega,Fernando Diaz_145472333.json,
"What is the paper ID of the paper ""Overview of the TREC 2021 Fair Ranking Track""?",5e1ba2d4416333dd6f6a31a4ff4221b40dfb74b1,Fernando Diaz_145472333.json,
What paper has the paper ID 5e1ba2d4416333dd6f6a31a4ff4221b40dfb74b1?,Overview of the TREC 2021 Fair Ranking Track,Fernando Diaz_145472333.json,
What is the TLDR of the paper 'Overview of the TREC 2021 Fair Ranking Track'?,"The 2021 Fair Ranking track aimed to ensure that documents that are about, or somehow represent, certain protected characteristics receive a fair exposure to the Wikipedia editors, so that the documents have an fair opportunity of being improved and, therefore, be well-represented in Wikipedia.",Fernando Diaz_145472333.json,
What is the abstract of the paper 'Overview of the TREC 2021 Fair Ranking Track'?,"The TREC Fair Ranking Track aims to provide a platform for participants to develop and evaluate novel retrieval algorithms that can provide a fair exposure to a mixture of demographics or attributes, such as ethnicity, that are represented by relevant documents in response to a search query. For example, particular demographics or attributes can be represented by the documents' topical content or authors. The 2021 Fair Ranking Track adopted a resource allocation task. The task focused on supporting Wikipedia editors who are looking to improve the encyclopedia's coverage of topics under the purview of a WikiProject. WikiProject coordinators and/or Wikipedia editors search for Wikipedia documents that are in need of editing to improve the quality of the article. The 2021 Fair Ranking track aimed to ensure that documents that are about, or somehow represent, certain protected characteristics receive a fair exposure to the Wikipedia editors, so that the documents have an fair opportunity of being improved and, therefore, be well-represented in Wikipedia. The under-representation of particular protected characteristics in Wikipedia can result in systematic biases that can have a negative human, social, and economic impact, particularly for disadvantaged or protected societal groups.",Fernando Diaz_145472333.json,
"What journal was the paper ""Fairness Through Domain Awareness: Mitigating Popularity Bias For Music Discovery"" published in?",ArXiv,Fernando Diaz_145472333.json,
"What venue was the paper ""Fairness Through Domain Awareness: Mitigating Popularity Bias For Music Discovery"" published in?",arXiv.org,Fernando Diaz_145472333.json,
"How many citations does the paper ""Fairness Through Domain Awareness: Mitigating Popularity Bias For Music Discovery"" have?",0,Fernando Diaz_145472333.json,
"Who are the authors of the paper ""Fairness Through Domain Awareness: Mitigating Popularity Bias For Music Discovery""?","Rebecca Salganik, Fernando Diaz, G. Farnadi",Fernando Diaz_145472333.json,
"Who is the first author of the paper ""Fairness Through Domain Awareness: Mitigating Popularity Bias For Music Discovery""?",Rebecca Salganik,Fernando Diaz_145472333.json,
"What is the paper ID of the paper ""Fairness Through Domain Awareness: Mitigating Popularity Bias For Music Discovery""?",567f6bc975deb3d728feec9bfcf7d4036ceabb12,Fernando Diaz_145472333.json,
What paper has the paper ID 567f6bc975deb3d728feec9bfcf7d4036ceabb12?,Fairness Through Domain Awareness: Mitigating Popularity Bias For Music Discovery,Fernando Diaz_145472333.json,
What is the TLDR of the paper 'Fairness Through Domain Awareness: Mitigating Popularity Bias For Music Discovery'?,"This work proposes a domain-aware, individual fairness-based approach which addresses popularity bias in graph neural network (GNNs) based recommender systems and applies the BOOST methodology to two discovery based tasks, performing recommendations at both the playlist level and user level.",Fernando Diaz_145472333.json,
What is the abstract of the paper 'Fairness Through Domain Awareness: Mitigating Popularity Bias For Music Discovery'?,"As online music platforms grow, music recommender systems play a vital role in helping users navigate and discover content within their vast musical databases. At odds with this larger goal, is the presence of popularity bias, which causes algorithmic systems to favor mainstream content over, potentially more relevant, but niche items. In this work we explore the intrinsic relationship between music discovery and popularity bias. To mitigate this issue we propose a domain-aware, individual fairness-based approach which addresses popularity bias in graph neural network (GNNs) based recommender systems. Our approach uses individual fairness to reflect a ground truth listening experience, i.e., if two songs sound similar, this similarity should be reflected in their representations. In doing so, we facilitate meaningful music discovery that is robust to popularity bias and grounded in the music domain. We apply our BOOST methodology to two discovery based tasks, performing recommendations at both the playlist level and user level. Then, we ground our evaluation in the cold start setting, showing that our approach outperforms existing fairness benchmarks in both performance and recommendation of lesser-known content. Finally, our analysis explains why our proposed methodology is a novel and promising approach to mitigating popularity bias and improving the discovery of new and niche content in music recommender systems.",Fernando Diaz_145472333.json,
"What journal was the paper ""Best-Case Retrieval Evaluation: Improving the Sensitivity of Reciprocal Rank with Lexicographic Precision"" published in?",ArXiv,Fernando Diaz_145472333.json,
"What venue was the paper ""Best-Case Retrieval Evaluation: Improving the Sensitivity of Reciprocal Rank with Lexicographic Precision"" published in?",arXiv.org,Fernando Diaz_145472333.json,
"How many citations does the paper ""Best-Case Retrieval Evaluation: Improving the Sensitivity of Reciprocal Rank with Lexicographic Precision"" have?",2,Fernando Diaz_145472333.json,
"Who are the authors of the paper ""Best-Case Retrieval Evaluation: Improving the Sensitivity of Reciprocal Rank with Lexicographic Precision""?",Fernando Diaz,Fernando Diaz_145472333.json,
"Who is the first author of the paper ""Best-Case Retrieval Evaluation: Improving the Sensitivity of Reciprocal Rank with Lexicographic Precision""?",Fernando Diaz,Fernando Diaz_145472333.json,
"What is the paper ID of the paper ""Best-Case Retrieval Evaluation: Improving the Sensitivity of Reciprocal Rank with Lexicographic Precision""?",55704caaf3d31e1795a1ca0c3bed9e77ae3a3c95,Fernando Diaz_145472333.json,
What paper has the paper ID 55704caaf3d31e1795a1ca0c3bed9e77ae3a3c95?,Best-Case Retrieval Evaluation: Improving the Sensitivity of Reciprocal Rank with Lexicographic Precision,Fernando Diaz_145472333.json,
What is the TLDR of the paper 'Best-Case Retrieval Evaluation: Improving the Sensitivity of Reciprocal Rank with Lexicographic Precision'?,"This work addresses the lack of sensitivity of reciprocal rank by introducing and connecting it to the concept of best-case retrieval, an evaluation method focusing on assessing the quality of a ranking for the most satisfied possible user across possible recall requirements.",Fernando Diaz_145472333.json,
What is the abstract of the paper 'Best-Case Retrieval Evaluation: Improving the Sensitivity of Reciprocal Rank with Lexicographic Precision'?,"Across a variety of ranking tasks, researchers use reciprocal rank to measure the effectiveness for users interested in exactly one relevant item. Despite its widespread use, evidence suggests that reciprocal rank is brittle when discriminating between systems. This brittleness, in turn, is compounded in modern evaluation settings where current, high-precision systems may be difficult to distinguish. We address the lack of sensitivity of reciprocal rank by introducing and connecting it to the concept of best-case retrieval, an evaluation method focusing on assessing the quality of a ranking for the most satisfied possible user across possible recall requirements. This perspective allows us to generalize reciprocal rank and define a new preference-based evaluation we call lexicographic precision or lexiprecision. By mathematical construction, we ensure that lexiprecision preserves differences detected by reciprocal rank, while empirically improving sensitivity and robustness across a broad set of retrieval and recommendation tasks.",Fernando Diaz_145472333.json,
What is the author ID of Graham Neubig?,1700325,data/paper_jsons/Graham Neubig_1700325.json,
What are the papers of Graham Neubig?,"Cross-Modal Fine-Tuning: Align then Refine, ChatGPT MT: Competitive for High- (but Not Low-) Resource Languages, GlobalBench: A Benchmark for Global Progress in Natural Language Processing, Learning Performance-Improving Code Edits, CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code, Neural Machine Translation for the Indigenous Languages of the Americas: An Introduction, User-Centric Evaluation of OCR Systems for Kwak’wala, Multi-Dimensional Evaluation of Text Summarization with In-Context Learning, A Gold Standard Dataset for the Reviewer Assignment Problem, SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing, Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation, FacTool: Factuality Detection in Generative AI - A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios, Active Retrieval Augmented Generation, Large Language Models Enable Few-Shot Clustering, Solving NLP Problems through Human-System Collaboration: A Discussion-based Approach, Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting, Why do Nearest Neighbor Language Models Work?, Syntax and Semantics Meet in the “Middle”: Probing the Syntax-Semantics Interface of LMs Through Agentivity, DataFinder: Scientific Dataset Recommendation from Natural Language Descriptions, Multi-lingual and Multi-cultural Figurative Language Understanding, It’s MBR All the Way Down: Modern Generation Techniques Through the Lens of Minimum Bayes Risk, Unlimiformer: Long-Range Transformers with Unlimited Length Input, WebArena: A Realistic Web Environment for Building Autonomous Agents, Prompt2Model: Generating Deployable Models from Natural Language Instructions, Computational Language Acquisition with Theory of Mind, Improving Factuality of Abstractive Summarization via Contrastive Reward Learning, The Devil Is in the Errors: Leveraging Large Language Models for Fine-grained Machine Translation Evaluation",data/paper_jsons/Graham Neubig_1700325.json,
What is the H-index of Graham Neubig?,75,data/paper_jsons/Graham Neubig_1700325.json,
What is the author citation count of Graham Neubig?,24256,data/paper_jsons/Graham Neubig_1700325.json,
What journals has Graham Neubig published in?,ArXiv,data/paper_jsons/Graham Neubig_1700325.json,
What are the journals and how many papers has Graham Neubig published in each?,{'ArXiv': 19},data/paper_jsons/Graham Neubig_1700325.json,
What are the fields of study of Graham Neubig?,"Computer Science, Mathematics",data/paper_jsons/Graham Neubig_1700325.json,
How many papers has Graham Neubig published in open access journals?,27,data/paper_jsons/Graham Neubig_1700325.json,
What venues has Graham Neubig published in?,"International Conference on Machine Learning, Conference on Machine Translation, Conference on Empirical Methods in Natural Language Processing, arXiv.org, AMERICASNLP, COMPUTEL, Annual Meeting of the Association for Computational Linguistics, Special Interest Group on Computational Morphology and Phonology Workshop, STARSEM, BIGPICTURE, International Conference on Learning Representations, TRUSTNLP",data/paper_jsons/Graham Neubig_1700325.json,
What is the most cited paper from Graham Neubig?,WebArena: A Realistic Web Environment for Building Autonomous Agents,data/paper_jsons/Graham Neubig_1700325.json,
What is the url of the most cited paper from Graham Neubig?,https://arxiv.org/pdf/2307.13854,data/paper_jsons/Graham Neubig_1700325.json,
Who are the authors of the most cited paper from Graham Neubig?,"Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, Graham Neubig",data/paper_jsons/Graham Neubig_1700325.json,
TLDR of the most cited paper from Graham Neubig?,"This paper builds an environment for language-guided agents that is highly realistic and reproducible, and creates an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management.",data/paper_jsons/Graham Neubig_1700325.json,
Abstract of the most cited paper from Graham Neubig?,"With advances in generative AI, there is now potential for autonomous agents to manage daily tasks via natural language commands. However, current agents are primarily created and tested in simplified synthetic environments, leading to a disconnect with real-world scenarios. In this paper, we build an environment for language-guided agents that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on the web, and create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our environment is enriched with tools (e.g., a map) and external knowledge bases (e.g., user manuals) to encourage human-like task-solving. Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and designed to emulate tasks that humans routinely perform on the internet. We experiment with several baseline agents, integrating recent techniques such as reasoning before acting. The results demonstrate that solving complex tasks is challenging: our best GPT-4-based agent only achieves an end-to-end task success rate of 14.41%, significantly lower than the human performance of 78.24%. These results highlight the need for further development of robust agents, that current state-of-the-art large language models are far from perfect performance in these real-life tasks, and that WebArena can be used to measure such progress.",data/paper_jsons/Graham Neubig_1700325.json,
"What journal was the paper ""DataFinder: Scientific Dataset Recommendation from Natural Language Descriptions"" published in?",ArXiv,Graham Neubig_1700325.json,
"What venue was the paper ""DataFinder: Scientific Dataset Recommendation from Natural Language Descriptions"" published in?",Annual Meeting of the Association for Computational Linguistics,Graham Neubig_1700325.json,
"How many citations does the paper ""DataFinder: Scientific Dataset Recommendation from Natural Language Descriptions"" have?",3,Graham Neubig_1700325.json,
"Who are the authors of the paper ""DataFinder: Scientific Dataset Recommendation from Natural Language Descriptions""?","Vijay Viswanathan, Luyu Gao, Tongshuang Sherry Wu, Pengfei Liu, Graham Neubig",Graham Neubig_1700325.json,
"Who is the first author of the paper ""DataFinder: Scientific Dataset Recommendation from Natural Language Descriptions""?",Vijay Viswanathan,Graham Neubig_1700325.json,
"What is the paper ID of the paper ""DataFinder: Scientific Dataset Recommendation from Natural Language Descriptions""?",cc1705fe421c70d85254b557634bd4669fdd49b0,Graham Neubig_1700325.json,
What paper has the paper ID cc1705fe421c70d85254b557634bd4669fdd49b0?,DataFinder: Scientific Dataset Recommendation from Natural Language Descriptions,Graham Neubig_1700325.json,
What is the TLDR of the paper 'DataFinder: Scientific Dataset Recommendation from Natural Language Descriptions'?,"This work operationalizes the task of recommending datasets given a short natural language description of a research idea, to help people find relevant datasets for their needs, and builds the DataFinder Dataset, a larger automatically-constructed training set and a smaller expert-annotated evaluation set.",Graham Neubig_1700325.json,
What is the abstract of the paper 'DataFinder: Scientific Dataset Recommendation from Natural Language Descriptions'?,"Modern machine learning relies on datasets to develop and validate research ideas. Given the growth of publicly available data, finding the right dataset to use is increasingly difficult. Any research question imposes explicit and implicit constraints on how well a given dataset will enable researchers to answer this question, such as dataset size, modality, and domain. We operationalize the task of recommending datasets given a short natural language description of a research idea, to help people find relevant datasets for their needs. Dataset recommendation poses unique challenges as an information retrieval problem; datasets are hard to directly index for search and there are no corpora readily available for this task. To facilitate this task, we build the DataFinder Dataset which consists of a larger automatically-constructed training set (17.5K queries) and a smaller expert-annotated evaluation set (392 queries). Using this data, we compare various information retrieval algorithms on our test set and present a superior bi-encoder retriever for text-based dataset recommendation. This system, trained on the DataFinder Dataset, finds more relevant search results than existing third-party dataset search engines. To encourage progress on dataset recommendation, we release our dataset and models to the public.",Graham Neubig_1700325.json,
"What journal was the paper ""Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting"" published in?",,Graham Neubig_1700325.json,
"What venue was the paper ""Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting"" published in?",Conference on Empirical Methods in Natural Language Processing,Graham Neubig_1700325.json,
"How many citations does the paper ""Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting"" have?",0,Graham Neubig_1700325.json,
"Who are the authors of the paper ""Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting""?","Emmy Liu, Aditi Chaudhary, Graham Neubig",Graham Neubig_1700325.json,
"Who is the first author of the paper ""Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting""?",Emmy Liu,Graham Neubig_1700325.json,
"What is the paper ID of the paper ""Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting""?",b4987da792dd45a84232cfb06d71b1c2ec488f38,Graham Neubig_1700325.json,
What paper has the paper ID b4987da792dd45a84232cfb06d71b1c2ec488f38?,Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting,Graham Neubig_1700325.json,
What is the TLDR of the paper 'Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting'?,"To improve translation of natural idioms, this work introduces two straightforward yet effective techniques: the strategic upweighting of training loss on potentially idiomatic sentences, and using retrieval-augmented models.",Graham Neubig_1700325.json,
What is the abstract of the paper 'Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting'?,"Idioms are common in everyday language, but often pose a challenge to translators because their meanings do not follow from the meanings of their parts. Despite significant advances, machine translation systems still struggle to translate idiomatic expressions. We provide a simple characterization of idiomatic translation and related issues. This allows us to conduct a synthetic experiment revealing a tipping point at which transformer-based machine translation models correctly default to idiomatic translations. To expand multilingual resources, we compile a dataset of ~4k natural sentences containing idiomatic expressions in French, Finnish, and Japanese. To improve translation of natural idioms, we introduce two straightforward yet effective techniques: the strategic upweighting of training loss on potentially idiomatic sentences, and using retrieval-augmented models. This not only improves the accuracy of a strong pretrained MT model on idiomatic sentences by up to 13% in absolute accuracy, but also holds potential benefits for non-idiomatic sentences.",Graham Neubig_1700325.json,
"What journal was the paper ""Prompt2Model: Generating Deployable Models from Natural Language Instructions"" published in?",ArXiv,Graham Neubig_1700325.json,
"What venue was the paper ""Prompt2Model: Generating Deployable Models from Natural Language Instructions"" published in?",Conference on Empirical Methods in Natural Language Processing,Graham Neubig_1700325.json,
"How many citations does the paper ""Prompt2Model: Generating Deployable Models from Natural Language Instructions"" have?",5,Graham Neubig_1700325.json,
"Who are the authors of the paper ""Prompt2Model: Generating Deployable Models from Natural Language Instructions""?","Vijay Viswanathan, Chenyang Zhao, Amanda Bertsch, Tongshuang Sherry Wu, Graham Neubig",Graham Neubig_1700325.json,
"Who is the first author of the paper ""Prompt2Model: Generating Deployable Models from Natural Language Instructions""?",Vijay Viswanathan,Graham Neubig_1700325.json,
"What is the paper ID of the paper ""Prompt2Model: Generating Deployable Models from Natural Language Instructions""?",e69684fb06a7b1fe621d7ef0c97fc2ca0e122c43,Graham Neubig_1700325.json,
What paper has the paper ID e69684fb06a7b1fe621d7ef0c97fc2ca0e122c43?,Prompt2Model: Generating Deployable Models from Natural Language Instructions,Graham Neubig_1700325.json,
What is the TLDR of the paper 'Prompt2Model: Generating Deployable Models from Natural Language Instructions'?,"This paper proposes Prompt2Model, a general-purpose method that takes a natural language task description like the prompts provided to LLMs, and uses it to train a special-purpose model that is conducive to deployment.",Graham Neubig_1700325.json,
What is the abstract of the paper 'Prompt2Model: Generating Deployable Models from Natural Language Instructions'?,"Large language models (LLMs) enable system builders today to create competent NLP systems through prompting, where they only need to describe the task in natural language and provide a few examples. However, in other ways, LLMs are a step backward from traditional special-purpose NLP models; they require extensive computational resources for deployment and can be gated behind APIs. In this paper, we propose Prompt2Model, a general-purpose method that takes a natural language task description like the prompts provided to LLMs, and uses it to train a special-purpose model that is conducive to deployment. This is done through a multi-step process of retrieval of existing datasets and pretrained models, dataset generation using LLMs, and supervised fine-tuning on these retrieved and generated datasets. Over three tasks, we demonstrate that given the same few-shot prompt as input, Prompt2Model trains models that outperform the results of a strong LLM, gpt-3.5-turbo, by an average of 20% while being up to 700 times smaller. We also show that this data can be used to obtain reliable performance estimates of model performance, enabling model developers to assess model reliability before deployment. Prompt2Model is available open-source at https://github.com/neulab/prompt2model.",Graham Neubig_1700325.json,
What is the author ID of Jamie Callan?,144987107,data/paper_jsons/Jamie Callan_144987107.json,
What are the papers of Jamie Callan?,"Conversational Search with Random Walks over Entity Graphs, KALE: Using a K-Sparse Projector for Lexical Expansion, CSurF: Sparse Lexical Retrieval through Contextualized Surface Forms, Active Retrieval Augmented Generation, Multi-Objective Improvement of Android Applications",data/paper_jsons/Jamie Callan_144987107.json,
What is the H-index of Jamie Callan?,75,data/paper_jsons/Jamie Callan_144987107.json,
What is the author citation count of Jamie Callan?,19329,data/paper_jsons/Jamie Callan_144987107.json,
What journals has Jamie Callan published in?,"Proceedings of the 2023 ACM SIGIR International Conference on Theory of Information Retrieval, ArXiv",data/paper_jsons/Jamie Callan_144987107.json,
What are the journals and how many papers has Jamie Callan published in each?,"{'Proceedings of the 2023 ACM SIGIR International Conference on Theory of Information Retrieval': 3, 'ArXiv': 2}",data/paper_jsons/Jamie Callan_144987107.json,
What are the fields of study of Jamie Callan?,Computer Science,data/paper_jsons/Jamie Callan_144987107.json,
How many papers has Jamie Callan published in open access journals?,5,data/paper_jsons/Jamie Callan_144987107.json,
What venues has Jamie Callan published in?,"International Conference on the Theory of Information Retrieval, Conference on Empirical Methods in Natural Language Processing, arXiv.org",data/paper_jsons/Jamie Callan_144987107.json,
What is the most cited paper from Jamie Callan?,Active Retrieval Augmented Generation,data/paper_jsons/Jamie Callan_144987107.json,
What is the url of the most cited paper from Jamie Callan?,http://arxiv.org/pdf/2305.06983,data/paper_jsons/Jamie Callan_144987107.json,
Who are the authors of the most cited paper from Jamie Callan?,"Zhengbao Jiang, Frank F. Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan, Graham Neubig",data/paper_jsons/Jamie Callan_144987107.json,
TLDR of the most cited paper from Jamie Callan?,"This work proposes Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens.",data/paper_jsons/Jamie Callan_144987107.json,
Abstract of the most cited paper from Jamie Callan?,"Despite the remarkable ability of large language models (LMs) to comprehend and generate language, they have a tendency to hallucinate and create factually inaccurate output. Augmenting LMs by retrieving information from external knowledge resources is one promising solution. Most existing retrieval augmented LMs employ a retrieve-and-generate setup that only retrieves information once based on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout generation is essential. In this work, we provide a generalized view of active retrieval augmented generation, methods that actively decide when and what to retrieve across the course of the generation. We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens. We test FLARE along with baselines comprehensively over 4 long-form knowledge-intensive generation tasks/datasets. FLARE achieves superior or competitive performance on all tasks, demonstrating the effectiveness of our method. Code and datasets are available at https://github.com/jzbjyb/FLARE.",data/paper_jsons/Jamie Callan_144987107.json,
"What journal was the paper ""CSurF: Sparse Lexical Retrieval through Contextualized Surface Forms"" published in?",Proceedings of the 2023 ACM SIGIR International Conference on Theory of Information Retrieval,Jamie Callan_144987107.json,
"What venue was the paper ""CSurF: Sparse Lexical Retrieval through Contextualized Surface Forms"" published in?",International Conference on the Theory of Information Retrieval,Jamie Callan_144987107.json,
"How many citations does the paper ""CSurF: Sparse Lexical Retrieval through Contextualized Surface Forms"" have?",0,Jamie Callan_144987107.json,
"Who are the authors of the paper ""CSurF: Sparse Lexical Retrieval through Contextualized Surface Forms""?","Zhen Fan, Luyu Gao, Jamie Callan",Jamie Callan_144987107.json,
"Who is the first author of the paper ""CSurF: Sparse Lexical Retrieval through Contextualized Surface Forms""?",Zhen Fan,Jamie Callan_144987107.json,
"What is the paper ID of the paper ""CSurF: Sparse Lexical Retrieval through Contextualized Surface Forms""?",6b7eefa15c0a461afeab4fa13cf862c5340fdc2a,Jamie Callan_144987107.json,
What paper has the paper ID 6b7eefa15c0a461afeab4fa13cf862c5340fdc2a?,CSurF: Sparse Lexical Retrieval through Contextualized Surface Forms,Jamie Callan_144987107.json,
What is the TLDR of the paper 'CSurF: Sparse Lexical Retrieval through Contextualized Surface Forms'?,"This paper proposes to directly bridge the surface form space and the term semantics space in lexical exact-match retrieval via contextualized surface forms (CSF), reaching comparable accuracy as lexical all-to-all soft match systems as an efficient exact- match-based system.",Jamie Callan_144987107.json,
What is the abstract of the paper 'CSurF: Sparse Lexical Retrieval through Contextualized Surface Forms'?,"Lexical exact-match systems perform text retrieval efficiently with sparse matching signals and fast retrieval through inverted lists, but naturally suffer from the mismatch between lexical surface form and implicit term semantics. This paper proposes to directly bridge the surface form space and the term semantics space in lexical exact-match retrieval via contextualized surface forms (CSF). Each CSF pairs a lexical surface form with a context source, and is represented by a lexical form weight and a contextualized semantic vector representation. This framework is able to perform sparse lexicon-based retrieval by learning to represent each query and document as a ""bag-of-CSFs"", simultaneously addressing two key factors in sparse retrieval: vocabulary expansion of surface form and semantic representation of term meaning. At retrieval time, it efficiently matches CSFs through exact-match of learned surface forms, and effectively scores each CSF pair via contextual semantic representations, leading to joint improvement in both term match and term scoring. Multiple experiments show that this approach successfully resolves the main mismatch issues in lexical exact-match retrieval and outperforms state-of-the-art lexical exact-match systems, reaching comparable accuracy as lexical all-to-all soft match systems as an efficient exact-match-based system.",Jamie Callan_144987107.json,
"What journal was the paper ""KALE: Using a K-Sparse Projector for Lexical Expansion"" published in?",Proceedings of the 2023 ACM SIGIR International Conference on Theory of Information Retrieval,Jamie Callan_144987107.json,
"What venue was the paper ""KALE: Using a K-Sparse Projector for Lexical Expansion"" published in?",International Conference on the Theory of Information Retrieval,Jamie Callan_144987107.json,
"How many citations does the paper ""KALE: Using a K-Sparse Projector for Lexical Expansion"" have?",0,Jamie Callan_144987107.json,
"Who are the authors of the paper ""KALE: Using a K-Sparse Projector for Lexical Expansion""?","Luís Borges, Bruno Martins, Jamie Callan",Jamie Callan_144987107.json,
"Who is the first author of the paper ""KALE: Using a K-Sparse Projector for Lexical Expansion""?",Luís Borges,Jamie Callan_144987107.json,
"What is the paper ID of the paper ""KALE: Using a K-Sparse Projector for Lexical Expansion""?",1e0a4ff0c5d2d850ff5907e310ffcedc9cad9718,Jamie Callan_144987107.json,
What paper has the paper ID 1e0a4ff0c5d2d850ff5907e310ffcedc9cad9718?,KALE: Using a K-Sparse Projector for Lexical Expansion,Jamie Callan_144987107.json,
What is the TLDR of the paper 'KALE: Using a K-Sparse Projector for Lexical Expansion'?,"KALE is a new lightweight method that uses a small model with a k-sparse projector to convert dense representations into a sparse set of entries from a latent vocabulary, which can replace the original lexical vocabulary with gains in accuracy and efficiency.",Jamie Callan_144987107.json,
What is the abstract of the paper 'KALE: Using a K-Sparse Projector for Lexical Expansion'?,"Recent research has proposed retrieval approaches based on sparse representations and inverted indexes, with terms produced by neural language models and leveraging the advantages from both neural retrieval and lexical matching. This paper proposes KALE, a new lightweight method of this family that uses a small model with a k-sparse projector to convert dense representations into a sparse set of entries from a latent vocabulary. The KALE vocabulary captures semantic concepts than perform well when used in isolation, and perform better when extending the original lexical vocabulary, this way improving first-stage retrieval accuracy. Experiments with the MSMARCOv1 passage retrieval dataset, the TREC Deep Learning dataset, and BEIR datasets, examined the effectiveness of KALE under varying conditions. Results show that the KALE terms can replace the original lexical vocabulary, with gains in accuracy and efficiency. Combining KALE with the original lexical vocabulary, or with other learned terms, can further improve retrieval accuracy with only a modest increase in computational cost.",Jamie Callan_144987107.json,
"What journal was the paper ""Multi-Objective Improvement of Android Applications"" published in?",ArXiv,Jamie Callan_144987107.json,
"What venue was the paper ""Multi-Objective Improvement of Android Applications"" published in?",arXiv.org,Jamie Callan_144987107.json,
"How many citations does the paper ""Multi-Objective Improvement of Android Applications"" have?",0,Jamie Callan_144987107.json,
"Who are the authors of the paper ""Multi-Objective Improvement of Android Applications""?","Jamie Callan, J. Petke",Jamie Callan_144987107.json,
"Who is the first author of the paper ""Multi-Objective Improvement of Android Applications""?",Jamie Callan,Jamie Callan_144987107.json,
"What is the paper ID of the paper ""Multi-Objective Improvement of Android Applications""?",ac9ee72a5cd611e9143e385f668af662583721ee,Jamie Callan_144987107.json,
What paper has the paper ID ac9ee72a5cd611e9143e385f668af662583721ee?,Multi-Objective Improvement of Android Applications,Jamie Callan_144987107.json,
What is the TLDR of the paper 'Multi-Objective Improvement of Android Applications'?,"This work proposes a practical approach and the first open-source tool, GIDroid, for multi-objective automated improvement of Android apps, and uses Genetic improvement, a search-based technique that navigates the space of software variants to find improved software.",Jamie Callan_144987107.json,
What is the abstract of the paper 'Multi-Objective Improvement of Android Applications'?,"Non-functional properties, such as runtime or memory use, are important to mobile app users and developers, as they affect user experience. Previous work on automated improvement of non-functional properties in mobile apps failed to address the inherent trade-offs between such properties. We propose a practical approach and the first open-source tool, GIDroid (2023), for multi-objective automated improvement of Android apps. In particular, we use Genetic improvement, a search-based technique that navigates the space of software variants to find improved software. We use a simulation-based testing framework to greatly improve the speed of search. GIDroid contains three state-of-the-art multi-objective algorithms, and two new mutation operators, which cache the results of method calls. Genetic improvement relies on testing to validate patches. Previous work showed that tests in open-source Android applications are scarce. We thus wrote tests for 21 versions of 7 Android apps, creating a new benchmark for performance improvements. We used GIDroid to improve versions of mobile apps where developers had previously found improvements to runtime, memory, and bandwidth use. Our technique automatically re-discovers 64% of existing improvements. We then applied our approach to current versions of software in which there were no known improvements. We were able to improve execution time by up to 35%, and memory use by up to 33% in these apps.",Jamie Callan_144987107.json,
What is the author ID of Jeffrey Bigham?,1744846,data/paper_jsons/Jeffrey P. Bigham_1744846.json,
What are the papers of Jeffrey Bigham?,"Screen Correspondence: Mapping Interchangeable Elements between UIs, Exploring Stigmergic Collaboration and Task Modularity Through an Expert Crowdsourcing Annotation System: The Case of Storm Phenomena in the Euro-Atlantic Region, Nonverbal Communication through Expressive Objects, USB: A Unified Summarization Benchmark Across Tasks and Domains, WebUI: A Dataset for Enhancing Visual UI Understanding with Web Semantics, Never-ending Learning of User Interfaces, Latent Phrase Matching for Dysarthric Speech, From User Perceptions to Technical Improvement: Enabling People Who Stutter to Better Use Speech Recognition",data/paper_jsons/Jeffrey P. Bigham_1744846.json,
What is the H-index of Jeffrey Bigham?,56,data/paper_jsons/Jeffrey P. Bigham_1744846.json,
What is the author citation count of Jeffrey Bigham?,10897,data/paper_jsons/Jeffrey P. Bigham_1744846.json,
What journals has Jeffrey Bigham published in?,"ArXiv, IEEE Access, Communications of the ACM, Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems, Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology",data/paper_jsons/Jeffrey P. Bigham_1744846.json,
What are the journals and how many papers has Jeffrey Bigham published in each?,"{'ArXiv': 2, 'Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems': 2, 'IEEE Access': 1, 'Communications of the ACM': 1, 'Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology': 1}",data/paper_jsons/Jeffrey P. Bigham_1744846.json,
What are the fields of study of Jeffrey Bigham?,"Computer Science, Engineering",data/paper_jsons/Jeffrey P. Bigham_1744846.json,
How many papers has Jeffrey Bigham published in open access journals?,8,data/paper_jsons/Jeffrey P. Bigham_1744846.json,
What venues has Jeffrey Bigham published in?,"arXiv.org, IEEE Access, Communications of the ACM, Conference on Empirical Methods in Natural Language Processing, International Conference on Human Factors in Computing Systems, ACM Symposium on User Interface Software and Technology, Interspeech",data/paper_jsons/Jeffrey P. Bigham_1744846.json,
What is the most cited paper from Jeffrey Bigham?,WebUI: A Dataset for Enhancing Visual UI Understanding with Web Semantics,data/paper_jsons/Jeffrey P. Bigham_1744846.json,
What is the url of the most cited paper from Jeffrey Bigham?,https://dl.acm.org/doi/pdf/10.1145/3544548.3581158,data/paper_jsons/Jeffrey P. Bigham_1744846.json,
Who are the authors of the most cited paper from Jeffrey Bigham?,"Jason Wu, Siyan Wang, Siman Shen, Yi-Hao Peng, Jeffrey Nichols, Jeffrey P. Bigham",data/paper_jsons/Jeffrey P. Bigham_1744846.json,
TLDR of the most cited paper from Jeffrey Bigham?,"This work crawled the web to construct WebUI, a large dataset of 400,000 rendered web pages associated with automatically extracted metadata, and analyzed the composition of WebUI to show that while automatically extracted data is noisy, most examples meet basic criteria for visual UI modeling.",data/paper_jsons/Jeffrey P. Bigham_1744846.json,
Abstract of the most cited paper from Jeffrey Bigham?,"Modeling user interfaces (UIs) from visual information allows systems to make inferences about the functionality and semantics needed to support use cases in accessibility, app automation, and testing. Current datasets for training machine learning models are limited in size due to the costly and time-consuming process of manually collecting and annotating UIs. We crawled the web to construct WebUI, a large dataset of 400,000 rendered web pages associated with automatically extracted metadata. We analyze the composition of WebUI and show that while automatically extracted data is noisy, most examples meet basic criteria for visual UI modeling. We applied several strategies for incorporating semantics found in web pages to increase the performance of visual UI understanding models in the mobile domain, where less labeled data is available: (i) element detection, (ii) screen classification and (iii) screen similarity.",data/paper_jsons/Jeffrey P. Bigham_1744846.json,
"What journal was the paper ""Screen Correspondence: Mapping Interchangeable Elements between UIs"" published in?",ArXiv,Jeffrey P. Bigham_1744846.json,
"What venue was the paper ""Screen Correspondence: Mapping Interchangeable Elements between UIs"" published in?",arXiv.org,Jeffrey P. Bigham_1744846.json,
"How many citations does the paper ""Screen Correspondence: Mapping Interchangeable Elements between UIs"" have?",4,Jeffrey P. Bigham_1744846.json,
"Who are the authors of the paper ""Screen Correspondence: Mapping Interchangeable Elements between UIs""?","Jason Wu, Amanda Swearngin, Xiaoyi Zhang, Jeffrey Nichols, Jeffrey P. Bigham",Jeffrey P. Bigham_1744846.json,
"Who is the first author of the paper ""Screen Correspondence: Mapping Interchangeable Elements between UIs""?",Jason Wu,Jeffrey P. Bigham_1744846.json,
"What is the paper ID of the paper ""Screen Correspondence: Mapping Interchangeable Elements between UIs""?",0e84679cf0945a2868245ba2be68c90453e48f2e,Jeffrey P. Bigham_1744846.json,
What paper has the paper ID 0e84679cf0945a2868245ba2be68c90453e48f2e?,Screen Correspondence: Mapping Interchangeable Elements between UIs,Jeffrey P. Bigham_1744846.json,
What is the TLDR of the paper 'Screen Correspondence: Mapping Interchangeable Elements between UIs'?,"This paper describes and implements a model that incorporates element semantics, appearance, and text to support correspondence computation without requiring any labeled examples, and shows that this approach improves upon baselines by incorporating multi-modal properties of UIs.",Jeffrey P. Bigham_1744846.json,
What is the abstract of the paper 'Screen Correspondence: Mapping Interchangeable Elements between UIs'?,"Understanding user interface (UI) functionality is a useful yet challenging task for both machines and people. In this paper, we investigate a machine learning approach for screen correspondence, which allows reasoning about UIs by mapping their elements onto previously encountered examples with known functionality and properties. We describe and implement a model that incorporates element semantics, appearance, and text to support correspondence computation without requiring any labeled examples. Through a comprehensive performance evaluation, we show that our approach improves upon baselines by incorporating multi-modal properties of UIs. Finally, we show three example applications where screen correspondence facilitates better UI understanding for humans and machines: (i) instructional overlay generation, (ii) semantic UI element search, and (iii) automated interface testing.",Jeffrey P. Bigham_1744846.json,
"What journal was the paper ""From User Perceptions to Technical Improvement: Enabling People Who Stutter to Better Use Speech Recognition"" published in?",Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,Jeffrey P. Bigham_1744846.json,
"What venue was the paper ""From User Perceptions to Technical Improvement: Enabling People Who Stutter to Better Use Speech Recognition"" published in?",International Conference on Human Factors in Computing Systems,Jeffrey P. Bigham_1744846.json,
"How many citations does the paper ""From User Perceptions to Technical Improvement: Enabling People Who Stutter to Better Use Speech Recognition"" have?",5,Jeffrey P. Bigham_1744846.json,
"Who are the authors of the paper ""From User Perceptions to Technical Improvement: Enabling People Who Stutter to Better Use Speech Recognition""?","Colin S. Lea, Zifang Huang, Jaya Narain, Lauren Tooley, Dianna Yee, Dung Tien Tran, P. Georgiou, Jeffrey P. Bigham, Leah Findlater",Jeffrey P. Bigham_1744846.json,
"Who is the first author of the paper ""From User Perceptions to Technical Improvement: Enabling People Who Stutter to Better Use Speech Recognition""?",Colin S. Lea,Jeffrey P. Bigham_1744846.json,
"What is the paper ID of the paper ""From User Perceptions to Technical Improvement: Enabling People Who Stutter to Better Use Speech Recognition""?",f29922cbfaf825d5e1d4986dc01bda74b4d88e04,Jeffrey P. Bigham_1744846.json,
What paper has the paper ID f29922cbfaf825d5e1d4986dc01bda74b4d88e04?,From User Perceptions to Technical Improvement: Enabling People Who Stutter to Better Use Speech Recognition,Jeffrey P. Bigham_1744846.json,
What is the TLDR of the paper 'From User Perceptions to Technical Improvement: Enabling People Who Stutter to Better Use Speech Recognition'?,"Through three technical investigations, it is demonstrated how many common errors can be prevented, resulting in a system that cuts utterances off 79.1% less often and improves word error rate from 25.4% to 9.9%.",Jeffrey P. Bigham_1744846.json,
What is the abstract of the paper 'From User Perceptions to Technical Improvement: Enabling People Who Stutter to Better Use Speech Recognition'?,"Consumer speech recognition systems do not work as well for many people with speech differences, such as stuttering, relative to the rest of the general population. However, what is not clear is the degree to which these systems do not work, how they can be improved, or how much people want to use them. In this paper, we first address these questions using results from a 61-person survey from people who stutter and find participants want to use speech recognition but are frequently cut off, misunderstood, or speech predictions do not represent intent. In a second study, where 91 people who stutter recorded voice assistant commands and dictation, we quantify how dysfluencies impede performance in a consumer-grade speech recognition system. Through three technical investigations, we demonstrate how many common errors can be prevented, resulting in a system that cuts utterances off 79.1% less often and improves word error rate from 25.4% to 9.9%.",Jeffrey P. Bigham_1744846.json,
"What journal was the paper ""WebUI: A Dataset for Enhancing Visual UI Understanding with Web Semantics"" published in?",Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,Jeffrey P. Bigham_1744846.json,
"What venue was the paper ""WebUI: A Dataset for Enhancing Visual UI Understanding with Web Semantics"" published in?",International Conference on Human Factors in Computing Systems,Jeffrey P. Bigham_1744846.json,
"How many citations does the paper ""WebUI: A Dataset for Enhancing Visual UI Understanding with Web Semantics"" have?",15,Jeffrey P. Bigham_1744846.json,
"Who are the authors of the paper ""WebUI: A Dataset for Enhancing Visual UI Understanding with Web Semantics""?","Jason Wu, Siyan Wang, Siman Shen, Yi-Hao Peng, Jeffrey Nichols, Jeffrey P. Bigham",Jeffrey P. Bigham_1744846.json,
"Who is the first author of the paper ""WebUI: A Dataset for Enhancing Visual UI Understanding with Web Semantics""?",Jason Wu,Jeffrey P. Bigham_1744846.json,
"What is the paper ID of the paper ""WebUI: A Dataset for Enhancing Visual UI Understanding with Web Semantics""?",98abc6de98a24d599cf009a9670eaa5c97cba9bb,Jeffrey P. Bigham_1744846.json,
What paper has the paper ID 98abc6de98a24d599cf009a9670eaa5c97cba9bb?,WebUI: A Dataset for Enhancing Visual UI Understanding with Web Semantics,Jeffrey P. Bigham_1744846.json,
What is the TLDR of the paper 'WebUI: A Dataset for Enhancing Visual UI Understanding with Web Semantics'?,"This work crawled the web to construct WebUI, a large dataset of 400,000 rendered web pages associated with automatically extracted metadata, and analyzed the composition of WebUI to show that while automatically extracted data is noisy, most examples meet basic criteria for visual UI modeling.",Jeffrey P. Bigham_1744846.json,
What is the abstract of the paper 'WebUI: A Dataset for Enhancing Visual UI Understanding with Web Semantics'?,"Modeling user interfaces (UIs) from visual information allows systems to make inferences about the functionality and semantics needed to support use cases in accessibility, app automation, and testing. Current datasets for training machine learning models are limited in size due to the costly and time-consuming process of manually collecting and annotating UIs. We crawled the web to construct WebUI, a large dataset of 400,000 rendered web pages associated with automatically extracted metadata. We analyze the composition of WebUI and show that while automatically extracted data is noisy, most examples meet basic criteria for visual UI modeling. We applied several strategies for incorporating semantics found in web pages to increase the performance of visual UI understanding models in the mobile domain, where less labeled data is available: (i) element detection, (ii) screen classification and (iii) screen similarity.",Jeffrey P. Bigham_1744846.json,
What is the author ID of Justine Cassell?,145431806,data/paper_jsons/Justine Cassell_145431806.json,
What are the papers of Justine Cassell?,"When to generate hedges in peer-tutoring interactions, How About Kind of Generating Hedges using End-to-End Neural Models?, ""You might think about slightly revising the title”: Identifying Hedges in Peer-tutoring Interactions",data/paper_jsons/Justine Cassell_145431806.json,
What is the H-index of Justine Cassell?,62,data/paper_jsons/Justine Cassell_145431806.json,
What is the author citation count of Justine Cassell?,16004,data/paper_jsons/Justine Cassell_145431806.json,
What journals has Justine Cassell published in?,ArXiv,data/paper_jsons/Justine Cassell_145431806.json,
What are the journals and how many papers has Justine Cassell published in each?,{'ArXiv': 1},data/paper_jsons/Justine Cassell_145431806.json,
What are the fields of study of Justine Cassell?,Computer Science,data/paper_jsons/Justine Cassell_145431806.json,
How many papers has Justine Cassell published in open access journals?,3,data/paper_jsons/Justine Cassell_145431806.json,
What venues has Justine Cassell published in?,"SIGDIAL Conferences, Annual Meeting of the Association for Computational Linguistics",data/paper_jsons/Justine Cassell_145431806.json,
What is the most cited paper from Justine Cassell?,"""You might think about slightly revising the title”: Identifying Hedges in Peer-tutoring Interactions",data/paper_jsons/Justine Cassell_145431806.json,
What is the url of the most cited paper from Justine Cassell?,https://aclanthology.org/2022.acl-long.153.pdf,data/paper_jsons/Justine Cassell_145431806.json,
Who are the authors of the most cited paper from Justine Cassell?,"Yann Raphalen, C. Clavel, Justine Cassell",data/paper_jsons/Justine Cassell_145431806.json,
TLDR of the most cited paper from Justine Cassell?,"A model explainability tool is employed to explore the features that characterize hedges in peer-tutoring conversations, and some novel features, and the benefits of a such a hybrid model approach are identified.",data/paper_jsons/Justine Cassell_145431806.json,
Abstract of the most cited paper from Justine Cassell?,"Hedges have an important role in the management of rapport. In peer-tutoring, they are notably used by tutors in dyads experiencing low rapport to tone down the impact of instructions and negative feedback.Pursuing the objective of building a tutoring agent that manages rapport with teenagers in order to improve learning, we used a multimodal peer-tutoring dataset to construct a computational framework for identifying hedges. We compared approaches relying on pre-trained resources with others that integrate insights from the social science literature. Our best performance involved a hybrid approach that outperforms the existing baseline while being easier to interpret. We employ a model explainability tool to explore the features that characterize hedges in peer-tutoring conversations, and we identify some novel features, and the benefits of a such a hybrid model approach.",data/paper_jsons/Justine Cassell_145431806.json,
"What journal was the paper """"You might think about slightly revising the title”: Identifying Hedges in Peer-tutoring Interactions"" published in?",,Justine Cassell_145431806.json,
"What venue was the paper """"You might think about slightly revising the title”: Identifying Hedges in Peer-tutoring Interactions"" published in?",Annual Meeting of the Association for Computational Linguistics,Justine Cassell_145431806.json,
"How many citations does the paper """"You might think about slightly revising the title”: Identifying Hedges in Peer-tutoring Interactions"" have?",10,Justine Cassell_145431806.json,
"Who are the authors of the paper """"You might think about slightly revising the title”: Identifying Hedges in Peer-tutoring Interactions""?","Yann Raphalen, C. Clavel, Justine Cassell",Justine Cassell_145431806.json,
"Who is the first author of the paper """"You might think about slightly revising the title”: Identifying Hedges in Peer-tutoring Interactions""?",Yann Raphalen,Justine Cassell_145431806.json,
"What is the paper ID of the paper """"You might think about slightly revising the title”: Identifying Hedges in Peer-tutoring Interactions""?",b3efaa75beada858414a5ba2346dec317203633c,Justine Cassell_145431806.json,
What paper has the paper ID b3efaa75beada858414a5ba2346dec317203633c?,"""You might think about slightly revising the title”: Identifying Hedges in Peer-tutoring Interactions",Justine Cassell_145431806.json,
"What is the TLDR of the paper '""You might think about slightly revising the title”: Identifying Hedges in Peer-tutoring Interactions'?","A model explainability tool is employed to explore the features that characterize hedges in peer-tutoring conversations, and some novel features, and the benefits of a such a hybrid model approach are identified.",Justine Cassell_145431806.json,
"What is the abstract of the paper '""You might think about slightly revising the title”: Identifying Hedges in Peer-tutoring Interactions'?","Hedges have an important role in the management of rapport. In peer-tutoring, they are notably used by tutors in dyads experiencing low rapport to tone down the impact of instructions and negative feedback.Pursuing the objective of building a tutoring agent that manages rapport with teenagers in order to improve learning, we used a multimodal peer-tutoring dataset to construct a computational framework for identifying hedges. We compared approaches relying on pre-trained resources with others that integrate insights from the social science literature. Our best performance involved a hybrid approach that outperforms the existing baseline while being easier to interpret. We employ a model explainability tool to explore the features that characterize hedges in peer-tutoring conversations, and we identify some novel features, and the benefits of a such a hybrid model approach.",Justine Cassell_145431806.json,
"What journal was the paper ""When to generate hedges in peer-tutoring interactions"" published in?",,Justine Cassell_145431806.json,
"What venue was the paper ""When to generate hedges in peer-tutoring interactions"" published in?",SIGDIAL Conferences,Justine Cassell_145431806.json,
"How many citations does the paper ""When to generate hedges in peer-tutoring interactions"" have?",0,Justine Cassell_145431806.json,
"Who are the authors of the paper ""When to generate hedges in peer-tutoring interactions""?","Alafate Abulimiti, C. Clavel, Justine Cassell",Justine Cassell_145431806.json,
"Who is the first author of the paper ""When to generate hedges in peer-tutoring interactions""?",Alafate Abulimiti,Justine Cassell_145431806.json,
"What is the paper ID of the paper ""When to generate hedges in peer-tutoring interactions""?",24bff26f19051b1413d1e343322c1ae4bba05428,Justine Cassell_145431806.json,
What paper has the paper ID 24bff26f19051b1413d1e343322c1ae4bba05428?,When to generate hedges in peer-tutoring interactions,Justine Cassell_145431806.json,
What is the TLDR of the paper 'When to generate hedges in peer-tutoring interactions'?,"The results show that embedding layers, capturing the semantic information of the previous turns, significantly improves the model’s performance and provides insights into the importance of various features, such as interpersonal rapport and nonverbal behaviors, in predicting hedges by using Shapley values for feature explanation.",Justine Cassell_145431806.json,
What is the abstract of the paper 'When to generate hedges in peer-tutoring interactions'?,"This paper explores the application of machine learning techniques to predict where hedging occurs in peer-tutoring interactions. The study uses a naturalistic face-to-face dataset annotated for natural language turns, conversational strategies, tutoring strategies, and nonverbal behaviors. These elements are processed into a vector representation of the previous turns, which serves as input to several machine learning models, including MLP and LSTM. The results show that embedding layers, capturing the semantic information of the previous turns, significantly improves the model’s performance. Additionally, the study provides insights into the importance of various features, such as interpersonal rapport and nonverbal behaviors, in predicting hedges by using Shapley values for feature explanation. We discover that the eye gaze of both the tutor and the tutee has a significant impact on hedge prediction. We further validate this observation through a follow-up ablation study.",Justine Cassell_145431806.json,
"What journal was the paper ""How About Kind of Generating Hedges using End-to-End Neural Models?"" published in?",ArXiv,Justine Cassell_145431806.json,
"What venue was the paper ""How About Kind of Generating Hedges using End-to-End Neural Models?"" published in?",Annual Meeting of the Association for Computational Linguistics,Justine Cassell_145431806.json,
"How many citations does the paper ""How About Kind of Generating Hedges using End-to-End Neural Models?"" have?",1,Justine Cassell_145431806.json,
"Who are the authors of the paper ""How About Kind of Generating Hedges using End-to-End Neural Models?""?","Alafate Abulimiti, C. Clavel, Justine Cassell",Justine Cassell_145431806.json,
"Who is the first author of the paper ""How About Kind of Generating Hedges using End-to-End Neural Models?""?",Alafate Abulimiti,Justine Cassell_145431806.json,
"What is the paper ID of the paper ""How About Kind of Generating Hedges using End-to-End Neural Models?""?",74fedee9d809ec766a2089a89435fa7dd1346693,Justine Cassell_145431806.json,
What paper has the paper ID 74fedee9d809ec766a2089a89435fa7dd1346693?,How About Kind of Generating Hedges using End-to-End Neural Models?,Justine Cassell_145431806.json,
What is the TLDR of the paper 'How About Kind of Generating Hedges using End-to-End Neural Models?'?,"This work develops a model of hedge generation based on fine-tuning state-of-the-art language models trained on human-human tutoring data, followed by reranking to select the candidate that best matches the expected hedging strategy within a candidate pool using a hedge classifier.",Justine Cassell_145431806.json,
What is the abstract of the paper 'How About Kind of Generating Hedges using End-to-End Neural Models?'?,"Hedging is a strategy for softening the impact of a statement in conversation. In reducing the strength of an expression, it may help to avoid embarrassment (more technically, “face threat”) to one’s listener. For this reason, it is often found in contexts of instruction, such as tutoring. In this work, we develop a model of hedge generation based on i) fine-tuning state-of-the-art language models trained on human-human tutoring data, followed by ii) reranking to select the candidate that best matches the expected hedging strategy within a candidate pool using a hedge classifier. We apply this method to a natural peer-tutoring corpus containing a significant number of disfluencies, repetitions, and repairs. The results show that generation in this noisy environment is feasible with reranking. By conducting an error analysis for both approaches, we reveal the challenges faced by systems attempting to accomplish both social and task-oriented goals in conversation.",Justine Cassell_145431806.json,
What is the author ID of Lei Li?,143900005,data/paper_jsons/Lei Li_143900005.json,
What are the papers of Lei Li?,"Co-benefits of carbon neutrality in enhancing and stabilizing solar and wind energy, A Reverse-Biased Voltage Controlling Method for Mitigating Arm Overcurrent and Submodule Overvoltage in Hybrid MMCs During DC Faults, Impacts of Aerosol Chemical Composition on Cloud Condensation Nuclei (CCN) Activity during Wintertime in Beijing, China, Quantitative Analysis of Natural Gas Diffusion Characteristics in Tight Oil Reservoirs Based on Experimental and Numerical Simulation Methods, Quantitative Evaluation of Dust and Black Carbon Column Concentration in the MERRA-2 Reanalysis Dataset Using Satellite-Based Component Retrievals, Seasonal and Diurnal Characteristics of the Vertical Profile of Aerosol Optical Properties in Urban Beijing, 2017-2021, PlayGround Low Resource Machine Translation System for the 2023 AmericasNLP Shared Task, Multilingual Machine Translation with Large Language Models: Empirical Results and Analysis",data/paper_jsons/Lei Li_143900005.json,
What is the H-index of Lei Li?,47,data/paper_jsons/Lei Li_143900005.json,
What is the author citation count of Lei Li?,9898,data/paper_jsons/Lei Li_143900005.json,
What journals has Lei Li published in?,"Nature Climate Change, IEEE Transactions on Power Electronics, Remote. Sens., ACS Omega, Proceedings of the Workshop on Natural Language Processing for Indigenous Languages of the Americas (AmericasNLP), ArXiv",data/paper_jsons/Lei Li_143900005.json,
What are the journals and how many papers has Lei Li published in each?,"{'Remote. Sens.': 3, 'Nature Climate Change': 1, 'IEEE Transactions on Power Electronics': 1, 'ACS Omega': 1, 'Proceedings of the Workshop on Natural Language Processing for Indigenous Languages of the Americas (AmericasNLP)': 1, 'ArXiv': 1}",data/paper_jsons/Lei Li_143900005.json,
What are the fields of study of Lei Li?,"Computer Science, Medicine",data/paper_jsons/Lei Li_143900005.json,
How many papers has Lei Li published in open access journals?,8,data/paper_jsons/Lei Li_143900005.json,
What venues has Lei Li published in?,"Nature Climate Change, IEEE transactions on power electronics, Remote Sensing, ACS Omega, AMERICASNLP, arXiv.org",data/paper_jsons/Lei Li_143900005.json,
What is the most cited paper from Lei Li?,Multilingual Machine Translation with Large Language Models: Empirical Results and Analysis,data/paper_jsons/Lei Li_143900005.json,
What is the url of the most cited paper from Lei Li?,http://arxiv.org/pdf/2304.04675,data/paper_jsons/Lei Li_143900005.json,
Who are the authors of the most cited paper from Lei Li?,"Wenhao Zhu, Hongyi Liu, Qingxiu Dong, Jingjing Xu, Lingpeng Kong, Jiajun Chen, Lei Li, Shujian Huang",data/paper_jsons/Lei Li_143900005.json,
TLDR of the most cited paper from Lei Li?,It is discovered that LLMs exhibit new working patterns when used for MMT and cross-lingual exemplars can provide better task guidance for low-resource translation than exemplars in the same language pairs.,data/paper_jsons/Lei Li_143900005.json,
Abstract of the most cited paper from Lei Li?,"Large language models (LLMs) have demonstrated remarkable potential in handling multilingual machine translation (MMT). In this paper, we systematically investigate the advantages and challenges of LLMs for MMT by answering two questions: 1) How well do LLMs perform in translating massive languages? 2) Which factors affect LLMs' performance in translation? We thoroughly evaluate eight popular LLMs, including ChatGPT and GPT-4. Our empirical results show that translation capabilities of LLMs are continually improving. GPT-4 has beat the strong supervised baseline NLLB in 40.91% of translation directions but still faces a large gap towards the commercial translation system, especially on low-resource languages. Through further analysis, we discover that LLMs exhibit new working patterns when used for MMT. First, instruction semantics can surprisingly be ignored when given in-context exemplars. Second, cross-lingual exemplars can provide better task guidance for low-resource translation than exemplars in the same language pairs. Third, LLM can acquire translation ability in a resource-efficient way and generate moderate translation even on zero-resource languages.",data/paper_jsons/Lei Li_143900005.json,
"What journal was the paper ""Quantitative Analysis of Natural Gas Diffusion Characteristics in Tight Oil Reservoirs Based on Experimental and Numerical Simulation Methods"" published in?",ACS Omega,Lei Li_143900005.json,
"What venue was the paper ""Quantitative Analysis of Natural Gas Diffusion Characteristics in Tight Oil Reservoirs Based on Experimental and Numerical Simulation Methods"" published in?",ACS Omega,Lei Li_143900005.json,
"How many citations does the paper ""Quantitative Analysis of Natural Gas Diffusion Characteristics in Tight Oil Reservoirs Based on Experimental and Numerical Simulation Methods"" have?",0,Lei Li_143900005.json,
"Who are the authors of the paper ""Quantitative Analysis of Natural Gas Diffusion Characteristics in Tight Oil Reservoirs Based on Experimental and Numerical Simulation Methods""?","Baishuo Liu, C. Yao, Yaqian Liu, Jia Zhao, Zhengdong Lei, Zhe Wang, Tianxiang Cheng, Lei Li",Lei Li_143900005.json,
"Who is the first author of the paper ""Quantitative Analysis of Natural Gas Diffusion Characteristics in Tight Oil Reservoirs Based on Experimental and Numerical Simulation Methods""?",Baishuo Liu,Lei Li_143900005.json,
"What is the paper ID of the paper ""Quantitative Analysis of Natural Gas Diffusion Characteristics in Tight Oil Reservoirs Based on Experimental and Numerical Simulation Methods""?",71f6931c4a5f7dda0382090a2c01bd5bff27d31e,Lei Li_143900005.json,
What paper has the paper ID 71f6931c4a5f7dda0382090a2c01bd5bff27d31e?,Quantitative Analysis of Natural Gas Diffusion Characteristics in Tight Oil Reservoirs Based on Experimental and Numerical Simulation Methods,Lei Li_143900005.json,
What is the TLDR of the paper 'Quantitative Analysis of Natural Gas Diffusion Characteristics in Tight Oil Reservoirs Based on Experimental and Numerical Simulation Methods'?,TLDR not found,Lei Li_143900005.json,
What is the abstract of the paper 'Quantitative Analysis of Natural Gas Diffusion Characteristics in Tight Oil Reservoirs Based on Experimental and Numerical Simulation Methods'?,"As an important mechanism in gas injection development, the diffusion characteristics of natural gas in tight reservoirs are important in the dynamic prediction of the development effect and optimization of injection-production parameters. In this paper, a high-pressure and high-temperature oil–gas diffusion experimental device was built, which was used to study the effects of the porous medium, pressure, permeability, and fracture on oil–gas diffusion under tight reservoir conditions. Two mathematical models were used to calculate the diffusion coefficients of natural gas in bulk oil and cores. Besides, the numerical simulation model was established to study the diffusion characteristics of natural gas in gas flooding and huff-n-puff, and five diffusion coefficients were selected based on experimental results for simulation study. The remaining oil saturation of grids, the recovery of single layers, and the distribution of CH4 mole fraction in oil were analyzed based on the simulation results. The experimental results show that the diffusion process can be divided into three stages: the initial stage of instability, the diffusion stage, and the stable stage. The absence of medium, high pressure, high permeability, and the existence of fracture are beneficial to natural gas diffusion, which can also reduce the equilibrium time and increase the gas pressure drop. Furthermore, the existence of fracture is beneficial to the early diffusion of gas. The simulation results show that the diffusion coefficient has a greater influence on the oil recovery of huff-n-puff. For gas flooding and huff-n-puff, the diffusion features both perform such that a high diffusion coefficient results in a close diffusion distance, small sweep range, and low oil recovery. However, a high diffusion coefficient can achieve high oil washing efficiency near the injecting well. The study is helpful to provide theoretical guidance for natural gas injection in tight oil reservoirs.",Lei Li_143900005.json,
"What journal was the paper ""PlayGround Low Resource Machine Translation System for the 2023 AmericasNLP Shared Task"" published in?",Proceedings of the Workshop on Natural Language Processing for Indigenous Languages of the Americas (AmericasNLP),Lei Li_143900005.json,
"What venue was the paper ""PlayGround Low Resource Machine Translation System for the 2023 AmericasNLP Shared Task"" published in?",AMERICASNLP,Lei Li_143900005.json,
"How many citations does the paper ""PlayGround Low Resource Machine Translation System for the 2023 AmericasNLP Shared Task"" have?",1,Lei Li_143900005.json,
"Who are the authors of the paper ""PlayGround Low Resource Machine Translation System for the 2023 AmericasNLP Shared Task""?","Tianrui Gu, Kaie Chen, Siqi Ouyang, Lei Li",Lei Li_143900005.json,
"Who is the first author of the paper ""PlayGround Low Resource Machine Translation System for the 2023 AmericasNLP Shared Task""?",Tianrui Gu,Lei Li_143900005.json,
"What is the paper ID of the paper ""PlayGround Low Resource Machine Translation System for the 2023 AmericasNLP Shared Task""?",c8b27d092e0f9e286bb354bb892984a30126c702,Lei Li_143900005.json,
What paper has the paper ID c8b27d092e0f9e286bb354bb892984a30126c702?,PlayGround Low Resource Machine Translation System for the 2023 AmericasNLP Shared Task,Lei Li_143900005.json,
What is the TLDR of the paper 'PlayGround Low Resource Machine Translation System for the 2023 AmericasNLP Shared Task'?,PlayGround’s submission to the AmericasNLP 2023 shared task on machine translation (MT) into indigenous languages is presented and the effectiveness of weight averaging and back translation is examined.,Lei Li_143900005.json,
What is the abstract of the paper 'PlayGround Low Resource Machine Translation System for the 2023 AmericasNLP Shared Task'?,"This paper presents PlayGround’s submission to the AmericasNLP 2023 shared task on machine translation (MT) into indigenous languages. We finetuned NLLB-600M, a multilingual MT model pre-trained on Flores-200, on 10 low-resource language directions and examined the effectiveness of weight averaging and back translation. Our experiments showed that weight averaging, on average, led to a 0.0169 improvement in the ChrF++ score. Additionally, we found that back translation resulted in a 0.008 improvement in the ChrF++ score.",Lei Li_143900005.json,
"What journal was the paper ""Multilingual Machine Translation with Large Language Models: Empirical Results and Analysis"" published in?",ArXiv,Lei Li_143900005.json,
"What venue was the paper ""Multilingual Machine Translation with Large Language Models: Empirical Results and Analysis"" published in?",arXiv.org,Lei Li_143900005.json,
"How many citations does the paper ""Multilingual Machine Translation with Large Language Models: Empirical Results and Analysis"" have?",50,Lei Li_143900005.json,
"Who are the authors of the paper ""Multilingual Machine Translation with Large Language Models: Empirical Results and Analysis""?","Wenhao Zhu, Hongyi Liu, Qingxiu Dong, Jingjing Xu, Lingpeng Kong, Jiajun Chen, Lei Li, Shujian Huang",Lei Li_143900005.json,
"Who is the first author of the paper ""Multilingual Machine Translation with Large Language Models: Empirical Results and Analysis""?",Wenhao Zhu,Lei Li_143900005.json,
"What is the paper ID of the paper ""Multilingual Machine Translation with Large Language Models: Empirical Results and Analysis""?",dfd8944d39b378489b878d6e105d040fa0e524db,Lei Li_143900005.json,
What paper has the paper ID dfd8944d39b378489b878d6e105d040fa0e524db?,Multilingual Machine Translation with Large Language Models: Empirical Results and Analysis,Lei Li_143900005.json,
What is the TLDR of the paper 'Multilingual Machine Translation with Large Language Models: Empirical Results and Analysis'?,It is discovered that LLMs exhibit new working patterns when used for MMT and cross-lingual exemplars can provide better task guidance for low-resource translation than exemplars in the same language pairs.,Lei Li_143900005.json,
What is the abstract of the paper 'Multilingual Machine Translation with Large Language Models: Empirical Results and Analysis'?,"Large language models (LLMs) have demonstrated remarkable potential in handling multilingual machine translation (MMT). In this paper, we systematically investigate the advantages and challenges of LLMs for MMT by answering two questions: 1) How well do LLMs perform in translating massive languages? 2) Which factors affect LLMs' performance in translation? We thoroughly evaluate eight popular LLMs, including ChatGPT and GPT-4. Our empirical results show that translation capabilities of LLMs are continually improving. GPT-4 has beat the strong supervised baseline NLLB in 40.91% of translation directions but still faces a large gap towards the commercial translation system, especially on low-resource languages. Through further analysis, we discover that LLMs exhibit new working patterns when used for MMT. First, instruction semantics can surprisingly be ignored when given in-context exemplars. Second, cross-lingual exemplars can provide better task guidance for low-resource translation than exemplars in the same language pairs. Third, LLM can acquire translation ability in a resource-efficient way and generate moderate translation even on zero-resource languages.",Lei Li_143900005.json,
What is the author ID of Lori S Levin?,1686960,data/paper_jsons/Lori S. Levin_1686960.json,
What are the papers of Lori S Levin?,"Somatosensory and motor representations following bilateral transplants of the hands: A 6-year longitudinal case report on the first pediatric bilateral hand transplant patient, Identifying Health-Related Quality of Life Domains after Upper Extremity Transplantation., Assessment of quality of life after upper extremity transplantation: Framework for patient-reported outcome scale domains",data/paper_jsons/Lori S. Levin_1686960.json,
What is the H-index of Lori S Levin?,34,data/paper_jsons/Lori S. Levin_1686960.json,
What is the author citation count of Lori S Levin?,3290,data/paper_jsons/Lori S. Levin_1686960.json,
What journals has Lori S Levin published in?,"Brain Research, Archives of physical medicine and rehabilitation, Frontiers in Psychology",data/paper_jsons/Lori S. Levin_1686960.json,
What are the journals and how many papers has Lori S Levin published in each?,"{'Brain Research': 1, 'Archives of physical medicine and rehabilitation': 1, 'Frontiers in Psychology': 1}",data/paper_jsons/Lori S. Levin_1686960.json,
What are the fields of study of Lori S Levin?,Medicine,data/paper_jsons/Lori S. Levin_1686960.json,
How many papers has Lori S Levin published in open access journals?,3,data/paper_jsons/Lori S. Levin_1686960.json,
What venues has Lori S Levin published in?,"Brain Research, Archives of Physical Medicine and Rehabilitation, Frontiers in Psychology",data/paper_jsons/Lori S. Levin_1686960.json,
What is the most cited paper from Lori S Levin?,Identifying Health-Related Quality of Life Domains after Upper Extremity Transplantation.,data/paper_jsons/Lori S. Levin_1686960.json,
What is the url of the most cited paper from Lori S Levin?,openAccessPdf not available,data/paper_jsons/Lori S. Levin_1686960.json,
Who are the authors of the most cited paper from Lori S Levin?,"D. Tulsky, Pamela A. Kisala, Callie E Tyner, J. Slotkin, C. Kaufman, C. Dearth, A. Horan, S. Talbot, J. Shores, K. Azari, C. Cetrulo, G. Brandacher, C. Cooney, David E Victorson, M. Dooley, Lori S. Levin, Cdr Scott M Tintle",data/paper_jsons/Lori S. Levin_1686960.json,
TLDR of the most cited paper from Lori S Levin?,"This study identified key constructs for use in evaluation of the potentially substantial physical, medical, social, and emotional effects of UET, including physical functioning and medical complications, positive and negative emotional functioning, and social participation, relationships, and independence.",data/paper_jsons/Lori S. Levin_1686960.json,
Abstract of the most cited paper from Lori S Levin?,,data/paper_jsons/Lori S. Levin_1686960.json,
"What journal was the paper ""Identifying Health-Related Quality of Life Domains after Upper Extremity Transplantation."" published in?",Archives of physical medicine and rehabilitation,Lori S. Levin_1686960.json,
"What venue was the paper ""Identifying Health-Related Quality of Life Domains after Upper Extremity Transplantation."" published in?",Archives of Physical Medicine and Rehabilitation,Lori S. Levin_1686960.json,
"How many citations does the paper ""Identifying Health-Related Quality of Life Domains after Upper Extremity Transplantation."" have?",1,Lori S. Levin_1686960.json,
"Who are the authors of the paper ""Identifying Health-Related Quality of Life Domains after Upper Extremity Transplantation.""?","D. Tulsky, Pamela A. Kisala, Callie E Tyner, J. Slotkin, C. Kaufman, C. Dearth, A. Horan, S. Talbot, J. Shores, K. Azari, C. Cetrulo, G. Brandacher, C. Cooney, David E Victorson, M. Dooley, Lori S. Levin, Cdr Scott M Tintle",Lori S. Levin_1686960.json,
"Who is the first author of the paper ""Identifying Health-Related Quality of Life Domains after Upper Extremity Transplantation.""?",D. Tulsky,Lori S. Levin_1686960.json,
"What is the paper ID of the paper ""Identifying Health-Related Quality of Life Domains after Upper Extremity Transplantation.""?",2f540bab03c2672715539ecf17ff4872ea521605,Lori S. Levin_1686960.json,
What paper has the paper ID 2f540bab03c2672715539ecf17ff4872ea521605?,Identifying Health-Related Quality of Life Domains after Upper Extremity Transplantation.,Lori S. Levin_1686960.json,
What is the TLDR of the paper 'Identifying Health-Related Quality of Life Domains after Upper Extremity Transplantation.'?,"This study identified key constructs for use in evaluation of the potentially substantial physical, medical, social, and emotional effects of UET, including physical functioning and medical complications, positive and negative emotional functioning, and social participation, relationships, and independence.",Lori S. Levin_1686960.json,
What is the abstract of the paper 'Identifying Health-Related Quality of Life Domains after Upper Extremity Transplantation.'?,,Lori S. Levin_1686960.json,
"What journal was the paper ""Somatosensory and motor representations following bilateral transplants of the hands: A 6-year longitudinal case report on the first pediatric bilateral hand transplant patient"" published in?",Brain Research,Lori S. Levin_1686960.json,
"What venue was the paper ""Somatosensory and motor representations following bilateral transplants of the hands: A 6-year longitudinal case report on the first pediatric bilateral hand transplant patient"" published in?",Brain Research,Lori S. Levin_1686960.json,
"How many citations does the paper ""Somatosensory and motor representations following bilateral transplants of the hands: A 6-year longitudinal case report on the first pediatric bilateral hand transplant patient"" have?",0,Lori S. Levin_1686960.json,
"Who are the authors of the paper ""Somatosensory and motor representations following bilateral transplants of the hands: A 6-year longitudinal case report on the first pediatric bilateral hand transplant patient""?","W. Gaetz, C. Dockstader, P. Furlong, S. Amaral, A. Vossough, E. Schwartz, T. Roberts, Lori S. Levin",Lori S. Levin_1686960.json,
"Who is the first author of the paper ""Somatosensory and motor representations following bilateral transplants of the hands: A 6-year longitudinal case report on the first pediatric bilateral hand transplant patient""?",W. Gaetz,Lori S. Levin_1686960.json,
"What is the paper ID of the paper ""Somatosensory and motor representations following bilateral transplants of the hands: A 6-year longitudinal case report on the first pediatric bilateral hand transplant patient""?",2cdc646a6b70418e7cbd7fbdb8bb113176c4659f,Lori S. Levin_1686960.json,
What paper has the paper ID 2cdc646a6b70418e7cbd7fbdb8bb113176c4659f?,Somatosensory and motor representations following bilateral transplants of the hands: A 6-year longitudinal case report on the first pediatric bilateral hand transplant patient,Lori S. Levin_1686960.json,
What is the TLDR of the paper 'Somatosensory and motor representations following bilateral transplants of the hands: A 6-year longitudinal case report on the first pediatric bilateral hand transplant patient'?,,Lori S. Levin_1686960.json,
What is the abstract of the paper 'Somatosensory and motor representations following bilateral transplants of the hands: A 6-year longitudinal case report on the first pediatric bilateral hand transplant patient'?,,Lori S. Levin_1686960.json,
"What journal was the paper ""Assessment of quality of life after upper extremity transplantation: Framework for patient-reported outcome scale domains"" published in?",Frontiers in Psychology,Lori S. Levin_1686960.json,
"What venue was the paper ""Assessment of quality of life after upper extremity transplantation: Framework for patient-reported outcome scale domains"" published in?",Frontiers in Psychology,Lori S. Levin_1686960.json,
"How many citations does the paper ""Assessment of quality of life after upper extremity transplantation: Framework for patient-reported outcome scale domains"" have?",1,Lori S. Levin_1686960.json,
"Who are the authors of the paper ""Assessment of quality of life after upper extremity transplantation: Framework for patient-reported outcome scale domains""?","Callie E Tyner, J. Slotkin, Pamela A. Kisala, Lori S. Levin, Scott M. Tintle, D. Tulsky",Lori S. Levin_1686960.json,
"Who is the first author of the paper ""Assessment of quality of life after upper extremity transplantation: Framework for patient-reported outcome scale domains""?",Callie E Tyner,Lori S. Levin_1686960.json,
"What is the paper ID of the paper ""Assessment of quality of life after upper extremity transplantation: Framework for patient-reported outcome scale domains""?",52a97ad16605c18e23c9750a388a26a9cdf12200,Lori S. Levin_1686960.json,
What paper has the paper ID 52a97ad16605c18e23c9750a388a26a9cdf12200?,Assessment of quality of life after upper extremity transplantation: Framework for patient-reported outcome scale domains,Lori S. Levin_1686960.json,
What is the TLDR of the paper 'Assessment of quality of life after upper extremity transplantation: Framework for patient-reported outcome scale domains'?,"Qualitative work with experts, clinicians, and patients has identified several domains of QOL that are unique to individuals who have received upper extremity transplants, which are distinct from topics covered by existing PRO measures.",Lori S. Levin_1686960.json,
What is the abstract of the paper 'Assessment of quality of life after upper extremity transplantation: Framework for patient-reported outcome scale domains'?,"Upper extremity transplantation offers the promise of restored function and regained quality of life (QOL) for individuals who have sustained hand or arm amputation. However, a major challenge for this procedure becoming an accessible treatment option for patients is the lack of standard measures to document benefits to QOL. Patient-reported outcomes (PRO) measures are well-suited for this kind of intervention, where the perspective of the patient is central to defining treatment success. To date, qualitative work with experts, clinicians, and patients has been used to identify the most important domains of QOL for PRO item development. Specifically, our group’s qualitative work has identified several domains of QOL that are unique to individuals who have received upper extremity transplants, which are distinct from topics covered by existing PRO measures. These include emotional and social aspects of upper extremity transplant, such as Expectations and Perceived Outcomes, Integration and Assimilation of Transplant, Fitting in, and Post-Surgical Challenges and Complications. The broad topic of Satisfaction with Transplant was subdivided into three subtopics: Function, Sensation, and Aesthetics. Satisfaction with Sensation was also identified as a unique domain not evaluated by existing PRO measures. This report operationalizes these eight QOL domains by presenting scoping definitions. This manuscript describes the work that has been completed for domain characterization as an early step toward developing standardized PRO measures to evaluate these important outcomes specific to upper extremity transplantation.",Lori S. Levin_1686960.json,
What is the author ID of Louis-Philippe Morency?,49933077,data/paper_jsons/Louis-Philippe Morency_49933077.json,
What are the papers of Louis-Philippe Morency?,"Quantifying & Modeling Feature Interactions: An Information Decomposition Framework, Reconstructing the neurodynamics of face perception during real world vision in humans using intracranial EEG recordings, MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning, SenteCon: Leveraging Lexicons to Learn Human-Interpretable Language Representations, Neural Mixed Effects for Nonlinear Personalized Predictions, SHAP-based Prediction of Mother's History of Depression to Understand the Influence on Child Behavior, Counterfactual Augmentation for Multimodal Learning Under Presentation Bias, Difference-Masking: Choosing What to Mask in Continued Pretraining, Expanding the Role of Affective Phenomena in Multimodal Interaction Research, Multimodal Fusion Interactions: A Study of Human and Automatic Quantification, Multimodal Learning Without Labeled Multimodal Data: Guarantees and Applications, Representation Learning for Interpersonal and Multimodal Behavior Dynamics: A Multiview Extension of Latent Change Score Models, MultiViz: Towards User-Centric Visualizations and Interpretations of Multimodal Models, Understanding Masked Autoencoders via Hierarchical Latent Variable Models, Factorized Contrastive Learning: Going Beyond Multi-view Redundancy, Language Models Get a Gender Makeover: Mitigating Gender Bias with Few-Shot Data Interventions",data/paper_jsons/Louis-Philippe Morency_49933077.json,
What is the H-index of Louis-Philippe Morency?,79,data/paper_jsons/Louis-Philippe Morency_49933077.json,
What is the author citation count of Louis-Philippe Morency?,28711,data/paper_jsons/Louis-Philippe Morency_49933077.json,
What journals has Louis-Philippe Morency published in?,"ArXiv, Journal of Vision, Proceedings of the 25th International Conference on Multimodal Interaction, Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",data/paper_jsons/Louis-Philippe Morency_49933077.json,
What are the journals and how many papers has Louis-Philippe Morency published in each?,"{'ArXiv': 5, 'Proceedings of the 25th International Conference on Multimodal Interaction': 5, 'Journal of Vision': 1, 'Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems': 1, '2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)': 1}",data/paper_jsons/Louis-Philippe Morency_49933077.json,
What are the fields of study of Louis-Philippe Morency?,"Computer Science, Mathematics",data/paper_jsons/Louis-Philippe Morency_49933077.json,
How many papers has Louis-Philippe Morency published in open access journals?,16,data/paper_jsons/Louis-Philippe Morency_49933077.json,
What venues has Louis-Philippe Morency published in?,"arXiv.org, Journal of Vision, Annual Meeting of the Association for Computational Linguistics, International Conference on Multimodal Interaction, Conference on Empirical Methods in Natural Language Processing, CHI Extended Abstracts, Computer Vision and Pattern Recognition",data/paper_jsons/Louis-Philippe Morency_49933077.json,
What is the most cited paper from Louis-Philippe Morency?,Quantifying & Modeling Feature Interactions: An Information Decomposition Framework,data/paper_jsons/Louis-Philippe Morency_49933077.json,
What is the url of the most cited paper from Louis-Philippe Morency?,https://arxiv.org/pdf/2302.12247,data/paper_jsons/Louis-Philippe Morency_49933077.json,
Who are the authors of the most cited paper from Louis-Philippe Morency?,"P. Liang, Yun Cheng, Xiang Fan, Chun Kai Ling, Suzanne Nie, Richard J. Chen, Zihao Deng, Faisal Mahmood, R. Salakhutdinov, Louis-Philippe Morency",data/paper_jsons/Louis-Philippe Morency_49933077.json,
TLDR of the most cited paper from Louis-Philippe Morency?,"This work proposes an information-theoretic approach to quantify the degree of redundancy, uniqueness, and synergy across input features, which is term the PID statistics of a multimodal distribution.",data/paper_jsons/Louis-Philippe Morency_49933077.json,
Abstract of the most cited paper from Louis-Philippe Morency?,"The recent explosion of interest in multimodal applications has resulted in a wide selection of datasets and methods for representing and inte-grating information from different signals. Despite these empirical advances, there remain fundamental research questions: how can we quantify the nature of interactions that exist among input features? Subsequently, how can we capture these interactions using suitable data-driven methods? To answer this question, we propose an information-theoretic approach to quantify the degree of redundancy , uniqueness , and synergy across input features, which we term the PID statistics of a multimodal distribution. Using 2 newly proposed estimators that scale to high-dimensional distributions, we demonstrate their usefulness in quantifying the interactions within multimodal datasets, the nature of interactions captured by multimodal models, and principled approaches for model selection. We conduct extensive experiments on both synthetic datasets where the PID statistics are known and on large-scale multimodal benchmarks where PID estimation was previously impossible. Finally, to demonstrate the real-world applicability of our approach, we present three case studies in pathology, mood prediction, and robotic perception where our framework accurately recommends strong multimodal models for each application.",data/paper_jsons/Louis-Philippe Morency_49933077.json,
"What journal was the paper ""Factorized Contrastive Learning: Going Beyond Multi-view Redundancy"" published in?",ArXiv,Louis-Philippe Morency_49933077.json,
"What venue was the paper ""Factorized Contrastive Learning: Going Beyond Multi-view Redundancy"" published in?",arXiv.org,Louis-Philippe Morency_49933077.json,
"How many citations does the paper ""Factorized Contrastive Learning: Going Beyond Multi-view Redundancy"" have?",6,Louis-Philippe Morency_49933077.json,
"Who are the authors of the paper ""Factorized Contrastive Learning: Going Beyond Multi-view Redundancy""?","P. Liang, Zihao Deng, Martin Q. Ma, James Y. Zou, Louis-Philippe Morency, R. Salakhutdinov",Louis-Philippe Morency_49933077.json,
"Who is the first author of the paper ""Factorized Contrastive Learning: Going Beyond Multi-view Redundancy""?",P. Liang,Louis-Philippe Morency_49933077.json,
"What is the paper ID of the paper ""Factorized Contrastive Learning: Going Beyond Multi-view Redundancy""?",e1b2a35a000ca296c32284b323c7e36a28fe0693,Louis-Philippe Morency_49933077.json,
What paper has the paper ID e1b2a35a000ca296c32284b323c7e36a28fe0693?,Factorized Contrastive Learning: Going Beyond Multi-view Redundancy,Louis-Philippe Morency_49933077.json,
What is the TLDR of the paper 'Factorized Contrastive Learning: Going Beyond Multi-view Redundancy'?,FactorCL is a new multimodal representation learning method to go beyond multi-view redundancy and captures both shared and unique information and achieves state-of-the-art results on six benchmarks.,Louis-Philippe Morency_49933077.json,
What is the abstract of the paper 'Factorized Contrastive Learning: Going Beyond Multi-view Redundancy'?,"In a wide range of multimodal tasks, contrastive learning has become a particularly appealing approach since it can successfully learn representations from abundant unlabeled data with only pairing information (e.g., image-caption or video-audio pairs). Underpinning these approaches is the assumption of multi-view redundancy - that shared information between modalities is necessary and sufficient for downstream tasks. However, in many real-world settings, task-relevant information is also contained in modality-unique regions: information that is only present in one modality but still relevant to the task. How can we learn self-supervised multimodal representations to capture both shared and unique information relevant to downstream tasks? This paper proposes FactorCL, a new multimodal representation learning method to go beyond multi-view redundancy. FactorCL is built from three new contributions: (1) factorizing task-relevant information into shared and unique representations, (2) capturing task-relevant information via maximizing MI lower bounds and removing task-irrelevant information via minimizing MI upper bounds, and (3) multimodal data augmentations to approximate task relevance without labels. On large-scale real-world datasets, FactorCL captures both shared and unique information and achieves state-of-the-art results on six benchmarks",Louis-Philippe Morency_49933077.json,
"What journal was the paper ""Expanding the Role of Affective Phenomena in Multimodal Interaction Research"" published in?",Proceedings of the 25th International Conference on Multimodal Interaction,Louis-Philippe Morency_49933077.json,
"What venue was the paper ""Expanding the Role of Affective Phenomena in Multimodal Interaction Research"" published in?",International Conference on Multimodal Interaction,Louis-Philippe Morency_49933077.json,
"How many citations does the paper ""Expanding the Role of Affective Phenomena in Multimodal Interaction Research"" have?",0,Louis-Philippe Morency_49933077.json,
"Who are the authors of the paper ""Expanding the Role of Affective Phenomena in Multimodal Interaction Research""?","Leena Mathur, Maja J Matari'c, Louis-Philippe Morency",Louis-Philippe Morency_49933077.json,
"Who is the first author of the paper ""Expanding the Role of Affective Phenomena in Multimodal Interaction Research""?",Leena Mathur,Louis-Philippe Morency_49933077.json,
"What is the paper ID of the paper ""Expanding the Role of Affective Phenomena in Multimodal Interaction Research""?",8d53c510928ad1164aebea4d9477812ed1893be2,Louis-Philippe Morency_49933077.json,
What paper has the paper ID 8d53c510928ad1164aebea4d9477812ed1893be2?,Expanding the Role of Affective Phenomena in Multimodal Interaction Research,Louis-Philippe Morency_49933077.json,
What is the TLDR of the paper 'Expanding the Role of Affective Phenomena in Multimodal Interaction Research'?,"An examination of research at the intersection of multimodal interaction and affective computing, with the objective of observing trends and identifying understudied areas, finds that this body of research has primarily focused on enabling machines to recognize or express affect and emotion.",Louis-Philippe Morency_49933077.json,
What is the abstract of the paper 'Expanding the Role of Affective Phenomena in Multimodal Interaction Research'?,"In recent decades, the field of affective computing has made substantial progress in advancing the ability of AI systems to recognize and express affective phenomena, such as affect and emotions, during human-human and human-machine interactions. This paper describes our examination of research at the intersection of multimodal interaction and affective computing, with the objective of observing trends and identifying understudied areas. We examined over 16,000 papers from selected conferences in multimodal interaction, affective computing, and natural language processing: ACM International Conference on Multimodal Interaction, AAAC International Conference on Affective Computing and Intelligent Interaction, Annual Meeting of the Association for Computational Linguistics, and Conference on Empirical Methods in Natural Language Processing. We identified 910 affect-related papers and present our analysis of the role of affective phenomena in these papers. We find that this body of research has primarily focused on enabling machines to recognize or express affect and emotion; there has been limited research on how affect and emotion predictions might, in turn, be used by AI systems to enhance machine understanding of human social behaviors and cognitive states. Based on our analysis, we discuss directions to expand the role of affective phenomena in multimodal interaction research.",Louis-Philippe Morency_49933077.json,
"What journal was the paper ""SHAP-based Prediction of Mother's History of Depression to Understand the Influence on Child Behavior"" published in?",Proceedings of the 25th International Conference on Multimodal Interaction,Louis-Philippe Morency_49933077.json,
"What venue was the paper ""SHAP-based Prediction of Mother's History of Depression to Understand the Influence on Child Behavior"" published in?",International Conference on Multimodal Interaction,Louis-Philippe Morency_49933077.json,
"How many citations does the paper ""SHAP-based Prediction of Mother's History of Depression to Understand the Influence on Child Behavior"" have?",0,Louis-Philippe Morency_49933077.json,
"Who are the authors of the paper ""SHAP-based Prediction of Mother's History of Depression to Understand the Influence on Child Behavior""?","Maneesh Bilalpur, Saurabh Hinduja, Laura Cariola, Lisa B. Sheeber, Nicholas B Allen, Louis-Philippe Morency, Jeffrey F. Cohn",Louis-Philippe Morency_49933077.json,
"Who is the first author of the paper ""SHAP-based Prediction of Mother's History of Depression to Understand the Influence on Child Behavior""?",Maneesh Bilalpur,Louis-Philippe Morency_49933077.json,
"What is the paper ID of the paper ""SHAP-based Prediction of Mother's History of Depression to Understand the Influence on Child Behavior""?",6838c43e702a3f995967ba2e3edd5f65ff5f5511,Louis-Philippe Morency_49933077.json,
What paper has the paper ID 6838c43e702a3f995967ba2e3edd5f65ff5f5511?,SHAP-based Prediction of Mother's History of Depression to Understand the Influence on Child Behavior,Louis-Philippe Morency_49933077.json,
What is the TLDR of the paper 'SHAP-based Prediction of Mother's History of Depression to Understand the Influence on Child Behavior'?,TLDR not found,Louis-Philippe Morency_49933077.json,
What is the abstract of the paper 'SHAP-based Prediction of Mother's History of Depression to Understand the Influence on Child Behavior'?,"Depression strongly impacts parents’ behavior. Does parents’ depression strongly affect the behavior of their children as well? To investigate this question, we compared dyadic interactions between 73 depressed and 75 non-depressed mothers and their adolescent child. Families were of low income and 84% were white. Child behavior was measured from audio-video recordings using manual annotation of verbal and nonverbal behavior by expert coders and by multimodal computational measures of facial expression, face and head dynamics, prosody, speech behavior, and linguistics. For both sets of measures, we used Support Vector Machines. For computational measures, we investigated the relative contribution of single versus multiple modalities using a novel approach to SHapley Additive exPlanations (SHAP). Computational measures outperformed manual ratings by human experts. Among individual computational measures, prosody was the most informative. SHAP reduction resulted in a four-fold decrease in the number of features and highest performance (77% accuracy; positive and negative agreements at 75% and 76%, respectively). These findings suggest that maternal depression strongly impacts the behavior of adolescent children; differences are most revealed in prosody; multimodal features together with SHAP reduction are most powerful.",Louis-Philippe Morency_49933077.json,
What is the author ID of Lu Jiang?,39978626,data/paper_jsons/Lu Jiang_39978626.json,
What are the papers of Lu Jiang?,"Muse: Text-To-Image Generation via Masked Generative Transformers, SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs, StyleDrop: Text-to-Image Generation in Any Style, Learning Disentangled Prompts for Compositional Image Synthesis, Language Model Beats Diffusion - Tokenizer is Key to Visual Generation, VideoGLUE: Video General Understanding Evaluation of Foundation Models",data/paper_jsons/Lu Jiang_39978626.json,
What is the H-index of Lu Jiang?,41,data/paper_jsons/Lu Jiang_39978626.json,
What is the author citation count of Lu Jiang?,7875,data/paper_jsons/Lu Jiang_39978626.json,
What journals has Lu Jiang published in?,ArXiv,data/paper_jsons/Lu Jiang_39978626.json,
What are the journals and how many papers has Lu Jiang published in each?,{'ArXiv': 6},data/paper_jsons/Lu Jiang_39978626.json,
What are the fields of study of Lu Jiang?,Computer Science,data/paper_jsons/Lu Jiang_39978626.json,
How many papers has Lu Jiang published in open access journals?,6,data/paper_jsons/Lu Jiang_39978626.json,
What venues has Lu Jiang published in?,"International Conference on Machine Learning, arXiv.org",data/paper_jsons/Lu Jiang_39978626.json,
What is the most cited paper from Lu Jiang?,Muse: Text-To-Image Generation via Masked Generative Transformers,data/paper_jsons/Lu Jiang_39978626.json,
What is the url of the most cited paper from Lu Jiang?,http://arxiv.org/pdf/2301.00704,data/paper_jsons/Lu Jiang_39978626.json,
Who are the authors of the most cited paper from Lu Jiang?,"Huiwen Chang, Han Zhang, Jarred Barber, AJ Maschinot, José Lezama, Lu Jiang, Ming Yang, K. Murphy, W. Freeman, Michael Rubinstein, Yuanzhen Li, Dilip Krishnan",data/paper_jsons/Lu Jiang_39978626.json,
TLDR of the most cited paper from Lu Jiang?,,data/paper_jsons/Lu Jiang_39978626.json,
Abstract of the most cited paper from Lu Jiang?,"We present Muse, a text-to-image Transformer model that achieves state-of-the-art image generation performance while being significantly more efficient than diffusion or autoregressive models. Muse is trained on a masked modeling task in discrete token space: given the text embedding extracted from a pre-trained large language model (LLM), Muse is trained to predict randomly masked image tokens. Compared to pixel-space diffusion models, such as Imagen and DALL-E 2, Muse is significantly more efficient due to the use of discrete tokens and requiring fewer sampling iterations; compared to autoregressive models, such as Parti, Muse is more efficient due to the use of parallel decoding. The use of a pre-trained LLM enables fine-grained language understanding, translating to high-fidelity image generation and the understanding of visual concepts such as objects, their spatial relationships, pose, cardinality etc. Our 900M parameter model achieves a new SOTA on CC3M, with an FID score of 6.06. The Muse 3B parameter model achieves an FID of 7.88 on zero-shot COCO evaluation, along with a CLIP score of 0.32. Muse also directly enables a number of image editing applications without the need to fine-tune or invert the model: inpainting, outpainting, and mask-free editing. More results are available at https://muse-model.github.io",data/paper_jsons/Lu Jiang_39978626.json,
"What journal was the paper ""Muse: Text-To-Image Generation via Masked Generative Transformers"" published in?",ArXiv,Lu Jiang_39978626.json,
"What venue was the paper ""Muse: Text-To-Image Generation via Masked Generative Transformers"" published in?",International Conference on Machine Learning,Lu Jiang_39978626.json,
"How many citations does the paper ""Muse: Text-To-Image Generation via Masked Generative Transformers"" have?",235,Lu Jiang_39978626.json,
"Who are the authors of the paper ""Muse: Text-To-Image Generation via Masked Generative Transformers""?","Huiwen Chang, Han Zhang, Jarred Barber, AJ Maschinot, José Lezama, Lu Jiang, Ming Yang, K. Murphy, W. Freeman, Michael Rubinstein, Yuanzhen Li, Dilip Krishnan",Lu Jiang_39978626.json,
"Who is the first author of the paper ""Muse: Text-To-Image Generation via Masked Generative Transformers""?",Huiwen Chang,Lu Jiang_39978626.json,
"What is the paper ID of the paper ""Muse: Text-To-Image Generation via Masked Generative Transformers""?",2a3213cb3c755f036d5dfec7261d726a819c78c1,Lu Jiang_39978626.json,
What paper has the paper ID 2a3213cb3c755f036d5dfec7261d726a819c78c1?,Muse: Text-To-Image Generation via Masked Generative Transformers,Lu Jiang_39978626.json,
What is the TLDR of the paper 'Muse: Text-To-Image Generation via Masked Generative Transformers'?,,Lu Jiang_39978626.json,
What is the abstract of the paper 'Muse: Text-To-Image Generation via Masked Generative Transformers'?,"We present Muse, a text-to-image Transformer model that achieves state-of-the-art image generation performance while being significantly more efficient than diffusion or autoregressive models. Muse is trained on a masked modeling task in discrete token space: given the text embedding extracted from a pre-trained large language model (LLM), Muse is trained to predict randomly masked image tokens. Compared to pixel-space diffusion models, such as Imagen and DALL-E 2, Muse is significantly more efficient due to the use of discrete tokens and requiring fewer sampling iterations; compared to autoregressive models, such as Parti, Muse is more efficient due to the use of parallel decoding. The use of a pre-trained LLM enables fine-grained language understanding, translating to high-fidelity image generation and the understanding of visual concepts such as objects, their spatial relationships, pose, cardinality etc. Our 900M parameter model achieves a new SOTA on CC3M, with an FID score of 6.06. The Muse 3B parameter model achieves an FID of 7.88 on zero-shot COCO evaluation, along with a CLIP score of 0.32. Muse also directly enables a number of image editing applications without the need to fine-tune or invert the model: inpainting, outpainting, and mask-free editing. More results are available at https://muse-model.github.io",Lu Jiang_39978626.json,
"What journal was the paper ""VideoGLUE: Video General Understanding Evaluation of Foundation Models"" published in?",ArXiv,Lu Jiang_39978626.json,
"What venue was the paper ""VideoGLUE: Video General Understanding Evaluation of Foundation Models"" published in?",arXiv.org,Lu Jiang_39978626.json,
"How many citations does the paper ""VideoGLUE: Video General Understanding Evaluation of Foundation Models"" have?",1,Lu Jiang_39978626.json,
"Who are the authors of the paper ""VideoGLUE: Video General Understanding Evaluation of Foundation Models""?","Liangzhe Yuan, Nitesh B. Gundavarapu, Long Zhao, Hao Zhou, Yin Cui, Lu Jiang, Xu Yang, Menglin Jia, Tobias Weyand, Luke Friedman, Mikhail Sirotenko, H. Wang, Florian Schroff, Hartwig Adam, Ming Yang, Ting Liu, Boqing Gong",Lu Jiang_39978626.json,
"Who is the first author of the paper ""VideoGLUE: Video General Understanding Evaluation of Foundation Models""?",Liangzhe Yuan,Lu Jiang_39978626.json,
"What is the paper ID of the paper ""VideoGLUE: Video General Understanding Evaluation of Foundation Models""?",c5202ab27294d5c1eb4d2f0ca7e82afef91888f0,Lu Jiang_39978626.json,
What paper has the paper ID c5202ab27294d5c1eb4d2f0ca7e82afef91888f0?,VideoGLUE: Video General Understanding Evaluation of Foundation Models,Lu Jiang_39978626.json,
What is the TLDR of the paper 'VideoGLUE: Video General Understanding Evaluation of Foundation Models'?,,Lu Jiang_39978626.json,
What is the abstract of the paper 'VideoGLUE: Video General Understanding Evaluation of Foundation Models'?,"We evaluate existing foundation models video understanding capabilities using a carefully designed experiment protocol consisting of three hallmark tasks (action recognition, temporal localization, and spatiotemporal localization), eight datasets well received by the community, and four adaptation methods tailoring a foundation model (FM) for a downstream task. Moreover, we propose a scalar VideoGLUE score (VGS) to measure an FMs efficacy and efficiency when adapting to general video understanding tasks. Our main findings are as follows. First, task-specialized models significantly outperform the six FMs studied in this work, in sharp contrast to what FMs have achieved in natural language and image understanding. Second,video-native FMs, whose pretraining data contains the video modality, are generally better than image-native FMs in classifying motion-rich videos, localizing actions in time, and understanding a video of more than one action. Third, the video-native FMs can perform well on video tasks under light adaptations to downstream tasks(e.g., freezing the FM backbones), while image-native FMs win in full end-to-end finetuning. The first two observations reveal the need and tremendous opportunities to conduct research on video-focused FMs, and the last confirms that both tasks and adaptation methods matter when it comes to the evaluation of FMs. Our code is released under: https://github.com/tensorflow/models/tree/master/official/projects/videoglue.",Lu Jiang_39978626.json,
"What journal was the paper ""Language Model Beats Diffusion - Tokenizer is Key to Visual Generation"" published in?",ArXiv,Lu Jiang_39978626.json,
"What venue was the paper ""Language Model Beats Diffusion - Tokenizer is Key to Visual Generation"" published in?",arXiv.org,Lu Jiang_39978626.json,
"How many citations does the paper ""Language Model Beats Diffusion - Tokenizer is Key to Visual Generation"" have?",12,Lu Jiang_39978626.json,
"Who are the authors of the paper ""Language Model Beats Diffusion - Tokenizer is Key to Visual Generation""?","Lijun Yu, Jos'e Lezama, Nitesh B. Gundavarapu, Luca Versari, Kihyuk Sohn, David C. Minnen, Yong Cheng, Agrim Gupta, Xiuye Gu, Alexander G. Hauptmann, Boqing Gong, Ming-Hsuan Yang, Irfan Essa, David A. Ross, Lu Jiang",Lu Jiang_39978626.json,
"Who is the first author of the paper ""Language Model Beats Diffusion - Tokenizer is Key to Visual Generation""?",Lijun Yu,Lu Jiang_39978626.json,
"What is the paper ID of the paper ""Language Model Beats Diffusion - Tokenizer is Key to Visual Generation""?",985f0c89c5a607742ec43c1fdc2cbfe54541cbad,Lu Jiang_39978626.json,
What paper has the paper ID 985f0c89c5a607742ec43c1fdc2cbfe54541cbad?,Language Model Beats Diffusion - Tokenizer is Key to Visual Generation,Lu Jiang_39978626.json,
What is the TLDR of the paper 'Language Model Beats Diffusion - Tokenizer is Key to Visual Generation'?,,Lu Jiang_39978626.json,
What is the abstract of the paper 'Language Model Beats Diffusion - Tokenizer is Key to Visual Generation'?,"While Large Language Models (LLMs) are the dominant models for generative tasks in language, they do not perform as well as diffusion models on image and video generation. To effectively use LLMs for visual generation, one crucial component is the visual tokenizer that maps pixel-space inputs to discrete tokens appropriate for LLM learning. In this paper, we introduce MAGVIT-v2, a video tokenizer designed to generate concise and expressive tokens for both videos and images using a common token vocabulary. Equipped with this new tokenizer, we show that LLMs outperform diffusion models on standard image and video generation benchmarks including ImageNet and Kinetics. In addition, we demonstrate that our tokenizer surpasses the previously top-performing video tokenizer on two more tasks: (1) video compression comparable to the next-generation video codec (VCC) according to human evaluations, and (2) learning effective representations for action recognition tasks.",Lu Jiang_39978626.json,
What is the author ID of Madhavi Ganapathiraju?,32747279,data/paper_jsons/M. Ganapathiraju_32747279.json,
What are the papers of Madhavi Ganapathiraju?,"Pathogenic mechanisms underlying adverse neurodevelopmental outcome in congenital heart disease, Editorial: Systems biology, women in science 2021/22: translational systems biology and in silico trials",data/paper_jsons/M. Ganapathiraju_32747279.json,
What is the H-index of Madhavi Ganapathiraju?,20,data/paper_jsons/M. Ganapathiraju_32747279.json,
What is the author citation count of Madhavi Ganapathiraju?,2040,data/paper_jsons/M. Ganapathiraju_32747279.json,
What journals has Madhavi Ganapathiraju published in?,"bioRxiv, Frontiers in Systems Biology",data/paper_jsons/M. Ganapathiraju_32747279.json,
What are the journals and how many papers has Madhavi Ganapathiraju published in each?,"{'bioRxiv': 1, 'Frontiers in Systems Biology': 1}",data/paper_jsons/M. Ganapathiraju_32747279.json,
What are the fields of study of Madhavi Ganapathiraju?,Biology,data/paper_jsons/M. Ganapathiraju_32747279.json,
How many papers has Madhavi Ganapathiraju published in open access journals?,2,data/paper_jsons/M. Ganapathiraju_32747279.json,
What venues has Madhavi Ganapathiraju published in?,"bioRxiv, Frontiers in Systems Biology",data/paper_jsons/M. Ganapathiraju_32747279.json,
What is the most cited paper from Madhavi Ganapathiraju?,Pathogenic mechanisms underlying adverse neurodevelopmental outcome in congenital heart disease,data/paper_jsons/M. Ganapathiraju_32747279.json,
What is the url of the most cited paper from Madhavi Ganapathiraju?,https://www.biorxiv.org/content/biorxiv/early/2023/11/06/2023.11.05.565716.full.pdf,data/paper_jsons/M. Ganapathiraju_32747279.json,
Who are the authors of the most cited paper from Madhavi Ganapathiraju?,"George C Gabriel, Hisato Yagi, Tuantuan Tan, A. Bais, Benjamin J. Glennon, Margaret C. Stapleton, Lihua Huang, William T Reynolds, Marla G. Shaffer, Xinxiu Xu, M. Ganapathiraju, Dennis Simon, Ashok Panigrahy, Yijen L. Wu, Cecilia W Lo",data/paper_jsons/M. Ganapathiraju_32747279.json,
TLDR of the most cited paper from Madhavi Ganapathiraju?,"The observations indicate the intrinsic factors contributing to the adverse neurodevelopmental outcome associated with HLHS involve spindle defects causing impaired corticoneurogenesis, and brain and behavioral deficits associated with perturbed epigenetic regulation of neuro developmental pathways.",data/paper_jsons/M. Ganapathiraju_32747279.json,
Abstract of the most cited paper from Madhavi Ganapathiraju?,"Background Hypoplastic left heart syndrome (HLHS), a severe congenital heart disease, is associated with poor neurodevelopmental outcomes, microcephaly, reduced cortical brain volume, brain dysmaturation, and neurobehavioral disorders such as autism. The involvement of patient intrinsic factors was indicated, but the mechanism is largely unknown. Methods Ohia mice with HLHS causing mutations in chromatin modifier Sin3A-associated protein 130 (Sap130) and cell adhesion protein ProtocadherinA9 (Pcdha9) were investigated for brain abnormalities by histology, immunomicroscopy, and molecular profiling by RNAseq, Sap130 ChIPseq, and genome-wide methylome analysis. Additionally, adult viable Pcdha9m/m and Emx1-cre:Sap130f/− mice with forebrain deletion of Sap130 were examined by brain MRI and behavioral assessments. Results Ohia mice have brain abnormalities comprising forebrain hypoplasia and microcephaly in conjunction with a cortical neurogenesis defect. This is associated with loss of intermediate progenitors due to mitotic arrest and apoptosis from multipolar spindle formation, a mechanism also observed in primary microcephaly. Brain RNAseq showed perturbation of REST transcriptional regulation of neurogenesis, disruption of CREB signaling regulating synaptic plasticity and memory, and defects in neurovascular coupling indicating perturbation of brain-sparing cerebral autoregulation. Disease pathways recovered included autism, intellectual disability, and other neurobehavioral/neurological deficits. These same pathways were observed upon intersection of genes that are differentially expressed with those that are differentially methylated and also are ChIPseq targets of Sap130, suggesting the transcriptional changes are epigenetically regulated. Adult viable mice harboring either the Pcdha9 mutation or forebrain-specific Sap130 deletion showed similar learning/memory deficits and autism-like behavior, suggesting they act on convergent pathways. Conclusions Our observations indicate the intrinsic factors contributing to the adverse neurodevelopmental outcome associated with HLHS involve spindle defects causing impaired corticoneurogenesis, and brain and behavioral deficits associated with perturbed epigenetic regulation of neurodevelopmental pathways. Novelty and Significance What is known? Hypoplastic left heart syndrome (HLHS), a severe congenital heart disease, is associated with adverse neurodevelopmental outcome attributable to patient intrinsic factors. Cortical neurogenesis defect with reduced brain volume and microcephaly are observed beginning in utero, suggesting a developmental etiology. Learning impairment and autism spectrum disorder are commonly observed in HLHS. What new information does this article contribute? The Ohia HLHS mouse model exhibits neurodevelopmental deficits comprising microcephaly and cortical neurogenesis defects with loss of neural progenitors from multipolar spindle formation, as well as impaired neurovascular coupling. Molecular profiling showed disturbance of REST, transcriptional regulator of neural stem cells, and CREB signaling regulating synaptic plasticity, with neurobehavioral assessments of the mutant mice showing learning/memory and autism-like behavioral deficits. Intersection of transcriptome and DNA methylation analyses uncovered an epigenetic basis for the neurodevelopmental/neurobehavioral abnormalities, Analysis of an HLHS mouse model indicated patient intrinsic factors causing adverse neurodevelopment in HLHS are genetic and epigenetic in etiology. This may include a mitotic spindle defect that would not be rescued by in utero aortic valvuloplasty, and a defect in neurovascular coupling that is likely to reduce the efficacy of maternal hyperoxygenation. However, epigenetic therapy may provide a new avenue for treatment that should be explored.",data/paper_jsons/M. Ganapathiraju_32747279.json,
"What journal was the paper ""Pathogenic mechanisms underlying adverse neurodevelopmental outcome in congenital heart disease"" published in?",bioRxiv,M. Ganapathiraju_32747279.json,
"What venue was the paper ""Pathogenic mechanisms underlying adverse neurodevelopmental outcome in congenital heart disease"" published in?",bioRxiv,M. Ganapathiraju_32747279.json,
"How many citations does the paper ""Pathogenic mechanisms underlying adverse neurodevelopmental outcome in congenital heart disease"" have?",0,M. Ganapathiraju_32747279.json,
"Who are the authors of the paper ""Pathogenic mechanisms underlying adverse neurodevelopmental outcome in congenital heart disease""?","George C Gabriel, Hisato Yagi, Tuantuan Tan, A. Bais, Benjamin J. Glennon, Margaret C. Stapleton, Lihua Huang, William T Reynolds, Marla G. Shaffer, Xinxiu Xu, M. Ganapathiraju, Dennis Simon, Ashok Panigrahy, Yijen L. Wu, Cecilia W Lo",M. Ganapathiraju_32747279.json,
"Who is the first author of the paper ""Pathogenic mechanisms underlying adverse neurodevelopmental outcome in congenital heart disease""?",George C Gabriel,M. Ganapathiraju_32747279.json,
"What is the paper ID of the paper ""Pathogenic mechanisms underlying adverse neurodevelopmental outcome in congenital heart disease""?",bc603b3878dd8638254f3746b892100cad687ea5,M. Ganapathiraju_32747279.json,
What paper has the paper ID bc603b3878dd8638254f3746b892100cad687ea5?,Pathogenic mechanisms underlying adverse neurodevelopmental outcome in congenital heart disease,M. Ganapathiraju_32747279.json,
What is the TLDR of the paper 'Pathogenic mechanisms underlying adverse neurodevelopmental outcome in congenital heart disease'?,"The observations indicate the intrinsic factors contributing to the adverse neurodevelopmental outcome associated with HLHS involve spindle defects causing impaired corticoneurogenesis, and brain and behavioral deficits associated with perturbed epigenetic regulation of neuro developmental pathways.",M. Ganapathiraju_32747279.json,
What is the abstract of the paper 'Pathogenic mechanisms underlying adverse neurodevelopmental outcome in congenital heart disease'?,"Background Hypoplastic left heart syndrome (HLHS), a severe congenital heart disease, is associated with poor neurodevelopmental outcomes, microcephaly, reduced cortical brain volume, brain dysmaturation, and neurobehavioral disorders such as autism. The involvement of patient intrinsic factors was indicated, but the mechanism is largely unknown. Methods Ohia mice with HLHS causing mutations in chromatin modifier Sin3A-associated protein 130 (Sap130) and cell adhesion protein ProtocadherinA9 (Pcdha9) were investigated for brain abnormalities by histology, immunomicroscopy, and molecular profiling by RNAseq, Sap130 ChIPseq, and genome-wide methylome analysis. Additionally, adult viable Pcdha9m/m and Emx1-cre:Sap130f/− mice with forebrain deletion of Sap130 were examined by brain MRI and behavioral assessments. Results Ohia mice have brain abnormalities comprising forebrain hypoplasia and microcephaly in conjunction with a cortical neurogenesis defect. This is associated with loss of intermediate progenitors due to mitotic arrest and apoptosis from multipolar spindle formation, a mechanism also observed in primary microcephaly. Brain RNAseq showed perturbation of REST transcriptional regulation of neurogenesis, disruption of CREB signaling regulating synaptic plasticity and memory, and defects in neurovascular coupling indicating perturbation of brain-sparing cerebral autoregulation. Disease pathways recovered included autism, intellectual disability, and other neurobehavioral/neurological deficits. These same pathways were observed upon intersection of genes that are differentially expressed with those that are differentially methylated and also are ChIPseq targets of Sap130, suggesting the transcriptional changes are epigenetically regulated. Adult viable mice harboring either the Pcdha9 mutation or forebrain-specific Sap130 deletion showed similar learning/memory deficits and autism-like behavior, suggesting they act on convergent pathways. Conclusions Our observations indicate the intrinsic factors contributing to the adverse neurodevelopmental outcome associated with HLHS involve spindle defects causing impaired corticoneurogenesis, and brain and behavioral deficits associated with perturbed epigenetic regulation of neurodevelopmental pathways. Novelty and Significance What is known? Hypoplastic left heart syndrome (HLHS), a severe congenital heart disease, is associated with adverse neurodevelopmental outcome attributable to patient intrinsic factors. Cortical neurogenesis defect with reduced brain volume and microcephaly are observed beginning in utero, suggesting a developmental etiology. Learning impairment and autism spectrum disorder are commonly observed in HLHS. What new information does this article contribute? The Ohia HLHS mouse model exhibits neurodevelopmental deficits comprising microcephaly and cortical neurogenesis defects with loss of neural progenitors from multipolar spindle formation, as well as impaired neurovascular coupling. Molecular profiling showed disturbance of REST, transcriptional regulator of neural stem cells, and CREB signaling regulating synaptic plasticity, with neurobehavioral assessments of the mutant mice showing learning/memory and autism-like behavioral deficits. Intersection of transcriptome and DNA methylation analyses uncovered an epigenetic basis for the neurodevelopmental/neurobehavioral abnormalities, Analysis of an HLHS mouse model indicated patient intrinsic factors causing adverse neurodevelopment in HLHS are genetic and epigenetic in etiology. This may include a mitotic spindle defect that would not be rescued by in utero aortic valvuloplasty, and a defect in neurovascular coupling that is likely to reduce the efficacy of maternal hyperoxygenation. However, epigenetic therapy may provide a new avenue for treatment that should be explored.",M. Ganapathiraju_32747279.json,
"What journal was the paper ""Editorial: Systems biology, women in science 2021/22: translational systems biology and in silico trials"" published in?",Frontiers in Systems Biology,M. Ganapathiraju_32747279.json,
"What venue was the paper ""Editorial: Systems biology, women in science 2021/22: translational systems biology and in silico trials"" published in?",Frontiers in Systems Biology,M. Ganapathiraju_32747279.json,
"How many citations does the paper ""Editorial: Systems biology, women in science 2021/22: translational systems biology and in silico trials"" have?",0,M. Ganapathiraju_32747279.json,
"Who are the authors of the paper ""Editorial: Systems biology, women in science 2021/22: translational systems biology and in silico trials""?","Jane A. Leopold, M. Ganapathiraju, N. Yanamala",M. Ganapathiraju_32747279.json,
"Who is the first author of the paper ""Editorial: Systems biology, women in science 2021/22: translational systems biology and in silico trials""?",Jane A. Leopold,M. Ganapathiraju_32747279.json,
"What is the paper ID of the paper ""Editorial: Systems biology, women in science 2021/22: translational systems biology and in silico trials""?",de52a2f746c5cf145ee2af3a978ee1942eec1a57,M. Ganapathiraju_32747279.json,
What paper has the paper ID de52a2f746c5cf145ee2af3a978ee1942eec1a57?,"Editorial: Systems biology, women in science 2021/22: translational systems biology and in silico trials",M. Ganapathiraju_32747279.json,
"What is the TLDR of the paper 'Editorial: Systems biology, women in science 2021/22: translational systems biology and in silico trials'?",TLDR not found,M. Ganapathiraju_32747279.json,
"What is the abstract of the paper 'Editorial: Systems biology, women in science 2021/22: translational systems biology and in silico trials'?",,M. Ganapathiraju_32747279.json,
What is the author ID of Maarten Sap?,2729164,data/paper_jsons/Maarten Sap_2729164.json,
What are the papers of Maarten Sap?,"Modeling Empathic Similarity in Personal Narratives, COBRA Frames: Contextual Reasoning about Effects and Harms of Offensive Statements, Riveter: Measuring Power and Social Dynamics Between Entities, Don't Take This Out of Context!: On the Need for Contextual Models and Evaluations for Stylistic Rewriting, BiasX: ""Thinking Slow"" in Toxic Content Moderation with Explanations of Implied Social Biases, Improving Language Models with Advantage-based Offline Policy Gradients, From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models, NLPositionality: Characterizing Design Biases of Datasets and Models, Don't Take This Out of Context! On the Need for Contextual Models and Evaluations for Stylistic Rewriting, Queer In AI: A Case Study in Community-Led Participatory AI, Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties, Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models, Towards Countering Essentialism through Social Bias Reasoning",data/paper_jsons/Maarten Sap_2729164.json,
What is the H-index of Maarten Sap?,36,data/paper_jsons/Maarten Sap_2729164.json,
What is the author citation count of Maarten Sap?,7517,data/paper_jsons/Maarten Sap_2729164.json,
What journals has Maarten Sap published in?,"ArXiv, Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency",data/paper_jsons/Maarten Sap_2729164.json,
What are the journals and how many papers has Maarten Sap published in each?,"{'ArXiv': 10, 'Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency': 1}",data/paper_jsons/Maarten Sap_2729164.json,
What are the fields of study of Maarten Sap?,Computer Science,data/paper_jsons/Maarten Sap_2729164.json,
How many papers has Maarten Sap published in open access journals?,13,data/paper_jsons/Maarten Sap_2729164.json,
What venues has Maarten Sap published in?,"Conference on Empirical Methods in Natural Language Processing, Annual Meeting of the Association for Computational Linguistics, arXiv.org, Conference on Fairness, Accountability and Transparency",data/paper_jsons/Maarten Sap_2729164.json,
What is the most cited paper from Maarten Sap?,Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models,data/paper_jsons/Maarten Sap_2729164.json,
What is the url of the most cited paper from Maarten Sap?,http://arxiv.org/pdf/2305.14763,data/paper_jsons/Maarten Sap_2729164.json,
Who are the authors of the most cited paper from Maarten Sap?,"Natalie Shapira, Mosh Levy, S. Alavi, Xuhui Zhou, Yejin Choi, Yoav Goldberg, Maarten Sap, Vered Shwartz",data/paper_jsons/Maarten Sap_2729164.json,
TLDR of the most cited paper from Maarten Sap?,"It is found that while LLMs exhibit certain N-ToM abilities, this behavior is far from being robust, indicating reliance on shallow heuristics rather than robust ToM abilities.",data/paper_jsons/Maarten Sap_2729164.json,
Abstract of the most cited paper from Maarten Sap?,"The escalating debate on AI's capabilities warrants developing reliable metrics to assess machine""intelligence"". Recently, many anecdotal examples were used to suggest that newer large language models (LLMs) like ChatGPT and GPT-4 exhibit Neural Theory-of-Mind (N-ToM); however, prior work reached conflicting conclusions regarding those abilities. We investigate the extent of LLMs' N-ToM through an extensive evaluation on 6 tasks and find that while LLMs exhibit certain N-ToM abilities, this behavior is far from being robust. We further examine the factors impacting performance on N-ToM tasks and discover that LLMs struggle with adversarial examples, indicating reliance on shallow heuristics rather than robust ToM abilities. We caution against drawing conclusions from anecdotal examples, limited benchmark testing, and using human-designed psychological tests to evaluate models.",data/paper_jsons/Maarten Sap_2729164.json,
"What journal was the paper ""Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models"" published in?",ArXiv,Maarten Sap_2729164.json,
"What venue was the paper ""Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models"" published in?",arXiv.org,Maarten Sap_2729164.json,
"How many citations does the paper ""Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models"" have?",38,Maarten Sap_2729164.json,
"Who are the authors of the paper ""Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models""?","Natalie Shapira, Mosh Levy, S. Alavi, Xuhui Zhou, Yejin Choi, Yoav Goldberg, Maarten Sap, Vered Shwartz",Maarten Sap_2729164.json,
"Who is the first author of the paper ""Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models""?",Natalie Shapira,Maarten Sap_2729164.json,
"What is the paper ID of the paper ""Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models""?",ddcd2bcc809bd0c2755a4a9487473d61ac327c50,Maarten Sap_2729164.json,
What paper has the paper ID ddcd2bcc809bd0c2755a4a9487473d61ac327c50?,Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models,Maarten Sap_2729164.json,
What is the TLDR of the paper 'Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models'?,"It is found that while LLMs exhibit certain N-ToM abilities, this behavior is far from being robust, indicating reliance on shallow heuristics rather than robust ToM abilities.",Maarten Sap_2729164.json,
What is the abstract of the paper 'Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models'?,"The escalating debate on AI's capabilities warrants developing reliable metrics to assess machine""intelligence"". Recently, many anecdotal examples were used to suggest that newer large language models (LLMs) like ChatGPT and GPT-4 exhibit Neural Theory-of-Mind (N-ToM); however, prior work reached conflicting conclusions regarding those abilities. We investigate the extent of LLMs' N-ToM through an extensive evaluation on 6 tasks and find that while LLMs exhibit certain N-ToM abilities, this behavior is far from being robust. We further examine the factors impacting performance on N-ToM tasks and discover that LLMs struggle with adversarial examples, indicating reliance on shallow heuristics rather than robust ToM abilities. We caution against drawing conclusions from anecdotal examples, limited benchmark testing, and using human-designed psychological tests to evaluate models.",Maarten Sap_2729164.json,
"What journal was the paper ""BiasX: ""Thinking Slow"" in Toxic Content Moderation with Explanations of Implied Social Biases"" published in?",ArXiv,Maarten Sap_2729164.json,
"What venue was the paper ""BiasX: ""Thinking Slow"" in Toxic Content Moderation with Explanations of Implied Social Biases"" published in?",Conference on Empirical Methods in Natural Language Processing,Maarten Sap_2729164.json,
"How many citations does the paper ""BiasX: ""Thinking Slow"" in Toxic Content Moderation with Explanations of Implied Social Biases"" have?",0,Maarten Sap_2729164.json,
"Who are the authors of the paper ""BiasX: ""Thinking Slow"" in Toxic Content Moderation with Explanations of Implied Social Biases""?","Yiming Zhang, Sravani Nanduri, Liwei Jiang, Tongshuang Wu, Maarten Sap",Maarten Sap_2729164.json,
"Who is the first author of the paper ""BiasX: ""Thinking Slow"" in Toxic Content Moderation with Explanations of Implied Social Biases""?",Yiming Zhang,Maarten Sap_2729164.json,
"What is the paper ID of the paper ""BiasX: ""Thinking Slow"" in Toxic Content Moderation with Explanations of Implied Social Biases""?",85a5ffc509fa50c96b415e09ae87fb6e5f435b37,Maarten Sap_2729164.json,
What paper has the paper ID 85a5ffc509fa50c96b415e09ae87fb6e5f435b37?,"BiasX: ""Thinking Slow"" in Toxic Content Moderation with Explanations of Implied Social Biases",Maarten Sap_2729164.json,
"What is the TLDR of the paper 'BiasX: ""Thinking Slow"" in Toxic Content Moderation with Explanations of Implied Social Biases'?","BiasX, a framework that enhances content moderation setups with free-text explanations of statements' implied social biases, is introduced and it is shown that indeed, participants substantially benefit from explanations for correctly identifying subtly (non-)toxic content.",Maarten Sap_2729164.json,
"What is the abstract of the paper 'BiasX: ""Thinking Slow"" in Toxic Content Moderation with Explanations of Implied Social Biases'?","Toxicity annotators and content moderators often default to mental shortcuts when making decisions. This can lead to subtle toxicity being missed, and seemingly toxic but harmless content being over-detected. We introduce BiasX, a framework that enhances content moderation setups with free-text explanations of statements' implied social biases, and explore its effectiveness through a large-scale crowdsourced user study. We show that indeed, participants substantially benefit from explanations for correctly identifying subtly (non-)toxic content. The quality of explanations is critical: imperfect machine-generated explanations (+2.4% on hard toxic examples) help less compared to expert-written human explanations (+7.2%). Our results showcase the promise of using free-text explanations to encourage more thoughtful toxicity moderation.",Maarten Sap_2729164.json,
"What journal was the paper ""Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties"" published in?",ArXiv,Maarten Sap_2729164.json,
"What venue was the paper ""Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties"" published in?",arXiv.org,Maarten Sap_2729164.json,
"How many citations does the paper ""Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties"" have?",8,Maarten Sap_2729164.json,
"Who are the authors of the paper ""Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties""?","Taylor Sorensen, Liwei Jiang, Jena D. Hwang, Sydney Levine, Valentina Pyatkin, Peter West, Nouha Dziri, Ximing Lu, Kavel Rao, Chandra Bhagavatula, Maarten Sap, J. Tasioulas, Yejin Choi",Maarten Sap_2729164.json,
"Who is the first author of the paper ""Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties""?",Taylor Sorensen,Maarten Sap_2729164.json,
"What is the paper ID of the paper ""Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties""?",d655f652d02251b45db43181c5e3c73dfc59cd51,Maarten Sap_2729164.json,
What paper has the paper ID d655f652d02251b45db43181c5e3c73dfc59cd51?,"Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties",Maarten Sap_2729164.json,
"What is the TLDR of the paper 'Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties'?","Kaleido is built, an open, light-weight, and structured language-based multi-task model that generates, explains, and assesses the relevance and valence of human values, rights, and duties within a specific context and demonstrates that Kaleido can help explain variability in human decision-making by outputting contrasting values.",Maarten Sap_2729164.json,
"What is the abstract of the paper 'Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties'?","Human values are crucial to human decision-making. Value pluralism is the view that multiple correct values may be held in tension with one another (e.g., when considering lying to a friend to protect their feelings, how does one balance honesty with friendship?). As statistical learners, AI systems fit to averages by default, washing out these potentially irreducible value conflicts. To improve AI systems to better reflect value pluralism, the first-order challenge is to explore the extent to which AI systems can model pluralistic human values, rights, and duties as well as their interaction. We introduce ValuePrism, a large-scale dataset of 218k values, rights, and duties connected to 31k human-written situations. ValuePrism's contextualized values are generated by GPT-4 and deemed high-quality by human annotators 91% of the time. We conduct a large-scale study with annotators across diverse social and demographic backgrounds to try to understand whose values are represented. With ValuePrism, we build Kaleido, an open, light-weight, and structured language-based multi-task model that generates, explains, and assesses the relevance and valence (i.e., support or oppose) of human values, rights, and duties within a specific context. Humans prefer the sets of values output by our system over the teacher GPT-4, finding them more accurate and with broader coverage. In addition, we demonstrate that Kaleido can help explain variability in human decision-making by outputting contrasting values. Finally, we show that Kaleido's representations transfer to other philosophical frameworks and datasets, confirming the benefit of an explicit, modular, and interpretable approach to value pluralism. We hope that our work will serve as a step to making more explicit the implicit values behind human decision-making and to steering AI systems to make decisions that are more in accordance with them.",Maarten Sap_2729164.json,
What is the author ID of Malihe Alikhani?,2715920,data/paper_jsons/Malihe Alikhani_2715920.json,
What are the papers of Malihe Alikhani?,"Learning to Generate Equitable Text in Dialogue from Biased Training Data, Learning Multimodal Cues of Children’s Uncertainty, Findings of the Second WMT Shared Task on Sign Language Translation (WMT-SLT23), Multilingual Content Moderation: A Case Study on Reddit, Image–text coherence and its implications for multimodal AI, A corpus of Persian literary text, D-CALM: A Dynamic Clustering-based Active Learning Approach for Mitigating Bias",data/paper_jsons/Malihe Alikhani_2715920.json,
What is the H-index of Malihe Alikhani?,12,data/paper_jsons/Malihe Alikhani_2715920.json,
What is the author citation count of Malihe Alikhani?,520,data/paper_jsons/Malihe Alikhani_2715920.json,
What journals has Malihe Alikhani published in?,"ArXiv, Frontiers in Artificial Intelligence, Language Resources and Evaluation",data/paper_jsons/Malihe Alikhani_2715920.json,
What are the journals and how many papers has Malihe Alikhani published in each?,"{'ArXiv': 1, 'Frontiers in Artificial Intelligence': 1, 'Language Resources and Evaluation': 1}",data/paper_jsons/Malihe Alikhani_2715920.json,
What are the fields of study of Malihe Alikhani?,"Computer Science, Medicine",data/paper_jsons/Malihe Alikhani_2715920.json,
How many papers has Malihe Alikhani published in open access journals?,7,data/paper_jsons/Malihe Alikhani_2715920.json,
What venues has Malihe Alikhani published in?,"Annual Meeting of the Association for Computational Linguistics, SIGDIAL Conferences, Conference on Machine Translation, Conference of the European Chapter of the Association for Computational Linguistics, Frontiers in Artificial Intelligence, Language Resources and Evaluation",data/paper_jsons/Malihe Alikhani_2715920.json,
What is the most cited paper from Malihe Alikhani?,Findings of the Second WMT Shared Task on Sign Language Translation (WMT-SLT23),data/paper_jsons/Malihe Alikhani_2715920.json,
What is the url of the most cited paper from Malihe Alikhani?,https://aclanthology.org/2023.wmt-1.4.pdf,data/paper_jsons/Malihe Alikhani_2715920.json,
Who are the authors of the most cited paper from Malihe Alikhani?,"Mathias Müller, Malihe Alikhani, Eleftherios Avramidis, Richard Bowden, Annelies Braffort, Necati Cihan Camgöz, Sarah Ebling, Cristina España-Bonet, A. Göhring, Roman Grundkiewicz, Mert Inan, Zifan Jiang, Oscar Koller, Amit Moryossef, Annette Rios, D. Shterionov, Sandra Sidler-Miserez, Katja Tissi, Davy Van Landuyt",data/paper_jsons/Malihe Alikhani_2715920.json,
TLDR of the most cited paper from Malihe Alikhani?,"This paper presents the results of the Second WMT Shared Task on Sign Language Translation, concerned with automatic translation between signed and spoken languages, which resulted in publicly available sets of system outputs and more human evaluation scores for sign language translation.",data/paper_jsons/Malihe Alikhani_2715920.json,
Abstract of the most cited paper from Malihe Alikhani?,"This paper presents the results of the Second WMT Shared Task on Sign Language Translation (WMT-SLT23; https://www.wmt-slt.com/). This shared task is concerned with automatic translation between signed and spoken languages. The task is unusual in the sense that it requires processing visual information (such as video frames or human pose estimation) beyond the well-known paradigm of text-to-text machine translation (MT). The task offers four tracks involving the following languages: Swiss German Sign Language (DSGS), French Sign Language of Switzerland (LSF-CH), Italian Sign Language of Switzerland (LIS-CH), German, French and Italian. Four teams (including one working on a baseline submission) participated in this second edition of the task, all submitting to the DSGS-to-German track. Besides a system ranking and system papers describing state-of-the-art techniques, this shared task makes the following scientific contributions: novel corpora and reproducible baseline systems. Finally, the task also resulted in publicly available sets of system outputs and more human evaluation scores for sign language translation.",data/paper_jsons/Malihe Alikhani_2715920.json,
"What journal was the paper ""A corpus of Persian literary text"" published in?",Language Resources and Evaluation,Malihe Alikhani_2715920.json,
"What venue was the paper ""A corpus of Persian literary text"" published in?",Language Resources and Evaluation,Malihe Alikhani_2715920.json,
"How many citations does the paper ""A corpus of Persian literary text"" have?",0,Malihe Alikhani_2715920.json,
"Who are the authors of the paper ""A corpus of Persian literary text""?","Shahab Raji, Malihe Alikhani, Gerard de Melo, Matthew Stone",Malihe Alikhani_2715920.json,
"Who is the first author of the paper ""A corpus of Persian literary text""?",Shahab Raji,Malihe Alikhani_2715920.json,
"What is the paper ID of the paper ""A corpus of Persian literary text""?",ee866d0dd47351542e4924f14203a767dd03194a,Malihe Alikhani_2715920.json,
What paper has the paper ID ee866d0dd47351542e4924f14203a767dd03194a?,A corpus of Persian literary text,Malihe Alikhani_2715920.json,
What is the TLDR of the paper 'A corpus of Persian literary text'?,"The corpus, the tools, and experiments described in this paper can be used not only for digital humanities studies of Persian literature but also for processing Persian texts in general, as well as in other broader cross-linguistic applications.",Malihe Alikhani_2715920.json,
What is the abstract of the paper 'A corpus of Persian literary text'?,,Malihe Alikhani_2715920.json,
"What journal was the paper ""D-CALM: A Dynamic Clustering-based Active Learning Approach for Mitigating Bias"" published in?",,Malihe Alikhani_2715920.json,
"What venue was the paper ""D-CALM: A Dynamic Clustering-based Active Learning Approach for Mitigating Bias"" published in?",Annual Meeting of the Association for Computational Linguistics,Malihe Alikhani_2715920.json,
"How many citations does the paper ""D-CALM: A Dynamic Clustering-based Active Learning Approach for Mitigating Bias"" have?",1,Malihe Alikhani_2715920.json,
"Who are the authors of the paper ""D-CALM: A Dynamic Clustering-based Active Learning Approach for Mitigating Bias""?","Sabit Hassan, Malihe Alikhani",Malihe Alikhani_2715920.json,
"Who is the first author of the paper ""D-CALM: A Dynamic Clustering-based Active Learning Approach for Mitigating Bias""?",Sabit Hassan,Malihe Alikhani_2715920.json,
"What is the paper ID of the paper ""D-CALM: A Dynamic Clustering-based Active Learning Approach for Mitigating Bias""?",f19180afd6cae7c241fa461eed122e4c04a14217,Malihe Alikhani_2715920.json,
What paper has the paper ID f19180afd6cae7c241fa461eed122e4c04a14217?,D-CALM: A Dynamic Clustering-based Active Learning Approach for Mitigating Bias,Malihe Alikhani_2715920.json,
What is the TLDR of the paper 'D-CALM: A Dynamic Clustering-based Active Learning Approach for Mitigating Bias'?,"A novel adaptive clustering-based active learning algorithm that dynamically adjusts clustering and annotation efforts in response to an estimated classifier error-rate, D-CALM, which showcases robustness against different measures of information gain and can significantly reduce unwanted model bias.",Malihe Alikhani_2715920.json,
What is the abstract of the paper 'D-CALM: A Dynamic Clustering-based Active Learning Approach for Mitigating Bias'?,"Despite recent advancements, NLP models continue to be vulnerable to bias. This bias often originates from the uneven distribution of real-world data and can propagate through the annotation process. Escalated integration of these models in our lives calls for methods to mitigate bias without overbearing annotation costs. While active learning (AL) has shown promise in training models with a small amount of annotated data, AL's reliance on the model's behavior for selective sampling can lead to an accumulation of unwanted bias rather than bias mitigation. However, infusing clustering with AL can overcome the bias issue of both AL and traditional annotation methods while exploiting AL's annotation efficiency. In this paper, we propose a novel adaptive clustering-based active learning algorithm, D-CALM, that dynamically adjusts clustering and annotation efforts in response to an estimated classifier error-rate. Experiments on eight datasets for a diverse set of text classification tasks, including emotion, hatespeech, dialog act, and book type detection, demonstrate that our proposed algorithm significantly outperforms baseline AL approaches with both pretrained transformers and traditional Support Vector Machines. D-CALM showcases robustness against different measures of information gain and, as evident from our analysis of label and error distribution, can significantly reduce unwanted model bias.",Malihe Alikhani_2715920.json,
"What journal was the paper ""Image–text coherence and its implications for multimodal AI"" published in?",Frontiers in Artificial Intelligence,Malihe Alikhani_2715920.json,
"What venue was the paper ""Image–text coherence and its implications for multimodal AI"" published in?",Frontiers in Artificial Intelligence,Malihe Alikhani_2715920.json,
"How many citations does the paper ""Image–text coherence and its implications for multimodal AI"" have?",2,Malihe Alikhani_2715920.json,
"Who are the authors of the paper ""Image–text coherence and its implications for multimodal AI""?","Malihe Alikhani, Baber Khalid, Matthew Stone",Malihe Alikhani_2715920.json,
"Who is the first author of the paper ""Image–text coherence and its implications for multimodal AI""?",Malihe Alikhani,Malihe Alikhani_2715920.json,
"What is the paper ID of the paper ""Image–text coherence and its implications for multimodal AI""?",e2be92ff1ae2abdc05c1929d6d02623c58f37097,Malihe Alikhani_2715920.json,
What paper has the paper ID e2be92ff1ae2abdc05c1929d6d02623c58f37097?,Image–text coherence and its implications for multimodal AI,Malihe Alikhani_2715920.json,
What is the TLDR of the paper 'Image–text coherence and its implications for multimodal AI'?,"This paper shows how image–text coherence relations can be used to model the pragmatics of image-text presentations in AI systems, and reviews case studies describing coherence in image– Text data sets, predicting coherence from few-shot annotations, and coherence models of image– text tasks such as caption generation and caption evaluation.",Malihe Alikhani_2715920.json,
What is the abstract of the paper 'Image–text coherence and its implications for multimodal AI'?,"Human communication often combines imagery and text into integrated presentations, especially online. In this paper, we show how image–text coherence relations can be used to model the pragmatics of image–text presentations in AI systems. In contrast to alternative frameworks that characterize image–text presentations in terms of the priority, relevance, or overlap of information across modalities, coherence theory postulates that each unit of a discourse stands in specific pragmatic relations to other parts of the discourse, with each relation involving its own information goals and inferential connections. Text accompanying an image may, for example, characterize what's visible in the image, explain how the image was obtained, offer the author's appraisal of or reaction to the depicted situation, and so forth. The advantage of coherence theory is that it provides a simple, robust, and effective abstraction of communicative goals for practical applications. To argue this, we review case studies describing coherence in image–text data sets, predicting coherence from few-shot annotations, and coherence models of image–text tasks such as caption generation and caption evaluation.",Malihe Alikhani_2715920.json,
What is the author ID of Matt Gormley?,1762110,data/paper_jsons/Matthew R. Gormley_1762110.json,
What are the papers of Matt Gormley?,"It’s MBR All the Way Down: Modern Generation Techniques Through the Lens of Minimum Bayes Risk, Unlimiformer: Long-Range Transformers with Unlimited Length Input, MDACE: MIMIC Documents Annotated with Code Evidence, SummQA at MEDIQA-Chat 2023: In-Context Learning with GPT-4 for Medical Summarization",data/paper_jsons/Matthew R. Gormley_1762110.json,
What is the H-index of Matt Gormley?,17,data/paper_jsons/Matthew R. Gormley_1762110.json,
What is the author citation count of Matt Gormley?,1117,data/paper_jsons/Matthew R. Gormley_1762110.json,
What journals has Matt Gormley published in?,ArXiv,data/paper_jsons/Matthew R. Gormley_1762110.json,
What are the journals and how many papers has Matt Gormley published in each?,{'ArXiv': 3},data/paper_jsons/Matthew R. Gormley_1762110.json,
What are the fields of study of Matt Gormley?,Computer Science,data/paper_jsons/Matthew R. Gormley_1762110.json,
How many papers has Matt Gormley published in open access journals?,4,data/paper_jsons/Matthew R. Gormley_1762110.json,
What venues has Matt Gormley published in?,"BIGPICTURE, arXiv.org, Annual Meeting of the Association for Computational Linguistics, Clinical Natural Language Processing Workshop",data/paper_jsons/Matthew R. Gormley_1762110.json,
What is the most cited paper from Matt Gormley?,Unlimiformer: Long-Range Transformers with Unlimited Length Input,data/paper_jsons/Matthew R. Gormley_1762110.json,
What is the url of the most cited paper from Matt Gormley?,http://arxiv.org/pdf/2305.01625,data/paper_jsons/Matthew R. Gormley_1762110.json,
Who are the authors of the most cited paper from Matt Gormley?,"Amanda Bertsch, Uri Alon, Graham Neubig, Matthew R. Gormley",data/paper_jsons/Matthew R. Gormley_1762110.json,
TLDR of the most cited paper from Matt Gormley?,"This work proposes Unlimiformer: a general approach that wraps any existing pretrained encoder-decoder transformer, and offloads the cross-attention computation to a single k-nearest-neighbor (kNN) index, while the returned kNN distances are the attention dot-product scores.",data/paper_jsons/Matthew R. Gormley_1762110.json,
Abstract of the most cited paper from Matt Gormley?,"Since the proposal of transformers, these models have been limited to bounded input lengths, because of their need to attend to every token in the input. In this work, we propose Unlimiformer: a general approach that wraps any existing pretrained encoder-decoder transformer, and offloads the cross-attention computation to a single k-nearest-neighbor (kNN) index, while the returned kNN distances are the attention dot-product scores. This kNN index can be kept on either the GPU or CPU memory and queried in sub-linear time; this way, we can index practically unlimited input sequences, while every attention head in every decoder layer retrieves its top-k keys, instead of attending to every key. We evaluate Unlimiformer on several long-document and book-summarization benchmarks, showing that it can process even 500k token-long inputs from the BookSum dataset, without any input truncation at test time. We demonstrate that Unlimiformer improves pretrained models such as BART and Longformer by extending them to unlimited inputs without additional learned weights and without modifying their code. We make our code and models publicly available at https://github.com/abertsch72/unlimiformer .",data/paper_jsons/Matthew R. Gormley_1762110.json,
"What journal was the paper ""It’s MBR All the Way Down: Modern Generation Techniques Through the Lens of Minimum Bayes Risk"" published in?",ArXiv,Matthew R. Gormley_1762110.json,
"What venue was the paper ""It’s MBR All the Way Down: Modern Generation Techniques Through the Lens of Minimum Bayes Risk"" published in?",BIGPICTURE,Matthew R. Gormley_1762110.json,
"How many citations does the paper ""It’s MBR All the Way Down: Modern Generation Techniques Through the Lens of Minimum Bayes Risk"" have?",6,Matthew R. Gormley_1762110.json,
"Who are the authors of the paper ""It’s MBR All the Way Down: Modern Generation Techniques Through the Lens of Minimum Bayes Risk""?","Amanda Bertsch, Alex Xie, Graham Neubig, Matthew R. Gormley",Matthew R. Gormley_1762110.json,
"Who is the first author of the paper ""It’s MBR All the Way Down: Modern Generation Techniques Through the Lens of Minimum Bayes Risk""?",Amanda Bertsch,Matthew R. Gormley_1762110.json,
"What is the paper ID of the paper ""It’s MBR All the Way Down: Modern Generation Techniques Through the Lens of Minimum Bayes Risk""?",d6ae4c0679bdceb029f652efd2a854ac5ade772f,Matthew R. Gormley_1762110.json,
What paper has the paper ID d6ae4c0679bdceb029f652efd2a854ac5ade772f?,It’s MBR All the Way Down: Modern Generation Techniques Through the Lens of Minimum Bayes Risk,Matthew R. Gormley_1762110.json,
What is the TLDR of the paper 'It’s MBR All the Way Down: Modern Generation Techniques Through the Lens of Minimum Bayes Risk'?,"It is shown that several recent methods that do not reference MBR can be written as special cases of MBR; this reformulation provides additional theoretical justification for the performance of these methods, explaining some results that were previously only empirical.",Matthew R. Gormley_1762110.json,
What is the abstract of the paper 'It’s MBR All the Way Down: Modern Generation Techniques Through the Lens of Minimum Bayes Risk'?,"Minimum Bayes Risk (MBR) decoding is a method for choosing the outputs of a machine learning system based not on the output with the highest probability, but the output with the lowest risk (expected error) among multiple candidates. It is a simple but powerful method: for an additional cost at inference time, MBR provides reliable several-point improvements across metrics for a wide variety of tasks without any additional data or training. Despite this, MBR is not frequently applied in NLP works, and knowledge of the method itself is limited. We first provide an introduction to the method and the recent literature. We show that several recent methods that do not reference MBR can be written as special cases of MBR; this reformulation provides additional theoretical justification for the performance of these methods, explaining some results that were previously only empirical. We provide theoretical and empirical results about the effectiveness of various MBR variants and make concrete recommendations for the application of MBR in NLP models, including future directions in this area.",Matthew R. Gormley_1762110.json,
"What journal was the paper ""Unlimiformer: Long-Range Transformers with Unlimited Length Input"" published in?",ArXiv,Matthew R. Gormley_1762110.json,
"What venue was the paper ""Unlimiformer: Long-Range Transformers with Unlimited Length Input"" published in?",arXiv.org,Matthew R. Gormley_1762110.json,
"How many citations does the paper ""Unlimiformer: Long-Range Transformers with Unlimited Length Input"" have?",38,Matthew R. Gormley_1762110.json,
"Who are the authors of the paper ""Unlimiformer: Long-Range Transformers with Unlimited Length Input""?","Amanda Bertsch, Uri Alon, Graham Neubig, Matthew R. Gormley",Matthew R. Gormley_1762110.json,
"Who is the first author of the paper ""Unlimiformer: Long-Range Transformers with Unlimited Length Input""?",Amanda Bertsch,Matthew R. Gormley_1762110.json,
"What is the paper ID of the paper ""Unlimiformer: Long-Range Transformers with Unlimited Length Input""?",dbc368bc8b49347dd27679894524fa62f88492c9,Matthew R. Gormley_1762110.json,
What paper has the paper ID dbc368bc8b49347dd27679894524fa62f88492c9?,Unlimiformer: Long-Range Transformers with Unlimited Length Input,Matthew R. Gormley_1762110.json,
What is the TLDR of the paper 'Unlimiformer: Long-Range Transformers with Unlimited Length Input'?,"This work proposes Unlimiformer: a general approach that wraps any existing pretrained encoder-decoder transformer, and offloads the cross-attention computation to a single k-nearest-neighbor (kNN) index, while the returned kNN distances are the attention dot-product scores.",Matthew R. Gormley_1762110.json,
What is the abstract of the paper 'Unlimiformer: Long-Range Transformers with Unlimited Length Input'?,"Since the proposal of transformers, these models have been limited to bounded input lengths, because of their need to attend to every token in the input. In this work, we propose Unlimiformer: a general approach that wraps any existing pretrained encoder-decoder transformer, and offloads the cross-attention computation to a single k-nearest-neighbor (kNN) index, while the returned kNN distances are the attention dot-product scores. This kNN index can be kept on either the GPU or CPU memory and queried in sub-linear time; this way, we can index practically unlimited input sequences, while every attention head in every decoder layer retrieves its top-k keys, instead of attending to every key. We evaluate Unlimiformer on several long-document and book-summarization benchmarks, showing that it can process even 500k token-long inputs from the BookSum dataset, without any input truncation at test time. We demonstrate that Unlimiformer improves pretrained models such as BART and Longformer by extending them to unlimited inputs without additional learned weights and without modifying their code. We make our code and models publicly available at https://github.com/abertsch72/unlimiformer .",Matthew R. Gormley_1762110.json,
"What journal was the paper ""MDACE: MIMIC Documents Annotated with Code Evidence"" published in?",ArXiv,Matthew R. Gormley_1762110.json,
"What venue was the paper ""MDACE: MIMIC Documents Annotated with Code Evidence"" published in?",Annual Meeting of the Association for Computational Linguistics,Matthew R. Gormley_1762110.json,
"How many citations does the paper ""MDACE: MIMIC Documents Annotated with Code Evidence"" have?",1,Matthew R. Gormley_1762110.json,
"Who are the authors of the paper ""MDACE: MIMIC Documents Annotated with Code Evidence""?","Hua Cheng, Rana Jafari, April Russell, Russell Klopfer, Edmond Lu, Benjamin Striner, Matthew R. Gormley",Matthew R. Gormley_1762110.json,
"Who is the first author of the paper ""MDACE: MIMIC Documents Annotated with Code Evidence""?",Hua Cheng,Matthew R. Gormley_1762110.json,
"What is the paper ID of the paper ""MDACE: MIMIC Documents Annotated with Code Evidence""?",e80f1b4c254a5c135f5f3416ba3a863f8ec4e06c,Matthew R. Gormley_1762110.json,
What paper has the paper ID e80f1b4c254a5c135f5f3416ba3a863f8ec4e06c?,MDACE: MIMIC Documents Annotated with Code Evidence,Matthew R. Gormley_1762110.json,
What is the TLDR of the paper 'MDACE: MIMIC Documents Annotated with Code Evidence'?,"MDACE is introduced, the first publicly available code evidence dataset, which is built on a subset of the MIMIC-III clinical records and can be used to evaluate code evidence extraction methods for CAC systems, as well as the accuracy and interpretability of deep learning models for multi-label classification.",Matthew R. Gormley_1762110.json,
What is the abstract of the paper 'MDACE: MIMIC Documents Annotated with Code Evidence'?,"We introduce a dataset for evidence/rationale extraction on an extreme multi-label classification task over long medical documents. One such task is Computer-Assisted Coding (CAC) which has improved significantly in recent years, thanks to advances in machine learning technologies. Yet simply predicting a set of final codes for a patient encounter is insufficient as CAC systems are required to provide supporting textual evidence to justify the billing codes. A model able to produce accurate and reliable supporting evidence for each code would be a tremendous benefit. However, a human annotated code evidence corpus is extremely difficult to create because it requires specialized knowledge. In this paper, we introduce MDACE, the first publicly available code evidence dataset, which is built on a subset of the MIMIC-III clinical records. The dataset – annotated by professional medical coders – consists of 302 Inpatient charts with 3,934 evidence spans and 52 Profee charts with 5,563 evidence spans. We implemented several evidence extraction methods based on the EffectiveCAN model (Liu et al., 2021) to establish baseline performance on this dataset. MDACE can be used to evaluate code evidence extraction methods for CAC systems, as well as the accuracy and interpretability of deep learning models for multi-label classification. We believe that the release of MDACE will greatly improve the understanding and application of deep learning technologies for medical coding and document classification.",Matthew R. Gormley_1762110.json,
What is the author ID of Matthias Grabmair?,2869551,data/paper_jsons/Matthias Grabmair_2869551.json,
What are the papers of Matthias Grabmair?,"Joint Span Segmentation and Rhetorical Role Labeling with Data Augmentation for Legal Documents, Zero-shot Transfer of Article-aware Legal Outcome Classification for European Court of Human Rights Cases, Leveraging Task Dependency and Contrastive Learning for Case Outcome Classification on European Court of Human Rights Cases",data/paper_jsons/Matthias Grabmair_2869551.json,
What is the H-index of Matthias Grabmair?,13,data/paper_jsons/Matthias Grabmair_2869551.json,
What is the author citation count of Matthias Grabmair?,464,data/paper_jsons/Matthias Grabmair_2869551.json,
What journals has Matthias Grabmair published in?,ArXiv,data/paper_jsons/Matthias Grabmair_2869551.json,
What are the journals and how many papers has Matthias Grabmair published in each?,{'ArXiv': 1},data/paper_jsons/Matthias Grabmair_2869551.json,
What are the fields of study of Matthias Grabmair?,Computer Science,data/paper_jsons/Matthias Grabmair_2869551.json,
How many papers has Matthias Grabmair published in open access journals?,3,data/paper_jsons/Matthias Grabmair_2869551.json,
What venues has Matthias Grabmair published in?,"European Conference on Information Retrieval, Findings, Conference of the European Chapter of the Association for Computational Linguistics",data/paper_jsons/Matthias Grabmair_2869551.json,
What is the most cited paper from Matthias Grabmair?,Zero-shot Transfer of Article-aware Legal Outcome Classification for European Court of Human Rights Cases,data/paper_jsons/Matthias Grabmair_2869551.json,
What is the url of the most cited paper from Matthias Grabmair?,http://arxiv.org/pdf/2302.00609,data/paper_jsons/Matthias Grabmair_2869551.json,
Who are the authors of the most cited paper from Matthias Grabmair?,"Santosh T.Y.S.S, O. Ichim, Matthias Grabmair",data/paper_jsons/Matthias Grabmair_2869551.json,
TLDR of the most cited paper from Matthias Grabmair?,"This paper casts Legal Judgment Prediction on European Court of Human Rights cases into an article-aware classification task, where the case outcome is classified from a combined input of case facts and convention articles, and finds that domain adaptation methods improve zero-shot transfer performance.",data/paper_jsons/Matthias Grabmair_2869551.json,
Abstract of the most cited paper from Matthias Grabmair?,"In this paper, we cast Legal Judgment Prediction on European Court of Human Rights cases into an article-aware classification task, where the case outcome is classified from a combined input of case facts and convention articles. This configuration facilitates the model learning some legal reasoning ability in mapping article text to specific case fact text. It also provides an opportunity to evaluate the model’s ability to generalize to zero-shot settings when asked to classify the case outcome with respect to articles not seen during training. We devise zero-shot experiments and apply domain adaptation methods based on domain discrimination and Wasserstein distance. Our results demonstrate that the article-aware architecture outperforms straightforward fact classification. We also find that domain adaptation methods improve zero-shot transfer performance, with article relatedness and encoder pre-training influencing the effect.",data/paper_jsons/Matthias Grabmair_2869551.json,
"What journal was the paper ""Zero-shot Transfer of Article-aware Legal Outcome Classification for European Court of Human Rights Cases"" published in?",,Matthias Grabmair_2869551.json,
"What venue was the paper ""Zero-shot Transfer of Article-aware Legal Outcome Classification for European Court of Human Rights Cases"" published in?",Findings,Matthias Grabmair_2869551.json,
"How many citations does the paper ""Zero-shot Transfer of Article-aware Legal Outcome Classification for European Court of Human Rights Cases"" have?",5,Matthias Grabmair_2869551.json,
"Who are the authors of the paper ""Zero-shot Transfer of Article-aware Legal Outcome Classification for European Court of Human Rights Cases""?","Santosh T.Y.S.S, O. Ichim, Matthias Grabmair",Matthias Grabmair_2869551.json,
"Who is the first author of the paper ""Zero-shot Transfer of Article-aware Legal Outcome Classification for European Court of Human Rights Cases""?",Santosh T.Y.S.S,Matthias Grabmair_2869551.json,
"What is the paper ID of the paper ""Zero-shot Transfer of Article-aware Legal Outcome Classification for European Court of Human Rights Cases""?",5315883bd39a4e4af6332e344bb32d29613b3c97,Matthias Grabmair_2869551.json,
What paper has the paper ID 5315883bd39a4e4af6332e344bb32d29613b3c97?,Zero-shot Transfer of Article-aware Legal Outcome Classification for European Court of Human Rights Cases,Matthias Grabmair_2869551.json,
What is the TLDR of the paper 'Zero-shot Transfer of Article-aware Legal Outcome Classification for European Court of Human Rights Cases'?,"This paper casts Legal Judgment Prediction on European Court of Human Rights cases into an article-aware classification task, where the case outcome is classified from a combined input of case facts and convention articles, and finds that domain adaptation methods improve zero-shot transfer performance.",Matthias Grabmair_2869551.json,
What is the abstract of the paper 'Zero-shot Transfer of Article-aware Legal Outcome Classification for European Court of Human Rights Cases'?,"In this paper, we cast Legal Judgment Prediction on European Court of Human Rights cases into an article-aware classification task, where the case outcome is classified from a combined input of case facts and convention articles. This configuration facilitates the model learning some legal reasoning ability in mapping article text to specific case fact text. It also provides an opportunity to evaluate the model’s ability to generalize to zero-shot settings when asked to classify the case outcome with respect to articles not seen during training. We devise zero-shot experiments and apply domain adaptation methods based on domain discrimination and Wasserstein distance. Our results demonstrate that the article-aware architecture outperforms straightforward fact classification. We also find that domain adaptation methods improve zero-shot transfer performance, with article relatedness and encoder pre-training influencing the effect.",Matthias Grabmair_2869551.json,
"What journal was the paper ""Joint Span Segmentation and Rhetorical Role Labeling with Data Augmentation for Legal Documents"" published in?",,Matthias Grabmair_2869551.json,
"What venue was the paper ""Joint Span Segmentation and Rhetorical Role Labeling with Data Augmentation for Legal Documents"" published in?",European Conference on Information Retrieval,Matthias Grabmair_2869551.json,
"How many citations does the paper ""Joint Span Segmentation and Rhetorical Role Labeling with Data Augmentation for Legal Documents"" have?",1,Matthias Grabmair_2869551.json,
"Who are the authors of the paper ""Joint Span Segmentation and Rhetorical Role Labeling with Data Augmentation for Legal Documents""?","Santosh T.Y.S.S, Philipp Bock, Matthias Grabmair",Matthias Grabmair_2869551.json,
"Who is the first author of the paper ""Joint Span Segmentation and Rhetorical Role Labeling with Data Augmentation for Legal Documents""?",Santosh T.Y.S.S,Matthias Grabmair_2869551.json,
"What is the paper ID of the paper ""Joint Span Segmentation and Rhetorical Role Labeling with Data Augmentation for Legal Documents""?",1109a51ff68d8c7a09d651d706028e9e380f2af8,Matthias Grabmair_2869551.json,
What paper has the paper ID 1109a51ff68d8c7a09d651d706028e9e380f2af8?,Joint Span Segmentation and Rhetorical Role Labeling with Data Augmentation for Legal Documents,Matthias Grabmair_2869551.json,
What is the TLDR of the paper 'Joint Span Segmentation and Rhetorical Role Labeling with Data Augmentation for Legal Documents'?,"This work reformulates the task at span level as identifying spans of multiple consecutive sentences that share the same rhetorical role label to be assigned via classification, and employs semi-Markov Conditional Random Fields (CRF) to jointly learn span segmentation and span label assignment.",Matthias Grabmair_2869551.json,
What is the abstract of the paper 'Joint Span Segmentation and Rhetorical Role Labeling with Data Augmentation for Legal Documents'?,"Segmentation and Rhetorical Role Labeling of legal judgements play a crucial role in retrieval and adjacent tasks, including case summarization, semantic search, argument mining etc. Previous approaches have formulated this task either as independent classification or sequence labeling of sentences. In this work, we reformulate the task at span level as identifying spans of multiple consecutive sentences that share the same rhetorical role label to be assigned via classification. We employ semi-Markov Conditional Random Fields (CRF) to jointly learn span segmentation and span label assignment. We further explore three data augmentation strategies to mitigate the data scarcity in the specialized domain of law where individual documents tend to be very long and annotation cost is high. Our experiments demonstrate improvement of span-level prediction metrics with a semi-Markov CRF model over a CRF baseline. This benefit is contingent on the presence of multi sentence spans in the document.",Matthias Grabmair_2869551.json,
"What journal was the paper ""Leveraging Task Dependency and Contrastive Learning for Case Outcome Classification on European Court of Human Rights Cases"" published in?",ArXiv,Matthias Grabmair_2869551.json,
"What venue was the paper ""Leveraging Task Dependency and Contrastive Learning for Case Outcome Classification on European Court of Human Rights Cases"" published in?",Conference of the European Chapter of the Association for Computational Linguistics,Matthias Grabmair_2869551.json,
"How many citations does the paper ""Leveraging Task Dependency and Contrastive Learning for Case Outcome Classification on European Court of Human Rights Cases"" have?",4,Matthias Grabmair_2869551.json,
"Who are the authors of the paper ""Leveraging Task Dependency and Contrastive Learning for Case Outcome Classification on European Court of Human Rights Cases""?","Santosh T.Y.S.S, Santosh T.Y.S.S, Phillip Kemper, Matthias Grabmair",Matthias Grabmair_2869551.json,
"Who is the first author of the paper ""Leveraging Task Dependency and Contrastive Learning for Case Outcome Classification on European Court of Human Rights Cases""?",Santosh T.Y.S.S,Matthias Grabmair_2869551.json,
"What is the paper ID of the paper ""Leveraging Task Dependency and Contrastive Learning for Case Outcome Classification on European Court of Human Rights Cases""?",ff28f812113a7082f7d285ed3bf6dcbed49d0320,Matthias Grabmair_2869551.json,
What paper has the paper ID ff28f812113a7082f7d285ed3bf6dcbed49d0320?,Leveraging Task Dependency and Contrastive Learning for Case Outcome Classification on European Court of Human Rights Cases,Matthias Grabmair_2869551.json,
What is the TLDR of the paper 'Leveraging Task Dependency and Contrastive Learning for Case Outcome Classification on European Court of Human Rights Cases'?,,Matthias Grabmair_2869551.json,
What is the abstract of the paper 'Leveraging Task Dependency and Contrastive Learning for Case Outcome Classification on European Court of Human Rights Cases'?,"We report on an experiment in case outcome classification on European Court of Human Rights cases where our model first learns to identify the convention articles allegedly violated by the state from case facts descriptions, and subsequently uses that information to classify whether the court finds a violation of those articles. We assess the dependency between these two tasks at the feature and outcome level. Furthermore, we leverage a hierarchical contrastive loss to pull together article-specific representations of cases at the higher level, leading to distinctive article clusters. The cases in each article cluster are further pulled closer based on their outcome, leading to sub-clusters of cases with similar outcomes. Our experiment results demonstrate that, given a static pre-trained encoder, our models produce a small but consistent improvement in classification performance over single-task and joint models without contrastive loss.",Matthias Grabmair_2869551.json,
What is the author ID of Mona Diab?,1700007,data/paper_jsons/Mona T. Diab_1700007.json,
What are the papers of Mona Diab?,"Author Correction: Arabic natural language processing for Qur’anic research: a systematic review, Evaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology",data/paper_jsons/Mona T. Diab_1700007.json,
What is the H-index of Mona Diab?,50,data/paper_jsons/Mona T. Diab_1700007.json,
What is the author citation count of Mona Diab?,12703,data/paper_jsons/Mona T. Diab_1700007.json,
What journals has Mona Diab published in?,Artificial Intelligence Review,data/paper_jsons/Mona T. Diab_1700007.json,
What are the journals and how many papers has Mona Diab published in each?,{'Artificial Intelligence Review': 1},data/paper_jsons/Mona T. Diab_1700007.json,
What are the fields of study of Mona Diab?,Computer Science,data/paper_jsons/Mona T. Diab_1700007.json,
How many papers has Mona Diab published in open access journals?,2,data/paper_jsons/Mona T. Diab_1700007.json,
What venues has Mona Diab published in?,"Artificial Intelligence Review, International Workshop on Spoken Language Translation",data/paper_jsons/Mona T. Diab_1700007.json,
What is the most cited paper from Mona Diab?,Evaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology,data/paper_jsons/Mona T. Diab_1700007.json,
What is the url of the most cited paper from Mona Diab?,https://aclanthology.org/2023.iwslt-1.2.pdf,data/paper_jsons/Mona T. Diab_1700007.json,
Who are the authors of the most cited paper from Mona Diab?,"Elizabeth Salesky, Kareem Darwish, Mohamed Al-Badrashiny, Mona T. Diab, J. Niehues",data/paper_jsons/Mona T. Diab_1700007.json,
TLDR of the most cited paper from Mona Diab?,"This dataset enables further research into multilingual speech translation under realistic recording conditions with unsegmented audio and domain-specific terminology, applying NLP tools to text and speech in the technical domain, and evaluating and improving model robustness to diverse speaker demographics.",data/paper_jsons/Mona T. Diab_1700007.json,
Abstract of the most cited paper from Mona Diab?,"We present the ACL 60/60 evaluation sets for multilingual translation of ACL 2022 technical presentations into 10 target languages. This dataset enables further research into multilingual speech translation under realistic recording conditions with unsegmented audio and domain-specific terminology, applying NLP tools to text and speech in the technical domain, and evaluating and improving model robustness to diverse speaker demographics.",data/paper_jsons/Mona T. Diab_1700007.json,
"What journal was the paper ""Evaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology"" published in?",,Mona T. Diab_1700007.json,
"What venue was the paper ""Evaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology"" published in?",International Workshop on Spoken Language Translation,Mona T. Diab_1700007.json,
"How many citations does the paper ""Evaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology"" have?",7,Mona T. Diab_1700007.json,
"Who are the authors of the paper ""Evaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology""?","Elizabeth Salesky, Kareem Darwish, Mohamed Al-Badrashiny, Mona T. Diab, J. Niehues",Mona T. Diab_1700007.json,
"Who is the first author of the paper ""Evaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology""?",Elizabeth Salesky,Mona T. Diab_1700007.json,
"What is the paper ID of the paper ""Evaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology""?",c5849f406e8263806a84e1a407ec0e0fe131bd5c,Mona T. Diab_1700007.json,
What paper has the paper ID c5849f406e8263806a84e1a407ec0e0fe131bd5c?,Evaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology,Mona T. Diab_1700007.json,
What is the TLDR of the paper 'Evaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology'?,"This dataset enables further research into multilingual speech translation under realistic recording conditions with unsegmented audio and domain-specific terminology, applying NLP tools to text and speech in the technical domain, and evaluating and improving model robustness to diverse speaker demographics.",Mona T. Diab_1700007.json,
What is the abstract of the paper 'Evaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology'?,"We present the ACL 60/60 evaluation sets for multilingual translation of ACL 2022 technical presentations into 10 target languages. This dataset enables further research into multilingual speech translation under realistic recording conditions with unsegmented audio and domain-specific terminology, applying NLP tools to text and speech in the technical domain, and evaluating and improving model robustness to diverse speaker demographics.",Mona T. Diab_1700007.json,
"What journal was the paper ""Author Correction: Arabic natural language processing for Qur’anic research: a systematic review"" published in?",Artificial Intelligence Review,Mona T. Diab_1700007.json,
"What venue was the paper ""Author Correction: Arabic natural language processing for Qur’anic research: a systematic review"" published in?",Artificial Intelligence Review,Mona T. Diab_1700007.json,
"How many citations does the paper ""Author Correction: Arabic natural language processing for Qur’anic research: a systematic review"" have?",0,Mona T. Diab_1700007.json,
"Who are the authors of the paper ""Author Correction: Arabic natural language processing for Qur’anic research: a systematic review""?","M. Bashir, Aqil M. Azmi, H. Nawaz, W. Zaghouani, Mona T. Diab, Ala I. Al-Fuqaha, Junaid Qadir",Mona T. Diab_1700007.json,
"Who is the first author of the paper ""Author Correction: Arabic natural language processing for Qur’anic research: a systematic review""?",M. Bashir,Mona T. Diab_1700007.json,
"What is the paper ID of the paper ""Author Correction: Arabic natural language processing for Qur’anic research: a systematic review""?",45f7ab2dd1bd86703f3fc0f713d35851ae15b038,Mona T. Diab_1700007.json,
What paper has the paper ID 45f7ab2dd1bd86703f3fc0f713d35851ae15b038?,Author Correction: Arabic natural language processing for Qur’anic research: a systematic review,Mona T. Diab_1700007.json,
What is the TLDR of the paper 'Author Correction: Arabic natural language processing for Qur’anic research: a systematic review'?,TLDR not found,Mona T. Diab_1700007.json,
What is the abstract of the paper 'Author Correction: Arabic natural language processing for Qur’anic research: a systematic review'?,,Mona T. Diab_1700007.json,
What is the author ID of Mona Diab?,2138579860,data/paper_jsons/Mona T. Diab_2138579860.json,
What are the papers of Mona Diab?,"Can Large Language Models Infer Causation from Correlation?, ALERT: Adapt Language Models to Reasoning Tasks, Care4Lang at MEDIQA-Chat 2023: Fine-tuning Language Models for Classifying and Summarizing Clinical Dialogues, The Troubling Emergence of Hallucination in Large Language Models - An Extensive Definition, Quantification, and Prescriptive Remediations, OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models, Methods for Measuring, Updating, and Visualizing Factual Beliefs in Language Models",data/paper_jsons/Mona T. Diab_2138579860.json,
What is the H-index of Mona Diab?,10,data/paper_jsons/Mona T. Diab_2138579860.json,
What is the author citation count of Mona Diab?,2128,data/paper_jsons/Mona T. Diab_2138579860.json,
What journals has Mona Diab published in?,ArXiv,data/paper_jsons/Mona T. Diab_2138579860.json,
What are the journals and how many papers has Mona Diab published in each?,{'ArXiv': 2},data/paper_jsons/Mona T. Diab_2138579860.json,
What are the fields of study of Mona Diab?,Computer Science,data/paper_jsons/Mona T. Diab_2138579860.json,
How many papers has Mona Diab published in open access journals?,6,data/paper_jsons/Mona T. Diab_2138579860.json,
What venues has Mona Diab published in?,"arXiv.org, Annual Meeting of the Association for Computational Linguistics, Clinical Natural Language Processing Workshop, Conference on Empirical Methods in Natural Language Processing, NLRSE, Conference of the European Chapter of the Association for Computational Linguistics",data/paper_jsons/Mona T. Diab_2138579860.json,
What is the most cited paper from Mona Diab?,Can Large Language Models Infer Causation from Correlation?,data/paper_jsons/Mona T. Diab_2138579860.json,
What is the url of the most cited paper from Mona Diab?,http://arxiv.org/pdf/2306.05836,data/paper_jsons/Mona T. Diab_2138579860.json,
Who are the authors of the most cited paper from Mona Diab?,"Zhijing Jin, Jiarui Liu, Zhiheng Lyu, Spencer Poff, Mrinmaya Sachan, Rada Mihalcea, Mona T. Diab, B. Scholkopf",data/paper_jsons/Mona T. Diab_2138579860.json,
TLDR of the most cited paper from Mona Diab?,"This work proposes the first benchmark dataset to test the pure causal inference skills of large language models (LLMs), and formulates a novel task Corr2Cause, which takes a set of correlational statements and determines the causal relationship between the variables.",data/paper_jsons/Mona T. Diab_2138579860.json,
Abstract of the most cited paper from Mona Diab?,"Causal inference is one of the hallmarks of human intelligence. While the field of CausalNLP has attracted much interest in the recent years, existing causal inference datasets in NLP primarily rely on discovering causality from empirical knowledge (e.g., commonsense knowledge). In this work, we propose the first benchmark dataset to test the pure causal inference skills of large language models (LLMs). Specifically, we formulate a novel task Corr2Cause, which takes a set of correlational statements and determines the causal relationship between the variables. We curate a large-scale dataset of more than 200K samples, on which we evaluate seventeen existing LLMs. Through our experiments, we identify a key shortcoming of LLMs in terms of their causal inference skills, and show that these models achieve almost close to random performance on the task. This shortcoming is somewhat mitigated when we try to re-purpose LLMs for this skill via finetuning, but we find that these models still fail to generalize -- they can only perform causal inference in in-distribution settings when variable names and textual expressions used in the queries are similar to those in the training set, but fail in out-of-distribution settings generated by perturbing these queries. Corr2Cause is a challenging task for LLMs, and would be helpful in guiding future research on improving LLMs' pure reasoning skills and generalizability. Our data is at https://huggingface.co/datasets/causalnlp/corr2cause. Our code is at https://github.com/causalNLP/corr2cause.",data/paper_jsons/Mona T. Diab_2138579860.json,
"What journal was the paper ""Methods for Measuring, Updating, and Visualizing Factual Beliefs in Language Models"" published in?",,Mona T. Diab_2138579860.json,
"What venue was the paper ""Methods for Measuring, Updating, and Visualizing Factual Beliefs in Language Models"" published in?",Conference of the European Chapter of the Association for Computational Linguistics,Mona T. Diab_2138579860.json,
"How many citations does the paper ""Methods for Measuring, Updating, and Visualizing Factual Beliefs in Language Models"" have?",26,Mona T. Diab_2138579860.json,
"Who are the authors of the paper ""Methods for Measuring, Updating, and Visualizing Factual Beliefs in Language Models""?","Peter Hase, Mona T. Diab, Asli Celikyilmaz, Xian Li, Zornitsa Kozareva, Veselin Stoyanov, Mohit Bansal, Srini Iyer",Mona T. Diab_2138579860.json,
"Who is the first author of the paper ""Methods for Measuring, Updating, and Visualizing Factual Beliefs in Language Models""?",Peter Hase,Mona T. Diab_2138579860.json,
"What is the paper ID of the paper ""Methods for Measuring, Updating, and Visualizing Factual Beliefs in Language Models""?",f727f928e7e179307d8d4a1da2387393f2bd7915,Mona T. Diab_2138579860.json,
What paper has the paper ID f727f928e7e179307d8d4a1da2387393f2bd7915?,"Methods for Measuring, Updating, and Visualizing Factual Beliefs in Language Models",Mona T. Diab_2138579860.json,
"What is the TLDR of the paper 'Methods for Measuring, Updating, and Visualizing Factual Beliefs in Language Models'?","The experiments suggest that models show only limited consistency between factual beliefs, but update methods can both fix incorrect model beliefs and greatly improve their consistency, and off-the-shelf optimizers can outperform them in more difficult settings than have been considered in past work.",Mona T. Diab_2138579860.json,
"What is the abstract of the paper 'Methods for Measuring, Updating, and Visualizing Factual Beliefs in Language Models'?","Language models can memorize a considerable amount of factual information during pretraining that can be elicited through prompting or finetuning models on tasks like question answering. In this paper, we discuss approaches to measuring model factual beliefs, updating incorrect factual beliefs in models, and visualizing graphical relationships between factual beliefs. Our main contributions include: (1) new metrics for evaluating belief-updating methods focusing on the logical consistency of beliefs, (2) a training objective for Sequential, Local, and Generalizing updates (SLAG) that improves the performance of existing hypernetwork approaches, and (3) the introduction of the belief graph, a new form of visualization for language models that shows relationships between stored model beliefs. Our experiments suggest that models show only limited consistency between factual beliefs, but update methods can both fix incorrect model beliefs and greatly improve their consistency. Although off-the-shelf optimizers are surprisingly strong belief-updating baselines, our learned optimizers can outperform them in more difficult settings than have been considered in past work.",Mona T. Diab_2138579860.json,
"What journal was the paper ""The Troubling Emergence of Hallucination in Large Language Models - An Extensive Definition, Quantification, and Prescriptive Remediations"" published in?",,Mona T. Diab_2138579860.json,
"What venue was the paper ""The Troubling Emergence of Hallucination in Large Language Models - An Extensive Definition, Quantification, and Prescriptive Remediations"" published in?",Conference on Empirical Methods in Natural Language Processing,Mona T. Diab_2138579860.json,
"How many citations does the paper ""The Troubling Emergence of Hallucination in Large Language Models - An Extensive Definition, Quantification, and Prescriptive Remediations"" have?",19,Mona T. Diab_2138579860.json,
"Who are the authors of the paper ""The Troubling Emergence of Hallucination in Large Language Models - An Extensive Definition, Quantification, and Prescriptive Remediations""?","Vipula Rawte, Swagata Chakraborty, Agnibh Pathak, Anubhav Sarkar, S.M. Towhidul Islam Tonmoy, Islam Tonmoy, Aman Chadha, Amit P. Sheth, Amitava Das, Paris, A. Sridhar, Erik Visser, Improved, Jianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, Yunfeng Liu, Roformer, Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, Tatsunori Hashimoto, Stanford, Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtow-icz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, Susan Zhang, Stephen Roller, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher De-wan, Mona T. Diab, Xi Xian Li, Todor Victoria Lin, Myle Ott, Kurt Shuster, Punit Daniel Simig, Singh Koura, Anjali Sridhar, Tianlu Wang, Luke Zettlemoyer. 2022, Daniel M. Ziegler, Nisan Stiennon, Jeffrey Wu, Tom Brown, Alec Radford, Dario Amodei, Paul F. Chris-tiano",Mona T. Diab_2138579860.json,
"Who is the first author of the paper ""The Troubling Emergence of Hallucination in Large Language Models - An Extensive Definition, Quantification, and Prescriptive Remediations""?",Vipula Rawte,Mona T. Diab_2138579860.json,
"What is the paper ID of the paper ""The Troubling Emergence of Hallucination in Large Language Models - An Extensive Definition, Quantification, and Prescriptive Remediations""?",99bfe503743c5ec8e16e50ab8438159cdb533a89,Mona T. Diab_2138579860.json,
What paper has the paper ID 99bfe503743c5ec8e16e50ab8438159cdb533a89?,"The Troubling Emergence of Hallucination in Large Language Models - An Extensive Definition, Quantification, and Prescriptive Remediations",Mona T. Diab_2138579860.json,
"What is the TLDR of the paper 'The Troubling Emergence of Hallucination in Large Language Models - An Extensive Definition, Quantification, and Prescriptive Remediations'?","This work defines two overarching orientations of hallucination and proposes two solution strategies for mitigating hallucinations, and firmly believes that HVI holds significant value as a tool for the wider NLP community, with the potential to serve as a rubric in AI-related policy-making.",Mona T. Diab_2138579860.json,
"What is the abstract of the paper 'The Troubling Emergence of Hallucination in Large Language Models - An Extensive Definition, Quantification, and Prescriptive Remediations'?","The recent advancements in Large Language Models (LLMs) have garnered widespread acclaim for their remarkable emerging capabilities. However, the issue of hallucination has parallelly emerged as a by-product, posing significant concerns. While some recent endeavors have been made to identify and mitigate different types of hallucination, there has been a limited emphasis on the nuanced categorization of hallucination and associated mitigation methods. To address this gap, we offer a fine-grained discourse on profiling hallucination based on its degree, orientation, and category, along with offering strategies for alleviation. As such, we define two overarching orientations of hallucination: (i) factual mirage (FM) and (ii) silver lining (SL). To provide a more comprehensive understanding, both orientations are further sub-categorized into intrinsic and extrinsic, with three degrees of severity - (i) mild, (ii) moderate, and (iii) alarming. We also meticulously categorize hallucination into six types: (i) acronym ambiguity, (ii) numeric nuisance, (iii) generated golem, (iv) virtual voice, (v) geographic erratum, and (vi) time wrap. Furthermore, we curate HallucInation eLiciTation (HILT), a publicly available dataset comprising of 75,000 samples generated using 15 contemporary LLMs along with human annotations for the aforementioned categories. Finally, to establish a method for quantifying and to offer a comparative spectrum that allows us to evaluate and rank LLMs based on their vulnerability to producing hallucinations, we propose Hallucination Vulnerability Index (HVI). We firmly believe that HVI holds significant value as a tool for the wider NLP community, with the potential to serve as a rubric in AI-related policy-making. In conclusion, we propose two solution strategies for mitigating hallucinations.",Mona T. Diab_2138579860.json,
"What journal was the paper ""Care4Lang at MEDIQA-Chat 2023: Fine-tuning Language Models for Classifying and Summarizing Clinical Dialogues"" published in?",,Mona T. Diab_2138579860.json,
"What venue was the paper ""Care4Lang at MEDIQA-Chat 2023: Fine-tuning Language Models for Classifying and Summarizing Clinical Dialogues"" published in?",Clinical Natural Language Processing Workshop,Mona T. Diab_2138579860.json,
"How many citations does the paper ""Care4Lang at MEDIQA-Chat 2023: Fine-tuning Language Models for Classifying and Summarizing Clinical Dialogues"" have?",1,Mona T. Diab_2138579860.json,
"Who are the authors of the paper ""Care4Lang at MEDIQA-Chat 2023: Fine-tuning Language Models for Classifying and Summarizing Clinical Dialogues""?","Amal AlQahtani, R. Salama, Mona T. Diab, Abdou Youssef",Mona T. Diab_2138579860.json,
"Who is the first author of the paper ""Care4Lang at MEDIQA-Chat 2023: Fine-tuning Language Models for Classifying and Summarizing Clinical Dialogues""?",Amal AlQahtani,Mona T. Diab_2138579860.json,
"What is the paper ID of the paper ""Care4Lang at MEDIQA-Chat 2023: Fine-tuning Language Models for Classifying and Summarizing Clinical Dialogues""?",5e2f8088647e357bb6440d271ed1fcc4d5ed7e7c,Mona T. Diab_2138579860.json,
What paper has the paper ID 5e2f8088647e357bb6440d271ed1fcc4d5ed7e7c?,Care4Lang at MEDIQA-Chat 2023: Fine-tuning Language Models for Classifying and Summarizing Clinical Dialogues,Mona T. Diab_2138579860.json,
What is the TLDR of the paper 'Care4Lang at MEDIQA-Chat 2023: Fine-tuning Language Models for Classifying and Summarizing Clinical Dialogues'?,"This paper presents their submission to this task using fine-tuned language models, including T5, BART and BioGPT models, and finds Flan-T5 achieved the highest aggregated score for dialogue summarization.",Mona T. Diab_2138579860.json,
What is the abstract of the paper 'Care4Lang at MEDIQA-Chat 2023: Fine-tuning Language Models for Classifying and Summarizing Clinical Dialogues'?,"Summarizing medical conversations is one of the tasks proposed by MEDIQA-Chat to promote research on automatic clinical note generation from doctor-patient conversations. In this paper, we present our submission to this task using fine-tuned language models, including T5, BART and BioGPT models. The fine-tuned models are evaluated using ensemble metrics including ROUGE, BERTScore andBLEURT. Among the fine-tuned models, Flan-T5 achieved the highest aggregated score for dialogue summarization.",Mona T. Diab_2138579860.json,
What is the author ID of Norman Sadeh?,2464164,data/paper_jsons/N. Sadeh_2464164.json,
What are the papers of Norman Sadeh?,"Do Privacy Labels Answer Users' Privacy Questions?, Exploring Smart Commercial Building Occupants’ Perceptions and Notification Preferences of Internet of Things Data Collection in the United States, Comparing Privacy Label Disclosures of Apps Published in both the App Store and Google Play Stores, ATLAS: Automatically Detecting Discrepancies Between Privacy Policies and Privacy Labels",data/paper_jsons/N. Sadeh_2464164.json,
What is the H-index of Norman Sadeh?,68,data/paper_jsons/N. Sadeh_2464164.json,
What is the author citation count of Norman Sadeh?,17165,data/paper_jsons/N. Sadeh_2464164.json,
What journals has Norman Sadeh published in?,"Proceedings 2023 Symposium on Usable Security, 2023 IEEE 8th European Symposium on Security and Privacy (EuroS&P), 2023 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW)",data/paper_jsons/N. Sadeh_2464164.json,
What are the journals and how many papers has Norman Sadeh published in each?,"{'2023 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW)': 2, 'Proceedings 2023 Symposium on Usable Security': 1, '2023 IEEE 8th European Symposium on Security and Privacy (EuroS&P)': 1}",data/paper_jsons/N. Sadeh_2464164.json,
What are the fields of study of Norman Sadeh?,Computer Science,data/paper_jsons/N. Sadeh_2464164.json,
How many papers has Norman Sadeh published in open access journals?,4,data/paper_jsons/N. Sadeh_2464164.json,
What venues has Norman Sadeh published in?,"Proceedings 2023 Symposium on Usable Security, European Symposium on Security and Privacy, 2023 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW)",data/paper_jsons/N. Sadeh_2464164.json,
What is the most cited paper from Norman Sadeh?,Do Privacy Labels Answer Users' Privacy Questions?,data/paper_jsons/N. Sadeh_2464164.json,
What is the url of the most cited paper from Norman Sadeh?,openAccessPdf not available,data/paper_jsons/N. Sadeh_2464164.json,
Who are the authors of the most cited paper from Norman Sadeh?,"Shikun Zhang, N. Sadeh",data/paper_jsons/N. Sadeh_2464164.json,
TLDR of the most cited paper from Norman Sadeh?,A crowd-sourced corpus of privacy questions collected from mobile app users is analyzed to determine to what extent these mobile app labels actually address users’ privacy concerns and questions.,data/paper_jsons/N. Sadeh_2464164.json,
Abstract of the most cited paper from Norman Sadeh?,"—Inspired by earlier academic research, iOS app privacy labels and the recent Google Play data safety labels have been introduced as a way to systematically present users with concise summaries of an app’s data practices. Yet, little research has been conducted to deter- mine how well today’s mobile app privacy labels address people’s actual privacy concerns or questions. We analyze a crowd-sourced corpus of privacy questions collected from mobile app users to determine to what extent these mobile app labels actually address users’ privacy concerns and questions. While there are differences between iOS labels and Google Play labels, our results indicate that an important percentage of people’s privacy questions are not answered or only partially addressed in today’s labels. Findings from this work not only shed light on the additional fields that would need to be included in mobile app privacy labels but can also help inform refinements to existing labels to better address users’ typical privacy questions",data/paper_jsons/N. Sadeh_2464164.json,
"What journal was the paper ""Exploring Smart Commercial Building Occupants’ Perceptions and Notification Preferences of Internet of Things Data Collection in the United States"" published in?",2023 IEEE 8th European Symposium on Security and Privacy (EuroS&P),N. Sadeh_2464164.json,
"What venue was the paper ""Exploring Smart Commercial Building Occupants’ Perceptions and Notification Preferences of Internet of Things Data Collection in the United States"" published in?",European Symposium on Security and Privacy,N. Sadeh_2464164.json,
"How many citations does the paper ""Exploring Smart Commercial Building Occupants’ Perceptions and Notification Preferences of Internet of Things Data Collection in the United States"" have?",1,N. Sadeh_2464164.json,
"Who are the authors of the paper ""Exploring Smart Commercial Building Occupants’ Perceptions and Notification Preferences of Internet of Things Data Collection in the United States""?","Tu Le, Alan Wang, Yaxing Yao, Yuanyuan Feng, Arsalan Heydarian, N. Sadeh, Yuan Tian",N. Sadeh_2464164.json,
"Who is the first author of the paper ""Exploring Smart Commercial Building Occupants’ Perceptions and Notification Preferences of Internet of Things Data Collection in the United States""?",Tu Le,N. Sadeh_2464164.json,
"What is the paper ID of the paper ""Exploring Smart Commercial Building Occupants’ Perceptions and Notification Preferences of Internet of Things Data Collection in the United States""?",3f165dae2310a5d8aa7294ffdc45573a51c957b8,N. Sadeh_2464164.json,
What paper has the paper ID 3f165dae2310a5d8aa7294ffdc45573a51c957b8?,Exploring Smart Commercial Building Occupants’ Perceptions and Notification Preferences of Internet of Things Data Collection in the United States,N. Sadeh_2464164.json,
What is the TLDR of the paper 'Exploring Smart Commercial Building Occupants’ Perceptions and Notification Preferences of Internet of Things Data Collection in the United States'?,It is found that around half of the participants are not fully aware of the data collection and use practices of IoT even though they notice the presence of IoT devices and sensors.,N. Sadeh_2464164.json,
What is the abstract of the paper 'Exploring Smart Commercial Building Occupants’ Perceptions and Notification Preferences of Internet of Things Data Collection in the United States'?,"Data collection through the Internet of Things (IoT) devices, or smart devices, in commercial buildings enables possibilities for increased convenience and energy efficiency. However, such benefits face a large perceptual challenge when being implemented in practice, due to the different ways occupants working in the buildings understand and trust in the data collection. The semi-public, pervasive, and multi-modal nature of data collection in smart buildings points to the need to study occupants’ understanding of data collection and notification preferences. We conduct an online study with 492 participants in the US who report working in smart commercial buildings regarding: 1) awareness and perception of data collection in smart commercial buildings, 2) privacy notification preferences, and 3) potential factors for privacy notification preferences. We find that around half of the participants are not fully aware of the data collection and use practices of IoT even though they notice the presence of IoT devices and sensors. We also discover many misunderstandings around different data practices. The majority of participants want to be notified of data practices in smart buildings, and they prefer push notifications to passive ones such as websites or physical signs. Surprisingly, mobile app notification, despite being a popular channel for smart homes, is the least preferred method for smart commercial buildings.",N. Sadeh_2464164.json,
"What journal was the paper ""Do Privacy Labels Answer Users' Privacy Questions?"" published in?",Proceedings 2023 Symposium on Usable Security,N. Sadeh_2464164.json,
"What venue was the paper ""Do Privacy Labels Answer Users' Privacy Questions?"" published in?",Proceedings 2023 Symposium on Usable Security,N. Sadeh_2464164.json,
"How many citations does the paper ""Do Privacy Labels Answer Users' Privacy Questions?"" have?",4,N. Sadeh_2464164.json,
"Who are the authors of the paper ""Do Privacy Labels Answer Users' Privacy Questions?""?","Shikun Zhang, N. Sadeh",N. Sadeh_2464164.json,
"Who is the first author of the paper ""Do Privacy Labels Answer Users' Privacy Questions?""?",Shikun Zhang,N. Sadeh_2464164.json,
"What is the paper ID of the paper ""Do Privacy Labels Answer Users' Privacy Questions?""?",3c6d1884d5f15577b76356a3f1e7da6ffba6e2bd,N. Sadeh_2464164.json,
What paper has the paper ID 3c6d1884d5f15577b76356a3f1e7da6ffba6e2bd?,Do Privacy Labels Answer Users' Privacy Questions?,N. Sadeh_2464164.json,
What is the TLDR of the paper 'Do Privacy Labels Answer Users' Privacy Questions?'?,A crowd-sourced corpus of privacy questions collected from mobile app users is analyzed to determine to what extent these mobile app labels actually address users’ privacy concerns and questions.,N. Sadeh_2464164.json,
What is the abstract of the paper 'Do Privacy Labels Answer Users' Privacy Questions?'?,"—Inspired by earlier academic research, iOS app privacy labels and the recent Google Play data safety labels have been introduced as a way to systematically present users with concise summaries of an app’s data practices. Yet, little research has been conducted to deter- mine how well today’s mobile app privacy labels address people’s actual privacy concerns or questions. We analyze a crowd-sourced corpus of privacy questions collected from mobile app users to determine to what extent these mobile app labels actually address users’ privacy concerns and questions. While there are differences between iOS labels and Google Play labels, our results indicate that an important percentage of people’s privacy questions are not answered or only partially addressed in today’s labels. Findings from this work not only shed light on the additional fields that would need to be included in mobile app privacy labels but can also help inform refinements to existing labels to better address users’ typical privacy questions",N. Sadeh_2464164.json,
"What journal was the paper ""Comparing Privacy Label Disclosures of Apps Published in both the App Store and Google Play Stores"" published in?",2023 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW),N. Sadeh_2464164.json,
"What venue was the paper ""Comparing Privacy Label Disclosures of Apps Published in both the App Store and Google Play Stores"" published in?",2023 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW),N. Sadeh_2464164.json,
"How many citations does the paper ""Comparing Privacy Label Disclosures of Apps Published in both the App Store and Google Play Stores"" have?",2,N. Sadeh_2464164.json,
"Who are the authors of the paper ""Comparing Privacy Label Disclosures of Apps Published in both the App Store and Google Play Stores""?","David Rodriguez, Akshatha Jain, J. D. Álamo, N. Sadeh",N. Sadeh_2464164.json,
"Who is the first author of the paper ""Comparing Privacy Label Disclosures of Apps Published in both the App Store and Google Play Stores""?",David Rodriguez,N. Sadeh_2464164.json,
"What is the paper ID of the paper ""Comparing Privacy Label Disclosures of Apps Published in both the App Store and Google Play Stores""?",88efd1663016c4170674c8f30067e7096b172598,N. Sadeh_2464164.json,
What paper has the paper ID 88efd1663016c4170674c8f30067e7096b172598?,Comparing Privacy Label Disclosures of Apps Published in both the App Store and Google Play Stores,N. Sadeh_2464164.json,
What is the TLDR of the paper 'Comparing Privacy Label Disclosures of Apps Published in both the App Store and Google Play Stores'?,"It is revealed that privacy label disclosures of what is ostensibly the same mobile app can be quite different, including the possibility that these discrepancies might be indicative of potential privacy compliance issues.",N. Sadeh_2464164.json,
What is the abstract of the paper 'Comparing Privacy Label Disclosures of Apps Published in both the App Store and Google Play Stores'?,"Apple and Android introduced privacy labels in 2020 and 2022 respectively as a way of providing consumers with succinct summaries of mobile apps’ more salient data practices. A number of apps are published in both stores, offering us the opportunity to compare their privacy label disclosures in the two app stores. This paper compares the data practices privacy labels are intended to capture in each store. It then proceeds to analyze the disclosures of 822 apps published in both app stores, focusing on possible discrepancies. This analysis reveals that privacy label disclosures of what is ostensibly the same mobile app can be quite different. We discuss the different possible reasons behind these differences, including the possibility that these discrepancies might be indicative of potential privacy compliance issues. In particular, focusing on data collection disclosures of five different data types (location, contact info, sensitive info, identifiers, and health & fitness) we find discrepancies between iOS and Google Play privacy label disclosures in 66.5% of the mobile apps we analyze.",N. Sadeh_2464164.json,
What is the author ID of Richard Stern?,1697819,data/paper_jsons/R. Stern_1697819.json,
What are the papers of Richard Stern?,Unsupervised Voice Type Discrimination Score Adaptation Using X-Vector Clusters,data/paper_jsons/R. Stern_1697819.json,
What is the H-index of Richard Stern?,45,data/paper_jsons/R. Stern_1697819.json,
What is the author citation count of Richard Stern?,8518,data/paper_jsons/R. Stern_1697819.json,
What journals has Richard Stern published in?,"ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",data/paper_jsons/R. Stern_1697819.json,
What are the journals and how many papers has Richard Stern published in each?,"{'ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)': 1}",data/paper_jsons/R. Stern_1697819.json,
What are the fields of study of Richard Stern?,Computer Science,data/paper_jsons/R. Stern_1697819.json,
How many papers has Richard Stern published in open access journals?,1,data/paper_jsons/R. Stern_1697819.json,
What venues has Richard Stern published in?,"IEEE International Conference on Acoustics, Speech, and Signal Processing",data/paper_jsons/R. Stern_1697819.json,
What is the most cited paper from Richard Stern?,Unsupervised Voice Type Discrimination Score Adaptation Using X-Vector Clusters,data/paper_jsons/R. Stern_1697819.json,
What is the url of the most cited paper from Richard Stern?,openAccessPdf not available,data/paper_jsons/R. Stern_1697819.json,
Who are the authors of the most cited paper from Richard Stern?,"Mark Lindsey, Tyler Vuong, R. Stern",data/paper_jsons/R. Stern_1697819.json,
TLDR of the most cited paper from Richard Stern?,"This adaptation method can be applied to the output of any VTD algorithm, requires no additional training data, and has been shown to yield a relative decrease in decision cost function (DCF) score of up to 47% on a standardized database collected for the task.",data/paper_jsons/R. Stern_1697819.json,
Abstract of the most cited paper from Richard Stern?,"Voice type discrimination (VTD) is the task of automatically detecting speech produced in the same room as a recording device (""live speech"") among other speech and non-speech noises, such as traffic noises or radio broadcasts (""distractor audio""). Existing work has described methods for performing the VTD task. This paper presents a method for adapting the output of these existing methods in an unsupervised manner via x-vector clustering and correlation. This adaptation method can be applied to the output of any VTD algorithm, requires no additional training data, and has been shown to yield a relative decrease in decision cost function (DCF) score of up to 47% on a standardized database collected for the task.",data/paper_jsons/R. Stern_1697819.json,
"What journal was the paper ""Unsupervised Voice Type Discrimination Score Adaptation Using X-Vector Clusters"" published in?","ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",R. Stern_1697819.json,
"What venue was the paper ""Unsupervised Voice Type Discrimination Score Adaptation Using X-Vector Clusters"" published in?","IEEE International Conference on Acoustics, Speech, and Signal Processing",R. Stern_1697819.json,
"How many citations does the paper ""Unsupervised Voice Type Discrimination Score Adaptation Using X-Vector Clusters"" have?",0,R. Stern_1697819.json,
"Who are the authors of the paper ""Unsupervised Voice Type Discrimination Score Adaptation Using X-Vector Clusters""?","Mark Lindsey, Tyler Vuong, R. Stern",R. Stern_1697819.json,
"Who is the first author of the paper ""Unsupervised Voice Type Discrimination Score Adaptation Using X-Vector Clusters""?",Mark Lindsey,R. Stern_1697819.json,
"What is the paper ID of the paper ""Unsupervised Voice Type Discrimination Score Adaptation Using X-Vector Clusters""?",8b49ebfc2b436c8b064ecf5b1eb3c5a12fc8d4b8,R. Stern_1697819.json,
What paper has the paper ID 8b49ebfc2b436c8b064ecf5b1eb3c5a12fc8d4b8?,Unsupervised Voice Type Discrimination Score Adaptation Using X-Vector Clusters,R. Stern_1697819.json,
What is the TLDR of the paper 'Unsupervised Voice Type Discrimination Score Adaptation Using X-Vector Clusters'?,"This adaptation method can be applied to the output of any VTD algorithm, requires no additional training data, and has been shown to yield a relative decrease in decision cost function (DCF) score of up to 47% on a standardized database collected for the task.",R. Stern_1697819.json,
What is the abstract of the paper 'Unsupervised Voice Type Discrimination Score Adaptation Using X-Vector Clusters'?,"Voice type discrimination (VTD) is the task of automatically detecting speech produced in the same room as a recording device (""live speech"") among other speech and non-speech noises, such as traffic noises or radio broadcasts (""distractor audio""). Existing work has described methods for performing the VTD task. This paper presents a method for adapting the output of these existing methods in an unsupervised manner via x-vector clustering and correlation. This adaptation method can be applied to the output of any VTD algorithm, requires no additional training data, and has been shown to yield a relative decrease in decision cost function (DCF) score of up to 47% on a standardized database collected for the task.",R. Stern_1697819.json,
What is the author ID of Rita Singh?,153915824,data/paper_jsons/Rita Singh_153915824.json,
What are the papers of Rita Singh?,"BASS: Block-wise Adaptation for Speech Summarization, Rethinking Voice-Face Correlation: A Geometry View, A Gene-Based Algorithm for Identifying Factors That May Affect a Speaker’s Voice, Deriving Vocal Fold Oscillation Information from Recorded Voice Signals Using Models of Phonation, Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations, The Hidden Dance of Phonemes and Visage: Unveiling the Enigmatic Link between Phonemes and Facial Features, Pengi: An Audio Language Model for Audio Tasks",data/paper_jsons/Rita Singh_153915824.json,
What is the H-index of Rita Singh?,25,data/paper_jsons/Rita Singh_153915824.json,
What is the author citation count of Rita Singh?,2781,data/paper_jsons/Rita Singh_153915824.json,
What journals has Rita Singh published in?,"ArXiv, Proceedings of the 31st ACM International Conference on Multimedia, Entropy",data/paper_jsons/Rita Singh_153915824.json,
What are the journals and how many papers has Rita Singh published in each?,"{'ArXiv': 4, 'Entropy': 2, 'Proceedings of the 31st ACM International Conference on Multimedia': 1}",data/paper_jsons/Rita Singh_153915824.json,
What are the fields of study of Rita Singh?,"Computer Science, Engineering, Medicine",data/paper_jsons/Rita Singh_153915824.json,
How many papers has Rita Singh published in open access journals?,7,data/paper_jsons/Rita Singh_153915824.json,
What venues has Rita Singh published in?,"Interspeech, ACM Multimedia, Entropy, arXiv.org",data/paper_jsons/Rita Singh_153915824.json,
What is the most cited paper from Rita Singh?,Pengi: An Audio Language Model for Audio Tasks,data/paper_jsons/Rita Singh_153915824.json,
What is the url of the most cited paper from Rita Singh?,http://arxiv.org/pdf/2305.11834,data/paper_jsons/Rita Singh_153915824.json,
Who are the authors of the most cited paper from Rita Singh?,"Soham Deshmukh, Benjamin Elizalde, Rita Singh, Huaming Wang",data/paper_jsons/Rita Singh_153915824.json,
TLDR of the most cited paper from Rita Singh?,"Pengi is introduced, a novel Audio Language Model that leverages Transfer Learning by framing all audio tasks as text-generation tasks, and shows that connecting language models with audio models is a major step towards general-purpose audio understanding.",data/paper_jsons/Rita Singh_153915824.json,
Abstract of the most cited paper from Rita Singh?,"In the domain of audio processing, Transfer Learning has facilitated the rise of Self-Supervised Learning and Zero-Shot Learning techniques. These approaches have led to the development of versatile models capable of tackling a wide array of tasks, while delivering state-of-the-art performance. However, current models inherently lack the capacity to produce the requisite language for open-ended tasks, such as Audio Captioning or Audio Question&Answering. We introduce Pengi, a novel Audio Language Model that leverages Transfer Learning by framing all audio tasks as text-generation tasks. It takes as input, an audio recording, and text, and generates free-form text as output. The input audio is represented as a sequence of continuous embeddings by an audio encoder. A text encoder does the same for the corresponding text input. Both sequences are combined as a prefix to prompt a pre-trained frozen language model. The unified architecture of Pengi enables open-ended tasks and close-ended tasks without any additional fine-tuning or task-specific extensions. When evaluated on 22 downstream tasks, our approach yields state-of-the-art performance in several of them. Our results show that connecting language models with audio models is a major step towards general-purpose audio understanding",data/paper_jsons/Rita Singh_153915824.json,
"What journal was the paper ""A Gene-Based Algorithm for Identifying Factors That May Affect a Speaker’s Voice"" published in?",Entropy,Rita Singh_153915824.json,
"What venue was the paper ""A Gene-Based Algorithm for Identifying Factors That May Affect a Speaker’s Voice"" published in?",Entropy,Rita Singh_153915824.json,
"How many citations does the paper ""A Gene-Based Algorithm for Identifying Factors That May Affect a Speaker’s Voice"" have?",0,Rita Singh_153915824.json,
"Who are the authors of the paper ""A Gene-Based Algorithm for Identifying Factors That May Affect a Speaker’s Voice""?",Rita Singh,Rita Singh_153915824.json,
"Who is the first author of the paper ""A Gene-Based Algorithm for Identifying Factors That May Affect a Speaker’s Voice""?",Rita Singh,Rita Singh_153915824.json,
"What is the paper ID of the paper ""A Gene-Based Algorithm for Identifying Factors That May Affect a Speaker’s Voice""?",63a4150c9ad87c003de43b32828c8ceec6bb4468,Rita Singh_153915824.json,
What paper has the paper ID 63a4150c9ad87c003de43b32828c8ceec6bb4468?,A Gene-Based Algorithm for Identifying Factors That May Affect a Speaker’s Voice,Rita Singh_153915824.json,
What is the TLDR of the paper 'A Gene-Based Algorithm for Identifying Factors That May Affect a Speaker’s Voice'?,"A simple path-finding algorithm that attempts to find links between vocal characteristics and perturbing factors using cytogenetic and genomic data and shows that in cases where strong links are exposed, vocal characteristics of the patients are indeed reported to be correspondingly affected.",Rita Singh_153915824.json,
What is the abstract of the paper 'A Gene-Based Algorithm for Identifying Factors That May Affect a Speaker’s Voice'?,"Over the past decades, many machine-learning- and artificial-intelligence-based technologies have been created to deduce biometric or bio-relevant parameters of speakers from their voice. These voice profiling technologies have targeted a wide range of parameters, from diseases to environmental factors, based largely on the fact that they are known to influence voice. Recently, some have also explored the prediction of parameters whose influence on voice is not easily observable through data-opportunistic biomarker discovery techniques. However, given the enormous range of factors that can possibly influence voice, more informed methods for selecting those that may be potentially deducible from voice are needed. To this end, this paper proposes a simple path-finding algorithm that attempts to find links between vocal characteristics and perturbing factors using cytogenetic and genomic data. The links represent reasonable selection criteria for use by computational by profiling technologies only, and are not intended to establish any unknown biological facts. The proposed algorithm is validated using a simple example from medical literature—that of the clinically observed effects of specific chromosomal microdeletion syndromes on the vocal characteristics of affected people. In this example, the algorithm attempts to link the genes involved in these syndromes to a single example gene (FOXP2) that is known to play a broad role in voice production. We show that in cases where strong links are exposed, vocal characteristics of the patients are indeed reported to be correspondingly affected. Validation experiments and subsequent analyses confirm that the methodology could be potentially useful in predicting the existence of vocal signatures in naïve cases where their existence has not been otherwise observed.",Rita Singh_153915824.json,
"What journal was the paper ""BASS: Block-wise Adaptation for Speech Summarization"" published in?",ArXiv,Rita Singh_153915824.json,
"What venue was the paper ""BASS: Block-wise Adaptation for Speech Summarization"" published in?",Interspeech,Rita Singh_153915824.json,
"How many citations does the paper ""BASS: Block-wise Adaptation for Speech Summarization"" have?",1,Rita Singh_153915824.json,
"Who are the authors of the paper ""BASS: Block-wise Adaptation for Speech Summarization""?","Roshan Sharma, Kenneth Zheng, Siddhant Arora, Shinji Watanabe, Rita Singh, B. Raj",Rita Singh_153915824.json,
"Who is the first author of the paper ""BASS: Block-wise Adaptation for Speech Summarization""?",Roshan Sharma,Rita Singh_153915824.json,
"What is the paper ID of the paper ""BASS: Block-wise Adaptation for Speech Summarization""?",3bd320ddb25886417ae90011b00f13f5d558097b,Rita Singh_153915824.json,
What paper has the paper ID 3bd320ddb25886417ae90011b00f13f5d558097b?,BASS: Block-wise Adaptation for Speech Summarization,Rita Singh_153915824.json,
What is the TLDR of the paper 'BASS: Block-wise Adaptation for Speech Summarization'?,This paper develops a method that allows one to train summarization models on very long sequences in an incremental manner and devise and test strategies to pass semantic context across the blocks.,Rita Singh_153915824.json,
What is the abstract of the paper 'BASS: Block-wise Adaptation for Speech Summarization'?,"End-to-end speech summarization has been shown to improve performance over cascade baselines. However, such models are difficult to train on very large inputs (dozens of minutes or hours) owing to compute restrictions and are hence trained with truncated model inputs. Truncation leads to poorer models, and a solution to this problem rests in block-wise modeling, i.e., processing a portion of the input frames at a time. In this paper, we develop a method that allows one to train summarization models on very long sequences in an incremental manner. Speech summarization is realized as a streaming process, where hypothesis summaries are updated every block based on new acoustic information. We devise and test strategies to pass semantic context across the blocks. Experiments on the How2 dataset demonstrate that the proposed block-wise training method improves by 3 points absolute on ROUGE-L over a truncated input baseline.",Rita Singh_153915824.json,
"What journal was the paper ""Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations"" published in?",ArXiv,Rita Singh_153915824.json,
"What venue was the paper ""Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations"" published in?",arXiv.org,Rita Singh_153915824.json,
"How many citations does the paper ""Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations"" have?",3,Rita Singh_153915824.json,
"Who are the authors of the paper ""Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations""?","Hao Chen, Ankit Shah, Jindong Wang, R. Tao, Yidong Wang, Xingxu Xie, Masashi Sugiyama, Rita Singh, B. Raj",Rita Singh_153915824.json,
"Who is the first author of the paper ""Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations""?",Hao Chen,Rita Singh_153915824.json,
"What is the paper ID of the paper ""Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations""?",8665c864d71df1e918d2010778fc06712f4e5550,Rita Singh_153915824.json,
What paper has the paper ID 8665c864d71df1e918d2010778fc06712f4e5550?,Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations,Rita Singh_153915824.json,
What is the TLDR of the paper 'Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations'?,"Imprecise label learning (ILL) is introduced, a framework for the unification of learning with various imprecise label configurations, marking the first unified framework with robust and effective performance across various challenging settings.",Rita Singh_153915824.json,
What is the abstract of the paper 'Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations'?,"Learning with reduced labeling standards, such as noisy label, partial label, and multiple label candidates, which we generically refer to as \textit{imprecise} labels, is a commonplace challenge in machine learning tasks. Previous methods tend to propose specific designs for every emerging imprecise label configuration, which is usually unsustainable when multiple configurations of imprecision coexist. In this paper, we introduce imprecise label learning (ILL), a framework for the unification of learning with various imprecise label configurations. ILL leverages expectation-maximization (EM) for modeling the imprecise label information, treating the precise labels as latent variables.Instead of approximating the correct labels for training, it considers the entire distribution of all possible labeling entailed by the imprecise information. We demonstrate that ILL can seamlessly adapt to partial label learning, semi-supervised learning, noisy label learning, and, more importantly, a mixture of these settings. Notably, ILL surpasses the existing specified techniques for handling imprecise labels, marking the first unified framework with robust and effective performance across various challenging settings. We hope our work will inspire further research on this topic, unleashing the full potential of ILL in wider scenarios where precise labels are expensive and complicated to obtain.",Rita Singh_153915824.json,
What is the author ID of Roni Rosenfeld?,88507334,data/paper_jsons/Roni Rosenfeld_88507334.json,
What are the papers of Roni Rosenfeld?,"Evaluation of FluSight influenza forecasting in the 2021–22 and 2022–23 seasons with a new target laboratory-confirmed influenza hospitalizations, Computationally Assisted Quality Control for Public Health Data Streams, Correcting for heterogeneity in real-time epidemiological indicators",data/paper_jsons/Roni Rosenfeld_88507334.json,
What is the H-index of Roni Rosenfeld?,24,data/paper_jsons/Roni Rosenfeld_88507334.json,
What is the author citation count of Roni Rosenfeld?,2904,data/paper_jsons/Roni Rosenfeld_88507334.json,
What journals has Roni Rosenfeld published in?,"medRxiv, ArXiv",data/paper_jsons/Roni Rosenfeld_88507334.json,
What are the journals and how many papers has Roni Rosenfeld published in each?,"{'medRxiv': 1, 'ArXiv': 1}",data/paper_jsons/Roni Rosenfeld_88507334.json,
What are the fields of study of Roni Rosenfeld?,"Medicine, Computer Science",data/paper_jsons/Roni Rosenfeld_88507334.json,
How many papers has Roni Rosenfeld published in open access journals?,3,data/paper_jsons/Roni Rosenfeld_88507334.json,
What venues has Roni Rosenfeld published in?,"medRxiv, International Joint Conference on Artificial Intelligence, arXiv.org",data/paper_jsons/Roni Rosenfeld_88507334.json,
What is the most cited paper from Roni Rosenfeld?,Computationally Assisted Quality Control for Public Health Data Streams,data/paper_jsons/Roni Rosenfeld_88507334.json,
What is the url of the most cited paper from Roni Rosenfeld?,http://arxiv.org/pdf/2306.16914,data/paper_jsons/Roni Rosenfeld_88507334.json,
Who are the authors of the most cited paper from Roni Rosenfeld?,"Ananya Joshi, Kathryn Mazaitis, Roni Rosenfeld, Bryan Wilder",data/paper_jsons/Roni Rosenfeld_88507334.json,
TLDR of the most cited paper from Roni Rosenfeld?,"FlaSH (Flagging Streams in public Health), a practical outlier detection framework for public health data users that uses simple, scalable models to capture these statistical properties explicitly, has been deployed on data streams used by public health stakeholders.",data/paper_jsons/Roni Rosenfeld_88507334.json,
Abstract of the most cited paper from Roni Rosenfeld?,"Irregularities in public health data streams (like COVID-19 Cases) hamper data-driven decision-making for public health stakeholders. A real-time, computer-generated list of the most important, outlying data points from thousands of public health data streams could assist an expert reviewer in identifying these irregularities. However, existing outlier detection frameworks perform poorly on this task because they do not account for the data volume or for the statistical properties of public health streams. Accordingly, we developed FlaSH (Flagging Streams in public Health), a practical outlier detection framework for public health data users that uses simple, scalable models to capture these statistical properties explicitly. In an experiment where human experts evaluate FlaSH and existing methods (including deep learning approaches), FlaSH scales to the data volume of this task, matches or exceeds these other methods in mean accuracy, and identifies the outlier points that users empirically rate as more helpful. Based on these results, FlaSH has been deployed on data streams used by public health stakeholders.",data/paper_jsons/Roni Rosenfeld_88507334.json,
"What journal was the paper ""Computationally Assisted Quality Control for Public Health Data Streams"" published in?",,Roni Rosenfeld_88507334.json,
"What venue was the paper ""Computationally Assisted Quality Control for Public Health Data Streams"" published in?",International Joint Conference on Artificial Intelligence,Roni Rosenfeld_88507334.json,
"How many citations does the paper ""Computationally Assisted Quality Control for Public Health Data Streams"" have?",1,Roni Rosenfeld_88507334.json,
"Who are the authors of the paper ""Computationally Assisted Quality Control for Public Health Data Streams""?","Ananya Joshi, Kathryn Mazaitis, Roni Rosenfeld, Bryan Wilder",Roni Rosenfeld_88507334.json,
"Who is the first author of the paper ""Computationally Assisted Quality Control for Public Health Data Streams""?",Ananya Joshi,Roni Rosenfeld_88507334.json,
"What is the paper ID of the paper ""Computationally Assisted Quality Control for Public Health Data Streams""?",61c7e06e7d6760ecf2f5d20f86711287d131d8ea,Roni Rosenfeld_88507334.json,
What paper has the paper ID 61c7e06e7d6760ecf2f5d20f86711287d131d8ea?,Computationally Assisted Quality Control for Public Health Data Streams,Roni Rosenfeld_88507334.json,
What is the TLDR of the paper 'Computationally Assisted Quality Control for Public Health Data Streams'?,"FlaSH (Flagging Streams in public Health), a practical outlier detection framework for public health data users that uses simple, scalable models to capture these statistical properties explicitly, has been deployed on data streams used by public health stakeholders.",Roni Rosenfeld_88507334.json,
What is the abstract of the paper 'Computationally Assisted Quality Control for Public Health Data Streams'?,"Irregularities in public health data streams (like COVID-19 Cases) hamper data-driven decision-making for public health stakeholders. A real-time, computer-generated list of the most important, outlying data points from thousands of public health data streams could assist an expert reviewer in identifying these irregularities. However, existing outlier detection frameworks perform poorly on this task because they do not account for the data volume or for the statistical properties of public health streams. Accordingly, we developed FlaSH (Flagging Streams in public Health), a practical outlier detection framework for public health data users that uses simple, scalable models to capture these statistical properties explicitly. In an experiment where human experts evaluate FlaSH and existing methods (including deep learning approaches), FlaSH scales to the data volume of this task, matches or exceeds these other methods in mean accuracy, and identifies the outlier points that users empirically rate as more helpful. Based on these results, FlaSH has been deployed on data streams used by public health stakeholders.",Roni Rosenfeld_88507334.json,
"What journal was the paper ""Correcting for heterogeneity in real-time epidemiological indicators"" published in?",ArXiv,Roni Rosenfeld_88507334.json,
"What venue was the paper ""Correcting for heterogeneity in real-time epidemiological indicators"" published in?",arXiv.org,Roni Rosenfeld_88507334.json,
"How many citations does the paper ""Correcting for heterogeneity in real-time epidemiological indicators"" have?",0,Roni Rosenfeld_88507334.json,
"Who are the authors of the paper ""Correcting for heterogeneity in real-time epidemiological indicators""?","Aaron M. Rumack, Roni Rosenfeld, F. W. Townes",Roni Rosenfeld_88507334.json,
"Who is the first author of the paper ""Correcting for heterogeneity in real-time epidemiological indicators""?",Aaron M. Rumack,Roni Rosenfeld_88507334.json,
"What is the paper ID of the paper ""Correcting for heterogeneity in real-time epidemiological indicators""?",d486295e298f682b2f98e21106af659d88d396a5,Roni Rosenfeld_88507334.json,
What paper has the paper ID d486295e298f682b2f98e21106af659d88d396a5?,Correcting for heterogeneity in real-time epidemiological indicators,Roni Rosenfeld_88507334.json,
What is the TLDR of the paper 'Correcting for heterogeneity in real-time epidemiological indicators'?,This work presents a method to use a ``guiding'' signal to correct for spatial and temporal biases and produce a more reliable signal that can be used for modeling and forecasting.,Roni Rosenfeld_88507334.json,
What is the abstract of the paper 'Correcting for heterogeneity in real-time epidemiological indicators'?,"Auxiliary data sources have become increasingly important in epidemiological surveillance, as they are often available at a finer spatial and temporal resolution, larger coverage, and lower latency than traditional surveillance signals. We describe the problem of spatial and temporal heterogeneity in these signals derived from these data sources, where spatial and/or temporal biases are present. We present a method to use a ``guiding'' signal to correct for these biases and produce a more reliable signal that can be used for modeling and forecasting. The method assumes that the heterogeneity can be approximated by a low-rank matrix and that the temporal heterogeneity is smooth over time. We also present a hyperparameter selection algorithm to choose the parameters representing the matrix rank and degree of temporal smoothness of the corrections. In the absence of ground truth, we use maps and plots to argue that this method does indeed reduce heterogeneity. Reducing heterogeneity from auxiliary data sources greatly increases their utility in modeling and forecasting epidemics.",Roni Rosenfeld_88507334.json,
"What journal was the paper ""Evaluation of FluSight influenza forecasting in the 2021–22 and 2022–23 seasons with a new target laboratory-confirmed influenza hospitalizations"" published in?",medRxiv,Roni Rosenfeld_88507334.json,
"What venue was the paper ""Evaluation of FluSight influenza forecasting in the 2021–22 and 2022–23 seasons with a new target laboratory-confirmed influenza hospitalizations"" published in?",medRxiv,Roni Rosenfeld_88507334.json,
"How many citations does the paper ""Evaluation of FluSight influenza forecasting in the 2021–22 and 2022–23 seasons with a new target laboratory-confirmed influenza hospitalizations"" have?",0,Roni Rosenfeld_88507334.json,
"Who are the authors of the paper ""Evaluation of FluSight influenza forecasting in the 2021–22 and 2022–23 seasons with a new target laboratory-confirmed influenza hospitalizations""?","Sarabeth M. Mathis, Alexander E. Webber, Tomás M León, Erin L. Murray, Monica Sun, L. A. White, L. Brooks, Alden Green, Addison J. Hu, Daniel J McDonald, Roni Rosenfeld, Dmitry Shemetov, R. Tibshirani, S. Kandula, Sen Pei, Jeffrey Shaman, R. Yaari, T. Yamana, Pulak Agarwal, Srikar Balusu, Gautham Gururajan, Harshavardhan Kamarthi, B. A. Prakash, Rishi Raman, Alexander Rodríguez, Zhiyuan Zhao, Akilan Meiyappan, Shalina Omar, P. Baccam, H. Gurung, S. Stage, B. Suchoski, M. Ajelli, A. G. Kummer, M. Litvinova, Paulo C. Ventura, Spencer Wadsworth, Jarad Niemi, Erica Carcelen, Alison Hill, Sung-Mok Jung, J. Lemaitre, J. Lessler, Sara L. Loo, Clif McKee, Koji Sato, Clair Smith, S. Truelove, Thomas McAndrew, Wenxuan Ye, Nikos Bosse, W. Hlavacek, Yen Ting Lin, A. Mallela, Ye Chen, Shelby Lamm, Jaechoul Lee, Richard G Posner, A. Perofsky, Cécile Viboud, Leonardo Clemente, Fred Lu, Austin G Meyer, Mauricio Santillana, Matteo Chinazzi, Jessica T. Davis, K. Mu, A. Pastore y Piontti, A. Vespignani, X. Xiong, M. Ben-Nun, P. Riley, J. Turtle, Chis Hulme-Lowe, Shakeel Jessa, V. Nagraj, Stephen D. Turner, Desiree Williams, Avranil Basu, John M Drake, S. Fox, G. Gibson, Ehsan Suez, E. Thommes, Monica G. Cojocaru, E. Cramer, Aaron Gerding, A. Stark, E. Ray, Nick Reich, Li Shandross, N. Wattanachit, Yijin Wang, Martha W Zorn, Majd Al Aawar, A. Srivastava, L. A. Meyers, A. Adiga, Benjamin Hurt, Gursharn Kaur, Bryan L Lewis, M. Marathe, S. Venkatramanan, P. Butler, Andrew Farabow, N. Muralidhar, Naren Ramakrishnan, Carrie Reed, M. Biggerstaff, R. Borchering",Roni Rosenfeld_88507334.json,
"Who is the first author of the paper ""Evaluation of FluSight influenza forecasting in the 2021–22 and 2022–23 seasons with a new target laboratory-confirmed influenza hospitalizations""?",Sarabeth M. Mathis,Roni Rosenfeld_88507334.json,
"What is the paper ID of the paper ""Evaluation of FluSight influenza forecasting in the 2021–22 and 2022–23 seasons with a new target laboratory-confirmed influenza hospitalizations""?",11b798422679ebd291e0eb62d97aace5cc0bd290,Roni Rosenfeld_88507334.json,
What paper has the paper ID 11b798422679ebd291e0eb62d97aace5cc0bd290?,Evaluation of FluSight influenza forecasting in the 2021–22 and 2022–23 seasons with a new target laboratory-confirmed influenza hospitalizations,Roni Rosenfeld_88507334.json,
What is the TLDR of the paper 'Evaluation of FluSight influenza forecasting in the 2021–22 and 2022–23 seasons with a new target laboratory-confirmed influenza hospitalizations'?,"Averaging across all forecast targets, the FluSight ensemble was the 2nd most accurate model measured by WIS in 2021-22 and the 5th most accurate in the 2022-23 season and most component models degraded over longer forecast horizons and during periods of rapid change.",Roni Rosenfeld_88507334.json,
What is the abstract of the paper 'Evaluation of FluSight influenza forecasting in the 2021–22 and 2022–23 seasons with a new target laboratory-confirmed influenza hospitalizations'?,"Accurate forecasts can enable more effective public health responses during seasonal influenza epidemics. Forecasting teams were asked to provide national and jurisdiction-specific probabilistic predictions of weekly confirmed influenza hospital admissions for one through four weeks ahead for the 2021-22 and 2022-23 influenza seasons. Across both seasons, 26 teams submitted forecasts, with the submitting teams varying between seasons. Forecast skill was evaluated using the Weighted Interval Score (WIS), relative WIS, and coverage. Six out of 23 models outperformed the baseline model across forecast weeks and locations in 2021-22 and 12 out of 18 models in 2022-23. Averaging across all forecast targets, the FluSight ensemble was the 2nd most accurate model measured by WIS in 2021-22 and the 5th most accurate in the 2022-23 season. Forecast skill and 95% coverage for the FluSight ensemble and most component models degraded over longer forecast horizons and during periods of rapid change. Current influenza forecasting efforts help inform situational awareness, but research is needed to address limitations, including decreased performance during periods of changing epidemic dynamics.",Roni Rosenfeld_88507334.json,
What is the author ID of Scott Fahlman?,1758714,data/paper_jsons/S. Fahlman_1758714.json,
What are the papers of Scott Fahlman?,Score: A Rule Engine for the Scone Knowledge Base System,data/paper_jsons/S. Fahlman_1758714.json,
What is the H-index of Scott Fahlman?,23,data/paper_jsons/S. Fahlman_1758714.json,
What is the author citation count of Scott Fahlman?,6875,data/paper_jsons/S. Fahlman_1758714.json,
What journals has Scott Fahlman published in?,ArXiv,data/paper_jsons/S. Fahlman_1758714.json,
What are the journals and how many papers has Scott Fahlman published in each?,{'ArXiv': 1},data/paper_jsons/S. Fahlman_1758714.json,
What are the fields of study of Scott Fahlman?,Computer Science,data/paper_jsons/S. Fahlman_1758714.json,
How many papers has Scott Fahlman published in open access journals?,1,data/paper_jsons/S. Fahlman_1758714.json,
What venues has Scott Fahlman published in?,arXiv.org,data/paper_jsons/S. Fahlman_1758714.json,
What is the most cited paper from Scott Fahlman?,Score: A Rule Engine for the Scone Knowledge Base System,data/paper_jsons/S. Fahlman_1758714.json,
What is the url of the most cited paper from Scott Fahlman?,http://arxiv.org/pdf/2305.04154,data/paper_jsons/S. Fahlman_1758714.json,
Who are the authors of the most cited paper from Scott Fahlman?,"Jeffrey Chen, S. Fahlman",data/paper_jsons/S. Fahlman_1758714.json,
TLDR of the most cited paper from Scott Fahlman?,"The Scone system is augmented with a production rule engine that automatically performs simple inference based on existing and newly-added structures in Scone's knowledge base, potentially improving the capabilities of any planning systems built on top of Scone.",data/paper_jsons/S. Fahlman_1758714.json,
Abstract of the most cited paper from Scott Fahlman?,"We present Score, a rule engine designed and implemented for the Scone knowledge base system. Scone is a knowledge base system designed for storing and manipulating rich representations of general knowledge in symbolic form. It represents knowledge in the form of nodes and links in a network structure, and it can perform basic inference about the relationships between different elements efficiently. On its own, Scone acts as a sort of""smart memory""that can interface with other software systems. One area of improvement for Scone is how useful it can be in supplying knowledge to an intelligent agent that can use the knowledge to perform actions and update the knowledge base with its observations. We augment the Scone system with a production rule engine that automatically performs simple inference based on existing and newly-added structures in Scone's knowledge base, potentially improving the capabilities of any planning systems built on top of Scone. Production rule systems consist of""if-then""production rules that try to match their predicates to existing knowledge and fire their actions when their predicates are satisfied. We propose two kinds of production rules, if-added and if-needed rules, that differ in how they are checked and fired to cover multiple use cases. We then implement methods to efficiently check and fire these rules in a large knowledge base. The new rule engine is not meant to be a complex stand-alone planner, so we discuss how it fits into the context of Scone and future work on planning systems.",data/paper_jsons/S. Fahlman_1758714.json,
"What journal was the paper ""Score: A Rule Engine for the Scone Knowledge Base System"" published in?",ArXiv,S. Fahlman_1758714.json,
"What venue was the paper ""Score: A Rule Engine for the Scone Knowledge Base System"" published in?",arXiv.org,S. Fahlman_1758714.json,
"How many citations does the paper ""Score: A Rule Engine for the Scone Knowledge Base System"" have?",0,S. Fahlman_1758714.json,
"Who are the authors of the paper ""Score: A Rule Engine for the Scone Knowledge Base System""?","Jeffrey Chen, S. Fahlman",S. Fahlman_1758714.json,
"Who is the first author of the paper ""Score: A Rule Engine for the Scone Knowledge Base System""?",Jeffrey Chen,S. Fahlman_1758714.json,
"What is the paper ID of the paper ""Score: A Rule Engine for the Scone Knowledge Base System""?",13922d438c437cea443b6c4747c54a29a8bdd742,S. Fahlman_1758714.json,
What paper has the paper ID 13922d438c437cea443b6c4747c54a29a8bdd742?,Score: A Rule Engine for the Scone Knowledge Base System,S. Fahlman_1758714.json,
What is the TLDR of the paper 'Score: A Rule Engine for the Scone Knowledge Base System'?,"The Scone system is augmented with a production rule engine that automatically performs simple inference based on existing and newly-added structures in Scone's knowledge base, potentially improving the capabilities of any planning systems built on top of Scone.",S. Fahlman_1758714.json,
What is the abstract of the paper 'Score: A Rule Engine for the Scone Knowledge Base System'?,"We present Score, a rule engine designed and implemented for the Scone knowledge base system. Scone is a knowledge base system designed for storing and manipulating rich representations of general knowledge in symbolic form. It represents knowledge in the form of nodes and links in a network structure, and it can perform basic inference about the relationships between different elements efficiently. On its own, Scone acts as a sort of""smart memory""that can interface with other software systems. One area of improvement for Scone is how useful it can be in supplying knowledge to an intelligent agent that can use the knowledge to perform actions and update the knowledge base with its observations. We augment the Scone system with a production rule engine that automatically performs simple inference based on existing and newly-added structures in Scone's knowledge base, potentially improving the capabilities of any planning systems built on top of Scone. Production rule systems consist of""if-then""production rules that try to match their predicates to existing knowledge and fire their actions when their predicates are satisfied. We propose two kinds of production rules, if-added and if-needed rules, that differ in how they are checked and fired to cover multiple use cases. We then implement methods to efficiently check and fire these rules in a large knowledge base. The new rule engine is not meant to be a complex stand-alone planner, so we discuss how it fits into the context of Scone and future work on planning systems.",S. Fahlman_1758714.json,
What is the author ID of Sean Welleck?,2129663,data/paper_jsons/S. Welleck_2129663.json,
What are the papers of Sean Welleck?,"Self-Refine: Iterative Refinement with Self-Feedback, Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs without Fine-tuning",data/paper_jsons/S. Welleck_2129663.json,
What is the H-index of Sean Welleck?,23,data/paper_jsons/S. Welleck_2129663.json,
What is the author citation count of Sean Welleck?,2845,data/paper_jsons/S. Welleck_2129663.json,
What journals has Sean Welleck published in?,ArXiv,data/paper_jsons/S. Welleck_2129663.json,
What are the journals and how many papers has Sean Welleck published in each?,{'ArXiv': 1},data/paper_jsons/S. Welleck_2129663.json,
What are the fields of study of Sean Welleck?,Computer Science,data/paper_jsons/S. Welleck_2129663.json,
How many papers has Sean Welleck published in open access journals?,2,data/paper_jsons/S. Welleck_2129663.json,
What venues has Sean Welleck published in?,"arXiv.org, Conference on Empirical Methods in Natural Language Processing",data/paper_jsons/S. Welleck_2129663.json,
What is the most cited paper from Sean Welleck?,Self-Refine: Iterative Refinement with Self-Feedback,data/paper_jsons/S. Welleck_2129663.json,
What is the url of the most cited paper from Sean Welleck?,http://arxiv.org/pdf/2303.17651,data/paper_jsons/S. Welleck_2129663.json,
Who are the authors of the most cited paper from Sean Welleck?,"Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, S. Welleck, Bodhisattwa Prasad Majumder, Shashank Gupta, A. Yazdanbakhsh, Peter Clark",data/paper_jsons/S. Welleck_2129663.json,
TLDR of the most cited paper from Sean Welleck?,"Self-Refine is introduced, an approach for improving initial outputs from LLMs through iterative feedback and refinement that demonstrates that even state-of-the-art LLMs like GPT-4 can be further improved at test time using this simple, standalone approach.",data/paper_jsons/S. Welleck_2129663.json,
Abstract of the most cited paper from Sean Welleck?,"Like humans, large language models (LLMs) do not always generate the best output on their first try. Motivated by how humans refine their written text, we introduce Self-Refine, an approach for improving initial outputs from LLMs through iterative feedback and refinement. The main idea is to generate an initial output using an LLMs; then, the same LLMs provides feedback for its output and uses it to refine itself, iteratively. Self-Refine does not require any supervised training data, additional training, or reinforcement learning, and instead uses a single LLM as the generator, refiner, and feedback provider. We evaluate Self-Refine across 7 diverse tasks, ranging from dialog response generation to mathematical reasoning, using state-of-the-art (GPT-3.5, ChatGPT, and GPT-4) LLMs. Across all evaluated tasks, outputs generated with Self-Refine are preferred by humans and automatic metrics over those generated with the same LLM using conventional one-step generation, improving by ~20% absolute on average in task performance. Our work demonstrates that even state-of-the-art LLMs like GPT-4 can be further improved at test time using our simple, standalone approach.",data/paper_jsons/S. Welleck_2129663.json,
"What journal was the paper ""Self-Refine: Iterative Refinement with Self-Feedback"" published in?",ArXiv,S. Welleck_2129663.json,
"What venue was the paper ""Self-Refine: Iterative Refinement with Self-Feedback"" published in?",arXiv.org,S. Welleck_2129663.json,
"How many citations does the paper ""Self-Refine: Iterative Refinement with Self-Feedback"" have?",383,S. Welleck_2129663.json,
"Who are the authors of the paper ""Self-Refine: Iterative Refinement with Self-Feedback""?","Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, S. Welleck, Bodhisattwa Prasad Majumder, Shashank Gupta, A. Yazdanbakhsh, Peter Clark",S. Welleck_2129663.json,
"Who is the first author of the paper ""Self-Refine: Iterative Refinement with Self-Feedback""?",Aman Madaan,S. Welleck_2129663.json,
"What is the paper ID of the paper ""Self-Refine: Iterative Refinement with Self-Feedback""?",3aaf6a2cbad5850ad81ab5c163599cb3d523436f,S. Welleck_2129663.json,
What paper has the paper ID 3aaf6a2cbad5850ad81ab5c163599cb3d523436f?,Self-Refine: Iterative Refinement with Self-Feedback,S. Welleck_2129663.json,
What is the TLDR of the paper 'Self-Refine: Iterative Refinement with Self-Feedback'?,"Self-Refine is introduced, an approach for improving initial outputs from LLMs through iterative feedback and refinement that demonstrates that even state-of-the-art LLMs like GPT-4 can be further improved at test time using this simple, standalone approach.",S. Welleck_2129663.json,
What is the abstract of the paper 'Self-Refine: Iterative Refinement with Self-Feedback'?,"Like humans, large language models (LLMs) do not always generate the best output on their first try. Motivated by how humans refine their written text, we introduce Self-Refine, an approach for improving initial outputs from LLMs through iterative feedback and refinement. The main idea is to generate an initial output using an LLMs; then, the same LLMs provides feedback for its output and uses it to refine itself, iteratively. Self-Refine does not require any supervised training data, additional training, or reinforcement learning, and instead uses a single LLM as the generator, refiner, and feedback provider. We evaluate Self-Refine across 7 diverse tasks, ranging from dialog response generation to mathematical reasoning, using state-of-the-art (GPT-3.5, ChatGPT, and GPT-4) LLMs. Across all evaluated tasks, outputs generated with Self-Refine are preferred by humans and automatic metrics over those generated with the same LLM using conventional one-step generation, improving by ~20% absolute on average in task performance. Our work demonstrates that even state-of-the-art LLMs like GPT-4 can be further improved at test time using our simple, standalone approach.",S. Welleck_2129663.json,
"What journal was the paper ""Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs without Fine-tuning"" published in?",,S. Welleck_2129663.json,
"What venue was the paper ""Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs without Fine-tuning"" published in?",Conference on Empirical Methods in Natural Language Processing,S. Welleck_2129663.json,
"How many citations does the paper ""Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs without Fine-tuning"" have?",6,S. Welleck_2129663.json,
"Who are the authors of the paper ""Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs without Fine-tuning""?","Ximing Lu, Faeze Brahman, Peter West, Jaehun Jang, Khyathi Raghavi Chandu, Abhilasha Ravichander, Lianhui Qin, Prithviraj Ammanabrolu, Liwei Jiang, Sahana Ramnath, Nouha Dziri, Jillian R. Fisher, Bill Yuchen Lin, Skyler Hallinan, Xiang Ren, S. Welleck, Yejin Choi",S. Welleck_2129663.json,
"Who is the first author of the paper ""Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs without Fine-tuning""?",Ximing Lu,S. Welleck_2129663.json,
"What is the paper ID of the paper ""Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs without Fine-tuning""?",ca991e0283a1c30a46eb585d9eb499fc0ec8ecc2,S. Welleck_2129663.json,
What paper has the paper ID ca991e0283a1c30a46eb585d9eb499fc0ec8ecc2?,Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs without Fine-tuning,S. Welleck_2129663.json,
What is the TLDR of the paper 'Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs without Fine-tuning'?,"Inference-time Policy Adapters (IPA) is proposed, which efficiently tailors a language model such as GPT-3 without fine-tuning it, and consistently brings significant improvements over off-the-shelf language models.",S. Welleck_2129663.json,
What is the abstract of the paper 'Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs without Fine-tuning'?,"While extreme-scale language models have demonstrated exceptional performance on a variety of language tasks, the degree of control over these language models through pure prompting can often be limited. Directly fine-tuning such language models can be effective for tailoring them, but it can be either extremely costly (e.g., GPT-3) or not even feasible for the broader community (e.g., GPT-4). We propose Inference-time Policy Adapters (IPA), which efficiently tailors a language model such as GPT-3 without fine-tuning it. IPA guides a large base model during decoding time through a lightweight policy adapter trained to optimize an arbitrary user objective with reinforcement learning. On five challenging text generation tasks, such as toxicity reduction and lexically constrained generation, IPA consistently brings significant improvements over off-the-shelf language models. It outperforms competitive baseline methods, sometimes even including expensive fine-tuning. In particular, tailoring GPT-2 with IPA can outperform GPT-3, while tailoring GPT-3 with IPA brings a major performance boost over GPT-3 (and sometimes even over GPT-4). Our promising results highlight the potential of IPA as a lightweight alternative to tailoring extreme-scale language models.",S. Welleck_2129663.json,
What is the author ID of Shinji Watanabe?,1746678,data/paper_jsons/Shinji Watanabe_1746678.json,
What are the papers of Shinji Watanabe?,"Saturation time of exposure interval for cross-neutralization response to SARS-CoV-2: Implications for vaccine dose interval, Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning, Tensor decomposition for minimization of E2E SLU model toward on-device processing, Decoder-only Architecture for Speech Recognition with CTC Prompts and Text Data Augmentation, ML-SUPERB: Multilingual Speech Universal PERformance Benchmark, Structured Pruning of Self-Supervised Pre-Trained Models for Speech Recognition and Understanding, Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization, A Comparative Study on E-Branchformer vs Conformer in Speech Recognition, Translation, and Understanding Tasks, Efficient Sequence Transduction by Jointly Predicting Tokens and Durations, Speech Summarization of Long Spoken Document: Improving Memory Efficiency of Speech/Text Encoders, UNSSOR: Unsupervised Neural Speech Separation by Leveraging Over-determined Training Mixtures, Segment-Level Vectorized Beam Search Based on Partially Autoregressive Inference, Unsupervised Data Selection for TTS: Using Arabic Broadcast News as a Case Study, BASS: Block-wise Adaptation for Speech Summarization, I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition, A Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech, A New Benchmark of Aphasia Speech Recognition and Detection Based on E-Branchformer and Multi-task Learning, Antiviral Susceptibilities of Distinct Lineages of Influenza C and D Viruses, Paaploss: A Phonetic-Aligned Acoustic Parameter Loss for Speech Enhancement, SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing, Exploring the Integration of Speech Separation and Recognition with Self-Supervised Learning Representation, Dynamic-SUPERB: Towards A Dynamic, Collaborative, and Comprehensive Instruction-Tuning Benchmark for Speech, Speaker-Independent Acoustic-to-Articulatory Speech Inversion, Towards Practical and Efficient Image-to-Speech Captioning with Vision-Language Pre-training and Multi-modal Tokens, Enhancing Speech-To-Speech Translation with Multiple TTS Targets, AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head, Improving Audio Captioning Models with Fine-grained Audio Features, Text Embedding Supervision, and LLM Mix-up Augmentation, Voxtlm: unified decoder-only models for consolidating speech recognition/synthesis and speech/text continuation tasks, Learning to Speak from Text: Zero-Shot Multilingual Text-to-Speech with Unsupervised Text Pretraining, FNeural Speech Enhancement with Very Low Algorithmic Latency and Complexity via Integrated full- and sub-band Modeling, Improving Massively Multilingual ASR with Auxiliary CTC Objectives, Toward Universal Speech Enhancement For Diverse Input Conditions, The Pipeline System of ASR and NLU with MLM-based data Augmentation Toward Stop Low-Resource Challenge, A Study on the Integration of Pipeline and E2E SLU Systems for Spoken Semantic Parsing Toward Stop Quality Challenge, A community cluster of influenza A(H3N2) virus infection with reduced susceptibility to baloxavir due to a PA E199G substitution in Japan, February to March 2023, Exploring Speech Recognition, Translation, and Understanding with Discrete Speech Units: A Comparative Study, Joint Modelling of Spoken Language Understanding Tasks with Integrated Dialog History, Enhancing End-to-End Conversational Speech Translation Through Target Language Context Utilization, Challenges of Corporate Alliance CLOMA toward Plastic Litter, The Multimodal Information Based Speech Processing (MISP) 2023 Challenge: Audio-Visual Target Speaker Extraction, Reproducing Whisper-Style Training Using An Open-Source Toolkit And Publicly Available Data, The CHiME-7 DASR Challenge: Distant Meeting Transcription with Multiple Devices in Diverse Scenarios, Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing, ESPnet-ST-v2: Multipurpose Spoken Language Translation Toolkit, Multi-Channel Target Speaker Extraction with Refinement: The WavLab Submission to the Second Clarity Enhancement Challenge, Fully Unsupervised Topic Clustering of Unlabelled Spoken Audio Using Self-Supervised Representation Learning and Topic Model, TAPLoss: A Temporal Acoustic Parameter Loss for Speech Enhancement, End-to-End Speech Recognition: A Survey, The Multimodal Information Based Speech Processing (Misp) 2022 Challenge: Audio-Visual Diarization And Recognition, DPHuBERT: Joint Distillation and Pruning of Self-Supervised Speech Models, An external quality assessment feasibility study; cross laboratory comparison of haemagglutination inhibition assay and microneutralization assay performance for seasonal influenza serology testing: A FLUCOP study, Multi-Channel Speaker Extraction with Adversarial Training: The Wavlab Submission to The Clarity ICASSP 2023 Grand Challenge, AV-SUPERB: A Multi-Task Evaluation Benchmark for Audio-Visual Representation Models, Improving Cascaded Unsupervised Speech Translation with Denoising Back-translation, Deep Speech Synthesis from MRI-Based Articulatory Representations, FINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN, Speech collage: code-switched audio generation by collaging monolingual corpora, Exploration on HuBERT with Multiple Resolutions",data/paper_jsons/Shinji Watanabe_1746678.json,
What is the H-index of Shinji Watanabe?,67,data/paper_jsons/Shinji Watanabe_1746678.json,
What is the author citation count of Shinji Watanabe?,22222,data/paper_jsons/Shinji Watanabe_1746678.json,
What journals has Shinji Watanabe published in?,"iScience, 2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU), INTERSPEECH 2023, ArXiv, ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Viruses, 2023 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA), Eurosurveillance, Oleoscience, IEEE/ACM Transactions on Audio, Speech, and Language Processing, Frontiers in Immunology",data/paper_jsons/Shinji Watanabe_1746678.json,
What are the journals and how many papers has Shinji Watanabe published in each?,"{'ArXiv': 27, 'ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)': 15, '2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)': 4, 'INTERSPEECH 2023': 2, 'iScience': 1, 'Viruses': 1, '2023 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)': 1, 'Eurosurveillance': 1, 'Oleoscience': 1, 'IEEE/ACM Transactions on Audio, Speech, and Language Processing': 1, 'Frontiers in Immunology': 1}",data/paper_jsons/Shinji Watanabe_1746678.json,
What are the fields of study of Shinji Watanabe?,"Medicine, Computer Science, Engineering",data/paper_jsons/Shinji Watanabe_1746678.json,
How many papers has Shinji Watanabe published in open access journals?,58,data/paper_jsons/Shinji Watanabe_1746678.json,
What venues has Shinji Watanabe published in?,"iScience, Automatic Speech Recognition & Understanding, Interspeech, arXiv.org, IEEE International Conference on Acoustics, Speech, and Signal Processing, International Conference on Machine Learning, AAAI Conference on Artificial Intelligence, Viruses, Special Interest Group on Computational Morphology and Phonology Workshop, IEEE Workshop on Applications of Signal Processing to Audio and Acoustics, International Joint Conference on Artificial Intelligence, Euro surveillance : bulletin Europeen sur les maladies transmissibles = European communicable disease bulletin, Oleoscience, 7th International Workshop on Speech Processing in Everyday Environments (CHiME 2023), Annual Meeting of the Association for Computational Linguistics, IEEE/ACM Transactions on Audio Speech and Language Processing, Frontiers in Immunology, International Workshop on Spoken Language Translation",data/paper_jsons/Shinji Watanabe_1746678.json,
What is the most cited paper from Shinji Watanabe?,"AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head",data/paper_jsons/Shinji Watanabe_1746678.json,
What is the url of the most cited paper from Shinji Watanabe?,http://arxiv.org/pdf/2304.12995,data/paper_jsons/Shinji Watanabe_1746678.json,
Who are the authors of the most cited paper from Shinji Watanabe?,"Rongjie Huang, Mingze Li, Dongchao Yang, Jiatong Shi, Xuankai Chang, Zhenhui Ye, Yuning Wu, Zhiqing Hong, Jia-Bin Huang, Jinglin Liu, Yixiang Ren, Zhou Zhao, Shinji Watanabe",data/paper_jsons/Shinji Watanabe_1746678.json,
TLDR of the most cited paper from Shinji Watanabe?,"A multi-modal AI system named AudioGPT is proposed, which complements LLMs with 1) foundation models to process complex audio information and solve numerous understanding and generation tasks; and 2) the input/output interface (ASR, TTS) to support spoken dialogue.",data/paper_jsons/Shinji Watanabe_1746678.json,
Abstract of the most cited paper from Shinji Watanabe?,"Large language models (LLMs) have exhibited remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. Despite the recent success, current LLMs are not capable of processing complex audio information or conducting spoken conversations (like Siri or Alexa). In this work, we propose a multi-modal AI system named AudioGPT, which complements LLMs (i.e., ChatGPT) with 1) foundation models to process complex audio information and solve numerous understanding and generation tasks; and 2) the input/output interface (ASR, TTS) to support spoken dialogue. With an increasing demand to evaluate multi-modal LLMs of human intention understanding and cooperation with foundation models, we outline the principles and processes and test AudioGPT in terms of consistency, capability, and robustness. Experimental results demonstrate the capabilities of AudioGPT in solving AI tasks with speech, music, sound, and talking head understanding and generation in multi-round dialogues, which empower humans to create rich and diverse audio content with unprecedented ease. Our system is publicly available at \url{https://github.com/AIGC-Audio/AudioGPT}.",data/paper_jsons/Shinji Watanabe_1746678.json,
"What journal was the paper ""Challenges of Corporate Alliance CLOMA toward Plastic Litter"" published in?",Oleoscience,Shinji Watanabe_1746678.json,
"What venue was the paper ""Challenges of Corporate Alliance CLOMA toward Plastic Litter"" published in?",Oleoscience,Shinji Watanabe_1746678.json,
"How many citations does the paper ""Challenges of Corporate Alliance CLOMA toward Plastic Litter"" have?",0,Shinji Watanabe_1746678.json,
"Who are the authors of the paper ""Challenges of Corporate Alliance CLOMA toward Plastic Litter""?",Shinji Watanabe,Shinji Watanabe_1746678.json,
"Who is the first author of the paper ""Challenges of Corporate Alliance CLOMA toward Plastic Litter""?",Shinji Watanabe,Shinji Watanabe_1746678.json,
"What is the paper ID of the paper ""Challenges of Corporate Alliance CLOMA toward Plastic Litter""?",c6f5da5eb57457457a49256f1434bf1db23d1898,Shinji Watanabe_1746678.json,
What paper has the paper ID c6f5da5eb57457457a49256f1434bf1db23d1898?,Challenges of Corporate Alliance CLOMA toward Plastic Litter,Shinji Watanabe_1746678.json,
What is the TLDR of the paper 'Challenges of Corporate Alliance CLOMA toward Plastic Litter'?,TLDR not found,Shinji Watanabe_1746678.json,
What is the abstract of the paper 'Challenges of Corporate Alliance CLOMA toward Plastic Litter'?,,Shinji Watanabe_1746678.json,
"What journal was the paper ""The Pipeline System of ASR and NLU with MLM-based data Augmentation Toward Stop Low-Resource Challenge"" published in?","ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",Shinji Watanabe_1746678.json,
"What venue was the paper ""The Pipeline System of ASR and NLU with MLM-based data Augmentation Toward Stop Low-Resource Challenge"" published in?","IEEE International Conference on Acoustics, Speech, and Signal Processing",Shinji Watanabe_1746678.json,
"How many citations does the paper ""The Pipeline System of ASR and NLU with MLM-based data Augmentation Toward Stop Low-Resource Challenge"" have?",2,Shinji Watanabe_1746678.json,
"Who are the authors of the paper ""The Pipeline System of ASR and NLU with MLM-based data Augmentation Toward Stop Low-Resource Challenge""?","Hayato Futami, Jessica Huynh, Siddhant Arora, Shih-Lun Wu, Yosuke Kashiwagi, Yifan Peng, Brian Yan, E. Tsunoo, Shinji Watanabe",Shinji Watanabe_1746678.json,
"Who is the first author of the paper ""The Pipeline System of ASR and NLU with MLM-based data Augmentation Toward Stop Low-Resource Challenge""?",Hayato Futami,Shinji Watanabe_1746678.json,
"What is the paper ID of the paper ""The Pipeline System of ASR and NLU with MLM-based data Augmentation Toward Stop Low-Resource Challenge""?",b4855ff933fb80846638469a1b43c1766df85d78,Shinji Watanabe_1746678.json,
What paper has the paper ID b4855ff933fb80846638469a1b43c1766df85d78?,The Pipeline System of ASR and NLU with MLM-based data Augmentation Toward Stop Low-Resource Challenge,Shinji Watanabe_1746678.json,
What is the TLDR of the paper 'The Pipeline System of ASR and NLU with MLM-based data Augmentation Toward Stop Low-Resource Challenge'?,"This system for the low-resource domain adaptation track (Track 3) in Spoken Language Understanding Grand Challenge, which is a part of ICASSP Signal Processing Grand Challenge 2023, adopts a pipeline approach of ASR and NLU and applies masked LM (MLM) -based data augmentation.",Shinji Watanabe_1746678.json,
What is the abstract of the paper 'The Pipeline System of ASR and NLU with MLM-based data Augmentation Toward Stop Low-Resource Challenge'?,"This paper describes our system for the low-resource domain adaptation track (Track 3) in Spoken Language Understanding Grand Challenge, which is a part of ICASSP Signal Processing Grand Challenge 2023. In the track, we adopt a pipeline approach of ASR and NLU. For ASR, we fine-tune Whisper for each domain with upsampling. For NLU, we fine-tune BART on all the Track3 data and then on low-resource domain data. We apply masked LM (MLM) -based data augmentation, where some of input tokens and corresponding target labels are replaced using MLM. We also apply a retrieval-based approach, where model input is augmented with similar training samples. As a result, we achieved exact match (EM) accuracy 63.3/75.0 (average: 69.15) for reminder/weather domain, and won the 1st place at the challenge.",Shinji Watanabe_1746678.json,
"What journal was the paper ""TAPLoss: A Temporal Acoustic Parameter Loss for Speech Enhancement"" published in?","ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",Shinji Watanabe_1746678.json,
"What venue was the paper ""TAPLoss: A Temporal Acoustic Parameter Loss for Speech Enhancement"" published in?","IEEE International Conference on Acoustics, Speech, and Signal Processing",Shinji Watanabe_1746678.json,
"How many citations does the paper ""TAPLoss: A Temporal Acoustic Parameter Loss for Speech Enhancement"" have?",7,Shinji Watanabe_1746678.json,
"Who are the authors of the paper ""TAPLoss: A Temporal Acoustic Parameter Loss for Speech Enhancement""?","YUNYANG ZENG, Joseph Konan, Shuo Han, David Bick, Muqiao Yang, Anurag Kumar, Shinji Watanabe, B. Raj",Shinji Watanabe_1746678.json,
"Who is the first author of the paper ""TAPLoss: A Temporal Acoustic Parameter Loss for Speech Enhancement""?",YUNYANG ZENG,Shinji Watanabe_1746678.json,
"What is the paper ID of the paper ""TAPLoss: A Temporal Acoustic Parameter Loss for Speech Enhancement""?",e146e5221c124d93f69516c5ae7e1b7b1822848e,Shinji Watanabe_1746678.json,
What paper has the paper ID e146e5221c124d93f69516c5ae7e1b7b1822848e?,TAPLoss: A Temporal Acoustic Parameter Loss for Speech Enhancement,Shinji Watanabe_1746678.json,
What is the TLDR of the paper 'TAPLoss: A Temporal Acoustic Parameter Loss for Speech Enhancement'?,This work shows that adding TAPLoss as an auxiliary objective in speech enhancement produces speech with improved perceptual quality and intelligibility and uses data from the Deep Noise Suppression 2020 Challenge to demonstrate that both time-domain models and time-frequency domain models can benefit from the method.,Shinji Watanabe_1746678.json,
What is the abstract of the paper 'TAPLoss: A Temporal Acoustic Parameter Loss for Speech Enhancement'?,"Speech enhancement models have greatly progressed in recent years, but still show limits in perceptual quality of their speech outputs. We propose an objective for perceptual quality based on temporal acoustic parameters. These are fundamental speech features that play an essential role in various applications, including speaker recognition and paralinguistic analysis. We provide a differentiable estimator for four categories of low-level acoustic descriptors involving: frequency-related parameters, energy or amplitude-related parameters, spectral balance parameters, and temporal features. Un-like prior work that looks at aggregated acoustic parameters or a few categories of acoustic parameters, our temporal acoustic parameter (TAP) loss enables auxiliary optimization and improvement of many fine-grained speech characteristics in enhancement workflows. We show that adding TAPLoss as an auxiliary objective in speech enhancement produces speech with improved perceptual quality and intelligibility. We use data from the Deep Noise Suppression 2020 Challenge to demonstrate that both time-domain models and time-frequency domain models can benefit from our method.",Shinji Watanabe_1746678.json,
What is the author ID of Teruko Mitamura?,1706595,data/paper_jsons/T. Mitamura_1706595.json,
What are the papers of Teruko Mitamura?,"Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA, Hierarchical Event Grounding",data/paper_jsons/T. Mitamura_1706595.json,
What is the H-index of Teruko Mitamura?,36,data/paper_jsons/T. Mitamura_1706595.json,
What is the author citation count of Teruko Mitamura?,4681,data/paper_jsons/T. Mitamura_1706595.json,
What journals has Teruko Mitamura published in?,"Proceedings of the Third DialDoc Workshop on Document-grounded Dialogue and Conversational Question Answering, ArXiv",data/paper_jsons/T. Mitamura_1706595.json,
What are the journals and how many papers has Teruko Mitamura published in each?,"{'Proceedings of the Third DialDoc Workshop on Document-grounded Dialogue and Conversational Question Answering': 1, 'ArXiv': 1}",data/paper_jsons/T. Mitamura_1706595.json,
What are the fields of study of Teruko Mitamura?,Computer Science,data/paper_jsons/T. Mitamura_1706595.json,
How many papers has Teruko Mitamura published in open access journals?,2,data/paper_jsons/T. Mitamura_1706595.json,
What venues has Teruko Mitamura published in?,"Workshop on Document-grounded Dialogue and Conversational Question Answering, AAAI Conference on Artificial Intelligence",data/paper_jsons/T. Mitamura_1706595.json,
What is the most cited paper from Teruko Mitamura?,Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA,data/paper_jsons/T. Mitamura_1706595.json,
What is the url of the most cited paper from Teruko Mitamura?,https://aclanthology.org/2023.dialdoc-1.11.pdf,data/paper_jsons/T. Mitamura_1706595.json,
Who are the authors of the most cited paper from Teruko Mitamura?,"Srinivas Gowriraj, Soham Dinesh Tiwari, Mitali Potnis, Srijan Bansal, T. Mitamura, Eric Nyberg",data/paper_jsons/T. Mitamura_1706595.json,
TLDR of the most cited paper from Teruko Mitamura?,"This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-gnostic approach is superior.",data/paper_jsons/T. Mitamura_1706595.json,
Abstract of the most cited paper from Teruko Mitamura?,"The DialDoc 2023 shared task has expanded the document-grounded dialogue task to encompass multiple languages, despite having limited annotated data. This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-agnostic approach is superior. Additionally, the study investigates the impact of query rewriting techniques using large language models, such as ChatGPT, on multilingual, document-grounded question-answering systems. The experiments conducted demonstrate that, for the examples examined, query rewriting does not enhance performance compared to the original queries. This failure is due to topic switching in final dialogue turns and irrelevant topics being considered for query rewriting.",data/paper_jsons/T. Mitamura_1706595.json,
"What journal was the paper ""Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA"" published in?",Proceedings of the Third DialDoc Workshop on Document-grounded Dialogue and Conversational Question Answering,T. Mitamura_1706595.json,
"What venue was the paper ""Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA"" published in?",Workshop on Document-grounded Dialogue and Conversational Question Answering,T. Mitamura_1706595.json,
"How many citations does the paper ""Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA"" have?",2,T. Mitamura_1706595.json,
"Who are the authors of the paper ""Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA""?","Srinivas Gowriraj, Soham Dinesh Tiwari, Mitali Potnis, Srijan Bansal, T. Mitamura, Eric Nyberg",T. Mitamura_1706595.json,
"Who is the first author of the paper ""Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA""?",Srinivas Gowriraj,T. Mitamura_1706595.json,
"What is the paper ID of the paper ""Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA""?",444737639aeea4e1e616509e368afb0bae8f89d6,T. Mitamura_1706595.json,
What paper has the paper ID 444737639aeea4e1e616509e368afb0bae8f89d6?,Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA,T. Mitamura_1706595.json,
What is the TLDR of the paper 'Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA'?,"This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-gnostic approach is superior.",T. Mitamura_1706595.json,
What is the abstract of the paper 'Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA'?,"The DialDoc 2023 shared task has expanded the document-grounded dialogue task to encompass multiple languages, despite having limited annotated data. This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-agnostic approach is superior. Additionally, the study investigates the impact of query rewriting techniques using large language models, such as ChatGPT, on multilingual, document-grounded question-answering systems. The experiments conducted demonstrate that, for the examples examined, query rewriting does not enhance performance compared to the original queries. This failure is due to topic switching in final dialogue turns and irrelevant topics being considered for query rewriting.",T. Mitamura_1706595.json,
"What journal was the paper ""Hierarchical Event Grounding"" published in?",ArXiv,T. Mitamura_1706595.json,
"What venue was the paper ""Hierarchical Event Grounding"" published in?",AAAI Conference on Artificial Intelligence,T. Mitamura_1706595.json,
"How many citations does the paper ""Hierarchical Event Grounding"" have?",0,T. Mitamura_1706595.json,
"Who are the authors of the paper ""Hierarchical Event Grounding""?","Jiefu Ou, Adithya Pratapa, Rishubh Gupta, T. Mitamura",T. Mitamura_1706595.json,
"Who is the first author of the paper ""Hierarchical Event Grounding""?",Jiefu Ou,T. Mitamura_1706595.json,
"What is the paper ID of the paper ""Hierarchical Event Grounding""?",ff77105b2c345f54e1a87f4fbb3a701201f0c1a8,T. Mitamura_1706595.json,
What paper has the paper ID ff77105b2c345f54e1a87f4fbb3a701201f0c1a8?,Hierarchical Event Grounding,T. Mitamura_1706595.json,
What is the TLDR of the paper 'Hierarchical Event Grounding'?,"This work presents an extension to the event grounding task that requires tackling hierarchical event structures from the KB, and proposes a retrieval methodology that leverages event hierarchy through an auxiliary hierarchical loss.",T. Mitamura_1706595.json,
What is the abstract of the paper 'Hierarchical Event Grounding'?,"Event grounding aims at linking mention references in text corpora to events from a knowledge base (KB). Previous work on this task focused primarily on linking to a single KB event, thereby overlooking the hierarchical aspects of events. Events in documents are typically described at various levels of spatio-temporal granularity. These hierarchical relations are utilized in downstream tasks of narrative understanding and schema construction. In this work, we present an extension to the event grounding task that requires tackling hierarchical event structures from the KB. Our proposed task involves linking a mention reference to a set of event labels from a subevent hierarchy in the KB. We propose a retrieval methodology that leverages event hierarchy through an auxiliary hierarchical loss. On an automatically created multilingual dataset from Wikipedia and Wikidata, our experiments demonstrate the effectiveness of the hierarchical loss against retrieve and re-rank baselines. Furthermore, we demonstrate the systems' ability to aid hierarchical discovery among unseen events. Code is available at https://github.com/JefferyO/Hierarchical-Event-Grounding",T. Mitamura_1706595.json,
What is the author ID of Taylor Berg-Kirkpatrick?,1400419309,data/paper_jsons/Taylor Berg-Kirkpatrick_1400419309.json,
What are the papers of Taylor Berg-Kirkpatrick?,"Smaller Language Models are Better Black-box Machine-Generated Text Detectors, Towards Improving Harmonic Sensitivity and Prediction Stability for Singing Melody Extraction, Jointly modeling products and resource pages for task-oriented recommendation, MusicLDM: Enhancing Novelty in Text-to-Music Generation Using Beat-Synchronous Mixup Strategies, Universal Source Separation with Weakly Labelled Data, ClimaBench: A Benchmark Dataset For Climate Change Text Understanding in English, CLIPSonic: Text-to-Audio Synthesis with Unlabeled Videos and Pretrained Language-Vision Models, Membership Inference Attacks against Language Models via Neighbourhood Comparison, Contrastive Attention Networks for Attribution of Early Modern Print",data/paper_jsons/Taylor Berg-Kirkpatrick_1400419309.json,
What is the H-index of Taylor Berg-Kirkpatrick?,36,data/paper_jsons/Taylor Berg-Kirkpatrick_1400419309.json,
What is the author citation count of Taylor Berg-Kirkpatrick?,5655,data/paper_jsons/Taylor Berg-Kirkpatrick_1400419309.json,
What journals has Taylor Berg-Kirkpatrick published in?,"ArXiv, Companion Proceedings of the ACM Web Conference 2023, 2023 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)",data/paper_jsons/Taylor Berg-Kirkpatrick_1400419309.json,
What are the journals and how many papers has Taylor Berg-Kirkpatrick published in each?,"{'ArXiv': 5, 'Companion Proceedings of the ACM Web Conference 2023': 1, '2023 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)': 1}",data/paper_jsons/Taylor Berg-Kirkpatrick_1400419309.json,
What are the fields of study of Taylor Berg-Kirkpatrick?,"Computer Science, Engineering",data/paper_jsons/Taylor Berg-Kirkpatrick_1400419309.json,
How many papers has Taylor Berg-Kirkpatrick published in open access journals?,9,data/paper_jsons/Taylor Berg-Kirkpatrick_1400419309.json,
What venues has Taylor Berg-Kirkpatrick published in?,"arXiv.org, International Society for Music Information Retrieval Conference, The Web Conference, IEEE Workshop on Applications of Signal Processing to Audio and Acoustics, Annual Meeting of the Association for Computational Linguistics, AAAI Conference on Artificial Intelligence",data/paper_jsons/Taylor Berg-Kirkpatrick_1400419309.json,
What is the most cited paper from Taylor Berg-Kirkpatrick?,Membership Inference Attacks against Language Models via Neighbourhood Comparison,data/paper_jsons/Taylor Berg-Kirkpatrick_1400419309.json,
What is the url of the most cited paper from Taylor Berg-Kirkpatrick?,https://arxiv.org/pdf/2305.18462,data/paper_jsons/Taylor Berg-Kirkpatrick_1400419309.json,
Who are the authors of the most cited paper from Taylor Berg-Kirkpatrick?,"Justus Mattern, Fatemehsadat Mireshghallah, Zhijing Jin, B. Scholkopf, Mrinmaya Sachan, Taylor Berg-Kirkpatrick",data/paper_jsons/Taylor Berg-Kirkpatrick_1400419309.json,
TLDR of the most cited paper from Taylor Berg-Kirkpatrick?,"Neighbourhood attacks are proposed and evaluated, which compare model scores for a given sample to scores of synthetically generated neighbour texts and therefore eliminate the need for access to the training data distribution and clearly outperforms existing reference-free attacks as well as reference-based attacks with imperfect knowledge.",data/paper_jsons/Taylor Berg-Kirkpatrick_1400419309.json,
Abstract of the most cited paper from Taylor Berg-Kirkpatrick?,"Membership Inference attacks (MIAs) aim to predict whether a data sample was present in the training data of a machine learning model or not, and are widely used for assessing the privacy risks of language models. Most existing attacks rely on the observation that models tend to assign higher probabilities to their training samples than non-training points. However, simple thresholding of the model score in isolation tends to lead to high false-positive rates as it does not account for the intrinsic complexity of a sample. Recent work has demonstrated that reference-based attacks which compare model scores to those obtained from a reference model trained on similar data can substantially improve the performance of MIAs. However, in order to train reference models, attacks of this kind make the strong and arguably unrealistic assumption that an adversary has access to samples closely resembling the original training data. Therefore, we investigate their performance in more realistic scenarios and find that they are highly fragile in relation to the data distribution used to train reference models. To investigate whether this fragility provides a layer of safety, we propose and evaluate neighbourhood attacks, which compare model scores for a given sample to scores of synthetically generated neighbour texts and therefore eliminate the need for access to the training data distribution. We show that, in addition to being competitive with reference-based attacks that have perfect knowledge about the training data distribution, our attack clearly outperforms existing reference-free attacks as well as reference-based attacks with imperfect knowledge, which demonstrates the need for a reevaluation of the threat model of adversarial attacks.",data/paper_jsons/Taylor Berg-Kirkpatrick_1400419309.json,
"What journal was the paper ""Smaller Language Models are Better Black-box Machine-Generated Text Detectors"" published in?",ArXiv,Taylor Berg-Kirkpatrick_1400419309.json,
"What venue was the paper ""Smaller Language Models are Better Black-box Machine-Generated Text Detectors"" published in?",arXiv.org,Taylor Berg-Kirkpatrick_1400419309.json,
"How many citations does the paper ""Smaller Language Models are Better Black-box Machine-Generated Text Detectors"" have?",23,Taylor Berg-Kirkpatrick_1400419309.json,
"Who are the authors of the paper ""Smaller Language Models are Better Black-box Machine-Generated Text Detectors""?","Fatemehsadat Mireshghallah, Justus Mattern, Sicun Gao, R. Shokri, Taylor Berg-Kirkpatrick",Taylor Berg-Kirkpatrick_1400419309.json,
"Who is the first author of the paper ""Smaller Language Models are Better Black-box Machine-Generated Text Detectors""?",Fatemehsadat Mireshghallah,Taylor Berg-Kirkpatrick_1400419309.json,
"What is the paper ID of the paper ""Smaller Language Models are Better Black-box Machine-Generated Text Detectors""?",1527d3b661154ff7310fa2759b6dd0ddfd559492,Taylor Berg-Kirkpatrick_1400419309.json,
What paper has the paper ID 1527d3b661154ff7310fa2759b6dd0ddfd559492?,Smaller Language Models are Better Black-box Machine-Generated Text Detectors,Taylor Berg-Kirkpatrick_1400419309.json,
What is the TLDR of the paper 'Smaller Language Models are Better Black-box Machine-Generated Text Detectors'?,"Overall, smaller and partially-trained models are better universal text detectors: they can more precisely detect text generated from both small and larger models.",Taylor Berg-Kirkpatrick_1400419309.json,
What is the abstract of the paper 'Smaller Language Models are Better Black-box Machine-Generated Text Detectors'?,"With the advent of fluent generative language models that can produce convincing utterances very similar to those written by humans, distinguishing whether a piece of text is machine-generated or human-written becomes more challenging and more important, as such models could be used to spread misinformation, fake news, fake reviews and to mimic certain authors and figures. To this end, there have been a slew of methods proposed to detect machine-generated text. Most of these methods need access to the logits of the target model or need the ability to sample from the target. One such black-box detection method relies on the observation that generated text is locally optimal under the likelihood function of the generator, while human-written text is not. We find that overall, smaller and partially-trained models are better universal text detectors: they can more precisely detect text generated from both small and larger models. Interestingly, we find that whether the detector and generator were trained on the same data is not critically important to the detection success. For instance the OPT-125M model has an AUC of 0.81 in detecting ChatGPT generations, whereas a larger model from the GPT family, GPTJ-6B, has AUC of 0.45.",Taylor Berg-Kirkpatrick_1400419309.json,
"What journal was the paper ""Contrastive Attention Networks for Attribution of Early Modern Print"" published in?",,Taylor Berg-Kirkpatrick_1400419309.json,
"What venue was the paper ""Contrastive Attention Networks for Attribution of Early Modern Print"" published in?",AAAI Conference on Artificial Intelligence,Taylor Berg-Kirkpatrick_1400419309.json,
"How many citations does the paper ""Contrastive Attention Networks for Attribution of Early Modern Print"" have?",0,Taylor Berg-Kirkpatrick_1400419309.json,
"Who are the authors of the paper ""Contrastive Attention Networks for Attribution of Early Modern Print""?","Nikolai Vogler, Kartik Goyal, Kishore PV Reddy, Elizaveta Pertseva, Sam Lemley, Christopher N. Warren, M. G'Sell, Taylor Berg-Kirkpatrick",Taylor Berg-Kirkpatrick_1400419309.json,
"Who is the first author of the paper ""Contrastive Attention Networks for Attribution of Early Modern Print""?",Nikolai Vogler,Taylor Berg-Kirkpatrick_1400419309.json,
"What is the paper ID of the paper ""Contrastive Attention Networks for Attribution of Early Modern Print""?",d9dc309f719233be9f2a6b6910072e537f96eec8,Taylor Berg-Kirkpatrick_1400419309.json,
What paper has the paper ID d9dc309f719233be9f2a6b6910072e537f96eec8?,Contrastive Attention Networks for Attribution of Early Modern Print,Taylor Berg-Kirkpatrick_1400419309.json,
What is the TLDR of the paper 'Contrastive Attention Networks for Attribution of Early Modern Print'?,"The method successfully improves downstream damaged type-imprint matching among printed works from this period, as validated by in-domain human experts and demonstrates potential to extend the extant historical research about the origins and content of these books.",Taylor Berg-Kirkpatrick_1400419309.json,
What is the abstract of the paper 'Contrastive Attention Networks for Attribution of Early Modern Print'?,"In this paper, we develop machine learning techniques to identify unknown printers in early modern (c.~1500--1800) English printed books.
Specifically, we focus on matching uniquely damaged character type-imprints in anonymously printed books to works with known printers in order to provide evidence of their origins.
Until now, this work has been limited to manual investigations by analytical bibliographers.
We present a Contrastive Attention-based Metric Learning approach to identify similar damage across character image pairs, which is sensitive to very subtle differences in glyph shapes, yet robust to various confounding sources of noise associated with digitized historical books. 
To overcome the scarce amount of supervised data, we design a random data synthesis procedure that aims to simulate bends, fractures, and inking variations induced by the early printing process.
Our method successfully improves downstream damaged type-imprint matching among printed works from this period, as validated by in-domain human experts. The results of our approach on two important philosophical works from the Early Modern period demonstrate potential to extend the extant historical research about the origins and content of these books.",Taylor Berg-Kirkpatrick_1400419309.json,
"What journal was the paper ""Membership Inference Attacks against Language Models via Neighbourhood Comparison"" published in?",ArXiv,Taylor Berg-Kirkpatrick_1400419309.json,
"What venue was the paper ""Membership Inference Attacks against Language Models via Neighbourhood Comparison"" published in?",Annual Meeting of the Association for Computational Linguistics,Taylor Berg-Kirkpatrick_1400419309.json,
"How many citations does the paper ""Membership Inference Attacks against Language Models via Neighbourhood Comparison"" have?",28,Taylor Berg-Kirkpatrick_1400419309.json,
"Who are the authors of the paper ""Membership Inference Attacks against Language Models via Neighbourhood Comparison""?","Justus Mattern, Fatemehsadat Mireshghallah, Zhijing Jin, B. Scholkopf, Mrinmaya Sachan, Taylor Berg-Kirkpatrick",Taylor Berg-Kirkpatrick_1400419309.json,
"Who is the first author of the paper ""Membership Inference Attacks against Language Models via Neighbourhood Comparison""?",Justus Mattern,Taylor Berg-Kirkpatrick_1400419309.json,
"What is the paper ID of the paper ""Membership Inference Attacks against Language Models via Neighbourhood Comparison""?",cb754310302086dfbbcd098263200e2a03f65874,Taylor Berg-Kirkpatrick_1400419309.json,
What paper has the paper ID cb754310302086dfbbcd098263200e2a03f65874?,Membership Inference Attacks against Language Models via Neighbourhood Comparison,Taylor Berg-Kirkpatrick_1400419309.json,
What is the TLDR of the paper 'Membership Inference Attacks against Language Models via Neighbourhood Comparison'?,"Neighbourhood attacks are proposed and evaluated, which compare model scores for a given sample to scores of synthetically generated neighbour texts and therefore eliminate the need for access to the training data distribution and clearly outperforms existing reference-free attacks as well as reference-based attacks with imperfect knowledge.",Taylor Berg-Kirkpatrick_1400419309.json,
What is the abstract of the paper 'Membership Inference Attacks against Language Models via Neighbourhood Comparison'?,"Membership Inference attacks (MIAs) aim to predict whether a data sample was present in the training data of a machine learning model or not, and are widely used for assessing the privacy risks of language models. Most existing attacks rely on the observation that models tend to assign higher probabilities to their training samples than non-training points. However, simple thresholding of the model score in isolation tends to lead to high false-positive rates as it does not account for the intrinsic complexity of a sample. Recent work has demonstrated that reference-based attacks which compare model scores to those obtained from a reference model trained on similar data can substantially improve the performance of MIAs. However, in order to train reference models, attacks of this kind make the strong and arguably unrealistic assumption that an adversary has access to samples closely resembling the original training data. Therefore, we investigate their performance in more realistic scenarios and find that they are highly fragile in relation to the data distribution used to train reference models. To investigate whether this fragility provides a layer of safety, we propose and evaluate neighbourhood attacks, which compare model scores for a given sample to scores of synthetically generated neighbour texts and therefore eliminate the need for access to the training data distribution. We show that, in addition to being competitive with reference-based attacks that have perfect knowledge about the training data distribution, our attack clearly outperforms existing reference-free attacks as well as reference-based attacks with imperfect knowledge, which demonstrates the need for a reevaluation of the threat model of adversarial attacks.",Taylor Berg-Kirkpatrick_1400419309.json,
What is the author ID of Tom Mitchell?,40975594,data/paper_jsons/Tom Michael Mitchell_40975594.json,
What are the papers of Tom Mitchell?,"Read and Reap the Rewards: Learning to Play Atari with the Help of Instruction Manuals, Learning to Give Useful Hints: Assistance Action Evaluation and Policy Improvements, Genitourinary Management and Follow-Up for Patients with Stevens-Johnson Syndrome/Toxic Epidermal Necrolysis",data/paper_jsons/Tom Michael Mitchell_40975594.json,
What is the H-index of Tom Mitchell?,81,data/paper_jsons/Tom Michael Mitchell_40975594.json,
What is the author citation count of Tom Mitchell?,34877,data/paper_jsons/Tom Michael Mitchell_40975594.json,
What journals has Tom Mitchell published in?,"ArXiv, Burns Open",data/paper_jsons/Tom Michael Mitchell_40975594.json,
What are the journals and how many papers has Tom Mitchell published in each?,"{'ArXiv': 1, 'Burns Open': 1}",data/paper_jsons/Tom Michael Mitchell_40975594.json,
What are the fields of study of Tom Mitchell?,Computer Science,data/paper_jsons/Tom Michael Mitchell_40975594.json,
How many papers has Tom Mitchell published in open access journals?,3,data/paper_jsons/Tom Michael Mitchell_40975594.json,
What venues has Tom Mitchell published in?,"arXiv.org, European Conference on Technology Enhanced Learning, Burns Open",data/paper_jsons/Tom Michael Mitchell_40975594.json,
What is the most cited paper from Tom Mitchell?,Read and Reap the Rewards: Learning to Play Atari with the Help of Instruction Manuals,data/paper_jsons/Tom Michael Mitchell_40975594.json,
What is the url of the most cited paper from Tom Mitchell?,http://arxiv.org/pdf/2302.04449,data/paper_jsons/Tom Michael Mitchell_40975594.json,
Who are the authors of the most cited paper from Tom Mitchell?,"Yue Wu, Yewen Fan, P. Liang, A. Azaria, Yuan-Fang Li, Tom Michael Mitchell",data/paper_jsons/Tom Michael Mitchell_40975594.json,
TLDR of the most cited paper from Tom Mitchell?,It is hypothesized that the ability to utilize human-written instruction manuals to assist learning policies for specific tasks should lead to a more efficient and better-performing agent in the Read and Reward framework.,data/paper_jsons/Tom Michael Mitchell_40975594.json,
Abstract of the most cited paper from Tom Mitchell?,"High sample complexity has long been a challenge for RL. On the other hand, humans learn to perform tasks not only from interaction or demonstrations, but also by reading unstructured text documents, e.g., instruction manuals. Instruction manuals and wiki pages are among the most abundant data that could inform agents of valuable features and policies or task-specific environmental dynamics and reward structures. Therefore, we hypothesize that the ability to utilize human-written instruction manuals to assist learning policies for specific tasks should lead to a more efficient and better-performing agent. We propose the Read and Reward framework. Read and Reward speeds up RL algorithms on Atari games by reading manuals released by the Atari game developers. Our framework consists of a QA Extraction module that extracts and summarizes relevant information from the manual and a Reasoning module that evaluates object-agent interactions based on information from the manual. An auxiliary reward is then provided to a standard A2C RL agent, when interaction is detected. Experimentally, various RL algorithms obtain significant improvement in performance and training speed when assisted by our design.",data/paper_jsons/Tom Michael Mitchell_40975594.json,
"What journal was the paper ""Genitourinary Management and Follow-Up for Patients with Stevens-Johnson Syndrome/Toxic Epidermal Necrolysis"" published in?",Burns Open,Tom Michael Mitchell_40975594.json,
"What venue was the paper ""Genitourinary Management and Follow-Up for Patients with Stevens-Johnson Syndrome/Toxic Epidermal Necrolysis"" published in?",Burns Open,Tom Michael Mitchell_40975594.json,
"How many citations does the paper ""Genitourinary Management and Follow-Up for Patients with Stevens-Johnson Syndrome/Toxic Epidermal Necrolysis"" have?",0,Tom Michael Mitchell_40975594.json,
"Who are the authors of the paper ""Genitourinary Management and Follow-Up for Patients with Stevens-Johnson Syndrome/Toxic Epidermal Necrolysis""?","Gina T. Baaklini, Tom Michael Mitchell, Jordan Davis, Kevin McGovern, J. Aden, L. Cancio",Tom Michael Mitchell_40975594.json,
"Who is the first author of the paper ""Genitourinary Management and Follow-Up for Patients with Stevens-Johnson Syndrome/Toxic Epidermal Necrolysis""?",Gina T. Baaklini,Tom Michael Mitchell_40975594.json,
"What is the paper ID of the paper ""Genitourinary Management and Follow-Up for Patients with Stevens-Johnson Syndrome/Toxic Epidermal Necrolysis""?",e98e4af918f3ad0f6ea65f2c68e2846a5b7eb333,Tom Michael Mitchell_40975594.json,
What paper has the paper ID e98e4af918f3ad0f6ea65f2c68e2846a5b7eb333?,Genitourinary Management and Follow-Up for Patients with Stevens-Johnson Syndrome/Toxic Epidermal Necrolysis,Tom Michael Mitchell_40975594.json,
What is the TLDR of the paper 'Genitourinary Management and Follow-Up for Patients with Stevens-Johnson Syndrome/Toxic Epidermal Necrolysis'?,TLDR not found,Tom Michael Mitchell_40975594.json,
What is the abstract of the paper 'Genitourinary Management and Follow-Up for Patients with Stevens-Johnson Syndrome/Toxic Epidermal Necrolysis'?,,Tom Michael Mitchell_40975594.json,
"What journal was the paper ""Learning to Give Useful Hints: Assistance Action Evaluation and Policy Improvements"" published in?",,Tom Michael Mitchell_40975594.json,
"What venue was the paper ""Learning to Give Useful Hints: Assistance Action Evaluation and Policy Improvements"" published in?",European Conference on Technology Enhanced Learning,Tom Michael Mitchell_40975594.json,
"How many citations does the paper ""Learning to Give Useful Hints: Assistance Action Evaluation and Policy Improvements"" have?",0,Tom Michael Mitchell_40975594.json,
"Who are the authors of the paper ""Learning to Give Useful Hints: Assistance Action Evaluation and Policy Improvements""?","Robin Schmucker, Nimish Pachapurkar, Bala Shanmugam, Miral Shah, Tom Michael Mitchell",Tom Michael Mitchell_40975594.json,
"Who is the first author of the paper ""Learning to Give Useful Hints: Assistance Action Evaluation and Policy Improvements""?",Robin Schmucker,Tom Michael Mitchell_40975594.json,
"What is the paper ID of the paper ""Learning to Give Useful Hints: Assistance Action Evaluation and Policy Improvements""?",8874cd8cb99d00e133fba10454e5e5e64f38ca85,Tom Michael Mitchell_40975594.json,
What paper has the paper ID 8874cd8cb99d00e133fba10454e5e5e64f38ca85?,Learning to Give Useful Hints: Assistance Action Evaluation and Policy Improvements,Tom Michael Mitchell_40975594.json,
What is the TLDR of the paper 'Learning to Give Useful Hints: Assistance Action Evaluation and Policy Improvements'?,TLDR not found,Tom Michael Mitchell_40975594.json,
What is the abstract of the paper 'Learning to Give Useful Hints: Assistance Action Evaluation and Policy Improvements'?,,Tom Michael Mitchell_40975594.json,
"What journal was the paper ""Read and Reap the Rewards: Learning to Play Atari with the Help of Instruction Manuals"" published in?",ArXiv,Tom Michael Mitchell_40975594.json,
"What venue was the paper ""Read and Reap the Rewards: Learning to Play Atari with the Help of Instruction Manuals"" published in?",arXiv.org,Tom Michael Mitchell_40975594.json,
"How many citations does the paper ""Read and Reap the Rewards: Learning to Play Atari with the Help of Instruction Manuals"" have?",15,Tom Michael Mitchell_40975594.json,
"Who are the authors of the paper ""Read and Reap the Rewards: Learning to Play Atari with the Help of Instruction Manuals""?","Yue Wu, Yewen Fan, P. Liang, A. Azaria, Yuan-Fang Li, Tom Michael Mitchell",Tom Michael Mitchell_40975594.json,
"Who is the first author of the paper ""Read and Reap the Rewards: Learning to Play Atari with the Help of Instruction Manuals""?",Yue Wu,Tom Michael Mitchell_40975594.json,
"What is the paper ID of the paper ""Read and Reap the Rewards: Learning to Play Atari with the Help of Instruction Manuals""?",61678a9f1d8291bb0f3d704a439ac8cd64fa6482,Tom Michael Mitchell_40975594.json,
What paper has the paper ID 61678a9f1d8291bb0f3d704a439ac8cd64fa6482?,Read and Reap the Rewards: Learning to Play Atari with the Help of Instruction Manuals,Tom Michael Mitchell_40975594.json,
What is the TLDR of the paper 'Read and Reap the Rewards: Learning to Play Atari with the Help of Instruction Manuals'?,It is hypothesized that the ability to utilize human-written instruction manuals to assist learning policies for specific tasks should lead to a more efficient and better-performing agent in the Read and Reward framework.,Tom Michael Mitchell_40975594.json,
What is the abstract of the paper 'Read and Reap the Rewards: Learning to Play Atari with the Help of Instruction Manuals'?,"High sample complexity has long been a challenge for RL. On the other hand, humans learn to perform tasks not only from interaction or demonstrations, but also by reading unstructured text documents, e.g., instruction manuals. Instruction manuals and wiki pages are among the most abundant data that could inform agents of valuable features and policies or task-specific environmental dynamics and reward structures. Therefore, we hypothesize that the ability to utilize human-written instruction manuals to assist learning policies for specific tasks should lead to a more efficient and better-performing agent. We propose the Read and Reward framework. Read and Reward speeds up RL algorithms on Atari games by reading manuals released by the Atari game developers. Our framework consists of a QA Extraction module that extracts and summarizes relevant information from the manual and a Reasoning module that evaluates object-agent interactions based on information from the manual. An auxiliary reward is then provided to a standard A2C RL agent, when interaction is detected. Experimentally, various RL algorithms obtain significant improvement in performance and training speed when assisted by our design.",Tom Michael Mitchell_40975594.json,
What is the author ID of William Cohen?,50056360,data/paper_jsons/William W. Cohen_50056360.json,
What are the papers of William Cohen?,"Answering Ambiguous Questions with a Database of Questions, Answers, and Revisions, MEMORY-VQ: Compression for Tractable Internet-Scale Memory, Subject-driven Text-to-Image Generation via Apprenticeship Learning, GLIMMER: generalized late-interaction memory reranker",data/paper_jsons/William W. Cohen_50056360.json,
What is the H-index of William Cohen?,88,data/paper_jsons/William W. Cohen_50056360.json,
What is the author citation count of William Cohen?,41245,data/paper_jsons/William W. Cohen_50056360.json,
What journals has William Cohen published in?,ArXiv,data/paper_jsons/William W. Cohen_50056360.json,
What are the journals and how many papers has William Cohen published in each?,{'ArXiv': 4},data/paper_jsons/William W. Cohen_50056360.json,
What are the fields of study of William Cohen?,Computer Science,data/paper_jsons/William W. Cohen_50056360.json,
How many papers has William Cohen published in open access journals?,4,data/paper_jsons/William W. Cohen_50056360.json,
What venues has William Cohen published in?,arXiv.org,data/paper_jsons/William W. Cohen_50056360.json,
What is the most cited paper from William Cohen?,Subject-driven Text-to-Image Generation via Apprenticeship Learning,data/paper_jsons/William W. Cohen_50056360.json,
What is the url of the most cited paper from William Cohen?,https://arxiv.org/pdf/2304.00186,data/paper_jsons/William W. Cohen_50056360.json,
Who are the authors of the most cited paper from William Cohen?,"Wenhu Chen, Hexiang Hu, Yandong Li, Nataniel Rui, Xuhui Jia, Ming-Wei Chang, William W. Cohen",data/paper_jsons/William W. Cohen_50056360.json,
TLDR of the most cited paper from William Cohen?,"Human evaluation shows that SuTI significantly outperforms existing models like InstructPix2Pix, Textual Inversion, Imagic, Prompt2Prompt, Re-Imagen and DreamBooth, especially on the subject and text alignment aspects.",data/paper_jsons/William W. Cohen_50056360.json,
Abstract of the most cited paper from William Cohen?,"Recent text-to-image generation models like DreamBooth have made remarkable progress in generating highly customized images of a target subject, by fine-tuning an ``expert model'' for a given subject from a few examples. However, this process is expensive, since a new expert model must be learned for each subject. In this paper, we present SuTI, a Subject-driven Text-to-Image generator that replaces subject-specific fine tuning with in-context learning. Given a few demonstrations of a new subject, SuTI can instantly generate novel renditions of the subject in different scenes, without any subject-specific optimization. SuTI is powered by apprenticeship learning, where a single apprentice model is learned from data generated by a massive number of subject-specific expert models. Specifically, we mine millions of image clusters from the Internet, each centered around a specific visual subject. We adopt these clusters to train a massive number of expert models, each specializing in a different subject. The apprentice model SuTI then learns to imitate the behavior of these fine-tuned experts. SuTI can generate high-quality and customized subject-specific images 20x faster than optimization-based SoTA methods. On the challenging DreamBench and DreamBench-v2, our human evaluation shows that SuTI significantly outperforms existing models like InstructPix2Pix, Textual Inversion, Imagic, Prompt2Prompt, Re-Imagen and DreamBooth, especially on the subject and text alignment aspects.",data/paper_jsons/William W. Cohen_50056360.json,
"What journal was the paper ""Answering Ambiguous Questions with a Database of Questions, Answers, and Revisions"" published in?",ArXiv,William W. Cohen_50056360.json,
"What venue was the paper ""Answering Ambiguous Questions with a Database of Questions, Answers, and Revisions"" published in?",arXiv.org,William W. Cohen_50056360.json,
"How many citations does the paper ""Answering Ambiguous Questions with a Database of Questions, Answers, and Revisions"" have?",1,William W. Cohen_50056360.json,
"Who are the authors of the paper ""Answering Ambiguous Questions with a Database of Questions, Answers, and Revisions""?","Haitian Sun, William W. Cohen, R. Salakhutdinov",William W. Cohen_50056360.json,
"Who is the first author of the paper ""Answering Ambiguous Questions with a Database of Questions, Answers, and Revisions""?",Haitian Sun,William W. Cohen_50056360.json,
"What is the paper ID of the paper ""Answering Ambiguous Questions with a Database of Questions, Answers, and Revisions""?",2ca8e50ffd6e2e67f3fe2fbf1af57dbedb4cf493,William W. Cohen_50056360.json,
What paper has the paper ID 2ca8e50ffd6e2e67f3fe2fbf1af57dbedb4cf493?,"Answering Ambiguous Questions with a Database of Questions, Answers, and Revisions",William W. Cohen_50056360.json,
"What is the TLDR of the paper 'Answering Ambiguous Questions with a Database of Questions, Answers, and Revisions'?","A new state-of-the-art for answering ambiguous questions that exploits a database of unambiguous questions generated from Wikipedia, which improves performance by 15% (relative improvement) on recall measures and 10% on measures which evaluate disambiguating questions from predicted outputs.",William W. Cohen_50056360.json,
"What is the abstract of the paper 'Answering Ambiguous Questions with a Database of Questions, Answers, and Revisions'?","Many open-domain questions are under-specified and thus have multiple possible answers, each of which is correct under a different interpretation of the question. Answering such ambiguous questions is challenging, as it requires retrieving and then reasoning about diverse information from multiple passages. We present a new state-of-the-art for answering ambiguous questions that exploits a database of unambiguous questions generated from Wikipedia. On the challenging ASQA benchmark, which requires generating long-form answers that summarize the multiple answers to an ambiguous question, our method improves performance by 15% (relative improvement) on recall measures and 10% on measures which evaluate disambiguating questions from predicted outputs. Retrieving from the database of generated questions also gives large improvements in diverse passage retrieval (by matching user questions q to passages p indirectly, via questions q' generated from p).",William W. Cohen_50056360.json,
"What journal was the paper ""MEMORY-VQ: Compression for Tractable Internet-Scale Memory"" published in?",ArXiv,William W. Cohen_50056360.json,
"What venue was the paper ""MEMORY-VQ: Compression for Tractable Internet-Scale Memory"" published in?",arXiv.org,William W. Cohen_50056360.json,
"How many citations does the paper ""MEMORY-VQ: Compression for Tractable Internet-Scale Memory"" have?",0,William W. Cohen_50056360.json,
"Who are the authors of the paper ""MEMORY-VQ: Compression for Tractable Internet-Scale Memory""?","Yury Zemlyanskiy, Michiel de Jong, L. Vilnis, Santiago Ontan'on, William W. Cohen, Sumit K. Sanghai, J. Ainslie",William W. Cohen_50056360.json,
"Who is the first author of the paper ""MEMORY-VQ: Compression for Tractable Internet-Scale Memory""?",Yury Zemlyanskiy,William W. Cohen_50056360.json,
"What is the paper ID of the paper ""MEMORY-VQ: Compression for Tractable Internet-Scale Memory""?",646cca9de110726000a6e44560743b241a4d7f91,William W. Cohen_50056360.json,
What paper has the paper ID 646cca9de110726000a6e44560743b241a4d7f91?,MEMORY-VQ: Compression for Tractable Internet-Scale Memory,William W. Cohen_50056360.json,
What is the TLDR of the paper 'MEMORY-VQ: Compression for Tractable Internet-Scale Memory'?,"This work proposes MEMORY-VQ, a new method to reduce storage requirements of memory-augmented models without sacrificing performance, which uses a vector quantization variational autoencoder (VQ-VAE) to compress token representations.",William W. Cohen_50056360.json,
What is the abstract of the paper 'MEMORY-VQ: Compression for Tractable Internet-Scale Memory'?,"Retrieval augmentation is a powerful but expensive method to make language models more knowledgeable about the world. Memory-based methods like LUMEN pre-compute token representations for retrieved passages to drastically speed up inference. However, memory also leads to much greater storage requirements from storing pre-computed representations. We propose MEMORY-VQ, a new method to reduce storage requirements of memory-augmented models without sacrificing performance. Our method uses a vector quantization variational autoencoder (VQ-VAE) to compress token representations. We apply MEMORY-VQ to the LUMEN model to obtain LUMEN-VQ, a memory model that achieves a 16x compression rate with comparable performance on the KILT benchmark. LUMEN-VQ enables practical retrieval augmentation even for extremely large retrieval corpora.",William W. Cohen_50056360.json,
"What journal was the paper ""GLIMMER: generalized late-interaction memory reranker"" published in?",ArXiv,William W. Cohen_50056360.json,
"What venue was the paper ""GLIMMER: generalized late-interaction memory reranker"" published in?",arXiv.org,William W. Cohen_50056360.json,
"How many citations does the paper ""GLIMMER: generalized late-interaction memory reranker"" have?",3,William W. Cohen_50056360.json,
"Who are the authors of the paper ""GLIMMER: generalized late-interaction memory reranker""?","Michiel de Jong, Yury Zemlyanskiy, Nicholas FitzGerald, Sumit K. Sanghai, William W. Cohen, J. Ainslie",William W. Cohen_50056360.json,
"Who is the first author of the paper ""GLIMMER: generalized late-interaction memory reranker""?",Michiel de Jong,William W. Cohen_50056360.json,
"What is the paper ID of the paper ""GLIMMER: generalized late-interaction memory reranker""?",c67099476f2b505dfd5a22c817707fad83de9994,William W. Cohen_50056360.json,
What paper has the paper ID c67099476f2b505dfd5a22c817707fad83de9994?,GLIMMER: generalized late-interaction memory reranker,William W. Cohen_50056360.json,
What is the TLDR of the paper 'GLIMMER: generalized late-interaction memory reranker'?,"GLIMMER is proposed, which improves on LUMEN through exploiting free access to the powerful memory representations by applying a shallow reranker on top of memory to drastically improve retrieval quality at low cost and incorporating multi-task training to learn a general and higher quality memory and live encoder.",William W. Cohen_50056360.json,
What is the abstract of the paper 'GLIMMER: generalized late-interaction memory reranker'?,"Memory-augmentation is a powerful approach for efficiently incorporating external information into language models, but leads to reduced performance relative to retrieving text. Recent work introduced LUMEN, a memory-retrieval hybrid that partially pre-computes memory and updates memory representations on the fly with a smaller live encoder. We propose GLIMMER, which improves on this approach through 1) exploiting free access to the powerful memory representations by applying a shallow reranker on top of memory to drastically improve retrieval quality at low cost, and 2) incorporating multi-task training to learn a general and higher quality memory and live encoder. GLIMMER achieves strong gains in performance at faster speeds compared to LUMEN and FiD on the KILT benchmark of knowledge-intensive tasks.",William W. Cohen_50056360.json,
What is the author ID of Yiming Yang?,35729970,data/paper_jsons/Yiming Yang_35729970.json,
What are the papers of Yiming Yang?,"Accelerating Diffusion-based Combinatorial Optimization Solvers by Progressive Distillation, Automatic synchrotron tomographic alignment schemes based on genetic algorithms and human-in-the-loop software, High CD8+tumor-infiltrating lymphocytes indicate severe exhaustion and poor prognosis in angioimmunoblastic T-cell lymphoma, Numerical Investigation of Fatigue Crack Propagation Behaviour of 550E High-Performance Steel, Association between albumin-to-globulin ratio and the risk of overall survival in advanced non-small cell lung cancer patients with anlotinib treatment: a retrospective cohort study, Analysis of Volatile Components in Dried Fruits and Branch Exudates of Schisandra chinensis with Different Fruit Colors Using GC-IMS Technology, Secreted endogenous macrosomes reduce Aβ burden and ameliorate Alzheimer’s disease, DIFUSCO: Graph-based Diffusion Solvers for Combinatorial Optimization, Balancing Exploration and Exploitation in Hierarchical Reinforcement Learning via Latent Landmark Graphs, Aligning Large Multimodal Models with Factually Augmented RLHF, An Experimental Study on Secondary Transfer Performances of Prestress after Anchoring Failure of Steel Wire Strands, MRI Features for Predicting Microvascular Invasion and Postoperative Recurrence in Hepatocellular Carcinoma Without Peritumoral Hypointensity, Impact of local governments’ construction land allocation strategies on innovation-driven development of China",data/paper_jsons/Yiming Yang_35729970.json,
What is the H-index of Yiming Yang?,64,data/paper_jsons/Yiming Yang_35729970.json,
What is the author citation count of Yiming Yang?,47104,data/paper_jsons/Yiming Yang_35729970.json,
What journals has Yiming Yang published in?,"ArXiv, Journal of Synchrotron Radiation, Frontiers in Immunology, Metals, BMC Pulmonary Medicine, Molecules, Science Advances, 2023 International Joint Conference on Neural Networks (IJCNN), Journal of Hepatocellular Carcinoma, 资源科学",data/paper_jsons/Yiming Yang_35729970.json,
What are the journals and how many papers has Yiming Yang published in each?,"{'ArXiv': 3, 'Metals': 2, 'Journal of Synchrotron Radiation': 1, 'Frontiers in Immunology': 1, 'BMC Pulmonary Medicine': 1, 'Molecules': 1, 'Science Advances': 1, '2023 International Joint Conference on Neural Networks (IJCNN)': 1, 'Journal of Hepatocellular Carcinoma': 1, '资源科学': 1}",data/paper_jsons/Yiming Yang_35729970.json,
What are the fields of study of Yiming Yang?,"Computer Science, Medicine",data/paper_jsons/Yiming Yang_35729970.json,
How many papers has Yiming Yang published in open access journals?,13,data/paper_jsons/Yiming Yang_35729970.json,
What venues has Yiming Yang published in?,"arXiv.org, Journal of Synchrotron Radiation, Frontiers in Immunology, Metals, BMC Pulmonary Medicine, Molecules, Science Advances, IEEE International Joint Conference on Neural Network, Journal of Hepatocellular Carcinoma, 资源科学",data/paper_jsons/Yiming Yang_35729970.json,
What is the most cited paper from Yiming Yang?,Aligning Large Multimodal Models with Factually Augmented RLHF,data/paper_jsons/Yiming Yang_35729970.json,
What is the url of the most cited paper from Yiming Yang?,https://arxiv.org/pdf/2309.14525,data/paper_jsons/Yiming Yang_35729970.json,
Who are the authors of the most cited paper from Yiming Yang?,"Zhiqing Sun, Sheng Shen, Shengcao Cao, Haotian Liu, Chunyuan Li, Yikang Shen, Chuang Gan, Liangyan Gui, Yu-Xiong Wang, Yiming Yang, K. Keutzer, Trevor Darrell",data/paper_jsons/Yiming Yang_35729970.json,
TLDR of the most cited paper from Yiming Yang?,"A new alignment algorithm called Factually Augmented RLHF is proposed that augments the reward model with additional factual information such as image captions and ground-truth multi-choice options, which alleviates the reward hacking phenomenon in RLHF and further improves the performance.",data/paper_jsons/Yiming Yang_35729970.json,
Abstract of the most cited paper from Yiming Yang?,"Large Multimodal Models (LMM) are built across modalities and the misalignment between two modalities can result in""hallucination"", generating textual outputs that are not grounded by the multimodal information in context. To address the multimodal misalignment issue, we adapt the Reinforcement Learning from Human Feedback (RLHF) from the text domain to the task of vision-language alignment, where human annotators are asked to compare two responses and pinpoint the more hallucinated one, and the vision-language model is trained to maximize the simulated human rewards. We propose a new alignment algorithm called Factually Augmented RLHF that augments the reward model with additional factual information such as image captions and ground-truth multi-choice options, which alleviates the reward hacking phenomenon in RLHF and further improves the performance. We also enhance the GPT-4-generated training data (for vision instruction tuning) with previously available human-written image-text pairs to improve the general capabilities of our model. To evaluate the proposed approach in real-world scenarios, we develop a new evaluation benchmark MMHAL-BENCH with a special focus on penalizing hallucinations. As the first LMM trained with RLHF, our approach achieves remarkable improvement on the LLaVA-Bench dataset with the 94% performance level of the text-only GPT-4 (while previous best methods can only achieve the 87% level), and an improvement by 60% on MMHAL-BENCH over other baselines. We opensource our code, model, data at https://llava-rlhf.github.io.",data/paper_jsons/Yiming Yang_35729970.json,
"What journal was the paper ""Numerical Investigation of Fatigue Crack Propagation Behaviour of 550E High-Performance Steel"" published in?",Metals,Yiming Yang_35729970.json,
"What venue was the paper ""Numerical Investigation of Fatigue Crack Propagation Behaviour of 550E High-Performance Steel"" published in?",Metals,Yiming Yang_35729970.json,
"How many citations does the paper ""Numerical Investigation of Fatigue Crack Propagation Behaviour of 550E High-Performance Steel"" have?",0,Yiming Yang_35729970.json,
"Who are the authors of the paper ""Numerical Investigation of Fatigue Crack Propagation Behaviour of 550E High-Performance Steel""?","Linfa Xiao, Heng Lin, Yongxiang Wang, Yiming Yang, Huapeng Chen",Yiming Yang_35729970.json,
"Who is the first author of the paper ""Numerical Investigation of Fatigue Crack Propagation Behaviour of 550E High-Performance Steel""?",Linfa Xiao,Yiming Yang_35729970.json,
"What is the paper ID of the paper ""Numerical Investigation of Fatigue Crack Propagation Behaviour of 550E High-Performance Steel""?",2bfa8ac40c1ff8e45c298115fcadae062526310e,Yiming Yang_35729970.json,
What paper has the paper ID 2bfa8ac40c1ff8e45c298115fcadae062526310e?,Numerical Investigation of Fatigue Crack Propagation Behaviour of 550E High-Performance Steel,Yiming Yang_35729970.json,
What is the TLDR of the paper 'Numerical Investigation of Fatigue Crack Propagation Behaviour of 550E High-Performance Steel'?,TLDR not found,Yiming Yang_35729970.json,
What is the abstract of the paper 'Numerical Investigation of Fatigue Crack Propagation Behaviour of 550E High-Performance Steel'?,"The fatigue crack propagation behaviour of Q550E high-performance steel (HPS) is studied in this paper. Static tensile testing and fatigue crack propagation testing were carried out, and the results were compared with those of Q235. Finite element models were developed and verified against the experimental results. The impacts of the initial crack angle, crack depth ratio, stress ratio, thickness, and corrosion pitting on the fatigue crack propagation behaviour of the HPS were analysed. The results show that the fatigue life of Q550 was reduced by 18% due to the corrosion pitting, but it did not change the crack propagation path. When the stress intensity factor is higher than a certain value, the fatigue performance of Q235 is better than that of Q550E. The initial crack angle of 52.5° is the critical angle of the crack stress intensity factor. The steel tends to fracture as the crack depth ratio increases, and more attention should be paid to the effective crack length in engineering practice. An increasing stress ratio leads to a smaller stress intensity factor, and the thickness affects the stress intensity factor in the later stage. The crack stress intensity factor around the corrosion pits gradually decreases along the thickness direction, and the crack tips around the corrosion pits tend to reach the yield state initially, accelerating the fatigue fracture of the specimen and ultimately leading to a decrease in fatigue life.",Yiming Yang_35729970.json,
"What journal was the paper ""High CD8+tumor-infiltrating lymphocytes indicate severe exhaustion and poor prognosis in angioimmunoblastic T-cell lymphoma"" published in?",Frontiers in Immunology,Yiming Yang_35729970.json,
"What venue was the paper ""High CD8+tumor-infiltrating lymphocytes indicate severe exhaustion and poor prognosis in angioimmunoblastic T-cell lymphoma"" published in?",Frontiers in Immunology,Yiming Yang_35729970.json,
"How many citations does the paper ""High CD8+tumor-infiltrating lymphocytes indicate severe exhaustion and poor prognosis in angioimmunoblastic T-cell lymphoma"" have?",0,Yiming Yang_35729970.json,
"Who are the authors of the paper ""High CD8+tumor-infiltrating lymphocytes indicate severe exhaustion and poor prognosis in angioimmunoblastic T-cell lymphoma""?","Qiqi Zhu, Yiming Yang, Xueqin Deng, Ningning Chao, Zihang Chen, Y. Ye, Wenyan Zhang, Weiping Liu, Sha Zhao",Yiming Yang_35729970.json,
"Who is the first author of the paper ""High CD8+tumor-infiltrating lymphocytes indicate severe exhaustion and poor prognosis in angioimmunoblastic T-cell lymphoma""?",Qiqi Zhu,Yiming Yang_35729970.json,
"What is the paper ID of the paper ""High CD8+tumor-infiltrating lymphocytes indicate severe exhaustion and poor prognosis in angioimmunoblastic T-cell lymphoma""?",16db1c1c00ac219984c28480cb60fd09b1897bf6,Yiming Yang_35729970.json,
What paper has the paper ID 16db1c1c00ac219984c28480cb60fd09b1897bf6?,High CD8+tumor-infiltrating lymphocytes indicate severe exhaustion and poor prognosis in angioimmunoblastic T-cell lymphoma,Yiming Yang_35729970.json,
What is the TLDR of the paper 'High CD8+tumor-infiltrating lymphocytes indicate severe exhaustion and poor prognosis in angioimmunoblastic T-cell lymphoma'?,"The study comprehensively reveals the exhaustion status of CD8+TILs and their potential negative impact on AITL prognosis, which facilitates further mechanistic studies and is valuable for guiding immunotherapy strategies.",Yiming Yang_35729970.json,
What is the abstract of the paper 'High CD8+tumor-infiltrating lymphocytes indicate severe exhaustion and poor prognosis in angioimmunoblastic T-cell lymphoma'?,"Background Exhaustion of CD8+ tumor-infiltrating lymphocytes (TILs), characterized by the overexpression of immune checkpoints (IC), is a major impediment to anti-tumor immunity. However, the exhaustion status of CD8+TILs in angioimmunoblastic T cell lymphoma (AITL) remains unclear. Therefore, we aimed to elucidate the exhaustion status of CD8+TILs in AITL and its influence on prognosis. Methods The correlation between CD8+TILs and IC expression in AITL was analyzed using single-cell RNA sequencing (n = 2), flow cytometry (n = 20), and RNA sequencing (n = 20). Biological changes related to CD8+TILs exhaustion at different cytotoxic T lymphocyte (CTL) levels (mean expression levels of CD8A, CD8B, GZMA, GZMB, and PRF1) in AITL were evaluated using RNA sequencing (n = 20) and further validated using the GEO dataset (n = 51). The impact of CD8 protein expression and CTL levels on patient prognosis was analyzed using flow cytometry and RNA sequencing, respectively. Results Our findings demonstrated that the higher the infiltration of CD8+TILs, the higher was the proportion of exhausted CD8+TILs characterized by the overexpression of multiple IC. This was accompanied by extensive exhaustion-related biological changes, which suggested severe exhaustion in CD8+TILs and may be one of the main reasons for the poor prognosis of patients with high CD8+TILs and CTL. Conclusion Our study comprehensively reveals the exhaustion status of CD8+TILs and their potential negative impact on AITL prognosis, which facilitates further mechanistic studies and is valuable for guiding immunotherapy strategies.",Yiming Yang_35729970.json,
"What journal was the paper ""MRI Features for Predicting Microvascular Invasion and Postoperative Recurrence in Hepatocellular Carcinoma Without Peritumoral Hypointensity"" published in?",Journal of Hepatocellular Carcinoma,Yiming Yang_35729970.json,
"What venue was the paper ""MRI Features for Predicting Microvascular Invasion and Postoperative Recurrence in Hepatocellular Carcinoma Without Peritumoral Hypointensity"" published in?",Journal of Hepatocellular Carcinoma,Yiming Yang_35729970.json,
"How many citations does the paper ""MRI Features for Predicting Microvascular Invasion and Postoperative Recurrence in Hepatocellular Carcinoma Without Peritumoral Hypointensity"" have?",0,Yiming Yang_35729970.json,
"Who are the authors of the paper ""MRI Features for Predicting Microvascular Invasion and Postoperative Recurrence in Hepatocellular Carcinoma Without Peritumoral Hypointensity""?","Zhiyuan Chen, Xiaohuan Li, Yu Zhang, Yiming Yang, Yan Zhang, Dongjing Zhou, Yu Yang, Shuping Zhang, Yupin Liu",Yiming Yang_35729970.json,
"Who is the first author of the paper ""MRI Features for Predicting Microvascular Invasion and Postoperative Recurrence in Hepatocellular Carcinoma Without Peritumoral Hypointensity""?",Zhiyuan Chen,Yiming Yang_35729970.json,
"What is the paper ID of the paper ""MRI Features for Predicting Microvascular Invasion and Postoperative Recurrence in Hepatocellular Carcinoma Without Peritumoral Hypointensity""?",f1a75a847c99ab399454c911235f0d5f7854c5a4,Yiming Yang_35729970.json,
What paper has the paper ID f1a75a847c99ab399454c911235f0d5f7854c5a4?,MRI Features for Predicting Microvascular Invasion and Postoperative Recurrence in Hepatocellular Carcinoma Without Peritumoral Hypointensity,Yiming Yang_35729970.json,
What is the TLDR of the paper 'MRI Features for Predicting Microvascular Invasion and Postoperative Recurrence in Hepatocellular Carcinoma Without Peritumoral Hypointensity'?,"In patients without peritumoral HBP hypointensity, a radiological capsule is useful for identifying MVI and satellite nodule is an independent risk factor for intrahepatic RFS, and a two-step flowchart was constructed to assist in clinical decision-making.",Yiming Yang_35729970.json,
What is the abstract of the paper 'MRI Features for Predicting Microvascular Invasion and Postoperative Recurrence in Hepatocellular Carcinoma Without Peritumoral Hypointensity'?,"Purpose To identify MRI features of hepatocellular carcinoma (HCC) that predict microvascular invasion (MVI) and postoperative intrahepatic recurrence in patients without peritumoral hepatobiliary phase (HBP) hypointensity. Patients and Methods One hundred and thirty patients with HCC who underwent preoperative gadoxetate-enhanced MRI and curative hepatic resection were retrospectively reviewed. Two radiologists reviewed all preoperative MR images and assessed the radiological features of HCCs. The ability of peritumoral HBP hypointensity to identify MVI and intrahepatic recurrence was analyzed. We then assessed the MRI features of HCC that predicted the MVI and intrahepatic recurrence-free survival (RFS) in the subgroup without peritumoral HBP hypointensity. Finally, a two-step flowchart was constructed to assist in clinical decision-making. Results Peritumoral HBP hypointensity (odds ratio, 3.019; 95% confidence interval: 1.071–8.512; P=0.037) was an independent predictor of MVI. The sensitivity, specificity, positive predictive value, negative predictive value, and AUROC of peritumoral HBP hypointensity in predicting MVI were 23.80%, 91.04%, 71.23%, 55.96%, and 0.574, respectively. Intrahepatic RFS was significantly shorter in patients with peritumoral HBP hypointensity (P<0.001). In patients without peritumoral HBP hypointensity, the only significant difference between MVI-positive and MVI-negative HCCs was the presence of a radiological capsule (P=0.038). Satellite nodule was an independent risk factor for intrahepatic RFS (hazard ratio,3.324; 95% CI: 1.733–6.378; P<0.001). The high-risk HCC detection rate was significantly higher when using the two-step flowchart that incorporated peritumoral HBP hypointensity and satellite nodule than when using peritumoral HBP hypointensity alone (P<0.001). Conclusion In patients without peritumoral HBP hypointensity, a radiological capsule is useful for identifying MVI and satellite nodule is an independent risk factor for intrahepatic RFS.",Yiming Yang_35729970.json,
What is the author ID of Yiming Yang?,46286308,data/paper_jsons/Yiming Yang_46286308.json,
What are the papers of Yiming Yang?,"PESCO: Prompt-enhanced Self Contrastive Learning for Zero-shot Text Classification, Learning Performance-Improving Code Edits, Generation-driven Contrastive Self-training for Zero-shot Text Classification with Instruction-tuned GPT, Self-Refine: Iterative Refinement with Self-Feedback, Long-tailed Extreme Multi-label Text Classification by the Retrieval of Generated Pseudo Label Descriptions, Learning a Fourier Transform for Linear Relative Positional Encodings in Transformers, Efficient Temporal Sentence Grounding in Videos with Multi-Teacher Knowledge Distillation, Active Retrieval Augmented Generation, Retrieval-Enhanced Generative Model for Large-Scale Knowledge Graph Completion, Let's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning and Coding with LLMs, Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision, Policy Representation via Diffusion Probability Model for Reinforcement Learning",data/paper_jsons/Yiming Yang_46286308.json,
What is the H-index of Yiming Yang?,17,data/paper_jsons/Yiming Yang_46286308.json,
What is the author citation count of Yiming Yang?,1532,data/paper_jsons/Yiming Yang_46286308.json,
What journals has Yiming Yang published in?,"ArXiv, Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval",data/paper_jsons/Yiming Yang_46286308.json,
What are the journals and how many papers has Yiming Yang published in each?,"{'ArXiv': 8, 'Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval': 1}",data/paper_jsons/Yiming Yang_46286308.json,
What are the fields of study of Yiming Yang?,Computer Science,data/paper_jsons/Yiming Yang_46286308.json,
How many papers has Yiming Yang published in open access journals?,12,data/paper_jsons/Yiming Yang_46286308.json,
What venues has Yiming Yang published in?,"Annual Meeting of the Association for Computational Linguistics, arXiv.org, Findings, Conference on Empirical Methods in Natural Language Processing, Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",data/paper_jsons/Yiming Yang_46286308.json,
What is the most cited paper from Yiming Yang?,Self-Refine: Iterative Refinement with Self-Feedback,data/paper_jsons/Yiming Yang_46286308.json,
What is the url of the most cited paper from Yiming Yang?,http://arxiv.org/pdf/2303.17651,data/paper_jsons/Yiming Yang_46286308.json,
Who are the authors of the most cited paper from Yiming Yang?,"Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, S. Welleck, Bodhisattwa Prasad Majumder, Shashank Gupta, A. Yazdanbakhsh, Peter Clark",data/paper_jsons/Yiming Yang_46286308.json,
TLDR of the most cited paper from Yiming Yang?,"Self-Refine is introduced, an approach for improving initial outputs from LLMs through iterative feedback and refinement that demonstrates that even state-of-the-art LLMs like GPT-4 can be further improved at test time using this simple, standalone approach.",data/paper_jsons/Yiming Yang_46286308.json,
Abstract of the most cited paper from Yiming Yang?,"Like humans, large language models (LLMs) do not always generate the best output on their first try. Motivated by how humans refine their written text, we introduce Self-Refine, an approach for improving initial outputs from LLMs through iterative feedback and refinement. The main idea is to generate an initial output using an LLMs; then, the same LLMs provides feedback for its output and uses it to refine itself, iteratively. Self-Refine does not require any supervised training data, additional training, or reinforcement learning, and instead uses a single LLM as the generator, refiner, and feedback provider. We evaluate Self-Refine across 7 diverse tasks, ranging from dialog response generation to mathematical reasoning, using state-of-the-art (GPT-3.5, ChatGPT, and GPT-4) LLMs. Across all evaluated tasks, outputs generated with Self-Refine are preferred by humans and automatic metrics over those generated with the same LLM using conventional one-step generation, improving by ~20% absolute on average in task performance. Our work demonstrates that even state-of-the-art LLMs like GPT-4 can be further improved at test time using our simple, standalone approach.",data/paper_jsons/Yiming Yang_46286308.json,
"What journal was the paper ""Efficient Temporal Sentence Grounding in Videos with Multi-Teacher Knowledge Distillation"" published in?",ArXiv,Yiming Yang_46286308.json,
"What venue was the paper ""Efficient Temporal Sentence Grounding in Videos with Multi-Teacher Knowledge Distillation"" published in?",arXiv.org,Yiming Yang_46286308.json,
"How many citations does the paper ""Efficient Temporal Sentence Grounding in Videos with Multi-Teacher Knowledge Distillation"" have?",7,Yiming Yang_46286308.json,
"Who are the authors of the paper ""Efficient Temporal Sentence Grounding in Videos with Multi-Teacher Knowledge Distillation""?","Renjie Liang, Yiming Yang, Hui Lu, Li Li",Yiming Yang_46286308.json,
"Who is the first author of the paper ""Efficient Temporal Sentence Grounding in Videos with Multi-Teacher Knowledge Distillation""?",Renjie Liang,Yiming Yang_46286308.json,
"What is the paper ID of the paper ""Efficient Temporal Sentence Grounding in Videos with Multi-Teacher Knowledge Distillation""?",846f60ef3b98590c7ad1d84727c66a08cc2258c8,Yiming Yang_46286308.json,
What paper has the paper ID 846f60ef3b98590c7ad1d84727c66a08cc2258c8?,Efficient Temporal Sentence Grounding in Videos with Multi-Teacher Knowledge Distillation,Yiming Yang_46286308.json,
What is the TLDR of the paper 'Efficient Temporal Sentence Grounding in Videos with Multi-Teacher Knowledge Distillation'?,"A novel efficient multi-teacher model (EMTM) based on knowledge distillation to transfer diverse knowledge from both heterogeneous and isomorphic networks is proposed, which is both effective and efficient without bells and whistles.",Yiming Yang_46286308.json,
What is the abstract of the paper 'Efficient Temporal Sentence Grounding in Videos with Multi-Teacher Knowledge Distillation'?,"Temporal Sentence Grounding in Videos (TSGV) aims to detect the event timestamps described by the natural language query from untrimmed videos. This paper discusses the challenge of achieving efficient computation in TSGV models while maintaining high performance. Most existing approaches exquisitely design complex architectures to improve accuracy with extra layers and loss, suffering from inefficiency and heaviness. Although some works have noticed that, they only make an issue of feature fusion layers, which can hardly enjoy the highspeed merit in the whole clunky network. To tackle this problem, we propose a novel efficient multi-teacher model (EMTM) based on knowledge distillation to transfer diverse knowledge from both heterogeneous and isomorphic networks. Specifically, We first unify different outputs of the heterogeneous models into one single form. Next, a Knowledge Aggregation Unit (KAU) is built to acquire high-quality integrated soft labels from multiple teachers. After that, the KAU module leverages the multi-scale video and global query information to adaptively determine the weights of different teachers. A Shared Encoder strategy is then proposed to solve the problem that the student shallow layers hardly benefit from teachers, in which an isomorphic teacher is collaboratively trained with the student to align their hidden states. Extensive experimental results on three popular TSGV benchmarks demonstrate that our method is both effective and efficient without bells and whistles.",Yiming Yang_46286308.json,
"What journal was the paper ""Generation-driven Contrastive Self-training for Zero-shot Text Classification with Instruction-tuned GPT"" published in?",ArXiv,Yiming Yang_46286308.json,
"What venue was the paper ""Generation-driven Contrastive Self-training for Zero-shot Text Classification with Instruction-tuned GPT"" published in?",arXiv.org,Yiming Yang_46286308.json,
"How many citations does the paper ""Generation-driven Contrastive Self-training for Zero-shot Text Classification with Instruction-tuned GPT"" have?",4,Yiming Yang_46286308.json,
"Who are the authors of the paper ""Generation-driven Contrastive Self-training for Zero-shot Text Classification with Instruction-tuned GPT""?","Ruohong Zhang, Yau-Shian Wang, Yiming Yang",Yiming Yang_46286308.json,
"Who is the first author of the paper ""Generation-driven Contrastive Self-training for Zero-shot Text Classification with Instruction-tuned GPT""?",Ruohong Zhang,Yiming Yang_46286308.json,
"What is the paper ID of the paper ""Generation-driven Contrastive Self-training for Zero-shot Text Classification with Instruction-tuned GPT""?",1804dc14b1cf7bbae96bf3215997e9f14425d622,Yiming Yang_46286308.json,
What paper has the paper ID 1804dc14b1cf7bbae96bf3215997e9f14425d622?,Generation-driven Contrastive Self-training for Zero-shot Text Classification with Instruction-tuned GPT,Yiming Yang_46286308.json,
What is the TLDR of the paper 'Generation-driven Contrastive Self-training for Zero-shot Text Classification with Instruction-tuned GPT'?,"This work proposes a new approach to zero-shot text classification, namely \ourmodelshort, which leverages the strong generative power of GPT to assist in training a smaller, more adaptable, and efficient sentence encoder classifier with contrastive self-training.",Yiming Yang_46286308.json,
What is the abstract of the paper 'Generation-driven Contrastive Self-training for Zero-shot Text Classification with Instruction-tuned GPT'?,"Moreover, GPT-based zero-shot classification models tend to make independent predictions over test instances, which can be sub-optimal as the instance correlations and the decision boundaries in the target space are ignored. To address these difficulties and limitations, we propose a new approach to zero-shot text classification, namely \ourmodelshort, which leverages the strong generative power of GPT to assist in training a smaller, more adaptable, and efficient sentence encoder classifier with contrastive self-training. Specifically, GenCo applies GPT in two ways: firstly, it generates multiple augmented texts for each input instance to enhance the semantic embedding of the instance and improve the mapping to relevant labels; secondly, it generates augmented texts conditioned on the predicted label during self-training, which makes the generative process tailored to the decision boundaries in the target space. In our experiments, GenCo outperforms previous state-of-the-art methods on multiple benchmark datasets, even when only limited in-domain text data is available.",Yiming Yang_46286308.json,
"What journal was the paper ""Long-tailed Extreme Multi-label Text Classification by the Retrieval of Generated Pseudo Label Descriptions"" published in?",,Yiming Yang_46286308.json,
"What venue was the paper ""Long-tailed Extreme Multi-label Text Classification by the Retrieval of Generated Pseudo Label Descriptions"" published in?",Findings,Yiming Yang_46286308.json,
"How many citations does the paper ""Long-tailed Extreme Multi-label Text Classification by the Retrieval of Generated Pseudo Label Descriptions"" have?",2,Yiming Yang_46286308.json,
"Who are the authors of the paper ""Long-tailed Extreme Multi-label Text Classification by the Retrieval of Generated Pseudo Label Descriptions""?","Ruohong Zhang, Yau-Shian Wang, Yiming Yang, Donghan Yu, Tom Vu, Li Lei",Yiming Yang_46286308.json,
"Who is the first author of the paper ""Long-tailed Extreme Multi-label Text Classification by the Retrieval of Generated Pseudo Label Descriptions""?",Ruohong Zhang,Yiming Yang_46286308.json,
"What is the paper ID of the paper ""Long-tailed Extreme Multi-label Text Classification by the Retrieval of Generated Pseudo Label Descriptions""?",3c92fd24ea2a49aeba4b368abe3ef13cbce40987,Yiming Yang_46286308.json,
What paper has the paper ID 3c92fd24ea2a49aeba4b368abe3ef13cbce40987?,Long-tailed Extreme Multi-label Text Classification by the Retrieval of Generated Pseudo Label Descriptions,Yiming Yang_46286308.json,
What is the TLDR of the paper 'Long-tailed Extreme Multi-label Text Classification by the Retrieval of Generated Pseudo Label Descriptions'?,"This paper addresses the challenge of tail label prediction by leveraging the power of dense neural retrieval model in mapping input documents to relevant label descriptions and generates pseudo label descriptions from a trained bag-of-words (BoW) classifier, which demonstrates better classification performance under severe scarce data conditions.",Yiming Yang_46286308.json,
What is the abstract of the paper 'Long-tailed Extreme Multi-label Text Classification by the Retrieval of Generated Pseudo Label Descriptions'?,"Extreme Multi-label Text Classification (XMTC) has been a tough challenge in machine learning research and applications due to the sheer sizes of the label spaces and the severe data scarcity problem associated with the long tail of rare labels in highly skewed distributions. This paper addresses the challenge of tail label prediction by leveraging the power of dense neural retrieval model in mapping input documents (as queries) to relevant label descriptions. To further enhance the quality of label descriptions, we propose to generate pseudo label descriptions from a trained bag-of-words (BoW) classifier, which demonstrates better classification performance under severe scarce data conditions.The proposed approach achieves the state-of-the-art (SOTA) performance of overall label prediction on XMTC benchmark datasets and especially outperforms the SOTA models in the tail label prediction. We also provide a theoretical analysis for relating the BoW and neural models w.r.t. performance lower bound.",Yiming Yang_46286308.json,
What is the author ID of Yonatan Bisk?,3312309,data/paper_jsons/Yonatan Bisk_3312309.json,
What are the papers of Yonatan Bisk?,"SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs, HomeRobot: Open-Vocabulary Mobile Manipulation, Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents, MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception, Reasoning about the Unseen for Efficient Outdoor Object Navigation, The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment, WebArena: A Realistic Web Environment for Building Autonomous Agents, Computational Language Acquisition with Theory of Mind",data/paper_jsons/Yonatan Bisk_3312309.json,
What is the H-index of Yonatan Bisk?,33,data/paper_jsons/Yonatan Bisk_3312309.json,
What is the author citation count of Yonatan Bisk?,7048,data/paper_jsons/Yonatan Bisk_3312309.json,
What journals has Yonatan Bisk published in?,ArXiv,data/paper_jsons/Yonatan Bisk_3312309.json,
What are the journals and how many papers has Yonatan Bisk published in each?,{'ArXiv': 8},data/paper_jsons/Yonatan Bisk_3312309.json,
What are the fields of study of Yonatan Bisk?,Computer Science,data/paper_jsons/Yonatan Bisk_3312309.json,
How many papers has Yonatan Bisk published in open access journals?,8,data/paper_jsons/Yonatan Bisk_3312309.json,
What venues has Yonatan Bisk published in?,"arXiv.org, Conference on Robot Learning, Conference on Empirical Methods in Natural Language Processing, International Conference on Learning Representations",data/paper_jsons/Yonatan Bisk_3312309.json,
What is the most cited paper from Yonatan Bisk?,WebArena: A Realistic Web Environment for Building Autonomous Agents,data/paper_jsons/Yonatan Bisk_3312309.json,
What is the url of the most cited paper from Yonatan Bisk?,https://arxiv.org/pdf/2307.13854,data/paper_jsons/Yonatan Bisk_3312309.json,
Who are the authors of the most cited paper from Yonatan Bisk?,"Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, Graham Neubig",data/paper_jsons/Yonatan Bisk_3312309.json,
TLDR of the most cited paper from Yonatan Bisk?,"This paper builds an environment for language-guided agents that is highly realistic and reproducible, and creates an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management.",data/paper_jsons/Yonatan Bisk_3312309.json,
Abstract of the most cited paper from Yonatan Bisk?,"With advances in generative AI, there is now potential for autonomous agents to manage daily tasks via natural language commands. However, current agents are primarily created and tested in simplified synthetic environments, leading to a disconnect with real-world scenarios. In this paper, we build an environment for language-guided agents that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on the web, and create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our environment is enriched with tools (e.g., a map) and external knowledge bases (e.g., user manuals) to encourage human-like task-solving. Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and designed to emulate tasks that humans routinely perform on the internet. We experiment with several baseline agents, integrating recent techniques such as reasoning before acting. The results demonstrate that solving complex tasks is challenging: our best GPT-4-based agent only achieves an end-to-end task success rate of 14.41%, significantly lower than the human performance of 78.24%. These results highlight the need for further development of robust agents, that current state-of-the-art large language models are far from perfect performance in these real-life tasks, and that WebArena can be used to measure such progress.",data/paper_jsons/Yonatan Bisk_3312309.json,
"What journal was the paper ""Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents"" published in?",ArXiv,Yonatan Bisk_3312309.json,
"What venue was the paper ""Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents"" published in?",arXiv.org,Yonatan Bisk_3312309.json,
"How many citations does the paper ""Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents"" have?",16,Yonatan Bisk_3312309.json,
"Who are the authors of the paper ""Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents""?","Yue Wu, So Yeon Min, Yonatan Bisk, R. Salakhutdinov, A. Azaria, Yuan-Fang Li, Tom M. Mitchell, Shrimai Prabhumoye",Yonatan Bisk_3312309.json,
"Who is the first author of the paper ""Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents""?",Yue Wu,Yonatan Bisk_3312309.json,
"What is the paper ID of the paper ""Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents""?",5ce2f1dff23a5620f77f9b11f1e534422ab8ff3f,Yonatan Bisk_3312309.json,
What paper has the paper ID 5ce2f1dff23a5620f77f9b11f1e534422ab8ff3f?,"Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents",Yonatan Bisk_3312309.json,
"What is the TLDR of the paper 'Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents'?","A framework to use the knowledge in LLMs to simplify the control problem, rather than solving it is proposed, which leads to a significant 15% improvement over SOTA for generalization to human goal specifications.",Yonatan Bisk_3312309.json,
"What is the abstract of the paper 'Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents'?","Pre-trained large language models (LLMs) capture procedural knowledge about the world. Recent work has leveraged LLM's ability to generate abstract plans to simplify challenging control tasks, either by action scoring, or action modeling (fine-tuning). However, the transformer architecture inherits several constraints that make it difficult for the LLM to directly serve as the agent: e.g. limited input lengths, fine-tuning inefficiency, bias from pre-training, and incompatibility with non-text environments. To maintain compatibility with a low-level trainable actor, we propose to instead use the knowledge in LLMs to simplify the control problem, rather than solving it. We propose the Plan, Eliminate, and Track (PET) framework. The Plan module translates a task description into a list of high-level sub-tasks. The Eliminate module masks out irrelevant objects and receptacles from the observation for the current sub-task. Finally, the Track module determines whether the agent has accomplished each sub-task. On the AlfWorld instruction following benchmark, the PET framework leads to a significant 15% improvement over SOTA for generalization to human goal specifications.",Yonatan Bisk_3312309.json,
"What journal was the paper ""HomeRobot: Open-Vocabulary Mobile Manipulation"" published in?",ArXiv,Yonatan Bisk_3312309.json,
"What venue was the paper ""HomeRobot: Open-Vocabulary Mobile Manipulation"" published in?",Conference on Robot Learning,Yonatan Bisk_3312309.json,
"How many citations does the paper ""HomeRobot: Open-Vocabulary Mobile Manipulation"" have?",16,Yonatan Bisk_3312309.json,
"Who are the authors of the paper ""HomeRobot: Open-Vocabulary Mobile Manipulation""?","Sriram Yenamandra, A. Ramachandran, Karmesh Yadav, Austin S. Wang, Mukul Khanna, Théophile Gervet, Tsung-Yen Yang, Vidhi Jain, Alexander Clegg, John Turner, Z. Kira, M. Savva, Angel X. Chang, Devendra Singh Chaplot, Dhruv Batra, Roozbeh Mottaghi, Yonatan Bisk, Chris Paxton",Yonatan Bisk_3312309.json,
"Who is the first author of the paper ""HomeRobot: Open-Vocabulary Mobile Manipulation""?",Sriram Yenamandra,Yonatan Bisk_3312309.json,
"What is the paper ID of the paper ""HomeRobot: Open-Vocabulary Mobile Manipulation""?",3b0c02955e88f5862e61b560c7f70ba8cf235b1d,Yonatan Bisk_3312309.json,
What paper has the paper ID 3b0c02955e88f5862e61b560c7f70ba8cf235b1d?,HomeRobot: Open-Vocabulary Mobile Manipulation,Yonatan Bisk_3312309.json,
What is the TLDR of the paper 'HomeRobot: Open-Vocabulary Mobile Manipulation'?,"The HomeRobot OVMM benchmark is introduced, where an agent navigates household environments to grasp novel objects and place them on target receptacles, and baselines achieve a 20% success rate in the real world; the experiments identify ways future research work improve performance.",Yonatan Bisk_3312309.json,
What is the abstract of the paper 'HomeRobot: Open-Vocabulary Mobile Manipulation'?,"HomeRobot (noun): An affordable compliant robot that navigates homes and manipulates a wide range of objects in order to complete everyday tasks. Open-Vocabulary Mobile Manipulation (OVMM) is the problem of picking any object in any unseen environment, and placing it in a commanded location. This is a foundational challenge for robots to be useful assistants in human environments, because it involves tackling sub-problems from across robotics: perception, language understanding, navigation, and manipulation are all essential to OVMM. In addition, integration of the solutions to these sub-problems poses its own substantial challenges. To drive research in this area, we introduce the HomeRobot OVMM benchmark, where an agent navigates household environments to grasp novel objects and place them on target receptacles. HomeRobot has two components: a simulation component, which uses a large and diverse curated object set in new, high-quality multi-room home environments; and a real-world component, providing a software stack for the low-cost Hello Robot Stretch to encourage replication of real-world experiments across labs. We implement both reinforcement learning and heuristic (model-based) baselines and show evidence of sim-to-real transfer. Our baselines achieve a 20% success rate in the real world; our experiments identify ways future research work improve performance. See videos on our website: https://ovmm.github.io/.",Yonatan Bisk_3312309.json,
"What journal was the paper ""SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs"" published in?",ArXiv,Yonatan Bisk_3312309.json,
"What venue was the paper ""SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs"" published in?",arXiv.org,Yonatan Bisk_3312309.json,
"How many citations does the paper ""SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs"" have?",9,Yonatan Bisk_3312309.json,
"Who are the authors of the paper ""SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs""?","Lijun Yu, Yong Cheng, Zhiruo Wang, Vivek Kumar, Wolfgang Macherey, Yanping Huang, David A. Ross, Irfan Essa, Yonatan Bisk, Ming Yang, K. Murphy, A. Hauptmann, Lu Jiang",Yonatan Bisk_3312309.json,
"Who is the first author of the paper ""SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs""?",Lijun Yu,Yonatan Bisk_3312309.json,
"What is the paper ID of the paper ""SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs""?",376f494126d1ea4f571ea0263c43ac2b6331800a,Yonatan Bisk_3312309.json,
What paper has the paper ID 376f494126d1ea4f571ea0263c43ac2b6331800a?,SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs,Yonatan Bisk_3312309.json,
What is the TLDR of the paper 'SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs'?,"This method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.",Yonatan Bisk_3312309.json,
What is the abstract of the paper 'SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs'?,"In this work, we introduce Semantic Pyramid AutoEncoder (SPAE) for enabling frozen LLMs to perform both understanding and generation tasks involving non-linguistic modalities such as images or videos. SPAE converts between raw pixels and interpretable lexical tokens (or words) extracted from the LLM's vocabulary. The resulting tokens capture both the semantic meaning and the fine-grained details needed for visual reconstruction, effectively translating the visual content into a language comprehensible to the LLM, and empowering it to perform a wide array of multimodal tasks. Our approach is validated through in-context learning experiments with frozen PaLM 2 and GPT 3.5 on a diverse set of image understanding and generation tasks. Our method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.",Yonatan Bisk_3312309.json,
What is the author ID of Yulia Tsvetkov?,145317727,data/paper_jsons/Yulia Tsvetkov_145317727.json,
What are the papers of Yulia Tsvetkov?,Understanding Ethics in NLP Authoring and Reviewing,data/paper_jsons/Yulia Tsvetkov_145317727.json,
What is the H-index of Yulia Tsvetkov?,33,data/paper_jsons/Yulia Tsvetkov_145317727.json,
What is the author citation count of Yulia Tsvetkov?,4659,data/paper_jsons/Yulia Tsvetkov_145317727.json,
What journals has Yulia Tsvetkov published in?,Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics: Tutorial Abstracts,data/paper_jsons/Yulia Tsvetkov_145317727.json,
What are the journals and how many papers has Yulia Tsvetkov published in each?,{'Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics: Tutorial Abstracts': 1},data/paper_jsons/Yulia Tsvetkov_145317727.json,
What are the fields of study of Yulia Tsvetkov?,,data/paper_jsons/Yulia Tsvetkov_145317727.json,
How many papers has Yulia Tsvetkov published in open access journals?,1,data/paper_jsons/Yulia Tsvetkov_145317727.json,
What venues has Yulia Tsvetkov published in?,Conference of the European Chapter of the Association for Computational Linguistics,data/paper_jsons/Yulia Tsvetkov_145317727.json,
What is the most cited paper from Yulia Tsvetkov?,Understanding Ethics in NLP Authoring and Reviewing,data/paper_jsons/Yulia Tsvetkov_145317727.json,
What is the url of the most cited paper from Yulia Tsvetkov?,https://aclanthology.org/2023.eacl-tutorials.4.pdf,data/paper_jsons/Yulia Tsvetkov_145317727.json,
Who are the authors of the most cited paper from Yulia Tsvetkov?,"Luciana Benotti, Karën Fort, Min-Yen Kan, Yulia Tsvetkov",data/paper_jsons/Yulia Tsvetkov_145317727.json,
TLDR of the most cited paper from Yulia Tsvetkov?,This tutorial will equip participants with basic guidelines for thinking deeply about ethical issues and review common considerations that recur in NLP research.,data/paper_jsons/Yulia Tsvetkov_145317727.json,
Abstract of the most cited paper from Yulia Tsvetkov?,"With NLP research now quickly being transferred into real-world applications, it is important to be aware of and think through the consequences of our scientific investigation. Such ethical considerations are important in both authoring and reviewing. This tutorial will equip participants with basic guidelines for thinking deeply about ethical issues and review common considerations that recur in NLP research. The methodology is interactive and participatory, including case studies and working in groups. Importantly, the participants will be co-building the tutorial outcomes and will be working to create further tutorial materials to share as public outcomes.",data/paper_jsons/Yulia Tsvetkov_145317727.json,
"What journal was the paper ""Understanding Ethics in NLP Authoring and Reviewing"" published in?",Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics: Tutorial Abstracts,Yulia Tsvetkov_145317727.json,
"What venue was the paper ""Understanding Ethics in NLP Authoring and Reviewing"" published in?",Conference of the European Chapter of the Association for Computational Linguistics,Yulia Tsvetkov_145317727.json,
"How many citations does the paper ""Understanding Ethics in NLP Authoring and Reviewing"" have?",0,Yulia Tsvetkov_145317727.json,
"Who are the authors of the paper ""Understanding Ethics in NLP Authoring and Reviewing""?","Luciana Benotti, Karën Fort, Min-Yen Kan, Yulia Tsvetkov",Yulia Tsvetkov_145317727.json,
"Who is the first author of the paper ""Understanding Ethics in NLP Authoring and Reviewing""?",Luciana Benotti,Yulia Tsvetkov_145317727.json,
"What is the paper ID of the paper ""Understanding Ethics in NLP Authoring and Reviewing""?",12902f724619344dfeae330043c4b7b1c9d99bd0,Yulia Tsvetkov_145317727.json,
What paper has the paper ID 12902f724619344dfeae330043c4b7b1c9d99bd0?,Understanding Ethics in NLP Authoring and Reviewing,Yulia Tsvetkov_145317727.json,
What is the TLDR of the paper 'Understanding Ethics in NLP Authoring and Reviewing'?,This tutorial will equip participants with basic guidelines for thinking deeply about ethical issues and review common considerations that recur in NLP research.,Yulia Tsvetkov_145317727.json,
What is the abstract of the paper 'Understanding Ethics in NLP Authoring and Reviewing'?,"With NLP research now quickly being transferred into real-world applications, it is important to be aware of and think through the consequences of our scientific investigation. Such ethical considerations are important in both authoring and reviewing. This tutorial will equip participants with basic guidelines for thinking deeply about ethical issues and review common considerations that recur in NLP research. The methodology is interactive and participatory, including case studies and working in groups. Importantly, the participants will be co-building the tutorial outcomes and will be working to create further tutorial materials to share as public outcomes.",Yulia Tsvetkov_145317727.json,
What is the author ID of Yulia Tsvetkov?,2073587169,data/paper_jsons/Yulia Tsvetkov_2073587169.json,
What are the papers of Yulia Tsvetkov?,"GlobalBench: A Benchmark for Global Progress in Natural Language Processing, Do All Languages Cost the Same? Tokenization in the Era of Commercial Language Models, BotPercent: Estimating Twitter Bot Populations from Groups to Crowds, Examining risks of racial biases in NLP tools for child protective services, Understanding In-Context Learning via Supportive Pretraining Data, Assessing Language Model Deployment with Risk Cards, From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models, FactKB: Generalizable Factuality Evaluation using Language Models Enhanced with Factual Knowledge, TalkUp: Paving the Way for Understanding Empowering Language, Trusting Your Evidence: Hallucinate Less with Context-aware Decoding, BUFFET: Benchmarking Large Language Models for Few-shot Cross-lingual Transfer, Mitigating Societal Harms in Large Language Models, Minding Language Models’ (Lack of) Theory of Mind: A Plug-and-Play Multi-Character Belief Tracker, Can Language Models Solve Graph Problems in Natural Language?, LEXPLAIN: Improving Model Explanations via Lexicon Supervision",data/paper_jsons/Yulia Tsvetkov_2073587169.json,
What is the H-index of Yulia Tsvetkov?,17,data/paper_jsons/Yulia Tsvetkov_2073587169.json,
What is the author citation count of Yulia Tsvetkov?,1382,data/paper_jsons/Yulia Tsvetkov_2073587169.json,
What journals has Yulia Tsvetkov published in?,"ArXiv, Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency, Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts",data/paper_jsons/Yulia Tsvetkov_2073587169.json,
What are the journals and how many papers has Yulia Tsvetkov published in each?,"{'ArXiv': 8, 'Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency': 1, 'Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts': 1}",data/paper_jsons/Yulia Tsvetkov_2073587169.json,
What are the fields of study of Yulia Tsvetkov?,Computer Science,data/paper_jsons/Yulia Tsvetkov_2073587169.json,
How many papers has Yulia Tsvetkov published in open access journals?,15,data/paper_jsons/Yulia Tsvetkov_2073587169.json,
What venues has Yulia Tsvetkov published in?,"Conference on Empirical Methods in Natural Language Processing, arXiv.org, Conference on Fairness, Accountability and Transparency, Annual Meeting of the Association for Computational Linguistics, Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts, STARSEM",data/paper_jsons/Yulia Tsvetkov_2073587169.json,
What is the most cited paper from Yulia Tsvetkov?,From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models,data/paper_jsons/Yulia Tsvetkov_2073587169.json,
What is the url of the most cited paper from Yulia Tsvetkov?,https://arxiv.org/pdf/2305.08283,data/paper_jsons/Yulia Tsvetkov_2073587169.json,
Who are the authors of the most cited paper from Yulia Tsvetkov?,"Shangbin Feng, Chan Young Park, Yuhan Liu, Yulia Tsvetkov",data/paper_jsons/Yulia Tsvetkov_2073587169.json,
TLDR of the most cited paper from Yulia Tsvetkov?,"The findings reveal that pretrained LMs do have political leanings which reinforce the polarization present in pretraining corpora, propagating social biases into hate speech predictions and media biases into misinformation detectors.",data/paper_jsons/Yulia Tsvetkov_2073587169.json,
Abstract of the most cited paper from Yulia Tsvetkov?,"Language models (LMs) are pretrained on diverse data sources—news, discussion forums, books, online encyclopedias. A significant portion of this data includes facts and opinions which, on one hand, celebrate democracy and diversity of ideas, and on the other hand are inherently socially biased. Our work develops new methods to (1) measure media biases in LMs trained on such corpora, along social and economic axes, and (2) measure the fairness of downstream NLP models trained on top of politically biased LMs. We focus on hate speech and misinformation detection, aiming to empirically quantify the effects of political (social, economic) biases in pretraining data on the fairness of high-stakes social-oriented tasks. Our findings reveal that pretrained LMs do have political leanings which reinforce the polarization present in pretraining corpora, propagating social biases into hate speech predictions and media biases into misinformation detectors. We discuss the implications of our findings for NLP research and propose future directions to mitigate unfairness.",data/paper_jsons/Yulia Tsvetkov_2073587169.json,
"What journal was the paper ""GlobalBench: A Benchmark for Global Progress in Natural Language Processing"" published in?",,Yulia Tsvetkov_2073587169.json,
"What venue was the paper ""GlobalBench: A Benchmark for Global Progress in Natural Language Processing"" published in?",Conference on Empirical Methods in Natural Language Processing,Yulia Tsvetkov_2073587169.json,
"How many citations does the paper ""GlobalBench: A Benchmark for Global Progress in Natural Language Processing"" have?",1,Yulia Tsvetkov_2073587169.json,
"Who are the authors of the paper ""GlobalBench: A Benchmark for Global Progress in Natural Language Processing""?","Yueqi Song, Catherine Cui, Simran Khanuja, Pengfei Liu, FAHIM FAISAL, Alissa Ostapenko, Genta Indra Winata, Alham Fikri Aji, Samuel Cahyawijaya, Yulia Tsvetkov, Antonios Anastasopoulos, Graham Neubig",Yulia Tsvetkov_2073587169.json,
"Who is the first author of the paper ""GlobalBench: A Benchmark for Global Progress in Natural Language Processing""?",Yueqi Song,Yulia Tsvetkov_2073587169.json,
"What is the paper ID of the paper ""GlobalBench: A Benchmark for Global Progress in Natural Language Processing""?",17605c43ca3eb982c99642052ddc21a93d116594,Yulia Tsvetkov_2073587169.json,
What paper has the paper ID 17605c43ca3eb982c99642052ddc21a93d116594?,GlobalBench: A Benchmark for Global Progress in Natural Language Processing,Yulia Tsvetkov_2073587169.json,
What is the TLDR of the paper 'GlobalBench: A Benchmark for Global Progress in Natural Language Processing'?,"This work introduces GlobalBench, an ever-expanding collection that aims to dynamically track progress on all NLP datasets in all languages and tracks the estimated per-speaker utility and equity of technology across all languages, providing a multi-faceted view of how language technology is serving people of the world.",Yulia Tsvetkov_2073587169.json,
What is the abstract of the paper 'GlobalBench: A Benchmark for Global Progress in Natural Language Processing'?,"Despite the major advances in NLP, significant disparities in NLP system performance across languages still exist. Arguably, these are due to uneven resource allocation and sub-optimal incentives to work on less resourced languages. To track and further incentivize the global development of equitable language technology, we introduce GlobalBench. Prior multilingual benchmarks are static and have focused on a limited number of tasks and languages. In contrast, GlobalBench is an ever-expanding collection that aims to dynamically track progress on all NLP datasets in all languages. Rather than solely measuring accuracy, GlobalBench also tracks the estimated per-speaker utility and equity of technology across all languages, providing a multi-faceted view of how language technology is serving people of the world. Furthermore, GlobalBench is designed to identify the most under-served languages, and rewards research efforts directed towards those languages. At present, the most under-served languages are the ones with a relatively high population, but nonetheless overlooked by composite multilingual benchmarks (like Punjabi, Portuguese, and Wu Chinese). Currently, GlobalBench covers 966 datasets in 190 languages, and has 1,128 system submissions spanning 62 languages.",Yulia Tsvetkov_2073587169.json,
"What journal was the paper ""Can Language Models Solve Graph Problems in Natural Language?"" published in?",ArXiv,Yulia Tsvetkov_2073587169.json,
"What venue was the paper ""Can Language Models Solve Graph Problems in Natural Language?"" published in?",arXiv.org,Yulia Tsvetkov_2073587169.json,
"How many citations does the paper ""Can Language Models Solve Graph Problems in Natural Language?"" have?",46,Yulia Tsvetkov_2073587169.json,
"Who are the authors of the paper ""Can Language Models Solve Graph Problems in Natural Language?""?","Heng Wang, Shangbin Feng, Tianxing He, Zhaoxuan Tan, Xiaochuang Han, Yulia Tsvetkov",Yulia Tsvetkov_2073587169.json,
"Who is the first author of the paper ""Can Language Models Solve Graph Problems in Natural Language?""?",Heng Wang,Yulia Tsvetkov_2073587169.json,
"What is the paper ID of the paper ""Can Language Models Solve Graph Problems in Natural Language?""?",df2beaae63e4d68ef8e762bcd4704c9f11f856d9,Yulia Tsvetkov_2073587169.json,
What paper has the paper ID df2beaae63e4d68ef8e762bcd4704c9f11f856d9?,Can Language Models Solve Graph Problems in Natural Language?,Yulia Tsvetkov_2073587169.json,
What is the TLDR of the paper 'Can Language Models Solve Graph Problems in Natural Language?'?,"This work evaluates LLMs (GPT-3/4) with various prompting approaches on the NLGraph benchmark and finds that language models do demonstrate preliminary graph reasoning abilities, but the benefit of advanced prompting and in-context learning diminishes on more complex graph problems, while LLMs are also (un)surprisingly brittle in the face of spurious correlations in graph and problem settings.",Yulia Tsvetkov_2073587169.json,
What is the abstract of the paper 'Can Language Models Solve Graph Problems in Natural Language?'?,"Large language models (LLMs) are increasingly adopted for a variety of tasks with implicit graphical structures, such as planning in robotics, multi-hop question answering or knowledge probing, structured commonsense reasoning, and more. While LLMs have advanced the state-of-the-art on these tasks with structure implications, whether LLMs could explicitly process textual descriptions of graphs and structures, map them to grounded conceptual spaces, and perform structured operations remains underexplored. To this end, we propose NLGraph (Natural Language Graph), a comprehensive benchmark of graph-based problem solving designed in natural language. NLGraph contains 29,370 problems, covering eight graph reasoning tasks with varying complexity from simple tasks such as connectivity and shortest path up to complex problems such as maximum flow and simulating graph neural networks. We evaluate LLMs (GPT-3/4) with various prompting approaches on the NLGraph benchmark and find that 1) language models do demonstrate preliminary graph reasoning abilities, 2) the benefit of advanced prompting and in-context learning diminishes on more complex graph problems, while 3) LLMs are also (un)surprisingly brittle in the face of spurious correlations in graph and problem settings. We then propose Build-a-Graph Prompting and Algorithmic Prompting, two instruction-based approaches to enhance LLMs in solving natural language graph problems. Build-a-Graph and Algorithmic prompting improve the performance of LLMs on NLGraph by 3.07% to 16.85% across multiple tasks and settings, while how to solve the most complicated graph reasoning tasks in our setup with language models remains an open research question. The NLGraph benchmark and evaluation code are available at https://github.com/Arthur-Heng/NLGraph.",Yulia Tsvetkov_2073587169.json,
"What journal was the paper ""Minding Language Models’ (Lack of) Theory of Mind: A Plug-and-Play Multi-Character Belief Tracker"" published in?",,Yulia Tsvetkov_2073587169.json,
"What venue was the paper ""Minding Language Models’ (Lack of) Theory of Mind: A Plug-and-Play Multi-Character Belief Tracker"" published in?",Annual Meeting of the Association for Computational Linguistics,Yulia Tsvetkov_2073587169.json,
"How many citations does the paper ""Minding Language Models’ (Lack of) Theory of Mind: A Plug-and-Play Multi-Character Belief Tracker"" have?",22,Yulia Tsvetkov_2073587169.json,
"Who are the authors of the paper ""Minding Language Models’ (Lack of) Theory of Mind: A Plug-and-Play Multi-Character Belief Tracker""?","Melanie Sclar, Sachin Kumar, Peter West, Alane Suhr, Yejin Choi, Yulia Tsvetkov",Yulia Tsvetkov_2073587169.json,
"Who is the first author of the paper ""Minding Language Models’ (Lack of) Theory of Mind: A Plug-and-Play Multi-Character Belief Tracker""?",Melanie Sclar,Yulia Tsvetkov_2073587169.json,
"What is the paper ID of the paper ""Minding Language Models’ (Lack of) Theory of Mind: A Plug-and-Play Multi-Character Belief Tracker""?",d7a3f5c612930a3c08f1632b88934252edc66d67,Yulia Tsvetkov_2073587169.json,
What paper has the paper ID d7a3f5c612930a3c08f1632b88934252edc66d67?,Minding Language Models’ (Lack of) Theory of Mind: A Plug-and-Play Multi-Character Belief Tracker,Yulia Tsvetkov_2073587169.json,
What is the TLDR of the paper 'Minding Language Models’ (Lack of) Theory of Mind: A Plug-and-Play Multi-Character Belief Tracker'?,"SymbolicToM is presented, a plug-and-play approach to reason about the belief states of multiple characters in reading comprehension tasks via explicit symbolic representation that dramatically enhances off-the-shelf neural networks’ theory of mind in a zero-shot setting while showing robust out-of-distribution performance compared to supervised baselines.",Yulia Tsvetkov_2073587169.json,
What is the abstract of the paper 'Minding Language Models’ (Lack of) Theory of Mind: A Plug-and-Play Multi-Character Belief Tracker'?,"Theory of Mind (ToM)—the ability to reason about the mental states of other people—is a key element of our social intelligence. Yet, despite their ever more impressive performance, large-scale neural language models still lack basic theory of mind capabilities out-of-the-box. We posit that simply scaling up models will not imbue them with theory of mind due to the inherently symbolic and implicit nature of the phenomenon, and instead investigate an alternative: can we design a decoding-time algorithm that enhances theory of mind of off-the-shelf neural language models without explicit supervision? We present SymbolicToM, a plug-and-play approach to reason about the belief states of multiple characters in reading comprehension tasks via explicit symbolic representation. More concretely, our approach tracks each entity’s beliefs, their estimation of other entities’ beliefs, and higher-order levels of reasoning, all through graphical representations, allowing for more precise and interpretable reasoning than previous approaches. Empirical results on the well-known ToMi benchmark (Le et al., 2019) demonstrate that SymbolicToM dramatically enhances off-the-shelf neural networks’ theory of mind in a zero-shot setting while showing robust out-of-distribution performance compared to supervised baselines. Our work also reveals spurious patterns in existing theory of mind benchmarks, emphasizing the importance of out-of-distribution evaluation and methods that do not overfit a particular dataset.",Yulia Tsvetkov_2073587169.json,
