
 ## PROFNAME
 Taylor Berg-Kirkpatrick
 ## AUTHORID
 1400419309
 ## AUTHORNAME
 Taylor Berg-Kirkpatrick
 ## AUTHORURL
 https://www.semanticscholar.org/author/1400419309
 ## AUTHORHINDEX
 36
 ## AUTHORAFFILIATIONS
 []
 ## AUTHORPAPERCOUNT
 112
 ## AUTHORCITATIONCOUNT
 5655
 ## PAPERID
 1527d3b661154ff7310fa2759b6dd0ddfd559492
 ## EXTERNALIDS
 {'ArXiv': '2305.09859', 'DBLP': 'journals/corr/abs-2305-09859', 'DOI': '10.48550/arXiv.2305.09859', 'CorpusId': 258740888}
 ## URL
 https://www.semanticscholar.org/paper/1527d3b661154ff7310fa2759b6dd0ddfd559492
 ## TITLE
 Smaller Language Models are Better Black-box Machine-Generated Text Detectors
 ## ABSTRACT
 With the advent of fluent generative language models that can produce convincing utterances very similar to those written by humans, distinguishing whether a piece of text is machine-generated or human-written becomes more challenging and more important, as such models could be used to spread misinformation, fake news, fake reviews and to mimic certain authors and figures. To this end, there have been a slew of methods proposed to detect machine-generated text. Most of these methods need access to the logits of the target model or need the ability to sample from the target. One such black-box detection method relies on the observation that generated text is locally optimal under the likelihood function of the generator, while human-written text is not. We find that overall, smaller and partially-trained models are better universal text detectors: they can more precisely detect text generated from both small and larger models. Interestingly, we find that whether the detector and generator were trained on the same data is not critically important to the detection success. For instance the OPT-125M model has an AUC of 0.81 in detecting ChatGPT generations, whereas a larger model from the GPT family, GPTJ-6B, has AUC of 0.45.
 ## VENUE
 arXiv.org
 ## YEAR
 2023
 ## REFERENCECOUNT
 38
 ## CITATIONCOUNT
 23
 ## INFLUENTIALCITATIONCOUNT
 1
 ## ISOPENACCESS
 True
 ## OPENACCESSPDF
 {'url': 'http://arxiv.org/pdf/2305.09859', 'status': None}
 ## FIELDSOFSTUDY
 ['Computer Science']
 ## JOURNAL
 {'volume': 'abs/2305.09859', 'name': 'ArXiv'}
 ## AUTHORS
 [{'authorId': '2115471757', 'name': 'Fatemehsadat Mireshghallah'}, {'authorId': '2138547910', 'name': 'Justus Mattern'}, {'authorId': '39219411', 'name': 'Sicun Gao'}, {'authorId': '2520493', 'name': 'R. Shokri'}, {'authorId': '1400419309', 'name': 'Taylor Berg-Kirkpatrick'}]
 ## TLDR
 Overall, smaller and partially-trained models are better universal text detectors: they can more precisely detect text generated from both small and larger models.
 Smaller Language Models are Better
Black-box Machine-Generated Text Detectors
Fatemehsadat Mireshghallah1, 2, Justus Mattern3, Sicun Gao1
Reza Shokri4,Taylor Berg-Kirkpatrick1
1University of California San Diego,2University of Washington,3RWTH Aachen
4National University of Singapore
[fatemeh, sicung,tberg]@ucsd.edu ,
justus.mattern@rwth-aachen.de,reza@comp.nus.edu.sg
As large language models are becoming more
ubiquitous and embedded in different user-facing
services, it is important to be able to distinguish
between human-written and machine-generated
text, to verify the authenticity of news articles,
product reviews, etc. Thus, in this paper we set
out to explore whether it is possible to use one
language model to identify machine-generated
text produced by another language model, even
if the two have different architectures and are
trained on different data. Further , if this is
possible, which language models make the best
general-purpose detectors  We find that overall,
smaller and partially-trained models are better
universal machine-generated text detectors   they
can more precisely detect text generated from
both small and larger models. Interestingly, we
find that whether or not the detector and generator
models were trained on the same data or have similar
 parameter counts is not critically important to
the detection success. For instance the OPT-125M
model has an AUC of 0.81 in detecting ChatGPT
generations, whereas a larger model from the
GPT family, GPTJ-6B, has AUC of 0.45.
With the rapid improvement in fluency of the text
generated by large language models (LLMs), these
system are being adopted more and more broadly in a
wide range of applications, including chatbots, writing
assistants, and summarizers. Generations from these
models are shown to have human-like fluency (Liang
et al., 2022  Y uan et al., 2022), making it difficult for
human readers to differentiate machine-generated text
from human-written text. This can have significant
ramifications, as such LLM-based tools can be abused
for unethical purposes like phishing, astroturfing, and
generating fake news (He et al., 2023). As such, we
need to be able to reliably and automatically detect
machine generated text.
Previous work has found that identifying local
optima in the likelihood surface of a trained languagemodel allows for detection of training utterances (Mattern
 et al., 2023), and generations for a given target
model (Mitchell et al., 2023). Specifically, the
approximate measure of local optimality, dubbed
curvature, is formed by comparing the loss of a target
sequence to the loss of nearby perturbations of the
target sequence, under the target model. The intuition
in both prior works is that this measure of curvature
ishigher around both training examples and model
generations, compared to unseen human-written text
and can therefore be used to determine if a given
sequence is part of the training data or not (Mattern
et al., 2023) or a generation of the target (generator)
model or not (Mitchell et al., 2023).
In practice, however, we often want to distinguish
between machine-generated text and human-written
text in situations where we do not know which model
could have been used as the generator   and even if
we do know the generator, we might not have access
to its likelihood function (e.g. ChatGPT), or access
might be behind a paywall (e.g. GPT3). Therefore,
in this paper we set out to explore the detection of
machine-generated text without knowledge of the generator.
 We do this by exploring whether it is possible
to use the curvature metric measured on one language
model (a detector model) to identify machinegenerated
 text generated by another language model
(the generator ), and under what conditions such crossdetection
 performs best. We use surrogate detector
models, whose likelihood functions we do have access
to. Then, we run the curvature test using the surrogate
(see Figure 1) and compare detection power with the
same test, but using the true generator s likelihood.
We conduct an extensive empirical analysis by
experimenting on a slew of models with different
sizes (from tens of millions to billions of parameters),
architectures (GPTs, OPTs, Pythias) and pre-training
data (Webtext and the Pile) and also from different
training stages (ranging from the first thousand steps
of training to full training  143k steps). Our main
finding is that cross-detection can come very closearXiv 2305.09859v3  [cs.CL]  12 Feb 2024Human Written T extPromptsMachine Generated T extPerturbed Target PoolDetector ModelGPT2Generative ModelChatGPT
Machine generated Figure 1  We want to study how models can cross-detect , i.e. distinguish between human-written text and machinegenerated
 text generated by another model. To this end, we create a target pool consisting of both human-written and
machine-generated text. We then generate perturbations of each target sequence using a perturbation model . We find
the likelihood of the target pool and perturbations under a detector model in order to estimate the local optimality under the
detector model s likelihood. We use the estimate of local optimality to determine if a sequence is machine generated or not.
to self-detection in terms of distinguishablity , and
thatthere are universal cross-detectors with high
average distinguishablity performance, meaning they
perform well in terms of detecting generations from a
wide-range of models, regardless of the architecture or
training data. More specifically, we find that smaller
models are better universal detectors . For instance
the OPT-125M model comes within 0.07area under
the ROC curve of self-detection, on average (see
Figure 10). And for models where we don t have
self-detection, such as ChatGPT, the AUC of using
OPT-125M is 0.81, whereas OPT 6.7B s AUC is 0.58.
We also find that partially trained models are
better detectors than the fully trained ones, and
this gap is bigger for larger models (see Figure 9).
We then further investigate some possible reasons
for this phenomenon by analyzing curvature and
log-likelihood of the different models, and find that
larger models are more conservative in terms of the
likelihood and curvature they assign to generations
from other models. Smaller models, however, assign
higher curvature to generations of models their size
or larger, therefore they can be used to cross-detect
on a broader range of models so the smaller model
is the best universal detector.
Figure 1 shows the methodology of our work, and
how we conduct our experiments  For a given target
pool of sequences, the task is to determine if each
sequence is human-written or machine-generated by
running a curvature (local optimality) test using the
likelihood surface of a surrogate detector model that
is different from the generator model, as our main
assumption is that we have no information about the
generator model . In the rest of this section we delve
deeper into the details of each component in the set
 ## PROFNAME
 Taylor Berg-Kirkpatrick
 ## AUTHORID
 1400419309
 ## AUTHORNAME
 Taylor Berg-Kirkpatrick
 ## AUTHORURL
 https://www.semanticscholar.org/author/1400419309
 ## AUTHORHINDEX
 36
 ## AUTHORAFFILIATIONS
 []
 ## AUTHORPAPERCOUNT
 112
 ## AUTHORCITATIONCOUNT
 5655
 ## PAPERID
 1527d3b661154ff7310fa2759b6dd0ddfd559492
 ## EXTERNALIDS
 {'ArXiv': '2305.09859', 'DBLP': 'journals/corr/abs-2305-09859', 'DOI': '10.48550/arXiv.2305.09859', 'CorpusId': 258740888}
 ## URL
 https://www.semanticscholar.org/paper/1527d3b661154ff7310fa2759b6dd0ddfd559492
 ## TITLE
 Smaller Language Models are Better Black-box Machine-Generated Text Detectors
 ## ABSTRACT
 With the advent of fluent generative language models that can produce convincing utterances very similar to those written by humans, distinguishing whether a piece of text is machine-generated or human-written becomes more challenging and more important, as such models could be used to spread misinformation, fake news, fake reviews and to mimic certain authors and figures. To this end, there have been a slew of methods proposed to detect machine-generated text. Most of these methods need access to the logits of the target model or need the ability to sample from the target. One such black-box detection method relies on the observation that generated text is locally optimal under the likelihood function of the generator, while human-written text is not. We find that overall, smaller and partially-trained models are better universal text detectors: they can more precisely detect text generated from both small and larger models. Interestingly, we find that whether the detector and generator were trained on the same data is not critically important to the detection success. For instance the OPT-125M model has an AUC of 0.81 in detecting ChatGPT generations, whereas a larger model from the GPT family, GPTJ-6B, has AUC of 0.45.
 ## VENUE
 arXiv.org
 ## YEAR
 2023
 ## REFERENCECOUNT
 38
 ## CITATIONCOUNT
 23
 ## INFLUENTIALCITATIONCOUNT
 1
 ## ISOPENACCESS
 True
 ## OPENACCESSPDF
 {'url': 'http://arxiv.org/pdf/2305.09859', 'status': None}
 ## FIELDSOFSTUDY
 ['Computer Science']
 ## JOURNAL
 {'volume': 'abs/2305.09859', 'name': 'ArXiv'}
 ## AUTHORS
 [{'authorId': '2115471757', 'name': 'Fatemehsadat Mireshghallah'}, {'authorId': '2138547910', 'name': 'Justus Mattern'}, {'authorId': '39219411', 'name': 'Sicun Gao'}, {'authorId': '2520493', 'name': 'R. Shokri'}, {'authorId': '1400419309', 'name': 'Taylor Berg-Kirkpatrick'}]
 ## TLDR
 Overall, smaller and partially-trained models are better universal text detectors: they can more precisely detect text generated from both small and larger models.
 up.
Target pool. The pool of sequences for which we
want to conduct the machine-generated text detection.We form this pool such that there is a 50%/50%
composition of machine-generated/human-written
text. The machine-generated text is created by
prompting the generator model with the first 20
tokens of each human-written sequence.
Generator model. This model is the generator of
the machine-generated utterances we would like to
distinguish from human-written utterances. We do
not always have full access to this model, or even
know what model it is. This scenario is what we
are actually interested in  we want to know how we
detect text generated by unknown models.
Detector model. This model is used as a surrogate
for the target model, to help us detect generations
when using the curvature test. The pool of sequences
and their neighbors are fed to the detector model, and
their loss under the detector model is measured and
used to calculate curvature and to distinguish between
generations and human written text.
Curvature (local optimality) test. The method we
use to distinguish between machine-generated and
human-written text relies on the local optimality
(curvature) of the target sequence, building on the
intuition that generations are more likely to be locally
optimal than unseen human-written text (Mitchell
et al., 2023  Mattern et al., 2023).
To estimate local optimality, following Mattern
et al. (2023)  Mitchell et al. (2023), we generate
additional utterances in a local neighborhood around
the target by perturbing the target (e.g. re-sampling
words at several positions). Then, the measure
of local optimality is computed by comparing the
likelihood of the target with the likelihood of the local
perturbations as follows 
Here, xis the target sequence, Î¸are the parametersof the detector model, and  xiis the ith perturbation
of the target utterance x(i.e. the ith neighbor) out of
the overall kperturbations. The perturbed sequences
are generated by masking parts of xand filling the
mask using a perturbation model. The curvature is
thresholded to make the machine-generated/humanwritten
 text decision. While technically this measure
is an approximate estimate of local optimality, past
work has referred to it as  curvature . For simplicity,
we use this nomenclature going forward.
Perturbation model. This model helps generate
neighbors by filling in randomly selected spans of the
target sequences in the pool and perturbing them. We
useT5-3B for this purpose in our experiments.
Success metric. We evaluate the success of the
detector by measuring the area under the ROC curve
(AUC), i.e. the false positive vs. true positive rate
curve. The higher the AUC, the more distinguishing
power the detection mechanism has.
Evaluation strategy. The results we report in the
paper fall into two main categories  (1) using a model
to detect its own generations, which is the main goal
of Mitchell et al. (2023) (in this setup, the target and detector
 models are the same, we call this self-detection ) 
and (2) using a model different from the generator
of the text to detect the generations. In this setup,
what we are basically doing is acting as if a surrogate
model has generated the text. In other words, we want
to see how well a model would claim another model s
generation as its own. We call this cross-detection .
This section briefly covers the experimental setup.
For more details refer to Appendix B.
Models We use the following model families in our
experiments  Facebook s OPT (we use the 125M,
350M, 1.3B, and 6.7B models), EleutherAI s GPT-J,
GPTNeo and Pythia (Biderman et al., 2023) (we
use GPTNeo-125M, GPTNeo-1.3B, GPTNeo-2.7B,
GPTJ-6B and Pythia models ranging from 70M to
2.8B parameters), and OpenAI s GPT models (distilGPT,
 GPT2-Small, GPT2-Medium, GPT2-Large,
GPT2-XL, GPT-3 and ChatGPT).
Evaluation dataset. We follow Mitchell et al.
(2023) s methodology for pre-processing and feeding
the data to the detector model. We use a subsample
of the SQuAD (Rajpurkar et al., 2016) and WritingPrompts
 (Fan et al., 2018) datasets, where the original
dataset sequences are used as the human-written text
in the target sequence pool. We then use the first 20tokens
 of each human-written sequence as a prompt, andfeed this to the target model, and have it generate completions
 for it. We then use this mix of generations and
human-written text to create the target pool on which
we do the detection. In all cases, our pool consists of
300human-written target samples, and 300machinegenerated
 samples, so the overall pool size is 600.
Pre-training datasets for the generator models. The
ElutherAI and Facebook models (GPTJ, GPTNeo,
Pythia and OPT families) are all trained on the
Pile dataset (Gao et al., 2020). There is limited
information and access to the training data of the
OpenAI models. The GPT-2 family is reportedly
trained on the WebText dataset, GPT-3 is trained on
a combination of the Common Crawl, WebText2,
books and Wikipedia, and there is not any information
released about the training data of ChatGPT.
4 Does cross-detection work 
In this section we conduct an extensive set of
experiments where we use 23models with different
sizes and architectures as detectors of text generated
by15other models. The results are averaged over
the SQuAD and WritingPrompts dataset. We also
experiment with partially trained checkpoints of the
detector models, to see how the detection power of
the models changes as the training progresses.
Our main finding is that cross detection can perform
 as well as self-detection, or come very close to it .
Figures 2 and 3 (full heatmap is Fig. 8 in Appendix)
show the AUC of cross-detection for different models.
Figures 10 and 9 in Appendix show how close each detector
 comes, in terms of AUC, to self-detection. We
can see that on average, OPT-125M is the best fully
trained universal cross-detector, showing on average
0.07lower AUC, compared to self-detection. If we
look at partially trained detector models, however, we
see that the Pythia-160M comes as close as 0.05AUC
points, with its 5k,10kand50kstep trained models
 (the fully trained model is trained for 143ksteps).
These models seem to even outperform self-detection
in some cases, for example when we look at GPTJ-6B
generations. In the rest of this section we further elaborate
 on these results and draw connections between
model size, training, and detection power.
4.1 Smaller Models Are Better Detectors
In this section we aim to see if there are any
correlations between model size and detection power.
To this end, we use 23different models with different
parameter counts, ranging from 70Mto6.7Bto
detect machine-generation texts from all the modelsOPT-6.7B
Detector ModelChatGPT
MeanGenerative Model0.67 0.62 0.67 0.67 0.72 0.79 0.72 0.75 0.80 0.79 0.83 0.80 0.82 0.84 0.84 0.82 0.83 0.86 0.84 0.86 0.84 0.83 0.83
0.70 0.69 0.73 0.73 0.74 0.78 0.75 0.76 0.77 0.78 0.79 0.79 0.79 0.79 0.81 0.82 0.82 0.82 0.84 0.80 0.80 0.84 0
 ## PROFNAME
 Taylor Berg-Kirkpatrick
 ## AUTHORID
 1400419309
 ## AUTHORNAME
 Taylor Berg-Kirkpatrick
 ## AUTHORURL
 https://www.semanticscholar.org/author/1400419309
 ## AUTHORHINDEX
 36
 ## AUTHORAFFILIATIONS
 []
 ## AUTHORPAPERCOUNT
 112
 ## AUTHORCITATIONCOUNT
 5655
 ## PAPERID
 1527d3b661154ff7310fa2759b6dd0ddfd559492
 ## EXTERNALIDS
 {'ArXiv': '2305.09859', 'DBLP': 'journals/corr/abs-2305-09859', 'DOI': '10.48550/arXiv.2305.09859', 'CorpusId': 258740888}
 ## URL
 https://www.semanticscholar.org/paper/1527d3b661154ff7310fa2759b6dd0ddfd559492
 ## TITLE
 Smaller Language Models are Better Black-box Machine-Generated Text Detectors
 ## ABSTRACT
 With the advent of fluent generative language models that can produce convincing utterances very similar to those written by humans, distinguishing whether a piece of text is machine-generated or human-written becomes more challenging and more important, as such models could be used to spread misinformation, fake news, fake reviews and to mimic certain authors and figures. To this end, there have been a slew of methods proposed to detect machine-generated text. Most of these methods need access to the logits of the target model or need the ability to sample from the target. One such black-box detection method relies on the observation that generated text is locally optimal under the likelihood function of the generator, while human-written text is not. We find that overall, smaller and partially-trained models are better universal text detectors: they can more precisely detect text generated from both small and larger models. Interestingly, we find that whether the detector and generator were trained on the same data is not critically important to the detection success. For instance the OPT-125M model has an AUC of 0.81 in detecting ChatGPT generations, whereas a larger model from the GPT family, GPTJ-6B, has AUC of 0.45.
 ## VENUE
 arXiv.org
 ## YEAR
 2023
 ## REFERENCECOUNT
 38
 ## CITATIONCOUNT
 23
 ## INFLUENTIALCITATIONCOUNT
 1
 ## ISOPENACCESS
 True
 ## OPENACCESSPDF
 {'url': 'http://arxiv.org/pdf/2305.09859', 'status': None}
 ## FIELDSOFSTUDY
 ['Computer Science']
 ## JOURNAL
 {'volume': 'abs/2305.09859', 'name': 'ArXiv'}
 ## AUTHORS
 [{'authorId': '2115471757', 'name': 'Fatemehsadat Mireshghallah'}, {'authorId': '2138547910', 'name': 'Justus Mattern'}, {'authorId': '39219411', 'name': 'Sicun Gao'}, {'authorId': '2520493', 'name': 'R. Shokri'}, {'authorId': '1400419309', 'name': 'Taylor Berg-Kirkpatrick'}]
 ## TLDR
 Overall, smaller and partially-trained models are better universal text detectors: they can more precisely detect text generated from both small and larger models.
 .84
0.93 0.64 0.74 0.74 0.78 0.81 0.79 0.81 0.91 0.84 0.84 0.84 0.84 0.84 0.91 0.85 0.86 0.90 0.87 0.85 0.83 0.85 0.85
0.72 0.88 0.77 0.77 0.81 0.78 0.82 0.82 0.84 0.85 0.82 0.85 0.85 0.82 0.86 0.86 0.86 0.87 0.87 0.83 0.82 0.86 0.86
0.62 0.56 0.72 0.71 0.95 0.81 0.83 0.83 0.83 0.87 0.86 0.87 0.89 0.87 0.88 0.88 0.88 0.89 0.89 0.88 0.84 0.87 0.87
0.61 0.52 0.68 0.68 0.78 0.98 0.81 0.82 0.86 0.86 0.94 0.89 0.90 0.95 0.93 0.91 0.91 0.93 0.92 0.94 0.90 0.89 0.90
0.69 0.53 0.66 0.65 0.74 0.82 0.79 0.79 0.98 0.83 0.88 0.87 0.89 0.89 0.95 0.91 0.90 0.95 0.91 0.91 0.89 0.89 0.90
0.55 0.49 0.67 0.65 0.80 0.80 0.83 0.84 0.84 0.99 0.88 0.92 0.93 0.90 0.93 0.94 0.93 0.94 0.95 0.91 0.90 0.92 0.92
0.55 0.46 0.64 0.63 0.75 0.89 0.81 0.82 0.85 0.86 0.99 0.91 0.92 0.96 0.95 0.93 0.93 0.95 0.94 0.96 0.93 0.92 0.92
0.40 0.33 0.53 0.49 0.64 0.81 0.72 0.73 0.77 0.80 0.92 0.90 0.91 1.00 0.95 0.94 0.93 0.95 0.95 0.97 0.94 0.92 0.93
0.46 0.35 0.52 0.50 0.63 0.73 0.72 0.73 0.82 0.80 0.86 0.91 0.91 0.91 1.00 0.96 0.96 0.99 0.97 0.96 0.97 0.97 0.96
0.33 0.25 0.38 0.37 0.47 0.57 0.57 0.57 0.67 0.67 0.73 0.84 0.83 0.83 0.96 0.96 0.96 1.00 0.97 0.96 0.98 0.97 0.97
0.24 0.21 0.32 0.30 0.41 0.48 0.51 0.50 0.52 0.60 0.65 0.82 0.80 0.77 0.91 0.96 0.96 0.96 1.00 0.96 0.97 0.98 0.97
0.24 0.21 0.34 0.32 0.43 0.58 0.55 0.56 0.58 0.64 0.77 0.84 0.84 0.89 0.93 0.96 0.95 0.98 0.97 1.00 0.99 0.97 0.97
0.15 0.14 0.19 0.18 0.27 0.24 0.33 0.34 0.33 0.42 0.39 0.62 0.60 0.54 0.76 0.89 0.88 0.91 0.93 0.88 1.00 0.97 0.97
0.52 0.46 0.57 0.56 0.66 0.72 0.70 0.71 0.76 0.77 0.81 0.84 0.85 0.85 0.91 0.91 0.90 0.93 0.92 0.91 0.91 0.91 0.91AUC of Distinguishing Human T ext from Generations
0.00.20.40.60.81.0Figure 2  AUC heatmap for cross-detection, where the rows are generator models and columns are the surrogate detector
models, both sorted by model size. We can see that smaller models are better detectors and larger models are the worst
models in terms of detection power.
Figure 2 shows the results for this experiment,
where the rows are the generator models (sizing up
from bottom row to top) and the columns show the
detector models (sizing up from right to left). So each
cell shows the detection power (AUC) of the given
detector model (column), on text generated from the
generator model (row). The last row is the mean,
which is an overall metric of how good of a detector
We see that the bottom left has the lowest values,
showing that larger models are not good at detecting
machine generated text from other models , and
they are particularly bad at it for detecting small
model generations. We can also see that smaller
models are much better detectors , as the right
side of the graph has much higher AUC values.
Another observation is the correlations between the
dataset andmodel architecture of the generator
and detector models. As the heatmap shows, models
from the same architecture family and trained on
the same/overlapping dataset are better at detecting
their own text, compared to models from a different
family. For instance, for detecting text generated by
OPT-6.7B the other models from the OPT family
are the best cross-detectors, with AUCs rangingfrom 0.89-0.87 (OPT-6.7B self-detects with AUC
0.91). The next best cross-detector is the smallest
GPTNeo-125M with AUC 0.86. However, the OpenAI
 GPT2 model of the same size has a lower AUC
of 0.84 (and overall the GPT2 family has the lowest
cross-detection AUC on OPT), which we hypothesize
is due to the larger gap in the training data, as the
OPT and GPTNeo/GPTJ models are all trained on
the Pile dataset, but GPT2 is trained on the Webtext.
All in all, the difference due to the dataset/architecture
differences is small as most of the dataset for all these
models is comprised of web-crawled data, showing
that cross-detection can be effective, regardless of
how much information we have about the target
model, and how accessible similar models are.
One noteworthy observation is that OPT-125M
can detect generations from models like GPT3 and
ChatGPT with relatively high AUC (0.81). However,
if the intuitive approach of taking another large,
 similar  model were to be taken and we were to use
OPT-6.7B, we would get AUC of 0.67 and 0.58 for
these models, respectively, which are both close to
random (0.5). Thus, intuitively, it seems that larger
models have more refined taste  they only show
higher local optimality (relative to human-written
text) on generations from large models. Conversely,0 20000 40000 60000 80000 100000 120000 140000
Training Step0.750.800.850.900.95AUCGenerative Model
0 20000 40000 60000 80000 100000 120000 140000
Training Step0.750.800.850.900.95AUCGenerative Model
0 20000 40000 60000 80000 100000 120000 140000
Training Step0.20.30.40.50.60.70.80.9AUCGenerative Model
Figure 3  Summary of the results for cross-detection power of different detector models trained for different number
of steps. Each subfigure shows a different detector model, and the x-axis shows the training step for the checkpoint used
as a detector. The results for all 15generator models are shown in Figure 8.
0.0000.0250.0500.0750.1000.1250.150CurvatureMachine-generated
(a) Curvature  OPT-125M as Detector
0.0000.0250.0500.0750.1000.1250.150CurvatureMachine-generated
Detector Model (b) Curvature  OPT-350M as Detector
0.000.050.100.150.20CurvatureMachine-generated
Detector Model (c) Curvature  OPT-6.7B as Detector
Log LikelihoodMachine-generated
(d) Loglikelihood  OPT-125M as Detector
Log LikelihoodMachine-generated
Detector Model (e) Logliklihood  OPT-350M as Detector
Log LikelihoodMachine-generated
Detector Model (f) Logliklihood  OPT-6.7B as Detector
Figure 4  Comparison of curvature and log likelihood values (mean and standard deviation) for the best universal
detector (OPT-125M), a medium sized detector (OPT-350M), and a larger detector from the same family (OPT-6.7B)
on generations from models of various sizes (x-axis). The  Detector Model  line shows values for when the generator
and detector are the same model. Detectors tend to show higher curvature on generations than human-written text only
for generations from models of the same size or larger.
smaller models are more forgiving  they show higher
local optimality on generations from similarly small
models and larger, making them better universal
detectors via local optimality comparison. We discuss
this further in Section 5.
Trained Models are Better Detectors
We take different training checkpoints of the Pythia
models (Biderman et al., 2023) at different steps (steps
1k,5k,10k,50k,100kand143k) with different sizes
(2.8B, 410M, and 70M), and use them as detectors of
generations from the 4 target models. Figure 3 shows
the results for this experiment (Figures 8 and 9 show
entire heatmaps of this experiment). For each model
we can see that the final checkpoint is consistentlythe worst one in terms of machine-generated text
detection , and it is one of the middle checkpoints
that has the best performance. Our hypothesis for this
is
 ## PROFNAME
 Taylor Berg-Kirkpatrick
 ## AUTHORID
 1400419309
 ## AUTHORNAME
 Taylor Berg-Kirkpatrick
 ## AUTHORURL
 https://www.semanticscholar.org/author/1400419309
 ## AUTHORHINDEX
 36
 ## AUTHORAFFILIATIONS
 []
 ## AUTHORPAPERCOUNT
 112
 ## AUTHORCITATIONCOUNT
 5655
 ## PAPERID
 1527d3b661154ff7310fa2759b6dd0ddfd559492
 ## EXTERNALIDS
 {'ArXiv': '2305.09859', 'DBLP': 'journals/corr/abs-2305-09859', 'DOI': '10.48550/arXiv.2305.09859', 'CorpusId': 258740888}
 ## URL
 https://www.semanticscholar.org/paper/1527d3b661154ff7310fa2759b6dd0ddfd559492
 ## TITLE
 Smaller Language Models are Better Black-box Machine-Generated Text Detectors
 ## ABSTRACT
 With the advent of fluent generative language models that can produce convincing utterances very similar to those written by humans, distinguishing whether a piece of text is machine-generated or human-written becomes more challenging and more important, as such models could be used to spread misinformation, fake news, fake reviews and to mimic certain authors and figures. To this end, there have been a slew of methods proposed to detect machine-generated text. Most of these methods need access to the logits of the target model or need the ability to sample from the target. One such black-box detection method relies on the observation that generated text is locally optimal under the likelihood function of the generator, while human-written text is not. We find that overall, smaller and partially-trained models are better universal text detectors: they can more precisely detect text generated from both small and larger models. Interestingly, we find that whether the detector and generator were trained on the same data is not critically important to the detection success. For instance the OPT-125M model has an AUC of 0.81 in detecting ChatGPT generations, whereas a larger model from the GPT family, GPTJ-6B, has AUC of 0.45.
 ## VENUE
 arXiv.org
 ## YEAR
 2023
 ## REFERENCECOUNT
 38
 ## CITATIONCOUNT
 23
 ## INFLUENTIALCITATIONCOUNT
 1
 ## ISOPENACCESS
 True
 ## OPENACCESSPDF
 {'url': 'http://arxiv.org/pdf/2305.09859', 'status': None}
 ## FIELDSOFSTUDY
 ['Computer Science']
 ## JOURNAL
 {'volume': 'abs/2305.09859', 'name': 'ArXiv'}
 ## AUTHORS
 [{'authorId': '2115471757', 'name': 'Fatemehsadat Mireshghallah'}, {'authorId': '2138547910', 'name': 'Justus Mattern'}, {'authorId': '39219411', 'name': 'Sicun Gao'}, {'authorId': '2520493', 'name': 'R. Shokri'}, {'authorId': '1400419309', 'name': 'Taylor Berg-Kirkpatrick'}]
 ## TLDR
 Overall, smaller and partially-trained models are better universal text detectors: they can more precisely detect text generated from both small and larger models.
  similar to that of Section 4, where we believe that
partially trained models have not yet fit to the training
data tightly (and have a smoother surface), so they
over claim other models  generations as their own,
whereas the longer a model is trained, the sequences
it ranks higher as its own narrow down.
5 How are smaller models better detectors 
To help shed light on why smaller models are better
detectors and larger models are not good at detecting
machine generated text, we plot a breakdown of the
curvature metric (Section 2) and log-likelihood values
for the best universal detector (OPT-125M), a medium10810910101011
#Params0.20.40.60.81.0AUC
Self-detectFigure 5  AUC of the three cross-detectors from Figure 4
sized detector of the same family (OPT-350M) and
a larger one from the same family (OPT-6.7B),
shown in Figure 4. The y-axis is the curvature/log
likelihood of the target generations (from the 15
models from Section B.1) under the detector models
(OPT-125M, 350M or 6.7B). The x-axis is the
number of parameters of the generator model (we do
not know how many parameters ChatGPT has, so we
plotted it as the rightmost point in the plots). Figure 5
plots the AUCs for detection under the three models,
for the 15generator models.
We can see that for the smaller detector model
(Figures 4a and 4d), the mean curvature and
log-likelihood values for the generated text are consistently
 higher than the curvature for the human-written
text. However, for the larger model (Figure 4c and 4f),
the curvature and log-likelihood values for the
machine-generated text is in most cases smaller than
or around the same value as the human written text.
The curvature and log-likelihood values for human
written text for both graphs are stable since the text
is the same and doesn t depend on the target model.
We can also see that overall the curvature and
likelihood values for the larger model are higher,
especially for the original text, than those of the
smaller model, and the values for text generated by
the other models have lower curvature and likelihood
value. This shows that the larger model places higher
likelihood on the human written text and fits it better.
The smaller model, however, assigns lower curvature
and likelihood to the human-written text compared to
generations by a large gap, and the assigned values are
overall lower than those of the large model. Broadly
we observe that all models respond similarly to
machine generated text from other models, so long
as the other model is same size or bigger. In other
words, they place high likelihood on text from larger
models. However, for models smaller than themselves,
 they place lower likelihood and curvature. Assuch, smaller models are better universal detectors ,
as the size of the set of sequences they assign higher
likelihood and curvature to is bigger than it is for large
models, and this higher curvature is much higher than
the curvature assigned to the human written text. The
spikes in all the sub-figures of Figure 4 graphs are
for the detector model detecting its own text.
6 Does neighborhood choice matter 
Our estimation of  curvature  hinges upon generating
numerous perturbations (neighbors) and comparing
their loss with that of a target point. Therefore, if
these perturbed neighbors are not sufficiently nearby
and lie in a different basin of the likelihood surface,
our measure of curvature is not accurate (the closer
the perturbed points are, the more accurate estimation
of curvature we achieve). The perturbation method directly
 impacts the size and shape of the neighborhood
we create. Therefore, we compare different perturbation
 schemes in order to see how sensitive detectors
of different sizes are to neighborhood choice.
We investigate two different methods for changing
the distance of the generated perturbations  (1) we
change the mask filling model size, by experimenting
withT5-Small ,T5-Large andT5-3B (Wolf et al., 2019 
Raffel et al., 2020) to test the intuition that larger maskfilling
 models, generate semantically closer neighbors
than a smaller model, we present the extended results
for this in Appendix A. A similar analysis is also
conducted in (Mitchell et al., 2023), we however, do
a more extensive analysis on numerous models of
different sizes and probe the curvature values. (2) We
change the percentage of the tokens that get masked
and replaced by the mask-filling model, as the more
tokens we mask and replace, the farther the generated
perturbations would be. (3) Finally, we look into how
many tokens we actually need in the generated/humanwritten
 sequences to create a neighborhood and be
able to accurately distinguish the texts.
6.1 Masking Percentage
Figure 6 shows the results for the experiment where
we change the percentage of tokens that are masked,
to produce the neighbors. In all previous experiments,
we used 15% masking with mask span length of 2tokens
 following the experimental setup in Mitchell et al.
(2023). In this section, however, we change the percentage
 of the masked tokens (and we set the masking
to be contiguous) to see how it affects the curvature
mean and standard deviation values, and the AUCs.
We can see that as the masking percentage decreases108109
#Params0.60.81.01.21.41.61.82.02.2CurvatureMachine-generated
Human-written(a)90% Masking
#Params0.10.20.30.40.50.6CurvatureMachine-generated
Human-written (b)50% Masking
#Params0.020.040.060.080.100.120.140.16CurvatureMachine-generated
Human-written (c)15% Masking
0.0000.0050.0100.0150.0200.0250.030CurvatureMachine-generated
0.0000.0050.0100.015CurvatureMachine-generated
Human-written (e)1%Masking
#Params0.550.600.650.700.750.800.850.900.95AUC
0.9 (f) AUCs for different masking pctgs.
Figure 6  The effect of changing the masking percentage on curvature values and self-detection power of different models
with different sizes (AUC).
(from 90% to2%), the AUCs and the self-detection
power of models increase rather consistently. When
we go to 1%, however, we see the AUC drop. If we
look at Figure 6e which depicts the curvature measures
for the 1%masking, we see that the curvatures overlap
 between machine-generated and human-written
text, which we hypothesize is because our implementation
 does not enforce that re-sampled words must
differ from the words they are replacing. Thus, for the
smallest masking percentage, it is possible that some
perturbations are identical to the target, which may
explain reduced detection accuracy in this setting1.
6.2 How many tokens do we need for detection 
Figure 7 shows how the length of the target sequence
affects the sequence s detectablity (AUC of detection),
and how many tokens we need to be able to do
precise detection. We compare sequences of different
lengths, ranging from 10 tokens to 200, for four
different models with four different parameter
counts, on the SQuAD dataset. In this setup we
target self-detection. We can see that the longer
the sequence, the easier it is to distinguish if it i
 ## PROFNAME
 Taylor Berg-Kirkpatrick
 ## AUTHORID
 1400419309
 ## AUTHORNAME
 Taylor Berg-Kirkpatrick
 ## AUTHORURL
 https://www.semanticscholar.org/author/1400419309
 ## AUTHORHINDEX
 36
 ## AUTHORAFFILIATIONS
 []
 ## AUTHORPAPERCOUNT
 112
 ## AUTHORCITATIONCOUNT
 5655
 ## PAPERID
 1527d3b661154ff7310fa2759b6dd0ddfd559492
 ## EXTERNALIDS
 {'ArXiv': '2305.09859', 'DBLP': 'journals/corr/abs-2305-09859', 'DOI': '10.48550/arXiv.2305.09859', 'CorpusId': 258740888}
 ## URL
 https://www.semanticscholar.org/paper/1527d3b661154ff7310fa2759b6dd0ddfd559492
 ## TITLE
 Smaller Language Models are Better Black-box Machine-Generated Text Detectors
 ## ABSTRACT
 With the advent of fluent generative language models that can produce convincing utterances very similar to those written by humans, distinguishing whether a piece of text is machine-generated or human-written becomes more challenging and more important, as such models could be used to spread misinformation, fake news, fake reviews and to mimic certain authors and figures. To this end, there have been a slew of methods proposed to detect machine-generated text. Most of these methods need access to the logits of the target model or need the ability to sample from the target. One such black-box detection method relies on the observation that generated text is locally optimal under the likelihood function of the generator, while human-written text is not. We find that overall, smaller and partially-trained models are better universal text detectors: they can more precisely detect text generated from both small and larger models. Interestingly, we find that whether the detector and generator were trained on the same data is not critically important to the detection success. For instance the OPT-125M model has an AUC of 0.81 in detecting ChatGPT generations, whereas a larger model from the GPT family, GPTJ-6B, has AUC of 0.45.
 ## VENUE
 arXiv.org
 ## YEAR
 2023
 ## REFERENCECOUNT
 38
 ## CITATIONCOUNT
 23
 ## INFLUENTIALCITATIONCOUNT
 1
 ## ISOPENACCESS
 True
 ## OPENACCESSPDF
 {'url': 'http://arxiv.org/pdf/2305.09859', 'status': None}
 ## FIELDSOFSTUDY
 ['Computer Science']
 ## JOURNAL
 {'volume': 'abs/2305.09859', 'name': 'ArXiv'}
 ## AUTHORS
 [{'authorId': '2115471757', 'name': 'Fatemehsadat Mireshghallah'}, {'authorId': '2138547910', 'name': 'Justus Mattern'}, {'authorId': '39219411', 'name': 'Sicun Gao'}, {'authorId': '2520493', 'name': 'R. Shokri'}, {'authorId': '1400419309', 'name': 'Taylor Berg-Kirkpatrick'}]
 ## TLDR
 Overall, smaller and partially-trained models are better universal text detectors: they can more precisely detect text generated from both small and larger models.
 s
human-written or machine-generated, and 75-100
tokens seems like the point where we hit diminishing
returns. We can also see that across different sequence
lengths, as models get smaller, the detection power
increases, as seen throughout the rest of the paper.
1Its noteworthy that the slight discrepancy between the results
for15% masking in this section and the previous section is that
there, the mask span length was 2so the masked portion of the
sequence is not contiguous. In this experiment, however, we use
25 50 75 100 125 150 175 200
T oken Length0.50.60.70.80.91.0AUCDistinguisher Model
OPT-6.7BFigure 7  Detectability as a function of candidate
utterance length. As expected, longer utterances are more
cross-detectable   though it s worth noting that utterances
as short as 60 tokens long are still cross-detectable with
relatively high accuracy.
The problem of machine-generated text detection has
already been studied for multiple years using a variety
of different approaches (Ippolito et al., 2020  Jawahar
et al., 2020  Uchendu et al., 2020, 2021)  Both
Gehrmann et al. (2019) and Dugan et al. (2022) have
found that humans generally struggle to distinguish
between human- and machine-generated text, thereby
motivating the development of automatic solutions.
Among those, some methods aim to detect machinegenerated
 text by training a classifier in a supervised
manner (Bakhtin et al., 2019  Uchendu et al., 2020),
while others perform detection in a zero-shot manner
(Solaiman et al., 2019  Ippolito et al., 2020). There is
also a line of work that relies on bot detection throughquestion answering (Wang et al., 2023  Chew and
Baird, 2003), which is outside the scope of this paper.
Most recently, Mitchell et al. (2023) introduced the
zero-shot method DetectGPT, which is based on the
hypothesis that texts generated from a LLM lie on
local maxima, and therefore negative curvature, of the
model s probability distribution. Other strategies have
been proposed to enable the detection of machinegenerated
 text in the wild. Particularly through efforts
on the side of the LLM provider, more powerful
detection methods can be devised. One such method
is watermarking, which injects algorithmically
detectable patterns into the released text while ideally
preserving the quality and diversity of language
model outputs. Watermarks for natural language
have already been proposed by Atallah et al. (2001)
and have since been adapted for outputs of neural
language models (Fang et al., 2017  Ziegler et al.,
2019). Notable recent attempts for transformer based
language models include work by Abdelnabi and Fritz
(2021), who propose an adversarial watermarking
transformer (AWT). While this watermarking method
is dependent on the model architecture, Kirchenbauer
et al. (2023) propose a watermark that can be applied
to texts generated by any common autoregressive
language model. As a strategy more reliable than
watermarking, Krishna et al. (2023) suggest a
retrieval-based approach  By storing all model
outputs in a database, LLM providers can verify
whether a given text was previously generated by
their language model. In practice, this would however
require storage of large amounts of data and highly
efficient retrieval techniques in order to provide fast
responses as the number of generated texts grows.
Relationship to Membership Inference Attacks
(MIA) Prior work (Mattern et al., 2023) demonstrated
 that the same optimality test can be used
to distinguish between training set members and
non-training members, i.e. as a membership inference
attack. As our experiments showed, when models
size up the detection power (i.e. distinguishablity
between machine-generated and human-written text)
decreases. For MIA, however, prior work demonstrate
inverse scaling, as in larger models demonstrate
higher distinguishing power (Mireshghallah et al.,
2022  Mattern et al., 2023). We attribute this to the
higher memorization capablities of these models, as
shown by (Tirumala et al., 2022), making it easier for
them to recognize their training data.8 Conclusion
With the increasing prevalence of LLMs and their
integration into various different services, it becomes
crucial to differentiate between text written by
humans and text generated by machines so as to avoid
fake news and impersonations. As such, we set out
to explore the possibilities of using existing models
to detect generations from unknown sources, and
distinguish them from human written text. We find
that when using zero-shot detection methods that rely
on local optimality, smaller models are overall better
at detecting generations, and larger models are poor
detectors. Our results offer hope of robust general
purpose protection against LLMs used with nefarious
intentions. However, as LLMs continue to change and
detection evasion methods become more prevalent,
so must methods for detection and validation studies.
Although we see high AUCs for black-box detection
of machine generated text in our experiments, this
does not necessarily mean that these detection methods
 are not avoidable, and that they can be applied
to all models and achieve high performance. Further
experiments are needed to evaluate the generalization
of our findings to other architectures and setups.
This research is supported in part by DARPA
SemaFor Program No. HR00112020054.
Sahar Abdelnabi and Mario Fritz. 2021. Adversarial
watermarking transformer  Towards tracing text
provenance with data hiding. In 42nd IEEE Symposium
on Security and Privacy .
Mikhail J. Atallah, Victor Raskin, Michael Crogan,
Christian Hempelmann, Florian Kerschbaum, Dina
Mohamed, and Sanket Naik. 2001. Natural language
watermarking  Design, analysis, and a proof-of-concept
implementation. In Information Hiding , pages 185 200,
Berlin, Heidelberg. Springer Berlin Heidelberg.
Anton Bakhtin, Sam Gross, Myle Ott, Y untian Deng,
Marc Aurelio Ranzato, and Arthur Szlam. 2019. Real
or fake  learning to discriminate machine from human
Stella Biderman, Hailey Schoelkopf, Quentin Anthony,
Herbie Bradley, Kyle O Brien, Eric Hallahan, Mohammad
 Aflah Khan, Shivanshu Purohit, USVSN Sai
Prashanth, Edward Raff, et al. 2023. Pythia  A suite
for analyzing large language models across training and
scaling. arXiv preprint arXiv 2304.01373 .Monica Chew and Henry S. Baird. 2003. Baffletext  a
human interactive proof. In IS&T/SPIE Electronic
Liam Dugan, Daphne Ippolito, Arun Kirubarajan, Sherry
Shi, and Chris Callison-Burch. 2022. Real or fake
text   Investigating human ability to detect boundaries
between human-written and machine-generated text.
Angela Fan, Mike Lewis, and Yann Dauphin. 2018.
Hierarchical neural story generation. arXiv preprint
Tina Fang, Martin Jaggi, and Katerina Argyraki. 2017.
Generating steganographic text with LSTMs. In
Proceedings of ACL 2017, Student Research Workshop ,
pages 100 106, Vancouver, Canada. Association for
Computational Linguistics.
Leo Gao, Stella Biderman, Sid Black, Laurence Golding,
Trav
 ## PROFNAME
 Taylor Berg-Kirkpatrick
 ## AUTHORID
 1400419309
 ## AUTHORNAME
 Taylor Berg-Kirkpatrick
 ## AUTHORURL
 https://www.semanticscholar.org/author/1400419309
 ## AUTHORHINDEX
 36
 ## AUTHORAFFILIATIONS
 []
 ## AUTHORPAPERCOUNT
 112
 ## AUTHORCITATIONCOUNT
 5655
 ## PAPERID
 1527d3b661154ff7310fa2759b6dd0ddfd559492
 ## EXTERNALIDS
 {'ArXiv': '2305.09859', 'DBLP': 'journals/corr/abs-2305-09859', 'DOI': '10.48550/arXiv.2305.09859', 'CorpusId': 258740888}
 ## URL
 https://www.semanticscholar.org/paper/1527d3b661154ff7310fa2759b6dd0ddfd559492
 ## TITLE
 Smaller Language Models are Better Black-box Machine-Generated Text Detectors
 ## ABSTRACT
 With the advent of fluent generative language models that can produce convincing utterances very similar to those written by humans, distinguishing whether a piece of text is machine-generated or human-written becomes more challenging and more important, as such models could be used to spread misinformation, fake news, fake reviews and to mimic certain authors and figures. To this end, there have been a slew of methods proposed to detect machine-generated text. Most of these methods need access to the logits of the target model or need the ability to sample from the target. One such black-box detection method relies on the observation that generated text is locally optimal under the likelihood function of the generator, while human-written text is not. We find that overall, smaller and partially-trained models are better universal text detectors: they can more precisely detect text generated from both small and larger models. Interestingly, we find that whether the detector and generator were trained on the same data is not critically important to the detection success. For instance the OPT-125M model has an AUC of 0.81 in detecting ChatGPT generations, whereas a larger model from the GPT family, GPTJ-6B, has AUC of 0.45.
 ## VENUE
 arXiv.org
 ## YEAR
 2023
 ## REFERENCECOUNT
 38
 ## CITATIONCOUNT
 23
 ## INFLUENTIALCITATIONCOUNT
 1
 ## ISOPENACCESS
 True
 ## OPENACCESSPDF
 {'url': 'http://arxiv.org/pdf/2305.09859', 'status': None}
 ## FIELDSOFSTUDY
 ['Computer Science']
 ## JOURNAL
 {'volume': 'abs/2305.09859', 'name': 'ArXiv'}
 ## AUTHORS
 [{'authorId': '2115471757', 'name': 'Fatemehsadat Mireshghallah'}, {'authorId': '2138547910', 'name': 'Justus Mattern'}, {'authorId': '39219411', 'name': 'Sicun Gao'}, {'authorId': '2520493', 'name': 'R. Shokri'}, {'authorId': '1400419309', 'name': 'Taylor Berg-Kirkpatrick'}]
 ## TLDR
 Overall, smaller and partially-trained models are better universal text detectors: they can more precisely detect text generated from both small and larger models.
 is Hoppe, Charles Foster, Jason Phang, Horace He,
Anish Thite, Noa Nabeshima, et al. 2020. The pile  An
800gb dataset of diverse text for language modeling.
arXiv preprint arXiv 2101.00027 .
Sebastian Gehrmann, Hendrik Strobelt, and Alexander
Rush. 2019. GLTR  Statistical detection and visualization
 of generated text. In Proceedings of the 57th Annual
Meeting of the Association for Computational Linguistics 
 System Demonstrations , pages 111 116, Florence,
Italy. Association for Computational Linguistics.
Xinlei He, Xinyue Shen, Zeyuan Chen, Michael Backes,
and Yang Zhang. 2023. Mgtbench  Benchmarking
machine-generated text detection. arXiv preprint
Daphne Ippolito, Daniel Duckworth, Chris Callison-Burch,
and Douglas Eck. 2020. Automatic detection of
generated text is easiest when humans are fooled. In
Proceedings of the 58th Annual Meeting of the Association
 for Computational Linguistics , pages 1808 1822,
Online. Association for Computational Linguistics.
Ganesh Jawahar, Muhammad Abdul-Mageed, and
Laks Lakshmanan, V .S. 2020. Automatic detection
of machine generated text  A critical survey. In
Proceedings of the 28th International Conference
on Computational Linguistics , pages 2296 2309,
Barcelona, Spain (Online). International Committee on
Computational Linguistics.
John Kirchenbauer, Jonas Geiping, Y uxin Wen, Jonathan
Katz, Ian Miers, and Tom Goldstein. 2023. A
watermark for large language models.
Kalpesh Krishna, Yixiao Song, Marzena Karpinska, John
Wieting, and Mohit Iyyer. 2023. Paraphrasing evades
detectors of ai-generated text, but retrieval is an effective
defense. arXiv preprint arXiv 2303.13408 .
Percy Liang, Rishi Bommasani, Tony Lee, Dimitris
Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian Zhang,
Deepak Narayanan, Yuhuai Wu, Ananya Kumar, et al.
2022. Holistic evaluation of language models. arXiv
preprint arXiv 2211.09110 .Justus Mattern, Fatemehsadat Mireshghallah, Zhijing Ji,
Bernhard Scholkop, Mrinmaya Sachan, and Taylor
Berg-Kirkpatrick. 2023. Membership inference attacks
against language models via neighbourhood comparison.
InProceedings of the 61st Annual Meeting of the Association
 for Computational Linguistics (ACL Findings) .
Fatemehsadat Mireshghallah, Kartik Goyal, Archit Uniyal,
Taylor Berg-Kirkpatrick, and Reza Shokri. 2022.
Quantifying privacy risks of masked language models
using membership inference attacks. arXiv preprint
Eric Mitchell, Y oonho Lee, Alexander Khazatsky, Christopher
 D Manning, and Chelsea Finn. 2023. Detectgpt 
Zero-shot machine-generated text detection using
probability curvature. arXiv preprint arXiv 2301.11305 .
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine
Lee, Sharan Narang, Michael Matena, Yanqi Zhou,
Wei Li, and Peter J Liu. 2020. Exploring the limits
of transfer learning with a unified text-to-text transformer.
 The Journal of Machine Learning Research ,
Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev,
and Percy Liang. 2016. Squad  100,000  questions
for machine comprehension of text. arXiv preprint
Irene Solaiman, Miles Brundage, Jack Clark, Amanda
Askell, Ariel Herbert-V oss, Jeff Wu, Alec Radford,
Gretchen Krueger, Jong Wook Kim, Sarah Kreps,
Miles McCain, Alex Newhouse, Jason Blazakis, Kris
McGuffie, and Jasmine Wang. 2019. Release strategies
and the social impacts of language models.
Kushal Tirumala, Aram Markosyan, Luke Zettlemoyer,
and Armen Aghajanyan. 2022. Memorization without
overfitting  Analyzing the training dynamics of large
language models. Advances in Neural Information
Processing Systems , 35 38274 38290.
Adaku Uchendu, Thai Le, Kai Shu, and Dongwon
Lee. 2020. Authorship attribution for neural text
generation. In Proceedings of the 2020 Conference on
Empirical Methods in Natural Language Processing
(EMNLP) , pages 8384 8395, Online. Association for
Computational Linguistics.
Adaku Uchendu, Zeyu Ma, Thai Le, Rui Zhang, and
Dongwon Lee. 2021. TURINGBENCH  A benchmark
environment for Turing test in the age of neural text
generation. In Findings of the Association for Computational
 Linguistics  EMNLP 2021 , pages 2001 2016,
Punta Cana, Dominican Republic. Association for
Computational Linguistics.
Hong Wang, Xuan Luo, Weizhi Wang, and Xifeng Yan.
2023. Bot or human  detecting chatgpt imposters with
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond,
 Clement Delangue, Anthony Moi, Pierric Cistac,
Tim Rault, RÃ©mi Louf, Morgan Funtowicz, et al. 2019.
Huggingface s transformers  State-of-the-art natural
language processing. arXiv preprint arXiv 1910.03771 .Ann Y uan, Andy Coenen, Emily Reif, and Daphne Ippolito.
2022. Wordcraft  story writing with large language
models. In 27th International Conference on Intelligent
User Interfaces , pages 841 852.
Zachary Ziegler, Y untian Deng, and Alexander Rush.
2019. Neural linguistic steganography. In Proceedings
of the 2019 Conference on Empirical Methods in
Natural Language Processing and the 9th International
Joint Conference on Natural Language Processing
(EMNLP-IJCNLP) , pages 1210 1215, Hong Kong,
China. Association for Computational Linguistics.A Ablating Mask Filling Models
Figure 11 shows the curvature numbers for each
model trying to detect its own generations, so for
each model the generator is also the detector. We
experiment with three perturbation generating models,
with three different sizes  (1) T5-small ( 60million
parameters) (2) T5-Large ( 770million parameters)
(3) T5-3B (3 billion parameter). The intuition behind
using three model sizes is to see the effect of having a
better replacement model on the measured curvatures
and the detection power of the detector models.
We can see that as the masking model sizes down
(going from top to the bottom subfigures), the overall
curvature values for both human-written and machinegenerated
 text increases (going from 0.2 maximum
in Figure 11a to 0.6 maximum in Figure 11c), and
the two sets of texts become less distinguishable. T5Small
 produces low-quality (low-fluency) neighbors
that are assigned lower likelihoods by the detector
model, resulting in high curvature numbers for both
human and machine generated text, making them
indistinguishable. As we improve the mask filling
model, however, the generated neighbors become of
higher quality (and semantically closer to the target
point), thereby creating a more accurate estimate of
the curvature and providing better distinguishablity,
as shown by the AUC numbers in Figure 11d.
We want to experiment with a wide range of models,
 with different architectures, parameter counts
and training datasets, therefore we use the following
model families in our experiments  Facebook s OPT
(we use the 125M, 350M, 1.3B, and 6.7B models),
EleutherAI s GPT-J, GPTNeo and Pythia (Biderman
et al., 2023) (we use GPTNeo-125M, GPTNeo-1.3B,
GPTNeo-2.7B, GPTJ-6B and Pythia models ranging
from 70M to 2.8B parameters), and OpenAI s GPT
models (distilGPT, GPT2-Small, GPT2-Medium,
GPT2-Large, GPT2-XL, GPT-3 and ChatGPT).
We also have experiments where we use parti
 ## PROFNAME
 Taylor Berg-Kirkpatrick
 ## AUTHORID
 1400419309
 ## AUTHORNAME
 Taylor Berg-Kirkpatrick
 ## AUTHORURL
 https://www.semanticscholar.org/author/1400419309
 ## AUTHORHINDEX
 36
 ## AUTHORAFFILIATIONS
 []
 ## AUTHORPAPERCOUNT
 112
 ## AUTHORCITATIONCOUNT
 5655
 ## PAPERID
 1527d3b661154ff7310fa2759b6dd0ddfd559492
 ## EXTERNALIDS
 {'ArXiv': '2305.09859', 'DBLP': 'journals/corr/abs-2305-09859', 'DOI': '10.48550/arXiv.2305.09859', 'CorpusId': 258740888}
 ## URL
 https://www.semanticscholar.org/paper/1527d3b661154ff7310fa2759b6dd0ddfd559492
 ## TITLE
 Smaller Language Models are Better Black-box Machine-Generated Text Detectors
 ## ABSTRACT
 With the advent of fluent generative language models that can produce convincing utterances very similar to those written by humans, distinguishing whether a piece of text is machine-generated or human-written becomes more challenging and more important, as such models could be used to spread misinformation, fake news, fake reviews and to mimic certain authors and figures. To this end, there have been a slew of methods proposed to detect machine-generated text. Most of these methods need access to the logits of the target model or need the ability to sample from the target. One such black-box detection method relies on the observation that generated text is locally optimal under the likelihood function of the generator, while human-written text is not. We find that overall, smaller and partially-trained models are better universal text detectors: they can more precisely detect text generated from both small and larger models. Interestingly, we find that whether the detector and generator were trained on the same data is not critically important to the detection success. For instance the OPT-125M model has an AUC of 0.81 in detecting ChatGPT generations, whereas a larger model from the GPT family, GPTJ-6B, has AUC of 0.45.
 ## VENUE
 arXiv.org
 ## YEAR
 2023
 ## REFERENCECOUNT
 38
 ## CITATIONCOUNT
 23
 ## INFLUENTIALCITATIONCOUNT
 1
 ## ISOPENACCESS
 True
 ## OPENACCESSPDF
 {'url': 'http://arxiv.org/pdf/2305.09859', 'status': None}
 ## FIELDSOFSTUDY
 ['Computer Science']
 ## JOURNAL
 {'volume': 'abs/2305.09859', 'name': 'ArXiv'}
 ## AUTHORS
 [{'authorId': '2115471757', 'name': 'Fatemehsadat Mireshghallah'}, {'authorId': '2138547910', 'name': 'Justus Mattern'}, {'authorId': '39219411', 'name': 'Sicun Gao'}, {'authorId': '2520493', 'name': 'R. Shokri'}, {'authorId': '1400419309', 'name': 'Taylor Berg-Kirkpatrick'}]
 ## TLDR
 Overall, smaller and partially-trained models are better universal text detectors: they can more precisely detect text generated from both small and larger models.
 ally
trained models as detectors. For those experiments,
we only use the Pythia models as they are the only
ones with available, open-source partially trained
checkpoints. For each Pythia models, there is also
a de-duplicated version available, where the model
is trained on the de-duplicated version of the data, as
opposed to the original dataset. All the models we use
are obtained from HuggingFace (Wolf et al., 2019).B.2 Dataset
Evaluation dataset. We follow Mitchell et al.
(2023) s methodology for pre-processing and feeding
 the data. We use a subsample of the SQuAD
dataset (Rajpurkar et al., 2016), where the original
dataset sequences are used as the human-written text
in the target sequence pool. We then use the first 20tokens
 of each human-written sequence as a prompt, and
feed this to the target model, and have it generate completions
 for it. We then use this mix of generations and
human-written text to create the target pool for which
we do the detection. In all cases, following the methodology
 from Mitchell et al. (2023), our pool consists of
300human-written target samples, and 300machinegenerated
 samples, so the overall pool size is 600.
Pre-training datasets for the generative models.
The ElutherAI and Facebook models (GPTJ, GPTNeo,
 Pythia and OPT families) are all trained on the
Pile dataset (Gao et al., 2020), a curated collection
of22English language datasets (consisting of
web-crawled data, academic articles, dialogues, etc.).
As mentioned above there are two versions of each
Pythia model (Biderman et al., 2023), one version is
trained on Pile, the other is trained on de-duplicated
Pile. The de-duplicated Pile is approximately 207B
tokens in size, compared to the original Pile which
contains 300B tokens. There is limited information
and access to the training data of the OpenAI models.
The GPT-2 family is reportedly trained on the
WebText dataset, GPT-3 is trained on a combination
of the Common Crawl2, WebText2, books and
Wikipedia, and there is not any information released
about the training data of ChatGPT.
C.1 Extensive Heatmaps
We provide the full heatmaps from experiments of
Section 4 here, to provide a detailed breakdown.
Figures 2 and 3 (full heatmap is Fig. 8 in Appendix)
show the AUC of cross-detection for different models.
Figures 10 and 9 in Appendix show how close each
detector comes, in terms of AUC, to self-detection.
C.2 Summary of Experiments
We provide a summary of Figure 2 in Figure 12,
where we have presented the numbers from the best
overall detector with mean AUC of 0.92 (OPT-125M)
and the biggest model of the same family, OPT-6.7B
with average AUC of 0.46.
2https //commoncrawl.orgPythia-2.8B-dd-1k
Detector ModelChatGPT
MeanGenerative Model0.75 0.75 0.70 0.60 0.54 0.52 0.75 0.78 0.75 0.68 0.64 0.64 0.75 0.79 0.78 0.76 0.73 0.73 0.72 0.77 0.76 0.75 0.74 0.73 0.75 0.78 0.78 0.79 0.76 0.75
0.83 0.80 0.77 0.70 0.66 0.67 0.80 0.80 0.79 0.75 0.72 0.72 0.81 0.83 0.80 0.81 0.78 0.78 0.78 0.81 0.82 0.81 0.81 0.81 0.80 0.81 0.81 0.83 0.82 0.82
0.83 0.84 0.81 0.77 0.67 0.67 0.83 0.85 0.83 0.81 0.78 0.77 0.84 0.85 0.85 0.84 0.84 0.82 0.83 0.85 0.85 0.84 0.84 0.84 0.82 0.84 0.84 0.84 0.84 0.83
0.82 0.84 0.82 0.78 0.73 0.71 0.83 0.84 0.83 0.80 0.79 0.77 0.84 0.83 0.84 0.84 0.84 0.82 0.84 0.83 0.84 0.83 0.82 0.82 0.81 0.82 0.82 0.82 0.82 0.82
0.84 0.87 0.87 0.78 0.69 0.65 0.83 0.87 0.87 0.84 0.80 0.79 0.84 0.87 0.87 0.88 0.87 0.87 0.83 0.87 0.87 0.87 0.87 0.86 0.83 0.85 0.85 0.85 0.86 0.85
0.85 0.90 0.89 0.76 0.63 0.60 0.85 0.90 0.91 0.85 0.78 0.77 0.86 0.90 0.90 0.91 0.89 0.89 0.85 0.89 0.89 0.90 0.90 0.90 0.85 0.88 0.88 0.88 0.88 0.88
0.87 0.89 0.86 0.69 0.56 0.53 0.86 0.90 0.89 0.80 0.72 0.71 0.85 0.90 0.90 0.89 0.86 0.87 0.87 0.90 0.90 0.90 0.90 0.89 0.86 0.88 0.88 0.89 0.88 0.89
0.90 0.93 0.91 0.74 0.61 0.56 0.90 0.93 0.93 0.87 0.78 0.80 0.90 0.92 0.92 0.93 0.93 0.91 0.90 0.91 0.92 0.93 0.92 0.92 0.89 0.91 0.91 0.91 0.91 0.91
0.90 0.93 0.90 0.73 0.59 0.55 0.89 0.93 0.94 0.86 0.77 0.77 0.90 0.93 0.94 0.92 0.92 0.91 0.89 0.92 0.93 0.93 0.93 0.93 0.89 0.91 0.91 0.92 0.92 0.92
0.87 0.91 0.88 0.59 0.44 0.37 0.85 0.93 0.91 0.80 0.65 0.65 0.85 0.92 0.93 0.91 0.90 0.88 0.86 0.91 0.91 0.93 0.94 0.92 0.85 0.90 0.90 0.90 0.91 0.92
0.96 0.95 0.88 0.58 0.41 0.36 0.94 0.97 0.95 0.79 0.62 0.64 0.93 0.98 0.97 0.94 0.90 0.90 0.94 0.97 0.97 0.97 0.96 0.95 0.95 0.97 0.97 0.97 0.97 0.97
0.96 0.92 0.79 0.38 0.25 0.22 0.94 0.97 0.91 0.62 0.41 0.43 0.93 0.98 0.97 0.87 0.81 0.78 0.95 0.98 0.98 0.97 0.96 0.96 0.95 0.98 0.98 0.98 0.98 0.98
0.95 0.90 0.75 0.35 0.25 0.21 0.93 0.97 0.91 0.60 0.39 0.40 0.93 0.98 0.97 0.86 0.77 0.76 0.93 0.98 0.98 0.97 0.96 0.96 0.94 0.97 0.98 0.97 0.97 0.97
0.95 0.92 0.78 0.38 0.24 0.21 0.92 0.97 0.92 0.64 0.42 0.44 0.92 0.98 0.96 0.89 0.80 0.81 0.92 0.98 0.97 0.97 0.96 0.95 0.93 0.97 0.97 0.98 0.97 0.97
0.97 0.76 0.54 0.23 0.15 0.13 0.92 0.91 0.74 0.40 0.24 0.26 0.91 0.96 0.90 0.68 0.55 0.55 0.92 0.97 0.96 0.90 0.89 0.86 0.95 0.98 0.97 0.97 0.97 0.97
0.88 0.87 0.81 0.60 0.49 0.46 0.87 0.90 0.87 0.74 0.63 0.64 0.87 0.91 0.90 0.86 0.83 0.82 0.87 0.90 0.90 0.90 0.89 0.89 0.87 0.90 0.90 0.90 0.90 0.89AUC of Distinguishing Human T ext from Generations
Figure 8  AUC heatmap for cross-detection, where the rows are generative models and columns are the surrogate detector
models from the Pythia family, at different training step checkpoints ( 1k,5k,10k,50k,100kand143k), both sorted
by model size. We can see that partially trained models are better detectors.
Detector ModelOPT-6.7B
MeanGenerative Model-0.08 -0.08 -0.10 -0.15 -0.25 -0.24 -0.09 -0.07 -0.08 -0.11 -0.13 -0.15 -0.07 -0.07 -0.06 -0.07 -0.08 -0.09 -0.08 -0.07 -0.07 -0.08 -0.08 -0.07 -0.09 -0.08 -0.08 -0.07 -0.07 -0.08
-0.00 0.02 -0.00 -0.04 -0.10 -0.12 0.01 0.02 0.01 -0.02 -0.03 -0.05 0.01 0.01 0.01 0.01 0.02 0.00 0.01 0.01 0.01 0.01 -0.01 0.00 -0.01 -0.00 0.00 -0.00 -0.01 -0.01
-0.10 -0.06 -0.06 -0.16 -0.25 -0.29 -0.11 -0.07 -0.06 -0.10 -0.14 -0.15 -0.10 -0.07 -0.07 -0.05 -0.07 -0.06 -0.11 -0.07 -0.07 -0.07 -0.06 -0.08 -0.11 -0.08 -0.09 -0.08 -0.07 -0.09
-0.13 -0.08 -0.09 -0.22 -0.35 -0.39 -0.14 -0.08 -0.08 -0.13 -0.20 -0.21 -0.13 -0.08 -0.08 -0.08 -0.09 -0.09 -0.13 -0.09 -0.09 -0.09 -0.09 -0.09 -0.14 -0.10 -0.10 -0.10 -0.10 -0.10
-0.10 -0.09 -0.12 -0.29 -0.42 -0.45 -0.12 -0.08 -0.09 -0.18 -0.26 -0.27 -0.13 -0.07 -0.08 -0.09 -0.12 -0.11 -0.10 -0.08 -0.08 -0.08 -0.08 -0.09 -0.12 -0.10 -0.10 -0.09 -0.10 -0.09
-0.08 -0.06 -0.08 -0.25 -0.38 -0.42 -0.08 -0.05 -0.05 -0.11 -0.20 -0.18 -0.08 -0.06 -0.06 -0.05 -0.06 -0.07 -0.08 -0.07 -0.06 -0.06 -0.06 -0.06 -0.10 -0.07 -0.08 -0.07 -0.08 -0.08
-0.09 -0.06 -0.09 -0.26 -0.40 -0.44 -0.10 -0.06 -0.05 -0.13 -0.22 -0.22 -0.09 -0.06 -0.05 -0.06 -0.07 -0.08 -0.10 -0.07 -0.06 -0.06 -0.06 -0.06 -0.09 -0.07 -0.08 -0.07 -0.07 -0.07
-0.13 -0.08 -0.12 -0.40 -0.56 -0.62 -0.15 -0.07 -0.09 -0.20 -0.35 -0.35 -0.14 -0.08 -0.07 -0.08 -0.10 -0.12 -0.14 -0.08 -0.08 -0.06 -0.06 -0.08 -0.14 -0.10 -0.09 -0.10 -0.09 -0.08
-0.04 -0.05 -0.12 -0.42 -0.59 -0.64 -0.06 -0.
 ## PROFNAME
 Taylor Berg-Kirkpatrick
 ## AUTHORID
 1400419309
 ## AUTHORNAME
 Taylor Berg-Kirkpatrick
 ## AUTHORURL
 https://www.semanticscholar.org/author/1400419309
 ## AUTHORHINDEX
 36
 ## AUTHORAFFILIATIONS
 []
 ## AUTHORPAPERCOUNT
 112
 ## AUTHORCITATIONCOUNT
 5655
 ## PAPERID
 1527d3b661154ff7310fa2759b6dd0ddfd559492
 ## EXTERNALIDS
 {'ArXiv': '2305.09859', 'DBLP': 'journals/corr/abs-2305-09859', 'DOI': '10.48550/arXiv.2305.09859', 'CorpusId': 258740888}
 ## URL
 https://www.semanticscholar.org/paper/1527d3b661154ff7310fa2759b6dd0ddfd559492
 ## TITLE
 Smaller Language Models are Better Black-box Machine-Generated Text Detectors
 ## ABSTRACT
 With the advent of fluent generative language models that can produce convincing utterances very similar to those written by humans, distinguishing whether a piece of text is machine-generated or human-written becomes more challenging and more important, as such models could be used to spread misinformation, fake news, fake reviews and to mimic certain authors and figures. To this end, there have been a slew of methods proposed to detect machine-generated text. Most of these methods need access to the logits of the target model or need the ability to sample from the target. One such black-box detection method relies on the observation that generated text is locally optimal under the likelihood function of the generator, while human-written text is not. We find that overall, smaller and partially-trained models are better universal text detectors: they can more precisely detect text generated from both small and larger models. Interestingly, we find that whether the detector and generator were trained on the same data is not critically important to the detection success. For instance the OPT-125M model has an AUC of 0.81 in detecting ChatGPT generations, whereas a larger model from the GPT family, GPTJ-6B, has AUC of 0.45.
 ## VENUE
 arXiv.org
 ## YEAR
 2023
 ## REFERENCECOUNT
 38
 ## CITATIONCOUNT
 23
 ## INFLUENTIALCITATIONCOUNT
 1
 ## ISOPENACCESS
 True
 ## OPENACCESSPDF
 {'url': 'http://arxiv.org/pdf/2305.09859', 'status': None}
 ## FIELDSOFSTUDY
 ['Computer Science']
 ## JOURNAL
 {'volume': 'abs/2305.09859', 'name': 'ArXiv'}
 ## AUTHORS
 [{'authorId': '2115471757', 'name': 'Fatemehsadat Mireshghallah'}, {'authorId': '2138547910', 'name': 'Justus Mattern'}, {'authorId': '39219411', 'name': 'Sicun Gao'}, {'authorId': '2520493', 'name': 'R. Shokri'}, {'authorId': '1400419309', 'name': 'Taylor Berg-Kirkpatrick'}]
 ## TLDR
 Overall, smaller and partially-trained models are better universal text detectors: they can more precisely detect text generated from both small and larger models.
 03 -0.05 -0.21 -0.38 -0.36 -0.07 -0.02 -0.03 -0.06 -0.10 -0.10 -0.06 -0.03 -0.03 -0.03 -0.04 -0.05 -0.05 -0.03 -0.03 -0.03 -0.03 -0.03
-0.04 -0.08 -0.21 -0.62 -0.74 -0.78 -0.06 -0.03 -0.09 -0.38 -0.59 -0.57 -0.07 -0.02 -0.03 -0.13 -0.19 -0.22 -0.05 -0.02 -0.02 -0.03 -0.04 -0.04 -0.05 -0.02 -0.02 -0.02 -0.02 -0.02
-0.05 -0.10 -0.25 -0.65 -0.75 -0.79 -0.07 -0.02 -0.09 -0.40 -0.61 -0.60 -0.07 -0.02 -0.03 -0.14 -0.23 -0.24 -0.07 -0.02 -0.02 -0.03 -0.04 -0.04 -0.05 -0.03 -0.02 -0.03 -0.03 -0.03
-0.05 -0.08 -0.21 -0.62 -0.76 -0.79 -0.08 -0.03 -0.08 -0.35 -0.58 -0.56 -0.08 -0.02 -0.03 -0.11 -0.20 -0.19 -0.08 -0.02 -0.03 -0.03 -0.03 -0.05 -0.07 -0.03 -0.03 -0.02 -0.03 -0.03
-0.03 -0.24 -0.46 -0.77 -0.85 -0.87 -0.08 -0.08 -0.25 -0.60 -0.75 -0.73 -0.09 -0.03 -0.10 -0.32 -0.44 -0.45 -0.07 -0.02 -0.04 -0.10 -0.11 -0.14 -0.05 -0.02 -0.02 -0.02 -0.02 -0.03
-0.07 -0.08 -0.15 -0.37 -0.49 -0.53 -0.09 -0.05 -0.08 -0.22 -0.34 -0.34 -0.08 -0.05 -0.05 -0.09 -0.13 -0.14 -0.08 -0.05 -0.05 -0.05 -0.06 -0.06 -0.08 -0.06 -0.06 -0.05 -0.06 -0.06AUC of Distinguishing Human T ext from Generations
Figure 9  AUC difference between self-detection and cross-detection heatmap (to better see how close cross-detection
comes to self detection), here the rows are generative models and columns are the surrogate detector models from the
Pythia family, at different training step checkpoints ( 1k,5k,10k,50k,100kand143k), both sorted by model size. This
plot is basically Figure 8, where each cell in a row is subtracted by the self-detection AUC for that row.OPT-6.7B
Detector ModelOPT-6.7B
MeanGenerative Model0.00 -0.24 -0.21 -0.20 -0.17 -0.17 -0.18 -0.17 -0.07 -0.15 -0.15 -0.16 -0.15 -0.16 -0.09 -0.14 -0.14 -0.10 -0.13 -0.15 -0.17 -0.15 -0.15
-0.22 0.00 -0.17 -0.17 -0.14 -0.21 -0.15 -0.16 -0.14 -0.14 -0.18 -0.15 -0.14 -0.18 -0.14 -0.14 -0.14 -0.13 -0.13 -0.17 -0.17 -0.13 -0.14
-0.32 -0.31 -0.22 -0.22 0.00 -0.17 -0.15 -0.15 -0.15 -0.12 -0.13 -0.12 -0.10 -0.13 -0.12 -0.11 -0.12 -0.11 -0.10 -0.12 -0.16 -0.13 -0.13
-0.32 -0.36 -0.26 -0.25 -0.18 0.00 -0.16 -0.15 -0.12 -0.12 -0.05 -0.10 -0.09 -0.05 -0.07 -0.09 -0.09 -0.07 -0.08 -0.06 -0.10 -0.11 -0.10
-0.25 -0.35 -0.28 -0.28 -0.21 -0.17 -0.19 -0.19 0.00 -0.15 -0.11 -0.13 -0.11 -0.11 -0.05 -0.09 -0.09 -0.05 -0.08 -0.09 -0.11 -0.11 -0.10
-0.38 -0.39 -0.27 -0.28 -0.16 -0.18 -0.15 -0.13 -0.15 0.00 -0.11 -0.07 -0.07 -0.09 -0.06 -0.06 -0.07 -0.06 -0.05 -0.08 -0.09 -0.08 -0.07
-0.38 -0.42 -0.30 -0.30 -0.21 -0.09 -0.17 -0.16 -0.13 -0.13 0.00 -0.08 -0.07 -0.03 -0.05 -0.07 -0.07 -0.05 -0.06 -0.03 -0.07 -0.08 -0.08
-0.54 -0.54 -0.42 -0.44 -0.31 -0.17 -0.25 -0.25 -0.21 -0.18 -0.07 -0.10 -0.09 0.00 -0.05 -0.06 -0.06 -0.04 -0.05 -0.03 -0.06 -0.08 -0.07
-0.48 -0.52 -0.43 -0.43 -0.32 -0.25 -0.25 -0.25 -0.16 -0.19 -0.14 -0.08 -0.08 -0.08 0.00 -0.04 -0.04 -0.01 -0.03 -0.03 -0.03 -0.03 -0.04
-0.60 -0.62 -0.57 -0.57 -0.48 -0.41 -0.40 -0.41 -0.31 -0.32 -0.26 -0.15 -0.16 -0.16 -0.04 -0.04 -0.04 0.00 -0.03 -0.03 -0.02 -0.03 -0.02
-0.69 -0.67 -0.63 -0.64 -0.54 -0.50 -0.46 -0.48 -0.46 -0.38 -0.34 -0.18 -0.19 -0.23 -0.09 -0.04 -0.04 -0.04 0.00 -0.04 -0.02 -0.02 -0.03
-0.69 -0.67 -0.60 -0.61 -0.52 -0.40 -0.43 -0.42 -0.40 -0.35 -0.23 -0.16 -0.15 -0.11 -0.07 -0.04 -0.04 -0.02 -0.03 0.00 -0.00 -0.03 -0.03
-0.78 -0.74 -0.75 -0.75 -0.68 -0.74 -0.65 -0.64 -0.65 -0.57 -0.60 -0.38 -0.39 -0.46 -0.24 -0.11 -0.12 -0.09 -0.07 -0.11 0.00 -0.03 -0.03
-0.43 -0.45 -0.39 -0.40 -0.30 -0.27 -0.28 -0.27 -0.23 -0.22 -0.18 -0.14 -0.14 -0.14 -0.08 -0.08 -0.08 -0.06 -0.07 -0.07 -0.08 -0.08 -0.08AUC of Distinguishing Human T ext from Generations
0.0Figure 10  AUC difference between self-detection and cross-detection heatmap (to better see how close cross-detection
comes to self detection), where the rows are generative models and columns are the surrogate detector models, both sorted
by model size. This plot is basically Figure 2, where each cell in a row is subtracted by the self-detection AUC for that row.108109
0.000.050.100.150.20CurvatureMachine-generated
Human-written(a) T5-3B
0.000.050.100.150.200.250.30CurvatureMachine-generated
#Params0.10.20.30.40.50.6CurvatureMachine-generated
#Params0.60.70.80.91.0AUC
(d) AUCs for different perturbation (masking) models
Figure 11  The effect of changing the perturbation
(masking) model on curvature values and self-detection
power of different models with different sizes (AUC).
ChatGPT GPT3 OPT-6.7B OPT-125M Mean
Generative Model0.20.30.40.50.60.70.80.91.0AUCDetector Model
OPT-6.7BFigure 12  Summary of the cross-detection area under
the ROC curve (AUC) results for a selection of generative
(the4models over the X axis) and detector (OPT-125M
and OPT-6.7B) models. We can see that the smaller OPT
model is a better universal cross-detector. Full results are