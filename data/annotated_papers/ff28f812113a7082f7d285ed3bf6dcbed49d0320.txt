
 ## PROFNAME
 Matthias Grabmair
 ## AUTHORID
 2869551
 ## AUTHORNAME
 Matthias Grabmair
 ## AUTHORURL
 https://www.semanticscholar.org/author/2869551
 ## AUTHORHINDEX
 13
 ## AUTHORAFFILIATIONS
 []
 ## AUTHORPAPERCOUNT
 38
 ## AUTHORCITATIONCOUNT
 464
 ## PAPERID
 ff28f812113a7082f7d285ed3bf6dcbed49d0320
 ## EXTERNALIDS
 {'ACL': '2023.eacl-main.78', 'DBLP': 'journals/corr/abs-2302-00768', 'ArXiv': '2302.00768', 'DOI': '10.48550/arXiv.2302.00768', 'CorpusId': 256503823}
 ## URL
 https://www.semanticscholar.org/paper/ff28f812113a7082f7d285ed3bf6dcbed49d0320
 ## TITLE
 Leveraging Task Dependency and Contrastive Learning for Case Outcome Classification on European Court of Human Rights Cases
 ## ABSTRACT
 We report on an experiment in case outcome classification on European Court of Human Rights cases where our model first learns to identify the convention articles allegedly violated by the state from case facts descriptions, and subsequently uses that information to classify whether the court finds a violation of those articles. We assess the dependency between these two tasks at the feature and outcome level. Furthermore, we leverage a hierarchical contrastive loss to pull together article-specific representations of cases at the higher level, leading to distinctive article clusters. The cases in each article cluster are further pulled closer based on their outcome, leading to sub-clusters of cases with similar outcomes. Our experiment results demonstrate that, given a static pre-trained encoder, our models produce a small but consistent improvement in classification performance over single-task and joint models without contrastive loss.
 ## VENUE
 Conference of the European Chapter of the Association for Computational Linguistics
 ## YEAR
 2023
 ## REFERENCECOUNT
 49
 ## CITATIONCOUNT
 4
 ## INFLUENTIALCITATIONCOUNT
 0
 ## ISOPENACCESS
 True
 ## OPENACCESSPDF
 {'url': 'http://arxiv.org/pdf/2302.00768', 'status': None}
 ## FIELDSOFSTUDY
 ['Computer Science']
 ## JOURNAL
 {'volume': 'abs/2302.00768', 'name': 'ArXiv'}
 ## AUTHORS
 [{'authorId': '2203911024', 'name': 'Santosh T.Y.S.S'}, {'authorId': '134765210', 'name': 'Santosh T.Y.S.S'}, {'authorId': '2203912234', 'name': 'Phillip Kemper'}, {'authorId': '2869551', 'name': 'Matthias Grabmair'}]
 ## TLDR
 nan
 Leveraging Task Dependency and Contrastive Learning for Case
Outcome Classiﬁcation on European Court of Human Rights Cases
Santosh T.Y.S.S, Marcel Perez San Blas, Phillip Kemper, Matthias Grabmair
School of Computation, Information, and Technology 
Technical University of Munich, Germany
{santosh.tokala, marcel.perez, phillip.kemper, matthias.grabmair}@tum.de
We report on an experiment in case outcome
classiﬁcation on European Court of Human
Rights cases where our model ﬁrst learns to
identify the convention articles allegedly violated
 by the state from case facts descriptions,
and subsequently uses that information to classify
 whether the court ﬁnds a violation of those
articles. We assess the dependency between
these two tasks at the feature and outcome
level. Furthermore, we leverage a hierarchical
contrastive loss to pull together article-speciﬁc
representations of cases at the higher level,
leading to distinctive article clusters. The
cases in each article cluster are further pulled
closer based on their outcome, leading to subclusters
 of cases with similar outcomes. Our
experiment results demonstrate that, given a
static pre-trained encoder, our models produce
a small but consistent improvement in classiﬁcation
 performance over single-task and joint
models without contrastive loss.
The NLP task of classifying case outcome information
 from a textual statement of case facts is
generally referred to as Legal Judgement Prediction
 (LJP)(e.g., Aletras et al. 2016  Chalkidis et al.
2019). It has been studied using corpora from different
 jurisdictions, such as the European Court
of Human Rights (ECtHR) (Chalkidis et al., 2019,
2021, 2022b  Aletras et al., 2016  Medvedeva et al.,
2020  Santosh et al., 2022, 2023), Chinese Criminal
Courts (Luo et al., 2017  Zhong et al., 2018  Yue
et al., 2021  Zhong et al., 2020  Yang et al., 2019),
US Supreme Court (Katz et al., 2017  Kaufman
et al., 2019), Indian Supreme Court (Malik et al.,
2021  Shaikh et al., 2020), the French court of Cassation
 (  Sulea et al., 2017), Brazilian courts (Bertalan
 and Ruiz, 2020), the Federal Supreme Court
of Switzerland (Niklaus et al., 2021), the Turkish
Constitutional court (Sert et al., 2021  Mumcuo  gluet al., 2021), UK courts (Strickson and De La Iglesia,
 2020), German courts (Waltl et al., 2017), the
Philippine Supreme court (Virtucio et al., 2018),
and the Thailand Supreme Court (Kowsrihawat
In this work, we experiment with classifying
case outcomes in the ECtHR A and B benchmark
tasks introduced by LexGLUE (Chalkidis et al.,
2022b). Task B is to identify the set of articles
of the European Convention of Human Rights
(ECHR) that the claimant alleges to have been violated,
 while Task A s goal is to classify which of
the convention s articles has been deemed violated
by the court. The input for both tasks is the case s
fact description that has been extracted from the
published judgement document. It should be noted
that, despite these tasks being typically referred to
as instances of  legal judgement prediction , the
fact statements are typically not ﬁnalized until the
decision outcome is known, making the task effectively
 one of retrospective classiﬁcation rather than
prediction (Medvedeva et al., 2021). While this
does lead to distracting and confounding phenomena
 (see our prior work in Santosh et al. 2022), the
dataset remains a useful resource for the development
 of NLP models that analyze these fact statements
 for text patterns that correspond to speciﬁc
convention articles as drafted by the court. Consequently,
 we speak of case outcome classiﬁcation
Positive instances for Task A are cases in which
an article was deemed violated by the court. Negative
 instances, however, usually encompass not
only cases in which that particular article was alleged
 and considered not violated, but also the
cases in which the particular article was not alleged
 in the ﬁrst place. Given that the conditional
probability of a positive task A label (violation)
given its task B label (allegation) can be very high
in the LexGLUE dataset, we posit that models can
fall into this pitfall of identifying dominant articlesarXiv 2302.00768v3  [cs.CL]  13 Feb 2023with high conditional violation probability, missing
 information speciﬁc to violation classiﬁcation.
Thus, we experiment with multi-task architectures
to decouple these reasoning steps involved in Task
A . This is similar to work in Chinese criminal
cases judgement prediction carried out in Zhong
et al. 2018  Yang et al. 2019  Xu et al. 2020  Yue
et al. 2021 that coordinated multiple outcome variables
 (law articles, criminal charges, and penalty
In the ECtHR context, most of the previous
works (Chalkidis et al., 2019, 2021, 2022b  Clavié
and Alphonsus, 2021  Santosh et al., 2022, 2023)
employed independent models for allegation identiﬁcation
 and violation classiﬁcation. Concurrent
work by Valvoda et al. 2023 has recently explored
multi-task joint models that learn Task A and Task
B simultaneously. Their Claim-Outcome model
decomposes them into two independent classiﬁers
with separate encoders for each allegation and violation
 classiﬁcation given allegation information.
Our work differs in three ways  (i) We learn the
joint representation for both tasks through a shared
encoder following our intuition that the shared representation
 is beneﬁcial as both tasks require similar
 features at the lower level  (ii) We model dependency
 from allegation to violation classiﬁcation
at both the allegation outcome and feature levels.
Conditioning violation classiﬁcation on the allegation
 outcome leads to higher performance, but
we ﬁnd that passing along feature level information
 yields additional improvement. This way, the
violation branch will focus on identifying speciﬁc
information required for determining violation than
falling prey to only allegation level features. (iii)
We also model correlations among different articles
that tend to be concurrently alleged.
Inspired by recent advances in contrastive learning
 to learn effective representations (Khosla et al.,
2020), we further devise a two-level hierarchical
contrastive loss for COC. First, we strive to maximize
 the latent space distance between different
article representations, which assists the model in
learning distinct article-speciﬁc views of case facts.
Second, we apply contrastive learning within each
article latent space to form distinct sub-clusters of
similar outcome cases. Unlike our two-level hierarchical
 contrastive learning, a single-level one has
been explored for LJP in the concurrent work by
Our experiments demonstrate that, given a static
Figure 1  Our architecture capturing task dependency
from allegation to violation classiﬁcation branch.
pre-trained encoder, our models outperform singletask
 and joint models without contrastive loss by a
small but consistent margin, with larger improvements
 for sparse classes in classiﬁcation performance.
Our model takes as input the ca
 ## PROFNAME
 Matthias Grabmair
 ## AUTHORID
 2869551
 ## AUTHORNAME
 Matthias Grabmair
 ## AUTHORURL
 https://www.semanticscholar.org/author/2869551
 ## AUTHORHINDEX
 13
 ## AUTHORAFFILIATIONS
 []
 ## AUTHORPAPERCOUNT
 38
 ## AUTHORCITATIONCOUNT
 464
 ## PAPERID
 ff28f812113a7082f7d285ed3bf6dcbed49d0320
 ## EXTERNALIDS
 {'ACL': '2023.eacl-main.78', 'DBLP': 'journals/corr/abs-2302-00768', 'ArXiv': '2302.00768', 'DOI': '10.48550/arXiv.2302.00768', 'CorpusId': 256503823}
 ## URL
 https://www.semanticscholar.org/paper/ff28f812113a7082f7d285ed3bf6dcbed49d0320
 ## TITLE
 Leveraging Task Dependency and Contrastive Learning for Case Outcome Classification on European Court of Human Rights Cases
 ## ABSTRACT
 We report on an experiment in case outcome classification on European Court of Human Rights cases where our model first learns to identify the convention articles allegedly violated by the state from case facts descriptions, and subsequently uses that information to classify whether the court finds a violation of those articles. We assess the dependency between these two tasks at the feature and outcome level. Furthermore, we leverage a hierarchical contrastive loss to pull together article-specific representations of cases at the higher level, leading to distinctive article clusters. The cases in each article cluster are further pulled closer based on their outcome, leading to sub-clusters of cases with similar outcomes. Our experiment results demonstrate that, given a static pre-trained encoder, our models produce a small but consistent improvement in classification performance over single-task and joint models without contrastive loss.
 ## VENUE
 Conference of the European Chapter of the Association for Computational Linguistics
 ## YEAR
 2023
 ## REFERENCECOUNT
 49
 ## CITATIONCOUNT
 4
 ## INFLUENTIALCITATIONCOUNT
 0
 ## ISOPENACCESS
 True
 ## OPENACCESSPDF
 {'url': 'http://arxiv.org/pdf/2302.00768', 'status': None}
 ## FIELDSOFSTUDY
 ['Computer Science']
 ## JOURNAL
 {'volume': 'abs/2302.00768', 'name': 'ArXiv'}
 ## AUTHORS
 [{'authorId': '2203911024', 'name': 'Santosh T.Y.S.S'}, {'authorId': '134765210', 'name': 'Santosh T.Y.S.S'}, {'authorId': '2203912234', 'name': 'Phillip Kemper'}, {'authorId': '2869551', 'name': 'Matthias Grabmair'}]
 ## TLDR
 nan
 se fact description
as token encodings x {x1,x2,...,x m}where
xi {xi1,xi2,...,x in}and outputs the set of articles
 claimed to be alleged by the applicant (Task
B) and set of articles deemed to be violated by the
court (Task A) as multi-hot vectors. xiandxip
denoteithsentence and pthtoken ofithsentence
of the case facts respectively. mandndenote the
number of sentences and tokens in the ithfact sentence,
 respectively. Our model is built on top of a
hierarchical attention network (Yang et al., 2016),
which we chose to be able to process the very long
fact description inputs. Our model contains three
main components  (1) encoding layer, (2) ArticleSpeciﬁc
 Case representation and (3) Task Dependency
 learning. See Fig. 1 for an overview of our
Encoding layer  We encode each sentence in the
case facts description with LegalBERT (Chalkidis
et al., 2020) to obtain the token level representations{zi1,zi2,...,z
 in}. Sentence level representations
 are then computed using a token-level atten-tion mechanism as follows 
uit tanh(Wwzit bw) &αit exp(uituw) 
whereWw,bwanduware trainable parameters.
The sentence level representations {f1,...,f m}
are passed through a GRU encoder to obtain
context-aware representations of the case facts
Article-Speciﬁc Case Representation  We disentangle
 the input case facts into multiple articleview-representations
 c {c1,c2,...,c k}where
kis the total number of modeled convention articles,
 through aggregating context-aware sentencelevel
 representations husingksentence-level attention
 mechanisms similar to eq. 1 for every article
individually. Through this article-speciﬁc attention
 mechanism, sentences relevant to a speciﬁc
article are emphasized and intended to aid in ﬁnegrained
 reasoning of outcome prediction for every
article. This is helpful especially for sparser classes
and mitigates the tendency of models to focus on
skewed dominant articles. This is distinct from previous
 works (Chalkidis et al., 2019, 2021, 2022b 
Santosh et al., 2022) which use a single vector representation
Task Dependency Learning  To capture both the
inter-article correlations for allegation, violation
classiﬁcation, and the inter-task dependency, we
again use a two-step architecture. First, we apply
a multi-head self-attention layer (Vaswani et al.,
2017) to the obtained article-speciﬁc representations
 of case cto allow interactions among articles
(e.g., some articles are typically alleged together
while others usually occur in isolation) and obtain
article-interaction-aware allegation feature representationsc 
passed through karticle-speciﬁc Task B classiﬁcation
 layers to obtain the binary outcome obcorresponding
 to each article for allegation classiﬁcation,
which are then concatenated into a multi-hot vector.
Then we utilize the task B allegation information
 to enhance task A violation classiﬁcation to
capture the task dependency. We concatenate the
obtained article-interaction-aware allegation representationsc 
band allegation label probability logits
b1with article-speciﬁc case representations cto
obtain the enhanced article-speciﬁc representation
for Task A as cai  [ci,c 
 use non-binarized response (i.e. probability logits) as
it avoids the information loss that can occur in the probability
space due to binarization.ploy multi-head self-attention mechanism on these
enhanced article-aware representations cafor violation
 prediction to capture the correlations that
exist between violation of different articles. Finally,
the obtained representations are passed through k
article-speciﬁc Task A classiﬁcation layers to obtain
 the binary outcome oacorresponding to each
article s violation output. To be able to evaluate
the effectiveness of our interaction architecture in
a clean way, we freeze the LegalBERT encoder
weights in all our experiments.
2.1 Hierarchical Contrastive Loss
Contrastive learning has recently gained attention
as a technique to obtain effective representations.
In essence, it involves pulling together an  anchor
point  and its related samples while pushing it away
from unrelated samples in the embedding space.
Originally developed in self-supervised learning
(Chen et al., 2020  Henaff, 2020), it has since been
adopted in supervised settings (Khosla et al., 2020)
where samples with the same/different labels are
deemed related/unrelated with respect to an anchor.
In this work, we use a hierarchical contrastive
loss (Liang et al., 2022) alongside the standard
binary cross entropy loss on the task outcome probability.
 On the higher level, this is intended to form
distinctive clusters of article-speciﬁc case representations.
 We hypothesize that this distinctiveness
maximization constraint in turn helps the articlespeciﬁc
 representation component to extract salient
information with respect to each article more effectively.
 At the lower level, inside the latent space for
each article, we further perform contrastive learning
 among cases based on their outcome for tasks
A and B, respectively. This allows the positive
outcome representations of cases under a speciﬁc
article to stay closer and separate from the negative
outcome cases, leading to formation of sub-clusters.
We apply contrastive losses for Task A and Task B
separately on the interaction-aware representations.
It is calculated as the mean loss computed based
on every article based representation as an anchor
point. The loss for the interaction-aware representation
 of thejthcase speciﬁc to the itharticle for Task
bijas an anchor point is calculated as follows 
blm l  i&m  j}(all rep-resentations except the anchor point), Q(i,j)  
blm l i&m  j)}(all representations
which share the same article as the anchor point),
blm l i&yij ylm&m  j},
yijthe denotes binary outcome label of case jwith
respect to article i(all representations which share
the same article and outcome of that article as the
anchor point). τaandτcare scalar temperature
parameters that control the penalties on negative
samples. The ﬁrst term in the above equation 2
denotes the contrastive loss among article representations
 (i.e., for a given anchor point, positive pairs
are obtained by article-aware representations of
cases in the batch which share the same article with
the anchor point  negative pairs are the remaining
article representations). The second term contrasts
the cases based on their task outcome within speciﬁc
 article representations. Contrastive learning
has shown to be more effective with larger batch
sizes (Radford et al., 2021  Chen et al., 2020). To
account for smaller batch size due to computational
constraints incurred with our hierarchical setup, we
use a memory bank (Wu et al., 2018) which progressively
 reuses the representations from previous
batches in computing the contrastive loss.
3 Experiments & Discussion
3.1 Dataset & Baseline Models
We experiment on the ECHR task A and B datasets
of LexGLUE (Chalkidis et al., 2022b), which consist
 of 11k case fact descriptions chronologically
split
 ## PROFNAME
 Matthias Grabmair
 ## AUTHORID
 2869551
 ## AUTHORNAME
 Matthias Grabmair
 ## AUTHORURL
 https://www.semanticscholar.org/author/2869551
 ## AUTHORHINDEX
 13
 ## AUTHORAFFILIATIONS
 []
 ## AUTHORPAPERCOUNT
 38
 ## AUTHORCITATIONCOUNT
 464
 ## PAPERID
 ff28f812113a7082f7d285ed3bf6dcbed49d0320
 ## EXTERNALIDS
 {'ACL': '2023.eacl-main.78', 'DBLP': 'journals/corr/abs-2302-00768', 'ArXiv': '2302.00768', 'DOI': '10.48550/arXiv.2302.00768', 'CorpusId': 256503823}
 ## URL
 https://www.semanticscholar.org/paper/ff28f812113a7082f7d285ed3bf6dcbed49d0320
 ## TITLE
 Leveraging Task Dependency and Contrastive Learning for Case Outcome Classification on European Court of Human Rights Cases
 ## ABSTRACT
 We report on an experiment in case outcome classification on European Court of Human Rights cases where our model first learns to identify the convention articles allegedly violated by the state from case facts descriptions, and subsequently uses that information to classify whether the court finds a violation of those articles. We assess the dependency between these two tasks at the feature and outcome level. Furthermore, we leverage a hierarchical contrastive loss to pull together article-specific representations of cases at the higher level, leading to distinctive article clusters. The cases in each article cluster are further pulled closer based on their outcome, leading to sub-clusters of cases with similar outcomes. Our experiment results demonstrate that, given a static pre-trained encoder, our models produce a small but consistent improvement in classification performance over single-task and joint models without contrastive loss.
 ## VENUE
 Conference of the European Chapter of the Association for Computational Linguistics
 ## YEAR
 2023
 ## REFERENCECOUNT
 49
 ## CITATIONCOUNT
 4
 ## INFLUENTIALCITATIONCOUNT
 0
 ## ISOPENACCESS
 True
 ## OPENACCESSPDF
 {'url': 'http://arxiv.org/pdf/2302.00768', 'status': None}
 ## FIELDSOFSTUDY
 ['Computer Science']
 ## JOURNAL
 {'volume': 'abs/2302.00768', 'name': 'ArXiv'}
 ## AUTHORS
 [{'authorId': '2203911024', 'name': 'Santosh T.Y.S.S'}, {'authorId': '134765210', 'name': 'Santosh T.Y.S.S'}, {'authorId': '2203912234', 'name': 'Phillip Kemper'}, {'authorId': '2869551', 'name': 'Matthias Grabmair'}]
 ## TLDR
 nan
  into training (2001 2016, 9k cases), validation
(2016 2017, 1k cases), and test sets (2017-2019,
1k cases). The label set for both tasks include 10
prominent ECHR articles. Implementation details
are given in Appendix A. We compare our models
against the following baselines 
Task A/B only  We train single-task models only
on task A and B labels, respectively. Their architecture
 is based on our model with contrastive loss,
task dependency and article-speciﬁc representation
Multi-task  Using the same architecture, we also
develop a model for both task A and B that is
trained in classic multi-task fashion with separate
classiﬁcation heads without article-speciﬁc representations
 and task dependency components.
3.2 Performance Evaluation
Following Chalkidis et al. 2022b, we report microF1
 (µ-F1) and macro-F1 (m-F1) scores across theTable 1  Results on Task A and B.  feat. ,  lab, .  Cont. 
indicate feature, label and contrastive, respectively
Model µ-F1 m-F1µ-F1 m-F1 hm-F1
Task B only 76.20 67.15 - - Task
 A only - - 68.42 56.26 54.14
Multi-task 78.17 69.16 69.29 58.05 55.57
Our Method 79.29 70.97 71.26 65.24 60.90
w/o feat. & lab. 78.93 71.45 70.07 59.14 57.09
w/o feat. 78.59 71.56 70.68 63.93 59.28
w/o label 79.09 71.38 70.32 64.12 61.70
only gold lab. 78.21 70.03 81.46 78.93 66.59
gold lab.   feat. 77.68 70.40 83.19 78.79 67.42
w/o outcome Cont. 78.42 69.48 69.86 60.84 57.62
w/o article Cont. 79.02 71.14 71.16 64.68 59.86
Task A Cont. - - 70.16 62.14 58.12
Task B Cont. 78.16 69.42 - - 10
 ECtHR articles contained in the dataset. We also
report hard-macro-F1 (hm-F1) for Task A following
 Santosh et al. 2022, which is the mean F1-score
computed for each article where cases with that
article having been violated are considered as positive
 instances, and cases with that article being
alleged but not found to have been violated as negative
 instances. This forms the most critical measure
for violation classiﬁcation as it conditions on allegation.
We compare the performance of our method with
the baselines in the ﬁrst four rows of Table 1. The
multi-task method performs better than the individual
 tasks alone, validating the dependency between
them. Our method performs better than the multitask
 architecture, highlighting the effectiveness of
our feature and label dependency components, as
well as of the hierarchical contrastive loss. It scores
higher by a small margin in Task B and Task A
micro-F1 but achieves a larger beneﬁt ( 5%) in
task A macro-F1 and hard macro-F1 metrics. This
suggests that our model is of particular utility for
3.3.1 Ablation on Task Dependency Learning
We create three ablation conditions by removing
one interaction mechanism in each of them  (i) w/o
feature & label (article-speciﬁc representation but
with no concatenation with features or labels) (ii)
w/o feature (article-speciﬁc representation concatenated
 with task B label as classiﬁed by the model)
and (iii) w/o label (article-speciﬁc representation
concatenated with task B features).
From the second section of Table 1, we observe
that even the performance of w/o feature and labelis
 better than multi-task model indicated by a
small but consistent margin, indicating that article-speciﬁc case representation is a competitive component.
 Both w/o feature ,w/o label models perform
better than w/o feature & label in Task A, demonstrating
 the beneﬁt of passing on task B model
information explicitly. Between them, w/o label
performs better in m-F1 and hm-F1 scores of Task
A than w/o feature showing that providing the ﬁnegrained
 representation of features from the allegation
 identiﬁcation model is more useful than the
predicted allegation labels only.
Further, to evaluate the impact of allegation identiﬁcation
 performance on downstream violation
classiﬁcation, we conduct a control experiment in
which we provide the actual gold allegation set of
articles as input to the violation component in place
of the predicted ones. We create two variants  only
gold labels andgold labels   features (gold labels
along with task B features). From the third section
of Table 1, we observe that performance on Task
A increases substantially in micro-F1 and macroF1,
 which is intuitive as the model gets access to
perfect allegation information. Interestingly, when
adding task allegation feature information, we notice
 an additional small increase in hard macro-F1,
indicating that adding feature information can have
beneﬁcial effect even in the presence of gold task
B labels. These results form an upper bound of
the beneﬁt of using task dependency information
from allegation branch to violation branch in our
architecture, and the size of the performance gap
motivates future work on accurate allegation classiﬁcation.
3.3.2 Ablation Hierarchical Contrastive Loss
We carry out an ablation experiment for each
component of our hierarchical contrastive loss 
(i) disable article-level contrastive learning to obtain
 distinctive article representations ( w/o article
contrastive ) and (ii) disable outcome-based contrastive
 learning to separate cases based on outcome
 within each article cluster ( w/o outcome
contrastive ). Intuitively, from the fourth section of
Table 1, we observe that removing the outcome contrastive
 loss has the larger effect on performance, as
it directly relates to the predicted label. The smaller
but consistent drop in performance when removing
article-level contrastive learning supports our hypothesis
 that maximizing the distinctiveness among
article representations encourages the model to
learn how to extract article-speciﬁc salient information
Finally, to study the impact of our contrastiveloss component alone, we evaluate single-task models
 applying our hierarchical contrastive loss referred
 to as  Task A/B Contrastive . From the last
section of Table 1, we observe that they outperform
their baseline counterparts in both tasks, but still
stay behind our model.
We improve ECtHR article violation classiﬁcation
from fact statements by leveraging feature and label
 information from an allegation classiﬁcation
model. We also leveraged hierarchical contrastive
loss to contrast between different article representations
 and case representations based on outcome
with respect to a speciﬁc article. Given a static pretrained
 encoder, our models outperform a straightforward
 multi-task architecture by a small but consistent
 margin, with larger improvements for sparse
classes. These results suggest that the tasks of allegation
 and violation classiﬁcation on ECtHR fact
statements interrelate in a way that may not be optimally
 captured using straightforward multi-task
architectures, and motivate further research on dependency
 modeling between related legal classiﬁcation
In this work, we have demonstrated improvements
in violation classiﬁcation for ECtHR cases by leveraging
 the dependency from allegation classiﬁcation
at the feature and label level. While our feature
transfer and contrastive learning tech
 ## PROFNAME
 Matthias Grabmair
 ## AUTHORID
 2869551
 ## AUTHORNAME
 Matthias Grabmair
 ## AUTHORURL
 https://www.semanticscholar.org/author/2869551
 ## AUTHORHINDEX
 13
 ## AUTHORAFFILIATIONS
 []
 ## AUTHORPAPERCOUNT
 38
 ## AUTHORCITATIONCOUNT
 464
 ## PAPERID
 ff28f812113a7082f7d285ed3bf6dcbed49d0320
 ## EXTERNALIDS
 {'ACL': '2023.eacl-main.78', 'DBLP': 'journals/corr/abs-2302-00768', 'ArXiv': '2302.00768', 'DOI': '10.48550/arXiv.2302.00768', 'CorpusId': 256503823}
 ## URL
 https://www.semanticscholar.org/paper/ff28f812113a7082f7d285ed3bf6dcbed49d0320
 ## TITLE
 Leveraging Task Dependency and Contrastive Learning for Case Outcome Classification on European Court of Human Rights Cases
 ## ABSTRACT
 We report on an experiment in case outcome classification on European Court of Human Rights cases where our model first learns to identify the convention articles allegedly violated by the state from case facts descriptions, and subsequently uses that information to classify whether the court finds a violation of those articles. We assess the dependency between these two tasks at the feature and outcome level. Furthermore, we leverage a hierarchical contrastive loss to pull together article-specific representations of cases at the higher level, leading to distinctive article clusters. The cases in each article cluster are further pulled closer based on their outcome, leading to sub-clusters of cases with similar outcomes. Our experiment results demonstrate that, given a static pre-trained encoder, our models produce a small but consistent improvement in classification performance over single-task and joint models without contrastive loss.
 ## VENUE
 Conference of the European Chapter of the Association for Computational Linguistics
 ## YEAR
 2023
 ## REFERENCECOUNT
 49
 ## CITATIONCOUNT
 4
 ## INFLUENTIALCITATIONCOUNT
 0
 ## ISOPENACCESS
 True
 ## OPENACCESSPDF
 {'url': 'http://arxiv.org/pdf/2302.00768', 'status': None}
 ## FIELDSOFSTUDY
 ['Computer Science']
 ## JOURNAL
 {'volume': 'abs/2302.00768', 'name': 'ArXiv'}
 ## AUTHORS
 [{'authorId': '2203911024', 'name': 'Santosh T.Y.S.S'}, {'authorId': '134765210', 'name': 'Santosh T.Y.S.S'}, {'authorId': '2203912234', 'name': 'Phillip Kemper'}, {'authorId': '2869551', 'name': 'Matthias Grabmair'}]
 ## TLDR
 nan
 niques are general,
 our experimental contributions are contextual
to the court. The nature of the fact statements as
being inﬂuenced by the eventual case outcome and
not suitable for prospective prediction has already
been addressed in section 1.
While similar tasks (i.e., allegations paired with
ﬁndings) exist in many other jurisdictions, they
will differ in, for example, legal nature, semantic
difﬁculty, and sub-task dependency. In our case,
we choose the allegation classiﬁcation as the auxiliary
 task which is closely related and also forms
a necessary sub-part of deriving the ﬁnal outcome
related to the main task (violation prediction) at
hand. We leave an exploration of the relatedness
of auxiliary tasks and their impact on LJP/COC for
One major challenge is dealing with long input
case facts description, which is currently handled
with hierarchical model in this work. These hierar-chical models do not allow tokens in one sentence
to attend to tokens in other sentence which leads
to sub-optimal interaction modelling. This modeling
 impact on performance is still underexplored
except some preliminary empirical work in Dai
et al. 2022  Chalkidis et al. 2022a. Additionally,
we freeze the weights in the LegalBERT encoder,
both to save computational resources and to evaluate
 the effectiveness of our dependency mechanism
We employ pre-trained language models and do not
train them from scratch, thus inheriting the biases
they may have acquired from their training corpus.
 Our experiments have been carried out on a
dataset of ECtHR decisions which is publicly available
 as the part of LexGLUE benchmark (Chalkidis
et al., 2022b) and has been derived from the public
court database HUDOC2. Though these decisions
are not anonymized and contain the real names of
the involved parties, we do not foresee any harm
incurred by our experiments beyond making this
information available. This collection of decision
documents is of course historical data and using
it to train model may result in classiﬁers that exhibit
 behavior that may be considered biased. For
example, Chalkidis et al. 2022c explores disparities
 in classiﬁcation performance with regard to an
applicant s gender, their age, and the identity of
the respondent state. If COC models are deployed
as part of a decision support systems, then they
of course must be screened for performance/error
differences in between groups that are to be treated
The task of LJP/COC in itself raises serious ethical
 and legal concerns, both in general and speciﬁc
to the European Court of Human Rights. However,
we do not advocate for the practical adoption of
LJP/COC systems by courts. Our prior work in
Santosh et al. 2022 demonstrates that these systems
 rely on several shallow surface-level spurious
signals that are statistically predictive but legally
irrelevant. This highlights the risk of using predictive
 systems in high stakes domains such as law.
In the same work, we argue that models leveraging
 the case outcome signal for analytical purposes
must be developed mindfully and with the goal of
aligning their inferences with legal expert reasoning.
 This further parallels the broader legal NLP
2https //hudoc.echr.coe.intcommunity increasingly addressing ethical aspects
of developed systems in the context of technical
research (e.g., Wang et al. 2021  Medvedeva et al.
2021, 2022  Tsarapatsanis and Aletras 2021  Leins
In this work, we use COC as a technical benchmarking
 task that allows the development and study
of neural NLP models on legal text. We focus on
how to leverage dependencies on two successive
tasks (allegation identiﬁcation and violation classiﬁcation)
 based on case facts, as well as on learning
effective representations of these facts using contrastive
 learning. Our results are hence to be understood
 as technical contributions in pursuit of the
overarching goal of developing models capable of
deriving insight from data that can be used legally,
ethically, and mindfully by experts in solving problems
 arising in legal research and practice.
All experiments were carried out using Google
Colab. We did not track computation hours.
Nikolaos Aletras, Dimitrios Tsarapatsanis, Daniel
Preo  tiuc-Pietro, and Vasileios Lampos. 2016. Predicting
 judicial decisions of the european court of
human rights  A natural language processing perspective.
 PeerJ Computer Science , 2 e93.
Vithor Gomes Ferreira Bertalan and Evandro Eduardo
 Seron Ruiz. 2020. Predicting judicial outcomes
 in the brazilian legal system using textual features.
 In DHandNLP@ PROPOR , pages 22 32.
Ilias Chalkidis, Ion Androutsopoulos, and Nikolaos
Aletras. 2019. Neural legal judgment prediction in
english. In Proceedings of the 57th Annual Meeting
 of the Association for Computational Linguistics ,
Ilias Chalkidis, Xiang Dai, Manos Fergadiotis, Prodromos
 Malakasiotis, and Desmond Elliott. 2022a.
An exploration of hierarchical attention transformers
 for efﬁcient long document classiﬁcation. arXiv
preprint arXiv 2210.05529 .
Ilias Chalkidis, Manos Fergadiotis, Prodromos Malakasiotis,
 Nikolaos Aletras, and Ion Androutsopoulos.
2020. Legal-bert  The muppets straight out of law
school. In Findings of the Association for Computational
 Linguistics  EMNLP 2020 , pages 2898 2904.
Ilias Chalkidis, Manos Fergadiotis, Dimitrios Tsarapatsanis,
 Nikolaos Aletras, Ion Androutsopoulos, and
Prodromos Malakasiotis. 2021. Paragraph-level rationale
 extraction through regularization  A case
study on european court of human rights cases. In
Proceedings of the 2021 Conference of the NorthAmerican Chapter of the Association for Computational
 Linguistics  Human Language Technologies ,
Ilias Chalkidis, Abhik Jana, Dirk Hartung, Michael
Bommarito, Ion Androutsopoulos, Daniel Katz, and
Nikolaos Aletras. 2022b. Lexglue  A benchmark
dataset for legal language understanding in english.
InProceedings of the 60th Annual Meeting of the
Association for Computational Linguistics (Volume
1  Long Papers) , pages 4310 4330.
Ilias Chalkidis, Tommaso Pasini, Sheng Zhang, Letizia
Tomada, Sebastian Schwemer, and Anders Søgaard.
2022c. Fairlex  A multilingual benchmark for evaluating
 fairness in legal text processing. In Proceedings
 of the 60th Annual Meeting of the Association
for Computational Linguistics (Volume 1  Long Papers)
Ting Chen, Simon Kornblith, Mohammad Norouzi,
and Geoffrey Hinton. 2020. A simple framework for
contrastive learning of visual representations. In International
 conference on machine learning , pages
Benjamin Clavié and Marc Alphonsus. 2021. The unreasonable
 effectiveness of the baseline  Discussing
svms in legal text classiﬁcation. In Legal Knowledge
and Information Systems , pages 58 61. IOS Press.
Xiang Dai, Ilias Chalkidis, Sune Darkner, and
Desmond Elliott. 2022. Revisiting transformerbased
 models for long document classiﬁcation. In
Findings of the Association for Computational Linguistics 
 EMNLP 2022 , pages 7212 7230, Abu
Dhabi, United Arab Emirates. Association 
 ## PROFNAME
 Matthias Grabmair
 ## AUTHORID
 2869551
 ## AUTHORNAME
 Matthias Grabmair
 ## AUTHORURL
 https://www.semanticscholar.org/author/2869551
 ## AUTHORHINDEX
 13
 ## AUTHORAFFILIATIONS
 []
 ## AUTHORPAPERCOUNT
 38
 ## AUTHORCITATIONCOUNT
 464
 ## PAPERID
 ff28f812113a7082f7d285ed3bf6dcbed49d0320
 ## EXTERNALIDS
 {'ACL': '2023.eacl-main.78', 'DBLP': 'journals/corr/abs-2302-00768', 'ArXiv': '2302.00768', 'DOI': '10.48550/arXiv.2302.00768', 'CorpusId': 256503823}
 ## URL
 https://www.semanticscholar.org/paper/ff28f812113a7082f7d285ed3bf6dcbed49d0320
 ## TITLE
 Leveraging Task Dependency and Contrastive Learning for Case Outcome Classification on European Court of Human Rights Cases
 ## ABSTRACT
 We report on an experiment in case outcome classification on European Court of Human Rights cases where our model first learns to identify the convention articles allegedly violated by the state from case facts descriptions, and subsequently uses that information to classify whether the court finds a violation of those articles. We assess the dependency between these two tasks at the feature and outcome level. Furthermore, we leverage a hierarchical contrastive loss to pull together article-specific representations of cases at the higher level, leading to distinctive article clusters. The cases in each article cluster are further pulled closer based on their outcome, leading to sub-clusters of cases with similar outcomes. Our experiment results demonstrate that, given a static pre-trained encoder, our models produce a small but consistent improvement in classification performance over single-task and joint models without contrastive loss.
 ## VENUE
 Conference of the European Chapter of the Association for Computational Linguistics
 ## YEAR
 2023
 ## REFERENCECOUNT
 49
 ## CITATIONCOUNT
 4
 ## INFLUENTIALCITATIONCOUNT
 0
 ## ISOPENACCESS
 True
 ## OPENACCESSPDF
 {'url': 'http://arxiv.org/pdf/2302.00768', 'status': None}
 ## FIELDSOFSTUDY
 ['Computer Science']
 ## JOURNAL
 {'volume': 'abs/2302.00768', 'name': 'ArXiv'}
 ## AUTHORS
 [{'authorId': '2203911024', 'name': 'Santosh T.Y.S.S'}, {'authorId': '134765210', 'name': 'Santosh T.Y.S.S'}, {'authorId': '2203912234', 'name': 'Phillip Kemper'}, {'authorId': '2869551', 'name': 'Matthias Grabmair'}]
 ## TLDR
 nan
 for Computational
Olivier Henaff. 2020. Data-efﬁcient image recognition
with contrastive predictive coding. In International
conference on machine learning , pages 4182 4192.
Daniel Martin Katz, Michael J Bommarito, and Josh
Blackman. 2017. A general approach for predicting
the behavior of the supreme court of the united states.
PloS one , 12(4) e0174698.
Aaron Russell Kaufman, Peter Kraft, and Maya Sen.
2019. Improving supreme court forecasting using
 boosted decision trees. Political Analysis ,
Prannay Khosla, Piotr Teterwak, Chen Wang, Aaron
Sarna, Yonglong Tian, Phillip Isola, Aaron
Maschinot, Ce Liu, and Dilip Krishnan. 2020. Supervised
 contrastive learning. Advances in Neural
Information Processing Systems , 33 18661 18673.
Diederik P Kingma and Jimmy Ba. 2015. Adam  a
method for stochastic optimization 3rd int. In International
 Conference on Learning Representations .Kankawin Kowsrihawat, Peerapon Vateekul, and
Prachya Boonkwan. 2018. Predicting judicial decisions
 of criminal cases from thai supreme court using
 bi-directional gru with attention mechanism. In
2018 5th Asian Conference on Defense Technology
(ACDT) , pages 50 55. IEEE.
Kobi Leins, Jey Han Lau, and Timothy Baldwin. 2020.
Give me convenience and give her death  Who
should decide what uses of nlp are appropriate, and
on what basis  In Proceedings of the 58th Annual
Meeting of the Association for Computational Linguistics
Bin Liang, Zixiao Chen, Lin Gui, Yulan He, Min Yang,
and Ruifeng Xu. 2022. Zero-shot stance detection
via contrastive learning. In Proceedings of the ACM
Web Conference 2022 , pages 2738 2747.
Bingfeng Luo, Yansong Feng, Jianbo Xu, Xiang Zhang,
and Dongyan Zhao. 2017. Learning to predict
charges for criminal cases with legal basis. In Proceedings
 of the 2017 Conference on Empirical Methods
 in Natural Language Processing , pages 2727 
Vijit Malik, Rishabh Sanjay, Shubham Kumar Nigam,
Kripabandhu Ghosh, Shouvik Kumar Guha, Arnab
Bhattacharya, and Ashutosh Modi. 2021. Ildc for
cjpe  Indian legal documents corpus for court judgment
 prediction and explanation. In Proceedings of
the 59th Annual Meeting of the Association for Computational
 Linguistics and the 11th International
Joint Conference on Natural Language Processing
(Volume 1  Long Papers) , pages 4046 4062.
Masha Medvedeva, Ahmet Üstün, Xiao Xu, Michel
V ols, and Martijn Wieling. 2021. Automatic judgement
 forecasting for pending applications of the european
 court of human rights. In ASAIL/LegalAIIA@
Masha Medvedeva, Michel V ols, and Martijn Wieling.
2020. Using machine learning to predict decisions
of the european court of human rights. Artiﬁcial Intelligence
 and Law , 28(2) 237 266.
Masha Medvedeva, Martijn Wieling, and Michel V ols.
2022. Rethinking the ﬁeld of automatic prediction
of court decisions. Artiﬁcial Intelligence and Law ,
Emre Mumcuo  glu, Ceyhun E Öztürk, Haldun M Ozaktas,
 and Aykut Koç. 2021. Natural language processing
 in law  Prediction of outcomes in the higher
courts of turkey. Information Processing & Management
Joel Niklaus, Ilias Chalkidis, and Matthias Stürmer.
2021. Swiss-judgment-prediction  A multilingual
legal judgment prediction benchmark. In Proceedings
 of the Natural Legal Language Processing
Workshop 2021 , pages 19 35.Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya
Ramesh, Gabriel Goh, Sandhini Agarwal, Girish
Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
et al. 2021. Learning transferable visual models
from natural language supervision. In International
Conference on Machine Learning , pages 8748 8763.
T. Y . S. S Santosh, Oana Ichim, and Matthias Grabmair.
 2023. Zero shot transfer of article-aware legal
outcome classiﬁcation for european court of human
rights cases. arXiv preprint arXiv 2302.00609 .
T.y.s.s Santosh, Shanshan Xu, Oana Ichim, and
Matthias Grabmair. 2022. Deconfounding legal
judgment prediction for European court of human
rights cases towards better alignment with experts.
InProceedings of the 2022 Conference on Empirical
 Methods in Natural Language Processing , pages
1120 1138, Abu Dhabi, United Arab Emirates. Association
 for Computational Linguistics.
Mehmet Fatih Sert, Engin Yıldırım, and  Irfan Ha  slak.
2021. Using artiﬁcial intelligence to predict decisions
 of the turkish constitutional court. Social Science
 Computer Review , page 08944393211010398.
Rafe Athar Shaikh, Tirath Prasad Sahu, and Veena
Anand. 2020. Predicting outcomes of legal cases
based on legal factors using classiﬁers. Procedia
Computer Science , 167 2393 2402.
Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky,
Ilya Sutskever, and Ruslan Salakhutdinov. 2014.
Dropout  a simple way to prevent neural networks
from overﬁtting. The journal of machine learning
research , 15(1) 1929 1958.
Benjamin Strickson and Beatriz De La Iglesia. 2020.
Legal judgement prediction for uk courts. In Proceedings
 of the 2020 the 3rd international conference
 on information science and system , pages 204 
Octavia-Maria   Sulea, Marcos Zampieri, Mihaela Vela,
and Josef van Genabith. 2017. Predicting the law
area and decisions of french supreme court cases. In
Proceedings of the International Conference Recent
Advances in Natural Language Processing, RANLP
2017 , pages 716 722.
Dimitrios Tsarapatsanis and Nikolaos Aletras. 2021.
On the ethical limits of natural language processing
 on legal text. In Findings of the Association
for Computational Linguistics  ACL-IJCNLP 2021 ,
Josef Valvoda, Ryan Cotterell, and Simone Teufel.
2023. On the role of negative precedent in legal outcome
 prediction. Transactions of the Association for
Computational Linguistics , 11 34 48.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz
Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. Advances in neural information processing
 systems , 30.Michael Benedict L Virtucio, Jeffrey A Aborot, John
Kevin C Abonita, Roxanne S Avinante, Rother Jay B
Copino, Michelle P Neverida, Vanesa O Osiana,
Elmer C Peramo, Joanna G Syjuco, and Glenn
Brian A Tan. 2018. Predicting decisions of the
philippine supreme court using natural language processing
 and machine learning. In 2018 IEEE 42nd
annual computer software and applications conference
 (COMPSAC) , volume 2, pages 130 135. IEEE.
Bernhard Waltl, Georg Bonczek, Elena Scepankova,
Jörg Landthaler, and Florian Matthes. 2017. Predicting
 the outcome of appeal decisions in germany s
tax law. In International conference on electronic
participation , pages 89 99. Springer.
Yuzhong Wang, Chaojun Xiao, Shirong Ma, Haoxi
Zhong, Cunchao Tu, Tianyang Zhang, Zhiyuan Liu,
and Maosong Sun. 2021. Equality before the law 
Legal judgment consistency analysis for fairness.
arXiv e-prints , pages arXiv 2103.
Zhirong Wu, Yuanjun Xiong, Stella X Yu, and Dahua
Lin. 2018. Unsupervised feature learning via nonparametric
 instance discrimination. In Proceedings
of the IEEE conference on computer vision and pattern
 recognition , pages 3733 3742.
Nuo Xu, Pinghui W
 ## PROFNAME
 Matthias Grabmair
 ## AUTHORID
 2869551
 ## AUTHORNAME
 Matthias Grabmair
 ## AUTHORURL
 https://www.semanticscholar.org/author/2869551
 ## AUTHORHINDEX
 13
 ## AUTHORAFFILIATIONS
 []
 ## AUTHORPAPERCOUNT
 38
 ## AUTHORCITATIONCOUNT
 464
 ## PAPERID
 ff28f812113a7082f7d285ed3bf6dcbed49d0320
 ## EXTERNALIDS
 {'ACL': '2023.eacl-main.78', 'DBLP': 'journals/corr/abs-2302-00768', 'ArXiv': '2302.00768', 'DOI': '10.48550/arXiv.2302.00768', 'CorpusId': 256503823}
 ## URL
 https://www.semanticscholar.org/paper/ff28f812113a7082f7d285ed3bf6dcbed49d0320
 ## TITLE
 Leveraging Task Dependency and Contrastive Learning for Case Outcome Classification on European Court of Human Rights Cases
 ## ABSTRACT
 We report on an experiment in case outcome classification on European Court of Human Rights cases where our model first learns to identify the convention articles allegedly violated by the state from case facts descriptions, and subsequently uses that information to classify whether the court finds a violation of those articles. We assess the dependency between these two tasks at the feature and outcome level. Furthermore, we leverage a hierarchical contrastive loss to pull together article-specific representations of cases at the higher level, leading to distinctive article clusters. The cases in each article cluster are further pulled closer based on their outcome, leading to sub-clusters of cases with similar outcomes. Our experiment results demonstrate that, given a static pre-trained encoder, our models produce a small but consistent improvement in classification performance over single-task and joint models without contrastive loss.
 ## VENUE
 Conference of the European Chapter of the Association for Computational Linguistics
 ## YEAR
 2023
 ## REFERENCECOUNT
 49
 ## CITATIONCOUNT
 4
 ## INFLUENTIALCITATIONCOUNT
 0
 ## ISOPENACCESS
 True
 ## OPENACCESSPDF
 {'url': 'http://arxiv.org/pdf/2302.00768', 'status': None}
 ## FIELDSOFSTUDY
 ['Computer Science']
 ## JOURNAL
 {'volume': 'abs/2302.00768', 'name': 'ArXiv'}
 ## AUTHORS
 [{'authorId': '2203911024', 'name': 'Santosh T.Y.S.S'}, {'authorId': '134765210', 'name': 'Santosh T.Y.S.S'}, {'authorId': '2203912234', 'name': 'Phillip Kemper'}, {'authorId': '2869551', 'name': 'Matthias Grabmair'}]
 ## TLDR
 nan
 ang, Long Chen, Li Pan, Xiaoyan
Wang, and Junzhou Zhao. 2020. Distinguish confusing
 law articles for legal judgment prediction. In
Proceedings of the 58th Annual Meeting of the Association
 for Computational Linguistics , pages 3086 
Wenmian Yang, Weijia Jia, Xiaojie Zhou, and Yutao
Luo. 2019. Legal judgment prediction via multiperspective
 bi-feedback network. In Proceedings of
the 28th International Joint Conference on Artiﬁcial
Intelligence , pages 4085 4091.
Zichao Yang, Diyi Yang, Chris Dyer, Xiaodong He,
Alex Smola, and Eduard Hovy. 2016. Hierarchical
 attention networks for document classiﬁcation.
InProceedings of the 2016 conference of the North
American chapter of the association for computational
 linguistics  human language technologies ,
Linan Yue, Qi Liu, Binbin Jin, Han Wu, Kai Zhang,
Yanqing An, Mingyue Cheng, Biao Yin, and Dayong
 Wu. 2021. Neurjudge  a circumstance-aware
neural framework for legal judgment prediction. In
Proceedings of the 44th International ACM SIGIR
Conference on Research and Development in Information
 Retrieval , pages 973 982.
Han Zhang, Zhicheng Dou, Yutao Zhu, and Ji-Rong
Wen. 2023. Contrastive learning for legal judgment
prediction. ACM Transactions on Information Systems.
Haoxi Zhong, Zhipeng Guo, Cunchao Tu, Chaojun
Xiao, Zhiyuan Liu, and Maosong Sun. 2018. Legal
 judgment prediction via topological learning. InProceedings of the 2018 Conference on Empirical
Methods in Natural Language Processing , pages
Haoxi Zhong, Yuzhong Wang, Cunchao Tu, Tianyang
Zhang, Zhiyuan Liu, and Maosong Sun. 2020. Iteratively
 questioning and answering for interpretable legal
 judgment prediction. In Proceedings of the AAAI
Conference on Artiﬁcial Intelligence , volume 34,
A Implementation Details
Our models compute word embeddings of size 768.
Our word level attention context vector size is 300.
The sentence level GRU encoder dimension is 200,
thus giving a bidirectional embedding of size 400,
and a sentence level attention vector dimension of
200. The ﬁnal dense classiﬁer for all tasks has 100
hidden units. We use a mini batches size of 32
and the model is optimized end-to-end using Adam
(Kingma and Ba, 2015). The dropout rate (Srivastava
 et al., 2014) in all layers is 0.1. We determine
the best learning rate using grid search on the development
 set and use early stopping based on the
development set m-F1 score. We ﬁnetuned τa,τc
with an additional constraint of τa τcamong the
values of{0.07,0.1,0.14,0.2,0.25,0.3}so that it
aids in pulling together the representations belonging
 to the same article in latent space (leading to
distinct article clusters) and also in further slightly
pulling together the representations of cases belonging
 to the same outcome in each separated
article-speciﬁc embedding latent space compared
to the other outcome cases in that same article. We
setαto be 0.5. We use a memory bank of size 32
per article and outcome, and store only the most
recent examples per article and its corresponding