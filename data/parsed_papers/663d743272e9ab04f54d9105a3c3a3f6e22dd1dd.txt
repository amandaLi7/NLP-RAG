FACTKB: Generalizable Factuality Evaluation using Language Models
Enhanced with Factual Knowledge
Shangbin Feng1Vidhisha Balachandran2Yuyang Bai3Yulia Tsvetkov1
1University of Washington2Carnegie Mellon University3Xi’an Jiaotong University
{shangbin, yuliats}@cs.washington.edu vbalacha@cs.cmu.edu 1206944633@stu.xjtu.edu.cn
Abstract
Evaluating the factual consistency of automati-
cally generated summaries is essential for the
progress and adoption of reliable summariza-
tion systems. Despite recent advances, exist-
ing factuality evaluation models are not ro-
bust, being especially prone to entity and re-
lation errors in new domains. We propose FAC-
TKB—a simple new approach to factuality
evaluation that is generalizable across domains,
in particular with respect to entities and re-
lations. FACTKBis based on language mod-
els pretrained using facts extracted from exter-
nal knowledge bases. We introduce three types
of complementary factuality pretraining objec-
tives based on entity-specific facts, facts ex-
tracted from auxiliary knowledge about entities,
and facts constructed compositionally through
knowledge base walks. The resulting factual-
ity evaluation model achieves state-of-the-art
performance on two in-domain news summa-
rization benchmarks as well as on three out-
of-domain scientific literature datasets. Further
analysis of FACTKBshows improved ability to
detect erroneous entities and relations in sum-
maries and is robust and easily generalizable
across domains. Code and data are available at
https://github.com/BunsenFeng/FactKB.
1 Introduction
Generating factually accurate document summaries
in addition to fluent and informative ones is critical
to the adoption of summarization models (Kry ´s-
ci´nski et al., 2020; Goyal and Durrett, 2020). How-
ever, evaluating the factual consistency of sum-
maries is still challenging, especially in special-
ized domains like scientific or legal (Cachola et al.,
2020; Goldsack et al., 2022; Polsley et al., 2016;
Kanapala et al., 2019). The key reason is that the
majority of existing approaches employ neural clas-
sifiers trained on synthetic data constructed from a
relatively small set of documents (Kry ´sci´nski et al.,
2020; Goyal and Durrett, 2020). These factuality
QAGS : Factual
 QAGS : Factual
 DAE: Factual
DAE: Factual
 FactCC : Factual
 FactCC : Factual
 QAGS : Factual
 DAE: Factual
 FactCC : Factual
Article:
The stone got past the elephant's fence and a ditch 
separating the animal and visitors … Scientific Director of 
the Amboseli Trust for Elephants, says that  targeted 
throwing of stones and branches by elephants  is very 
unusual . "It can happen when elephants are frustrated or 
bored...  The moments after the girl was struck  at Rabat 
Zoo on Tuesday were filmed by a bystander and uploaded 
onto YouTube  ...
Summary:
An elephant has been hit  by a stone at a zoo in western 
France after it was hit by a tree.Gold: Not FactualGold: Not FactualArticle:
The stone got past the elephant's fence and a ditch 
separating the animal and visitors … Scientific Director of 
the Amboseli Trust for Elephants, says that  targeted 
throwing of stones and branches by elephants  is very 
unusual . "It can happen when elephants are frustrated or 
bored...  The moments after the girl was struck  at Rabat 
Zoo on Tuesday were filmed by a bystander and uploaded 
onto YouTube  ...
Summary:
An elephant has been hit  by a stone at a zoo in western 
France after it was hit by a tree.Gold: Not FactualFigure 1: Existing factuality models struggle to identify
semantic frame errors encompassing entities and rela-
tions. In the example, they fail to identify an error in the
generated summary about who was hit by the stone.
classifiers are thus not robust to ever-growing infor-
mation, in which the distribution of entities, events,
and their relations changes greatly across time and
domains (Elsahar and Gallé, 2019; Laparra et al.,
2020). Pagnoni et al. (2021) highlighted this limi-
tation, finding that over 50% of factuality errors in
the XSUM (Narayan et al., 2018) summarization
dataset stem from semantic frame errors , namely
entities, events, and relations between them, as il-
lustrated in Figure 1.
To address these issues, we develop a new fac-
tuality evaluation model with improved factual
knowledge representation, specifically focusing on
entities and relations. Entity-oriented pretraining
objectives have been shown to improve QA and
reasoning tasks (Yasunaga et al., 2022; Liu et al.,
2022b); we thus hypothesize that similar objectives
can aid factuality evaluation in better detecting se-
mantic frame errors in generated summaries.
We propose FACTKB, a novel factuality eval-
uation model built upon language models (LMs)
augmented with factual knowledge (§2). The LMsarXiv:2305.08281v2  [cs.CL]  18 Oct 2023...... Language Model
...... Language Model Fact-Enhanced LM Fact-Enhanced LM...
...Fact-Enhanced LM...
...FactKBFactKB...
...FactKB...
...was born inis ina country of
isdoctoral advisorwas born in
is in
a member of .........
<MASK><MASK>
Weil der Stadt
Weil der Stadt
European 
Union
European 
Union
Europe
Europe
Astronomer
Astronomer
Michael 
Maestlin
Michael 
Maestlin
Göppingen
Göppingen
Johannes 
Kepler
Johannes 
Kepler
Knowledge 
Base
Knowledge Walkis
Johannes 
Kepler
Johannes Kepler is <MASK> . 
Johannes Kepler is a key figure 
in the 17th -century Scientific 
Revolution, best known for his 
laws of planetary motion  ...
<MASK><MASK>
Wikipedia
WikipediaKnowledge 
BaseKnowledge 
Base
Evidence ExtractionJohannes Kepler is a key figure 
in the 17th -century Scientific 
Revolution, best known for his 
laws of planetary motion  ...
Entity WikiKepler doctoral advisor Michael Maestlin . 
Kepler is <MASK> . Kepler born in Weil 
der Stadt . Kepler writes Somnium .Knowledge 
Base
Factuality Evaluation Model
Factuality PretrainingFactCollect
Fine-tuningwrites born inis<MASK><MASK>
Somnium
Somnium
 Weil der Stadt
Weil der Stadt
Michael 
Maestlin
Michael 
Maestlin
Johannes 
Kepler
Johannes 
Kepler
doctoral advisor
writes born inis<MASK>
Somnium
 Weil der Stadt
Michael 
Maestlin
Johannes 
Kepler
doctoral advisorAstronomer
<MASK >=
 <MASK >=
Astronomer
<MASK >=
Astronomer
<MASK >=
Astronomer
<MASK >=
Astronomer
<MASK >=
Astronomer
<MASK >=Germany
Germany
<MASK>=
Germany
<MASK>=
Germany
<MASK>=
Kepler was born in Weil der Stadt  is in 
<MASK>  is a country in Europe...Figure 2: Overview of FACTKB.FACTKBpretrains LMs using three entity-centric pretraining strategies to improve
fact representations. The objectives are designed to fill masked entities/relations in KB facts using i) Entity Wiki -
direct facts about entities ii) Evidence Extraction - auxiliary knowledge about entities and iii) Knowledge Walk -
compositional knowledge from the KB. The pretrained LMs are then fine-tuned for robust factuality evaluation.
are pretrained with knowledge-focused objectives
using text synthesized from external knowledge
bases (KBs) which store high-quality facts about
entities and relations. We propose three types of
complementary pretraining strategies: (1) entity
wiki, with a focus on improving entity understand-
ing; (2) evidence extraction , with a focus on in-
corporating supporting evidence from surrounding
context; and (3) knowledge walks , with a focus
on augmenting compositional reasoning about en-
tities. For factuality evaluation, we first pretrain a
language model using these three entity-centric pre-
training strategies, and then fine-tune the enhanced
LM on a factual error detection dataset.
We evaluate FACTKB’s correlation with human
factuality judgments across three settings (§3). In
in-domain (news) summarization, FACTKBsig-
nificantly outperforms baselines by 2–7 balanced
accuracy (BACC) points on the FactCollect dataset
(Ribeiro et al., 2022) and 10–12 correlation points
on the FRANK benchmark (Pagnoni et al., 2021),
particularly showing marked improvements in se-
mantic frame errors. In out-of-domain experiments,
FACTKB consistently outperforms existing ap-
proaches by 3–5 BACC points on three datasets in
biomedical and scientific domains (Saakyan et al.,
2021; Sarrouti et al., 2021; Wadden et al., 2020),
demonstrating stronger generalizability to unseen
documents in new domains. Further analysis shows
thatFACTKBis compatible with different LMs and
KBs while presenting a lightweight and easy-to-use
approach to factuality evaluation. Code, data, and
trained factuality evaluation models are publicly
available.2 F ACTKB Methodology
FACTKBaims to improve the robustness and gen-
eralizability of factuality evaluation by a simple
factuality pretraining , which improves entity and
relation representations in LMs. We first propose
three pretraining strategies (§2.1). We then describe
the training process to (1) pretrain an LM using
the proposed strategies and (2) fine-tune the fact-
enhanced LM on a factuality error detection dataset,
resulting in FACTKB(§2.2). Figure 2 presents an
overview of our approach.
2.1 Factuality Pretraining
Knowledge bases are rich reservoirs of facts about
entities and relations (Vrande ˇci´c and Krötzsch,
2014; Pellissier Tanon et al., 2020), and we ex-
plore the possibility of leveraging external KBs as
“fact teachers” to enhance an LM’s representation
of entities and relations.
Let KB = ( E,R,A, ϵ, φ), where E=
{e1, . . . , e N}represents the entities in the KB,
R={r1, . . . , r M}denotes the relations in the KB,
Adenotes the adjacency matrix where aij=kin-
dicates relation rkconnecting entities eiandej
(ei, rk, ej)∈KB,ϵ(·) :E → strandφ(·) :R →
strmap the entities and relations to their textual
names. We propose three novel types of factuality
pretraining strategies that leverage the KB.
Strategy 1: Entity Wiki Entities in KBs often
have multiple edges connecting them to other enti-
ties via relations, each representing a distinct but
related fact about the entity. Inspired by the task of
knowledge base completion (Bordes et al., 2013;
Vashishth et al., 2019) to predict missing connec-Factuality Pretraining Corpus Size Bound # Tokens Example
ENTITY WIKI ∝ |E| 5.4M Johannes Kepler is born in Italy. Johannes
Kepler is an [MASK]. [SEP] Johannes Ke-
pler is the author of Astronomia nova. . . .
EVIDENCE EXTRACTION ∝ ||A||0 12.2M Hillary Clinton party affiliation [MASK]
Hillary Diane Rodham Clinton is an Amer-
ican politician, . . .Member of the Demo-
cratic Party, she was the nominee . . .
KNOWLEDGE WALK ∝ |E| (||A|| 0
|E|)k2.7M University of Edinburgh located in Scot-
land located in [MASK] is a continent . . .
Table 1: Summary of the three factuality pretraining strategies.
tions in KBs based on available KB facts, we pro-
pose the entity wiki factuality pretraining, where an
LM is pretrained with the task of predicting masked
entities or relations in KB facts. Specifically, for
each entity ei∈ E, we retrieve its one-hop neigh-
borhood in the KB as Eei={ej| ∃rks.t. a ij=
k}. We then synthesize a sentence using entity ei
and its connected one-hop facts:
di= concat ej∈Eei
ϵ(ei)φ(rk|aij=k)ϵ(ej)[SEP]
where concat denotes string concatenation and
[SEP ]denotes the special token. Repeating this
generation process for all e∈ E, we produce a
corpus of entity facts as {di}|E|
i=1with the max size
being the number of entities |E|. We use this entity
wiki corpus to pretrain an LM for better factual rea-
soning by randomly masking entities and relations
in it and training the LM to predict the mask given
the surrounding facts about an entity. We randomly
mask the corpora with probability pand pretrain
LMs with the masked language modeling objective.
We expect this objective to train LMs to infer facts
from surrounding knowledge and penalize unsup-
ported hallucinations about entities and relations.
Strategy 2: Evidence Extraction The goal of
this pretraining strategy is to enhance the model’s
ability to evaluate facts based on relevant evi-
dence. We begin by randomly selecting a triple
(ei, rk, ej)∈KBand use the first paragraph of the
Wikipedia description of eias the auxiliary knowl-
edge. We synthesize a sentence using the two as:
di=ϵ(ei)φ(rk) [MASK] Wikipedia( ei)
where we mask out ϵ(ej)and[MASK] denotes
the special token, Wikipedia( ·) :E → strmaps
entities to the first paragraph of their Wikipedia de-
scription. Repeating this process Ntimes with ran-
domly selected triples, we obtain a corpus of triples
paired with auxiliary knowledge {di}N
i=1. The cor-
pus size is bounded by all KB triples represented astheL0norm of the adjacency matrix ||A||0. We use
this corpus for the evidence extraction factuality
pretraining and train the LM to predict the mask by
using relevant evidence in the auxiliary paragraph.
Through this, we aim to augment FACTKB’s ability
to implicitly select evidence from the document to
support its factuality evaluation.
Strategy 3: Knowledge Walk Natural language
documents often include compositional statements
about entities and relations (Feldman and El-
Yaniv, 2019; Wang and Pan, 2022), but pretrained
LMs struggle with such compositional reasoning
(Press et al., 2022). To improve FACTKB’s abil-
ity to understand multi-hop claims, we propose
theknowledge walk factuality pretraining strat-
egy. Specifically, we randomly select a starting en-
titye(0)and randomly select an entity e(1)from
its direct neighborhood Ee(0), resulting in a one-
hop triple {e(0), r(0,1), e(1)}where r(0,1)denotes
the relation between e(0)ande(1). Now, from
e(1), we randomly select an entity from it’s di-
rect neighborhood to take the next step. We re-
peat this process for Ktimes, and obtain a K-
hop random walk of triples beginning at e(0):
{e(0), r(0,1), e(1),···, r(K−1,K), e(K)}. We then
produce a sentence based on the K-hop walk:
di=ϵ(e(0)) concatK−1
i=0
φ(r(i,i+1))ϵ(e(i+1))
Repeating this K-hop walk Ntimes with differ-
ent randomly selected starting entities, we obtain
{di}N
i=1as the corpus for the knowledge walk fac-
tuality pretraining, whose size is bounded by the
number of all possible K-hop walks as |E|(||A|| 0
|E|)k.
In this corpus, we randomly mask entities or rela-
tions in each group of facts with probability pand
train an LM to predict the masked element using
the compositional facts around it using the masked
language model objective. Through this pretraining,
we expect FACTKBto improve in compositionalModelAll Data CNN/DM XSUM
BACC F1 BACC F1 BACC F1
QAGS 79.8 79 .7 64 .2 76 .2 59 .3 85 .2
QUALS 78.3 78 .5 60 .8 76 .2 57 .5 82 .2
ROBERT A 76.1 76 .5 62 .5 76 .2 62 .1 78 .3
FALSE SUM 78.9 78 .2 53 .7 34 .6 61 .1 64 .3
FALSE SUM+ 84.2 83 .7 64 .2 77 .1 67 .4 82 .1
SUMMA C 86.6 86 .2 75 .4 83 .5 71 .9 90 .4
FACTCC 76.0 76 .3 69 .0 77 .8 55 .9 73 .9
FACTCC+ 83.9(±0.4)84.2(±0.4)68.0(±1.0)83.7(±0.5)58.3(±2.2)84.0(±1.0)
FACTGRAPH 86.3(±1.3)86.7(±1.1)73.0(±2.3)86.8(±0.8)68.6(±2.3)86.6(±2.0)
FACTGRAPH -ADAPTERS 87.6(±0.7)87.8(±0.7)76.0(±2.8)87.5(±0.4)69.9(±2.3)88.4(±1.2)
FACTKB- WIKI 89.3(±0.4)∗89.5 (±0.5)∗77.3(±0.3)∗88.2 (±0.6)∗77.3 (±1.3)∗91.8 (±1.2)∗
FACTKB- EVIDENCE 89.4 (±0.2)∗89.5 (±0.3)∗77.7(±1.4)∗87.9(±0.7)76.8(±1.9)∗90.8(±0.8)∗
FACTKB- WALK 89.1(±0.4)∗89.3(±0.5)∗78.3 (±1.2)∗87.7(±0.4)76.4(±0.3)∗90.4(±1.4)∗
Table 2: Performance of FACTKBon the FactCollect dataset. We report average performance and standard deviation
across 5 random seeds. Best performance is shown in bold , while * indicates statistical significance. FACTKB
significantly outperforms existing factuality evaluation approaches on in-domain evaluation.
fact understanding about entities and relations ap-
pearing in the summary and the input document.
We briefly summarize the three factuality pre-
training strategies and provide examples in Table 1.
2.2 F ACTKB Training
We initialize FACTKBwith encoder-based LMs
and pretrain FACTKB separately with each of
the three factuality pretraining corpora using the
masked language modeling objective to study the
effectiveness of each strategy. This results in fact-
enhanced LMs with the ability to better represent
facts, entities, and relations. Finally, we fine-tune
FACTKBon human-annotated factual error detec-
tion datasets with the sequence classification set-
ting, taking SUMMARY [SEP]DOCUMENT as input
and produce FACTUAL orNON -FACTUAL labels.
The [ CLS ] token is adopted for classification. As a
result, we obtain FACTKB, our entailment-based
factuality evaluation model that classifies machine-
generated summaries as factual or non-factual.
3 Data and Experiment Settings
3.1 Training
Data We use YAGO (Pellissier Tanon et al.,
2020), an encyclopedic knowledge base based on
Wikidata (Vrande ˇci´c and Krötzsch, 2014), to con-
struct the three types of factuality pretraining cor-
pora, while we discuss FACTKB’s compatibility
with different KBs in Section 5.2. For finetuning,
we use the FactCollect dataset (Ribeiro et al., 2022),
a dataset for factual error detection that gathers
human annotations from different sources (Wang
et al., 2020a; Kry ´sci´nski et al., 2020; Maynez et al.,2020; Pagnoni et al., 2021) and consolidates them
into a single dataset. It mainly focuses on the
news media domain, covering summaries and ar-
ticles from CNN, Daily Mail, and BBC. FactCol-
lect follows a binary classification setting where
each ( SUMMARY ,ARTICLE ) pair has a FACTUAL
orNON -FACTUAL label. We present more details
about the FactCollect dataset in Appendix C.
Settings We use a ROBERT A-BASE (Liu et al.,
2019) checkpoint and continue pretraining sepa-
rately on each of the three factuality pretraining
corpora. We discuss FACTKB’s compatibility with
different LM initializations in Section §5.2. We
assign corpus size parameter N= 1e5, masking
probability p= 0.15, and knowledge walk length
K= 5 in the experiments, while we discuss the
effect of corpus size and knowledge walk length
in Appendix 5.4. We use a learning rate of 2e−5
for pretraining, 1e−4for fine-tuning, a batch size
of 32, and the RAdam optimizer. Pretraining is
conducted for 5 epochs and fine-tuning has 50 max-
imum epochs with early stopping. More hyperpa-
rameter settings are presented in Appendix 3.1.
Hyperparameters We propose to further pre-
train LM checkpoints with three types of factuality
pretraining and fine-tune on factuality evaluation
datasets. We present hyperparameters for the pre-
training and fine-tuning stage in Table 4. We mostly
follow the hyperparameters in Gururangan et al.
(2020) for the pretraining stage. The default hy-
perparameters on Huggingface Transformers are
adopted if not included in Table 4.ModelAll Data CNN/DM XSUM
ρ p-val r p-val ρ p-val r p-val ρ p-val r p-val
QAGS .22 .00 .23 .00 .34 .00 .27 .00 .07 .05 .06 .09
QUALS .22 .00 .19 .00 .31 .00 .27 .00 .14 .00 .07 .03
DAE .17 .00 .20 .00 .27 .00 .22 .00 .03 .38 .33 .00
ROBERT A .35 .00 .41 .00 .43 .00 .31 .00 .23 .00 .15 .00
FALSE SUM .05 .00 .04 .11 .07 .05 .07 .03 .04 .28 .04 .35
FALSE SUM+ .22 .00 .26 .00 .27 .00 .33 .00 .24 .00 .27 .00
SUMMA C .33 .00 .35 .00 .42 .00 .36 .00 .24 .00 .25 .00
FACTCC .20 .00 .29 .00 .36 .00 .30 .00 .06 .07 .19 .00
FACTCC+ .32 .00 .38 .00 .40 .00 .28 .00 .24 .00 .16 .00
FACTGRAPH .35 .00 .42 .00 .45 .00 .34 .00 .30 .00 .49 .00
FACTKB- WIKI .46 .00 .52 .00 .57 .00 .49 .00 .29 .00 .39 .00
FACTKB- EVIDENCE .43 .00 .49 .00 .53 .00 .45 .00 .31 .00 .37 .00
FACTKB- WALK .47 .00 .52 .00 .57 .00 .45 .00 .35 .00 .36 .00
Table 3: Correlation of FACTKBwith human judgments of factuality on the FRANK benchmark. Best performance
is shown in bold . FACTKB has the highest correlation with human judgments across five of the six settings.
Pretraining Stage Fine-Tuning Stage
Hyperparameter Value Hyperparameter Value
LEARNING RATE 2e-5 LEARNING RATE 1e-4
WEIGHT DECAY 1e-5 WEIGHT DECAY 1e-5
MAX EPOCHS 5 MAX EPOCHS 50
BATCH SIZE 32 BATCH SIZE 32
OPTIMIZER ADAM OPTIMIZER RADAM
ADAM EPSILON 1e-6
ADAM BETA 0.9,0.98
WARMUP RATIO 0.06
EVIDENCE :N 1e5
WALK :N 1e5
WALK :K 5
Table 4: Hyperparameter settings of F ACTKB.
3.2 Evaluation
To study the robustness of FACTKB, we perform
both in-domain and out-of-domain evaluation.
In-Domain Evaluation Since most research and
resources on summarization and factuality are in
the news media domain, we leverage the FactCol-
lect dataset (Ribeiro et al., 2022) and the FRANK
benchmark (Pagnoni et al., 2021) for in-domain
factuality evaluation. We evaluate FACTKB on
the held-out test set of the FactCollect dataset.
FRANK (Pagnoni et al., 2021) is a factuality eval-
uation benchmark with human judgments on the
factual consistency of model-generated summaries
collected across 9 summarization models along
with human annotations on the category of factual
errors. Following the FRANK benchmark guide-
lines, we use two correlation measures (Pearson
(Benesty et al., 2009) and Spearman (Myers and
Sirois, 2004)). We present more details about the
FRANK benchmark in Appendix C. Following pre-
vious work (Ribeiro et al., 2022), we train FACTKBon the FactCollect dataset without the FRANK sub-
set for the FRANK evaluation.
Generalizable Factuality Evaluation Summa-
rization systems are used in diverse domains in the
real world, including but not limited to news media
(Liu et al., 2022c; Eyal et al., 2019; Li et al., 2016),
social media (Syed et al., 2019; Kano et al., 2018;
He et al., 2020), and scientific literature (Cachola
et al., 2020; Lev et al., 2019). Consequently, factu-
ality metrics should also provide reliable factuality
scores in the face of shifting domains. To study this,
we perform an out-of-domain evaluation using un-
seen documents and summaries from the scientific
domain. To establish a test bed for generalizable
factuality evaluation, we make use of three datasets
in the scientific literature domain:
•CovidFact (Saakyan et al., 2021) collects claims
from the r/COVID19 subreddit and verifies them
against relevant scientific literature and Google
search results, resulting in a binary classification
setting that is similar to the FactCollect dataset.
•HealthVer (Sarrouti et al., 2021) consists of
claims sourced from TREC-COVID (V oorhees
et al., 2021) and verified against the CORD-19
(Wang et al., 2020b) corpus. While HealthVer
originally follows a three-way classification set-
ting ( SUPPORT ,REFUTE ,NOT ENOUGH INFOR -
MATION ), we remove the examples in the " NOT
ENOUGH INFORMATION " category to evaluate
models as they are trained on the binary classifi-
cation setting (factual, non-factual).ModelCovidFact HealthVer SciFact
BACC F1 BACC F1 BACC F1
RANDOM 52.7 41 .3 46 .8 53 .0 49 .0 57 .5
FACTCC 52.3 49 .2 51 .8 51 .9 42 .7 45 .9
FACTCC+ 51.1 50 .5 49 .5 51 .6 48 .6 55 .2
FACTGRAPH 57.6 53 .5 55 .1 24 .3 61 .0 42 .2
FACTGRAPH -EDGE 50.6 48 .4 50 .6 53 .5 56 .7 68 .2
FALSE SUM 50.6 41 .6 56 .8 51 .2 45 .7 65 .3
FALSE SUM+ 50.1 41 .2 57 .3 51 .6 51 .9 65 .4
SUMMA C 57.6 53 .4 52 .5 41 .2 59 .8 46 .9
ROBERT A 59.0(±3.2)46.4(±4.3)55.0(±2.2)50.0(±3.9)58.1(±4.0)71.3(±3.5)
FACTKB- WIKI 64.8 (±0.3)∗54.4 (±0.7)∗60.1 (±0.4)∗71.6 (±2.9)∗62.9(±0.4)∗72.3(±1.1)∗
FACTKB- EVIDENCE 63.9(±0.6)∗53.3(±1.7)59.0(±1.0)∗70.8(±0.9)∗61.4(±0.5)∗74.1 (±1.6)∗
FACTKB- WALK 63.7(±1.0)∗53.1(±1.6)58.5(±0.5)∗68.7(±1.7)∗63.1 (±1.1)∗67.6(±4.1)
Table 5: Performance of FACTKBon out-of-domain scientific datasets. We report average performance and standard
deviation across 5 random seeds. Best performance is shown in bold , while * indicates statistical significance.
FACTKB exhibits better generalization to new domains across all three datasets.
•SciFact (Wadden et al., 2020) includes claims
sourced from citation sentences in biomedical
literature and verified against the cited paper’s
abstract. While SciFact uses three-way classifi-
cation that includes " NOT ENOUGH INFORMA -
TION ", we similarly remove them in this work.
We leverage the well-organized version of the three
datasets in Wadden et al. (2022).1We train and
validate FACTKBwith the FactCollect dataset from
the news domain and evaluate on the test set of
these datasets for zero-shot transfer learning.
Baselines We compare FACTKB with differ-
ent types of existing factuality evaluation mod-
els: QAGS (Wang et al., 2020a), QUALS (Nan
et al., 2021), DAE (Goyal and Durrett, 2020),
FalseSum (Utama et al., 2022), SummaC (Laban
et al., 2022), FactCC (Kry ´sci´nski et al., 2020), and
FactGraph (Ribeiro et al., 2022). Since training
data is a key factor in factuality evaluation mod-
els and they are often used off-the-shelf, we in-
clude factuality evaluation measures trained on
both synthetic data (QAGS, QUALS, DAE, Sum-
maC, FalseSum, FactCC) and human-annotated
data (RoBERTa, FalseSum+, FactCC+, FactGraph,
FactGraph-edge). We follow the same train/dev/test
dataset split and experiment settings so that the
results are directly comparable. We present more
details about the baselines in Appendix D.
4 Results
In-Domain Results We evaluate FACTKBand
baselines on the FactCollect dataset using the en-
1Dataset statistics are presented in Table 8.tire held-out test data, the CNN/DM subset and
the XSUM (BBC) subset, and report balanced ac-
curacy scores and micro F1 scores. We run each
method five times with different random seeds and
report the average performance as well as the stan-
dard deviation. Table 2 demonstrates that FACTKB
significantly (*) outperforms all baseline factuality
evaluation methods by 3.8 BACC points on aver-
age across the three dataset settings. This demon-
strates that the introduction of KBs and factuality
pretraining is beneficial for factuality evaluation.
Among the three factuality pretraining strategies,
all of them outperform baseline models, suggesting
thatFACTKB’s general methodology is compatible
with different types of KB utilization.
Human Correlation We evaluate FACTKBand
baselines on the FRANK benchmark to study how
well FACTKBcorrelates with human judgments.
We use the official script2to report the Pearson ( ρ)
and Spearman ( r) correlation and p-values. Results
in Table 3 show that classification-based metrics
(FactCC, FactGraph, and FACTKB) generally out-
perform QA-based metrics ( QAGS andQUALS ).
FACTKBsignificantly advances the state-of-the-art
on the FRANK benchmark, resulting in the im-
provement of 5-15 correlation points across mul-
tiple settings. Our results show that FACTKBis
highly correlated with human judgments, making
it a practical approach for evaluating the factual
consistency of generated news summaries.
Out-of-Domain Results We evaluate FACTKB
and existing factuality evaluation models on out-of-
2https://github.com/artidoro/frank/uni00000051/uni00000052/uni00000003/uni0000002e/uni00000025/uni00000035/uni00000052/uni00000025/uni00000028/uni00000035/uni00000037/uni00000044
/uni00000028/uni0000004f/uni00000048/uni00000046/uni00000057/uni00000055/uni00000044
/uni00000025/uni00000024/uni00000035/uni00000037
/uni00000027/uni00000048/uni00000025/uni00000028/uni00000035/uni00000037/uni00000044
/uni00000024/uni0000002f/uni00000025/uni00000028/uni00000035/uni00000037
/uni00000047/uni0000004c/uni00000056/uni00000057/uni0000004c/uni0000004f/uni00000035/uni00000052/uni00000025/uni00000028/uni00000035/uni00000037/uni00000044/uni0000001b/uni00000018/uni00000011/uni00000016
/uni0000001b/uni00000018/uni00000011/uni0000001b
/uni0000001b/uni00000017/uni00000011/uni00000013
/uni0000001b/uni0000001a/uni00000011/uni00000018
/uni0000001b/uni00000018/uni00000011/uni00000018
/uni0000001b/uni00000018/uni00000011/uni00000013/uni00000059/uni00000044/uni00000051/uni0000004c/uni0000004f/uni0000004f/uni00000044
/uni0000003c/uni00000024/uni0000002a/uni00000032 /uni0000003a/uni0000002c/uni0000002e/uni0000002c /uni00000026/uni00000033/uni00000031/uni00000048/uni00000057 /uni00000024/uni00000057/uni00000052/uni00000050/uni0000004c/uni00000046 /uni0000002e/uni0000002a/uni00000024/uni00000033 /uni00000038/uni00000030/uni0000002f/uni00000036/uni0000001b/uni0000001c/uni00000011/uni00000017 /uni0000001b/uni0000001a/uni00000011/uni00000019 /uni0000001b/uni00000019/uni00000011/uni0000001a /uni0000001b/uni0000001a/uni00000011/uni00000018 /uni0000001b/uni0000001c/uni00000011/uni00000014 /uni0000001b/uni0000001a/uni00000011/uni0000001a
/uni0000001b/uni0000001a/uni00000011/uni00000013 /uni0000001b/uni00000019/uni00000011/uni0000001b /uni0000001b/uni00000017/uni00000011/uni00000017 /uni0000001b/uni00000019/uni00000011/uni00000014 /uni0000001b/uni0000001a/uni00000011/uni0000001b /uni0000001b/uni0000001a/uni00000011/uni00000016
/uni0000001b/uni00000017/uni00000011/uni00000018 /uni0000001b/uni00000018/uni00000011/uni00000017 /uni0000001b/uni00000016/uni00000011/uni0000001b /uni0000001b/uni00000018/uni00000011/uni00000014 /uni0000001b/uni00000017/uni00000011/uni0000001c /uni0000001b/uni00000018/uni00000011/uni0000001c
/uni0000001b/uni0000001a/uni00000011/uni0000001c /uni0000001b/uni0000001a/uni00000011/uni0000001c /uni0000001b/uni00000019/uni00000011/uni00000019 /uni0000001b/uni00000018/uni00000011/uni0000001b /uni0000001c/uni00000013/uni00000011/uni00000014 /uni0000001c/uni00000013/uni00000011/uni00000014
/uni0000001b/uni0000001b/uni00000011/uni00000019 /uni0000001b/uni0000001a/uni00000011/uni00000014 /uni0000001b/uni00000019/uni00000011/uni00000015 /uni0000001b/uni00000018/uni00000011/uni0000001b /uni0000001b/uni0000001b/uni00000011/uni00000013 /uni0000001b/uni0000001a/uni00000011/uni00000017
/uni0000001b/uni0000001a/uni00000011/uni00000015 /uni0000001b/uni00000019/uni00000011/uni0000001a /uni0000001b/uni00000018/uni00000011/uni00000019 /uni0000001b/uni00000018/uni00000011/uni00000016 /uni0000001b/uni0000001a/uni00000011/uni00000017 /uni0000001b/uni00000019/uni00000011/uni0000001b/uni00000029/uni00000044/uni00000046/uni00000057/uni0000002e/uni00000025/uni00000010/uni0000005a/uni0000004c/uni0000004e/uni0000004c
/uni0000003c/uni00000024/uni0000002a/uni00000032 /uni0000003a/uni0000002c/uni0000002e/uni0000002c /uni00000026/uni00000033/uni00000031/uni00000048/uni00000057 /uni00000024/uni00000057/uni00000052/uni00000050/uni0000004c/uni00000046 /uni0000002e/uni0000002a/uni00000024/uni00000033 /uni00000038/uni00000030/uni0000002f/uni00000036/uni0000001b/uni0000001c/uni00000011/uni00000017 /uni0000001b/uni0000001b/uni00000011/uni00000016 /uni0000001b/uni0000001a/uni00000011/uni00000019 /uni0000001b/uni0000001b/uni00000011/uni00000013 /uni0000001b/uni0000001b/uni00000011/uni0000001a /uni0000001b/uni0000001a/uni00000011/uni00000019
/uni0000001b/uni0000001a/uni00000011/uni00000014 /uni0000001b/uni0000001a/uni00000011/uni00000014 /uni0000001b/uni00000019/uni00000011/uni00000015 /uni0000001b/uni00000019/uni00000011/uni00000014 /uni0000001b/uni00000019/uni00000011/uni00000015 /uni0000001b/uni00000019/uni00000011/uni0000001c
/uni0000001b/uni00000018/uni00000011/uni0000001c /uni0000001b/uni00000017/uni00000011/uni00000014 /uni0000001b/uni00000017/uni00000011/uni0000001c /uni0000001b/uni00000018/uni00000011/uni00000019 /uni0000001b/uni00000016/uni00000011/uni00000016 /uni0000001b/uni00000017/uni00000011/uni0000001c
/uni0000001b/uni0000001c/uni00000011/uni00000013 /uni0000001b/uni0000001c/uni00000011/uni00000013 /uni0000001b/uni0000001c/uni00000011/uni00000013 /uni0000001b/uni0000001a/uni00000011/uni00000018 /uni0000001b/uni0000001b/uni00000011/uni00000017 /uni0000001b/uni0000001b/uni00000011/uni00000013
/uni0000001b/uni0000001a/uni00000011/uni00000018 /uni0000001b/uni0000001c/uni00000011/uni00000014 /uni0000001b/uni0000001a/uni00000011/uni0000001c /uni0000001b/uni0000001b/uni00000011/uni00000019 /uni0000001b/uni0000001a/uni00000011/uni0000001a /uni0000001b/uni0000001a/uni00000011/uni0000001a
/uni0000001b/uni00000019/uni00000011/uni0000001a /uni0000001b/uni0000001a/uni00000011/uni00000014 /uni0000001b/uni0000001a/uni00000011/uni00000019 /uni0000001b/uni00000019/uni00000011/uni00000015 /uni0000001b/uni0000001a/uni00000011/uni00000014 /uni0000001b/uni00000019/uni00000011/uni0000001c/uni00000029/uni00000044/uni00000046/uni00000057/uni0000002e/uni00000025/uni00000010/uni00000048/uni00000059/uni0000004c/uni00000047/uni00000048/uni00000051/uni00000046/uni00000048
/uni0000003c/uni00000024/uni0000002a/uni00000032 /uni0000003a/uni0000002c/uni0000002e/uni0000002c /uni00000026/uni00000033/uni00000031/uni00000048/uni00000057 /uni00000024/uni00000057/uni00000052/uni00000050/uni0000004c/uni00000046 /uni0000002e/uni0000002a/uni00000024/uni00000033 /uni00000038/uni00000030/uni0000002f/uni00000036/uni0000001b/uni0000001c/uni00000011/uni00000014 /uni0000001b/uni0000001a/uni00000011/uni0000001b /uni0000001b/uni0000001a/uni00000011/uni00000017 /uni0000001b/uni0000001a/uni00000011/uni00000017 /uni0000001b/uni00000019/uni00000011/uni00000019 /uni0000001b/uni0000001b/uni00000011/uni00000017
/uni0000001b/uni00000018/uni00000011/uni00000018 /uni0000001b/uni0000001a/uni00000011/uni00000013 /uni0000001b/uni00000019/uni00000011/uni00000016 /uni0000001b/uni00000019/uni00000011/uni00000016 /uni0000001b/uni00000019/uni00000011/uni00000014 /uni0000001b/uni00000019/uni00000011/uni00000015
/uni0000001b/uni00000016/uni00000011/uni0000001c /uni0000001b/uni00000017/uni00000011/uni00000016 /uni0000001b/uni00000018/uni00000011/uni00000013 /uni0000001b/uni00000018/uni00000011/uni00000014 /uni0000001b/uni00000017/uni00000011/uni0000001c /uni0000001b/uni00000017/uni00000011/uni0000001c
/uni0000001b/uni0000001a/uni00000011/uni0000001a /uni0000001b/uni0000001a/uni00000011/uni0000001a /uni0000001b/uni0000001b/uni00000011/uni00000015 /uni0000001b/uni0000001a/uni00000011/uni00000013 /uni0000001b/uni0000001c/uni00000011/uni00000014 /uni0000001b/uni0000001c/uni00000011/uni00000015
/uni0000001b/uni0000001a/uni00000011/uni0000001a /uni0000001b/uni0000001a/uni00000011/uni00000013 /uni0000001b/uni00000019/uni00000011/uni00000015 /uni0000001b/uni0000001a/uni00000011/uni00000019 /uni0000001b/uni00000019/uni00000011/uni00000015 /uni0000001b/uni0000001a/uni00000011/uni00000014
/uni0000001b/uni00000019/uni00000011/uni00000015 /uni0000001b/uni00000019/uni00000011/uni00000014 /uni0000001b/uni00000019/uni00000011/uni00000017 /uni0000001b/uni00000019/uni00000011/uni00000016 /uni0000001b/uni00000019/uni00000011/uni00000019 /uni0000001b/uni00000019/uni00000011/uni0000001a/uni00000029/uni00000044/uni00000046/uni00000057/uni0000002e/uni00000025/uni00000010/uni0000005a/uni00000044/uni0000004f/uni0000004e
/uni00000017
/uni00000016
/uni00000015
/uni00000014
/uni00000013/uni00000014/uni00000015/uni00000016/uni00000017Figure 3: Compatibility of FACTKBacross various LMs and KBs. We report BACC scores of different setups on
the FactCollect dataset. F ACTKB is a general method compatible with various LM and KB settings.
/uni00000056/uni00000048/uni00000050/uni00000044/uni00000051/uni00000057/uni0000004c/uni00000046/uni00000003/uni00000049/uni00000055/uni00000044/uni00000050/uni00000048 /uni00000047/uni0000004c/uni00000056/uni00000046/uni00000052/uni00000058/uni00000055/uni00000056/uni00000048 /uni00000046/uni00000052/uni00000051/uni00000057/uni00000048/uni00000051/uni00000057/uni00000003/uni00000059/uni00000048/uni00000055/uni0000004c/uni00000049/uni0000004c/uni00000044/uni00000045/uni0000004c/uni0000004f/uni0000004c/uni00000057/uni0000005c/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000014/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000016/uni00000013/uni00000011/uni00000017/uni00000033/uni00000048/uni00000044/uni00000055/uni00000056/uni00000052/uni00000051/uni00000003/uni00000026/uni00000052/uni00000055/uni00000055/uni00000048/uni0000004f/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000025/uni00000028/uni00000035/uni00000037/uni00000036/uni00000046/uni00000052/uni00000055/uni00000048
/uni00000029/uni00000044/uni00000046/uni00000057/uni0000002a/uni00000055/uni00000044/uni00000053/uni0000004b/uni00000034/uni00000024/uni0000002a/uni00000036
/uni00000029/uni00000044/uni00000046/uni00000057/uni0000002e/uni00000025/uni00000010/uni0000005a/uni00000044/uni0000004f/uni0000004e/uni00000027/uni00000024/uni00000028
/uni00000029/uni00000044/uni00000046/uni00000057/uni0000002e/uni00000025/uni00000010/uni0000005a/uni0000004c/uni0000004e/uni0000004c/uni00000029/uni00000044/uni00000046/uni00000057/uni00000026/uni00000026
/uni00000029/uni00000044/uni00000046/uni00000057/uni0000002e/uni00000025/uni00000010/uni00000048/uni00000059/uni0000004c/uni00000047/uni00000048/uni00000051/uni00000046/uni00000048
Figure 4: Correlation of FACTKBand baselines with hu-
man judgments across error categories. FACTKBshows
significant improvement in capturing semantic frame
errors and has slightly better or on-par performance on
discourse and content verifiability errors.
domain scientific literature datasets in a zero-shot
manner. Results are presented in Table 5, which
demonstrate that while existing factuality evalua-
tion models previously achieve good performance
in the in-domain setting, they exhibit severe perfor-
mance drops on the three out-of-domain datasets,
performing only slightly better than random factu-
ality scores ( RANDOM ). This suggests that existing
approaches are not generalizable to other domains,
limiting their applicability. On the contrary, FAC-
TKBsignificantly (*) outperforms existing factual-
ity metrics by 4.1 BACC points on average across
the three out-of-domain datasets. Our results sug-
gest that the factuality pretraining strategies enable
FACTKBto better represent facts (entities and re-
lations) in a new domain, making the factuality
evaluation model more robust to shifting domains.
5 Analysis and Discussion
5.1 Where did F ACTKB Improve?
To better understand FACTKB’s improvement over
existing approaches, we leverage the factual error
typology in the FRANK benchmark (Pagnoni et al.,2021) and examine FACTKB’s performance on the
three error categories: semantic frame, discourse,
and content verifiability errors. Using the official
script in the FRANK benchmark, we remove each
category of errors and report changes in correlation
scores. Higher variation indicates a greater influ-
ence on a model’s ability to handle a certain type
of error. Figure 4 demonstrates that FACTKBis
significantly better at identifying semantic frame
errors, which focus on entities and relations. This
indicates that our KB-based factuality pretraining
strategies successfully result in a better understand-
ing of the facts regarding entities and relations.
FACTKBalso has good performance in other cat-
egories, resulting in a factuality evaluation model
that captures diverse types of errors and advances
the state-of-the-art across the board. We conduct
further qualitative analysis in Appendix B.
5.2 KB and LM Compatibility
FACTKBuses pretrained LMs for initialization,
leverages external KBs for factuality pretraining,
and trains on factuality evaluation datasets to result
in a factuality metric. Our general methodology to
leverage knowledge bases as fact teachers for gen-
eralizable factuality evaluation could work with dif-
ferent LM and KB combinations. To study whether
out approach works across different settings, we ap-
ply the FACTKBmethodology to six different LMs
(RoBERTa, Electra, BART, DeBERTa, ALBERT,
and distilRoBERTa) and pretrain the LMs on fac-
tuality pretraining corpora constructed based on
six different KBs (YAGO, Wikidata, ConceptNet,
Atomic, KGAP, and UMLS). For each combination,
we initialize a particular LM and pretrain it using
the proposed three pretraining strategies based on a
particular KB. For each setting, we evaluate the re-
sulting model using the FactCollect dataset and re-
port the BACC scores. We present the performanceMetric Pearson Spearman Usage Steps
QAGS .22 .23 1) extract answer candidates 2) generate the questions 3) answer the
generated questions 4) compare the answers to obtain the QAGS
factuality score
QUALS .22 .19 1) generating question and answer pairs from summaries 2) filter the
generated question and answer for high-quality pairs 3) evaluate the
generated question and answer pairs using the source document as
input, compute QUALS scores for each summary
DAE .17 .20 1) preprocess summaries and documents with dependency parsing 2)
run the pretrained model to get DAE scores
FACTCC .20 .29 1) run the pretrained model to get FactCC scores
FACTGRAPH .35 .42 1) build abstract meaning representation graphs 2) run the pretrained
model to get FactGraph scores
FACTKB .47 .52 1) run the pretrained model to get F ACTKB scores
Table 6: Usage steps of factuality metrics and their performance on the FRANK benchmark. FACTKB(WALK )
presents a state-of-the-art factuality metric with minimum hassle when evaluating new summaries and articles.
of different settings in Figure 3, which illustrates
that regardless of which LM and KB, FACTKB
generally results in improved factual error detec-
tion capabilities compared to the vanilla LM check-
points without factuality pretraining. In addition,
certain LMs (RoBERTa and DeBERTa) and KBs
(YAGO, KGAP, and UMLS) are better than oth-
ers, suggesting that the choice of the base LM and
external KB warrants further research. Our results
demonstrate that FACTKBis a general pretraining
approach that can be applied to various LM-KB
combinations to improve fact representations and
develop better factuality evaluation models.
5.3 Simplicity Study
While existing factuality evaluation approaches re-
quire additional processing (such as computing the
dependency structure (Goyal and Durrett, 2020)
and AMR graphs (Ribeiro et al., 2022) or running
multiple iterations of question generation (Fabbri
et al., 2022)) in the face of new data, FACTKBre-
quires no preprocessing and only uses a fine-tuned
RoBERTa for sequence classification. We summa-
rize the steps involved in using existing approaches
and their performance on the FRANK benchmark
in Table 6, which demonstrates that FACTKBnot
only has state-of-the-art performance but is also a
lightweight and simple factuality evaluation model.
5.4 Parameter Analysis
Corpus size. For evidence extraction and knowl-
edge walk, the pretraining corpus size Nis con-
trollable and governs the amount of information
towards augmenting FACTKB’s ability towards fac-
tual errors regarding entities and relations. While
we adopted N= 1e5in the main experiments,we further explore the effect of factuality pretrain-
ing corpus size in Figure 5. It is illustrated that
N= 1e4orN= 1e5are generally desirable set-
tings, while factuality pretraining with too large
Ns might be counterproductive. This could in part
be attributed to catastrophic forgetting (Ramasesh
et al., 2021), which warrants further research.
Pretraining epoch. FACTKBfurther pretrains
LM checkpoints on the three factuality pretrain-
ing corpora, while the training epoch governs the
intensity of such exercises. We adopted 5 epochs
of continued pretraining in the main experiments,
while we further explore the effect of pretraining
epochs in Figure 5. it is demonstrated that 1 to 10
epochs are generally desirable while exercising too
much might be counterproductive.
Knowledge walk length. An important aspect
of the knowledge walk factuality pretraining is the
generated walk length K, which governs the de-
gree of compositionality in the pretraining corpus.
While we adopted K= 5in the main experiments,
we further explore the effect of Kin Figure 5. It
is illustrated that K= 5performs best by provid-
ing a moderate amount of compositionality in the
factuality pretraining corpora.
6 Related Work
Factuality Evaluation Recent advances in text
summarization have presented models and systems
that are capable of generating increasingly fluent,
controllable, and informative summaries of docu-
ments (Liu and Lapata, 2019; Balachandran et al.,
2021; Meng et al., 2022; Tang et al., 2022; Gold-
sack et al., 2022; Peng et al., 2021; Aharoni et al.,2023; Liu et al., 2022d; Rothe et al., 2021; Narayan
et al., 2021; Bhattacharjee et al., 2023; Chen et al.,
2023b; He et al., 2023; Liu et al., 2023b; Chen
et al., 2023a). However, they suffer from hallucina-
tion and might not be factually faithful towards the
source document (Cao et al., 2018; Pagnoni et al.,
2021; Balachandran et al., 2022; Tang et al., 2023;
Liu et al., 2023a; Luo et al., 2023), leading to in-
creased research in factuality evaluation. QA-based
approaches (Wang et al., 2020a; Nan et al., 2021;
Scialom et al., 2021; Fabbri et al., 2022) attempt
to generate and answer questions based on sum-
maries and documents and judge the factuality by
comparing answers. Later approaches are generally
entailment-based (Kry ´sci´nski et al., 2020; Goyal
and Durrett, 2020, 2021; Laban et al., 2022; Ribeiro
et al., 2022), proposing to classify (summary, docu-
ment) pairs into FACTUAL orNON-FACTUAL labels.
Among them, FactCC (Kry ´sci´nski et al., 2020) is
one of the first entailment-based metrics and is
trained on synthetic data; DAE (Goyal and Durrett,
2020, 2021) proposes to leverage the dependency
structure of summaries and documents; FactGraph
(Ribeiro et al., 2022) builds abstract meaning repre-
sentation graphs and adopts graph neural networks
for joint representation learning along the textual
content. In addition, hypothesis re-ranking (Gar-
neau and Lamontagne, 2021), counterfactual esti-
mation (Xie et al., 2021), NLI models (Utama et al.,
2022), phrase-level localization (Takatsuka et al.,
2022), and weighting facts in the source document
(Xu et al., 2020) were also explored in factuality
evaluation. Moving beyond a binary concept of fac-
tuality, FRANK (Pagnoni et al., 2021) promotes a
fine-grained understanding of factuality and pro-
poses a typology of factuality errors. Inspired by
its analysis that semantic frame errors , errors re-
garding entities and relations, are a major source of
factuality errors yet under-explored by existing fac-
tuality metrics, we propose FACTKBto leverage
external KBs for factuality pretraining and help en-
force better factuality towards entities and relations
discussed in summaries and documents.
Knowledge Bases in NLP Knowledge base is a
standard format for structured knowledge represen-
tation. One application of KBs in NLP is to inject
knowledge and augment LMs, where different ap-
proaches focused aspects such as pretraining (Chen
et al., 2020; Agarwal et al., 2021; Rosset et al.,
2020; Li et al., 2022), document graphs (Hu et al.,
2021; Zhang et al., 2022a), KB structure (Yasunaga
1k 10k 100k 1m 10m
corpus size0.800.850.900.95BACC
walk
evidence
1k 10k 100k 1m 10m
corpus size0.800.850.900.95F1
walk
evidence
1 5 10 50 100
pre-training epoch0.800.850.900.95BACC
walk
evidence
wiki
1 5 10 50 100
pre-training epoch0.800.850.900.95F1
walk
evidence
wiki
1 2 5 10 50
walk length0.800.850.900.95BACC
walk
1 2 5 10 50
walk length0.800.850.900.95F1
walkFigure 5: Parameter analysis of pretraining corpus size,
epoch, and knowledge walk length.
et al., 2021; Zhang et al., 2022b), and long docu-
ments (Feng et al., 2023). KB-enhanced approaches
also advanced numerous NLP tasks, ranging from
question answering (Mitra et al., 2022; Bosselut
et al., 2021; Oguz et al., 2022; Feng et al., 2022;
Heo et al., 2022; Ma et al., 2022), text generation
(Rony et al., 2022; Dognin et al., 2021; Yu et al.,
2021), and commonsense reasoning (Kim et al.,
2022; Jung et al., 2022; Amayuelas et al., 2021;
Liu et al., 2022a). In this work, we tap into KBs’
nature as high-quality reservoirs of factual informa-
tion and construct factuality pretraining objectives
to augment factuality evaluation.
7 Conclusion
We propose FACTKB, a simple and novel approach
to factuality evaluation using language models pre-
trained on facts from external KBs to improve en-
tity and relation representations. Specifically, we
leverage KBs to construct three factuality pretrain-
ing objectives: entity wiki, evidence extraction, and
knowledge walk. FACTKBpretrains an LM using
the three objectives and fine-tunes the resulting
model on factuality evaluation datasets. Extensive
experiments demonstrate that FACTKBadvances
the state-of-the-art in both in-domain and out-of-
domain factuality evaluation, better correlates with
human factuality annotations, and better detects se-
mantic frame errors. FACTKBpresents an easy-to-
use and generalizable factuality metric, facilitating
research on factually-consistent summarization.Limitations
LM and KB Selection While Section 5.2 offers
empirical evidence that FACTKBis compatible
with 6 language models and 6 external knowledge
bases, it remains unclear upfront which LM and
KB combination would be most desirable. While
empirical performance could be a good guide, there
are several unaddressed possibilities: For language
models, it is possible to leverage an ensemble of
FACTKBs seeded with different LM checkpoints
and architectures. This might result in better fac-
tuality evaluation, but would also dramatically in-
crease the computation costs when evaluating on
new data. For knowledge bases, it is possible to
leverage domain expertise and select an external
knowledge base that would be most helpful for the
domain adaptation of factuality evaluation. It is
also possible to leverage a combination of existing
knowledge bases for FACTKB’s factuality pretrain-
ing, while the specific combination and how to
apply different factuality pretraining to different
KBs are hard to determine. All in all, FACTKB
presents a general KB-enhanced factuality metric
with numerous possibilities, while we leave some
of these considerations to future work.
FACTKBtraining is not end-to-end. FACTKB
has a two-step training process: pretraining with
KB-based factuality pretraining and fine-tuning on
factuality evaluation datasets. This creates several
limitations, among which is the difficulty of hy-
perparameter tuning. Appendix 3.1 presents the
study of hyperparameters in the factuality pretrain-
ing stage, which demonstrates that FACTKBworks
best with a moderate but not excessive amount of
factuality pretraining. This reliance on certain hy-
perparameter configurations is further complicated
by more hyperparameter choices in the fine-tuning
stage. While the current hyperparameter setting
in Appendix 3.1 achieves state-of-the-art empiri-
cal performance, we acknowledge the difficulty in
FACTKB hyperparameter tuning.
Out-of-Domain Factuality Evaluation. An im-
portant focus of this work is out-of-domain factual-
ity evaluation: Summarization systems face input
documents from varying domains, which requires
factuality metrics to also generalize to different
document domains. Existing metrics struggle with
semantic frame errors and such struggle is exacer-
bated by the domain shift of entities and relations,
while FACTKBoffers a stronger and more gener-alizable factuality metric. However, in this work,
we mainly focused on the additional domain of
scientific literature, while other potential domains
remain underexplored such as social media (Syed
et al., 2019; Kano et al., 2018; He et al., 2020). We
leave it to future work the exploration of FACTKB
and existing factuality metrics on more document
domains that are present in summarization systems.
Tradeoff between Performance and Granularity
Existing approaches (Kry ´sci´nski et al., 2020; Takat-
suka et al., 2022) struggle with semantic frame er-
rors and involve heavy preprocessing, while they
provide fine-grained analysis and specific localiza-
tion of summarization errors. FACTKBachieves
significantly better factuality evaluation results and
is easier to use while lacking the ability of error
localization. We argue that this tradeoff should be
considered with the use case in mind: for LLM
evaluation, it is better to have an accurate metric
for benchmarking efforts and an efficient metric for
handling large-scale LM generation. As a result,
FACTKBprovides a valuable tool for factuality
evaluation and LLM research.
Ethics Statement
LM and KB Bias FACTKBis initialized with
pretrained language model checkpoints and lever-
ages knowledge-base-based factuality pretraining.
Consequently, FACTKBmight pick up the biases
of the adopted language models (Liang et al., 2021;
Nadeem et al., 2021; Shaikh et al., 2023; Tan and
Celis, 2019) and knowledge bases (Fisher et al.,
2020; Mehrabi et al., 2021). As a result, FACTKB
might leverage these biases in judging the factu-
ality of summaries, further reinforcing the bias in
text summarization systems. We leave it to future
work on understanding and mitigating the bias of
factuality metrics.
Misuse Potential FACTKB leverages high-
quality and factual knowledge bases to generate fac-
tuality pretraining corpora and augment LM’s abil-
ity to stay factual with respect to entities and rela-
tions discussed in the summary and document. On
the contrary, if non-factual and misleading knowl-
edge is leveraged for the three factuality pretraining
strategies, it might jeopardize the factuality of FAC-
TKBand make it insensitive to misinformation and
falsehoods in summaries and documents. As a re-
sult, we encourage the responsible use of FACTKB
and the factuality pretraining methodology.Acknowledgements
We thank the reviewers, the area chair, members of
Tsvetshop, and the UW NLP Group for their feed-
back. This research was supported by This research
is supported in part by the Office of the Director
of National Intelligence (ODNI), Intelligence Ad-
vanced Research Projects Activity (IARPA), via the
HIATUS Program contract #2022-22072200004.
This material is also funded by the DARPA Grant
under Contract No. HR001120C0124. We also
gratefully acknowledge support from NSF CA-
REER Grant No. IIS2142739 and the Alfred
P. Sloan Foundation Fellowship. The views and
conclusions contained herein are those of the au-
thors and should not be interpreted as necessarily
representing the official policies, either expressed
or implied, of ODNI, IARPA, or the U.S. Gov-
ernment. The U.S. Government is authorized to
reproduce and distribute reprints for governmental
purposes notwithstanding any copyright annotation
therein.
References
Oshin Agarwal, Heming Ge, Siamak Shakeri, and Rami
Al-Rfou. 2021. Knowledge graph based synthetic
corpus generation for knowledge-enhanced language
model pre-training. In Proceedings of the 2021 Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies , pages 3554–3565.
Roee Aharoni, Shashi Narayan, Joshua Maynez,
Jonathan Herzig, Elizabeth Clark, and Mirella La-
pata. 2023. Multilingual summarization with factual
consistency evaluation. In Findings of the Associa-
tion for Computational Linguistics: ACL 2023 , pages
3562–3591.
Alfonso Amayuelas, Shuai Zhang, Xi Susie Rao, and
Ce Zhang. 2021. Neural methods for logical reason-
ing over knowledge graphs. In International Confer-
ence on Learning Representations .
Vidhisha Balachandran, Hannaneh Hajishirzi, William
Cohen, and Yulia Tsvetkov. 2022. Correcting diverse
factual errors in abstractive summarization via post-
editing and language model infilling. In Proceedings
of the 2022 Conference on Empirical Methods in
Natural Language Processing .
Vidhisha Balachandran, Artidoro Pagnoni, Jay Yoon
Lee, Dheeraj Rajagopal, Jaime Carbonell, and Yu-
lia Tsvetkov. 2021. StructSum: Summarization via
structured representations. In Proceedings of the 16th
Conference of the European Chapter of the Associ-
ation for Computational Linguistics: Main Volume ,
pages 2575–2585.Jacob Benesty, Jingdong Chen, Yiteng Huang, and Is-
rael Cohen. 2009. Pearson correlation coefficient.
InNoise reduction in speech processing , pages 1–4.
Springer.
Abhik Bhattacharjee, Tahmid Hasan, Wasi Uddin Ah-
mad, Yuan-Fang Li, Yong-Bin Kang, and Rifat
Shahriyar. 2023. CrossSum: Beyond English-centric
cross-lingual summarization for 1,500+ language
pairs. In Proceedings of the 61st Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 1: Long Papers) , pages 2541–2564.
Steven Bird, Ewan Klein, and Edward Loper. 2009. Nat-
ural language processing with Python: analyzing text
with the natural language toolkit . " O’Reilly Media,
Inc.".
Antoine Bordes, Nicolas Usunier, Alberto Garcia-
Duran, Jason Weston, and Oksana Yakhnenko.
2013. Translating embeddings for modeling multi-
relational data. Advances in neural information pro-
cessing systems , 26.
Antoine Bosselut, Ronan Le Bras, and Yejin Choi. 2021.
Dynamic neuro-symbolic knowledge graph construc-
tion for zero-shot commonsense question answering.
InProceedings of the 35th AAAI Conference on Arti-
ficial Intelligence (AAAI) .
Isabel Cachola, Kyle Lo, Arman Cohan, and Daniel S
Weld. 2020. Tldr: Extreme summarization of sci-
entific documents. In Findings of the Association
for Computational Linguistics: EMNLP 2020 , pages
4766–4777.
Ziqiang Cao, Furu Wei, Wenjie Li, and Sujian Li. 2018.
Faithful to the original: Fact aware neural abstractive
summarization. In thirty-second AAAI conference on
artificial intelligence .
Wenhu Chen, Yu Su, Xifeng Yan, and William Yang
Wang. 2020. Kgpt: Knowledge-grounded pre-
training for data-to-text generation. In Proceedings
of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP) , pages 8635–
8648.
Xiuying Chen, Guodong Long, Chongyang Tao,
Mingzhe Li, Xin Gao, Chengqi Zhang, and Xian-
gliang Zhang. 2023a. Improving the robustness of
summarization systems with dual augmentation. In
Proceedings of the 61st Annual Meeting of the As-
sociation for Computational Linguistics (Volume 1:
Long Papers) , pages 6846–6857.
Yulong Chen, Yang Liu, Ruochen Xu, Ziyi Yang, Chen-
guang Zhu, Michael Zeng, and Yue Zhang. 2023b.
UniSumm and SummZoo: Unified model and diverse
benchmark for few-shot summarization. In Proceed-
ings of the 61st Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers) ,
pages 12833–12855.Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2019. Bert: Pre-training of deep
bidirectional transformers for language understand-
ing. In Proceedings of the 2019 Conference of the
North American Chapter of the Association for Com-
putational Linguistics: Human Language Technolo-
gies, Volume 1 (Long and Short Papers) , pages 4171–
4186.
Pierre Dognin, Inkit Padhi, Igor Melnyk, and Payel Das.
2021. ReGen: Reinforcement learning for text and
knowledge base generation using pretrained language
models. In Proceedings of the 2021 Conference on
Empirical Methods in Natural Language Processing ,
pages 1084–1099.
Hady Elsahar and Matthias Gallé. 2019. To annotate or
not? predicting performance drop under domain shift.
InProceedings of the 2019 Conference on Empirical
Methods in Natural Language Processing and the 9th
International Joint Conference on Natural Language
Processing (EMNLP-IJCNLP) , pages 2163–2173.
Matan Eyal, Tal Baumel, and Michael Elhadad. 2019.
Question answering as an automatic evaluation met-
ric for news article summarization. In Proceedings
of the 2019 Conference of the North American Chap-
ter of the Association for Computational Linguistics:
Human Language Technologies, Volume 1 (Long and
Short Papers) , pages 3938–3948.
Alexander Fabbri, Chien-Sheng Wu, Wenhao Liu, and
Caiming Xiong. 2022. QAFactEval: Improved QA-
based factual consistency evaluation for summariza-
tion. In Proceedings of the 2022 Conference of the
North American Chapter of the Association for Com-
putational Linguistics: Human Language Technolo-
gies, pages 2587–2601.
William Falcon and The PyTorch Lightning team. 2019.
PyTorch Lightning.
Yair Feldman and Ran El-Yaniv. 2019. Multi-hop para-
graph retrieval for open-domain question answering.
InProceedings of the 57th Annual Meeting of the As-
sociation for Computational Linguistics , pages 2296–
2309.
Shangbin Feng, Zilong Chen, Wenqian Zhang, Qingyao
Li, Qinghua Zheng, Xiaojun Chang, and Minnan Luo.
2021. Kgap: Knowledge graph augmented political
perspective detection in news media. arXiv preprint
arXiv:2108.03861 .
Shangbin Feng, Zhaoxuan Tan, Wenqian Zhang, Zhenyu
Lei, and Yulia Tsvetkov. 2023. KALM: Knowledge-
aware integration of local, document, and global con-
texts for long document understanding. In Proceed-
ings of ACL 2023 , pages 2116–2138.
Yue Feng, Zhen Han, Mingming Sun, and Ping Li.
2022. Multi-hop open-domain question answering
over structured and unstructured knowledge. In Find-
ings of the Association for Computational Linguistics:
NAACL 2022 , pages 151–156, Seattle, United States.Joseph Fisher, Arpit Mittal, Dave Palfrey, and Chris-
tos Christodoulopoulos. 2020. Debiasing knowledge
graph embeddings. In Proceedings of the 2020 Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP) , pages 7332–7345.
Nicolas Garneau and Luc Lamontagne. 2021. Trainable
ranking models to evaluate the semantic accuracy
of data-to-text neural generator. In Proceedings of
the 2nd Workshop on Evaluation and Comparison of
NLP Systems , pages 51–61.
Tomas Goldsack, Zhihao Zhang, Chenghua Lin, and
Carolina Scarton. 2022. Making science simple: Cor-
pora for the lay summarisation of scientific literature.
InProceedings of the 2022 Conference on Empirical
Methods in Natural Language Processing .
Tanya Goyal and Greg Durrett. 2020. Evaluating factu-
ality in generation with dependency-level entailment.
InFindings of the Association for Computational
Linguistics: EMNLP 2020 , pages 3592–3603.
Tanya Goyal and Greg Durrett. 2021. Annotating and
modeling fine-grained factuality in summarization.
InProceedings of the 2021 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies .
Suchin Gururangan, Ana Marasovi ´c, Swabha
Swayamdipta, Kyle Lo, Iz Beltagy, Doug Downey,
and Noah A Smith. 2020. Don’t stop pretraining:
Adapt language models to domains and tasks. In
Proceedings of the 58th Annual Meeting of the
Association for Computational Linguistics , pages
8342–8360.
Charles R Harris, K Jarrod Millman, Stéfan J Van
Der Walt, Ralf Gommers, Pauli Virtanen, David Cour-
napeau, Eric Wieser, Julian Taylor, Sebastian Berg,
Nathaniel J Smith, et al. 2020. Array programming
with numpy. Nature , 585(7825):357–362.
Pengcheng He, Baolin Peng, Song Wang, Yang Liu,
Ruochen Xu, Hany Hassan, Yu Shi, Chenguang Zhu,
Wayne Xiong, Michael Zeng, Jianfeng Gao, and Xue-
dong Huang. 2023. Z-code++: A pre-trained lan-
guage model optimized for abstractive summariza-
tion. In Proceedings of the 61st Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 1: Long Papers) , pages 5095–5112.
Ruifang He, Liangliang Zhao, and Huanyu Liu. 2020.
TWEETSUM: Event oriented social summarization
dataset. In Proceedings of the 28th International
Conference on Computational Linguistics , pages
5731–5736.
Yu-Jung Heo, Eun-Sol Kim, Woo Suk Choi, and
Byoung-Tak Zhang. 2022. Hypergraph trans-
former: Weakly-supervised multi-hop reasoning for
knowledge-based visual question answering. In Pro-
ceedings of the 60th Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 1: Long
Papers) , pages 373–390.Linmei Hu, Tianchi Yang, Luhao Zhang, Wanjun Zhong,
Duyu Tang, Chuan Shi, Nan Duan, and Ming Zhou.
2021. Compare to the knowledge: Graph neural fake
news detection with external knowledge. In Proceed-
ings of the 59th Annual Meeting of the Association for
Computational Linguistics and the 11th International
Joint Conference on Natural Language Processing
(Volume 1: Long Papers) , pages 754–763.
Yong-Ho Jung, Jun-Hyung Park, Joon-Young Choi,
Mingyu Lee, Junho Kim, Kang-Min Kim, and
SangKeun Lee. 2022. Learning from missing rela-
tions: Contrastive learning with commonsense knowl-
edge graphs for commonsense inference. In Findings
of the Association for Computational Linguistics:
ACL 2022 , pages 1514–1523.
Ambedkar Kanapala, Sukomal Pal, and Rajendra Pa-
mula. 2019. Text summarization from legal doc-
uments: a survey. Artificial Intelligence Review ,
51(3):371–402.
Ryuji Kano, Yasuhide Miura, Motoki Taniguchi, Yan-
Ying Chen, Francine Chen, and Tomoko Ohkuma.
2018. Harnessing popularity in social media for
extractive summarization of online conversations.
InProceedings of the 2018 Conference on Empir-
ical Methods in Natural Language Processing , pages
1139–1145.
Yu Jin Kim, Beong-woo Kwak, Youngwook Kim,
Reinald Kim Amplayo, Seung-won Hwang, and Jiny-
oung Yeo. 2022. Modularized transfer learning with
multiple knowledge graphs for zero-shot common-
sense reasoning. In Proceedings of the 2022 Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies , pages 2244–2257.
Wojciech Kry ´sci´nski, Bryan McCann, Caiming Xiong,
and Richard Socher. 2020. Evaluating the factual
consistency of abstractive text summarization. In
Proceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing (EMNLP) ,
pages 9332–9346.
Philippe Laban, Tobias Schnabel, Paul N. Bennett, and
Marti A. Hearst. 2022. SummaC: Re-Visiting NLI-
based Models for Inconsistency Detection in Summa-
rization. Transactions of the Association for Compu-
tational Linguistics , 10:163–177.
Timothée Lacroix, Guillaume Obozinski, and Nicolas
Usunier. 2019. Tensor decompositions for temporal
knowledge base completion. In International Con-
ference on Learning Representations .
Egoitz Laparra, Steven Bethard, and Timothy A Miller.
2020. Rethinking domain adaptation for machine
learning over clinical language. JAMIA open ,
3(2):146–150.
Guy Lev, Michal Shmueli-Scheuer, Jonathan Herzig,
Achiya Jerbi, and David Konopnicki. 2019. Talk-
Summ: A dataset and scalable annotation method forscientific paper summarization based on conference
talks. In Proceedings of the 57th Annual Meeting of
the Association for Computational Linguistics , pages
2125–2131.
Chen Li, Zhongyu Wei, Yang Liu, Yang Jin, and Fei
Huang. 2016. Using relevant public posts to en-
hance news article summarization. In Proceedings of
COLING 2016, the 26th International Conference on
Computational Linguistics: Technical Papers , pages
557–566.
Shaobo Li, Xiaoguang Li, Lifeng Shang, Chengjie Sun,
Bingquan Liu, Zhenzhou Ji, Xin Jiang, and Qun Liu.
2022. Pre-training language models with determin-
istic factual knowledge. In Proceedings of the 2022
Conference on Empirical Methods in Natural Lan-
guage Processing .
Paul Pu Liang, Chiyu Wu, Louis-Philippe Morency, and
Ruslan Salakhutdinov. 2021. Towards understand-
ing and mitigating social biases in language models.
InInternational Conference on Machine Learning ,
pages 6565–6576. PMLR.
Jiacheng Liu, Alisa Liu, Ximing Lu, Sean Welleck, Pe-
ter West, Ronan Le Bras, Yejin Choi, and Hannaneh
Hajishirzi. 2022a. Generated knowledge prompting
for commonsense reasoning. In Proceedings of the
60th Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers) , pages
3154–3169.
Xiao Liu, Shiyu Zhao, Kai Su, Yukuo Cen, Jiezhong
Qiu, Mengdi Zhang, Wei Wu, Yuxiao Dong, and Jie
Tang. 2022b. Mask and reason: Pre-training knowl-
edge graph transformers for complex logical queries.
InProceedings of the 28th ACM SIGKDD Confer-
ence on Knowledge Discovery and Data Mining ,
pages 1120–1130.
Yang Liu and Mirella Lapata. 2019. Text summariza-
tion with pretrained encoders. In Proceedings of
the 2019 Conference on Empirical Methods in Natu-
ral Language Processing and the 9th International
Joint Conference on Natural Language Processing
(EMNLP-IJCNLP) , pages 3730–3740.
Yang Liu, Chenguang Zhu, and Michael Zeng. 2022c.
End-to-end segmentation-based news summarization.
InFindings of the Association for Computational
Linguistics: ACL 2022 , pages 544–554.
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-
dar Joshi, Danqi Chen, Omer Levy, Mike Lewis,
Luke Zettlemoyer, and Veselin Stoyanov. 2019.
Roberta: A robustly optimized bert pretraining ap-
proach. arXiv preprint arXiv:1907.11692 .
Yixin Liu, Budhaditya Deb, Milagro Teruel, Aaron Hal-
faker, Dragomir Radev, and Ahmed Hassan Awadal-
lah. 2023a. On improving summarization factual
consistency from natural language feedback. In Pro-
ceedings of the 61st Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 1: Long
Papers) , pages 15144–15161.Yixin Liu, Alex Fabbri, Pengfei Liu, Yilun Zhao, Liny-
ong Nan, Ruilin Han, Simeng Han, Shafiq Joty,
Chien-Sheng Wu, Caiming Xiong, and Dragomir
Radev. 2023b. Revisiting the gold standard: Ground-
ing summarization evaluation with robust human
evaluation. In Proceedings of the 61st Annual Meet-
ing of the Association for Computational Linguistics
(Volume 1: Long Papers) , pages 4140–4170.
Yongtai Liu, Joshua Maynez, Gonçalo Simões, and
Shashi Narayan. 2022d. Data augmentation for low-
resource dialogue summarization. In Findings of the
Association for Computational Linguistics: NAACL
2022 , pages 703–710.
Zheheng Luo, Qianqian Xie, and Sophia Ananiadou.
2023. Chatgpt as a factual inconsistency evaluator
for abstractive text summarization. arXiv preprint
arXiv:2303.15621 .
Kaixin Ma, Hao Cheng, Xiaodong Liu, Eric Nyberg,
and Jianfeng Gao. 2022. Open domain question
answering with a unified knowledge interface. In
Proceedings of the 60th Annual Meeting of the As-
sociation for Computational Linguistics (Volume 1:
Long Papers) , pages 1605–1620, Dublin, Ireland.
Joshua Maynez, Shashi Narayan, Bernd Bohnet, and
Ryan McDonald. 2020. On faithfulness and factu-
ality in abstractive summarization. In Proceedings
of the 58th Annual Meeting of the Association for
Computational Linguistics , pages 1906–1919.
Ninareh Mehrabi, Pei Zhou, Fred Morstatter, Jay Pu-
jara, Xiang Ren, and Aram Galstyan. 2021. Lawyers
are dishonest? quantifying representational harms in
commonsense knowledge resources. In Proceedings
of the 2021 Conference on Empirical Methods in
Natural Language Processing , pages 5016–5033.
Kevin Meng, David Bau, Alex J Andonian, and Yonatan
Belinkov. 2022. Locating and editing factual asso-
ciations in gpt. In Advances in Neural Information
Processing Systems .
Sayantan Mitra, Roshni Ramnani, and Shubhashis Sen-
gupta. 2022. Constraint-based multi-hop question
answering with knowledge graph. In Proceedings of
the 2022 Conference of the North American Chapter
of the Association for Computational Linguistics: Hu-
man Language Technologies: Industry Track , pages
280–288.
Leann Myers and Maria J Sirois. 2004. Spearman cor-
relation coefficients, differences between. Encyclo-
pedia of statistical sciences , 12.
Moin Nadeem, Anna Bethke, and Siva Reddy. 2021.
Stereoset: Measuring stereotypical bias in pretrained
language models. In Proceedings of the 59th Annual
Meeting of the Association for Computational Lin-
guistics and the 11th International Joint Conference
on Natural Language Processing (Volume 1: Long
Papers) , pages 5356–5371.Feng Nan, Cicero dos Santos, Henghui Zhu, Patrick
Ng, Kathleen Mckeown, Ramesh Nallapati, Dejiao
Zhang, Zhiguo Wang, Andrew O Arnold, and Bing
Xiang. 2021. Improving factual consistency of ab-
stractive summarization via question answering. In
Proceedings of the 59th Annual Meeting of the Asso-
ciation for Computational Linguistics and the 11th
International Joint Conference on Natural Language
Processing (Volume 1: Long Papers) , pages 6881–
6894.
Shashi Narayan, Shay Cohen, and Maria Lapata. 2018.
Don’t give me the details, just the summary! topic-
aware convolutional neural networks for extreme
summarization. In 2018 Conference on Empirical
Methods in Natural Language Processing , pages
1797–1807. Association for Computational Linguis-
tics.
Shashi Narayan, Yao Zhao, Joshua Maynez, Gonçalo
Simões, Vitaly Nikolaev, and Ryan McDonald. 2021.
Planning with learned entity prompts for abstractive
summarization. Transactions of the Association for
Computational Linguistics , 9:1475–1492.
Barlas Oguz, Xilun Chen, Vladimir Karpukhin, Stan
Peshterliev, Dmytro Okhonko, Michael Schlichtkrull,
Sonal Gupta, Yashar Mehdad, and Scott Yih. 2022.
UniK-QA: Unified representations of structured and
unstructured knowledge for open-domain question
answering. In Findings of the Association for Compu-
tational Linguistics: NAACL 2022 , pages 1535–1546,
Seattle, United States.
Artidoro Pagnoni, Vidhisha Balachandran, and Yulia
Tsvetkov. 2021. Understanding factuality in abstrac-
tive summarization with frank: A benchmark for fac-
tuality metrics. In Proceedings of the 2021 Confer-
ence of the North American Chapter of the Associ-
ation for Computational Linguistics: Human Lan-
guage Technologies , pages 4812–4829.
Adam Paszke, Sam Gross, Francisco Massa, Adam
Lerer, James Bradbury, Gregory Chanan, Trevor
Killeen, Zeming Lin, Natalia Gimelshein, Luca
Antiga, et al. 2019. Pytorch: An imperative style,
high-performance deep learning library. Advances in
neural information processing systems , 32.
F. Pedregosa, G. Varoquaux, A. Gramfort, V . Michel,
B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer,
R. Weiss, V . Dubourg, J. Vanderplas, A. Passos,
D. Cournapeau, M. Brucher, M. Perrot, and E. Duch-
esnay. 2011. Scikit-learn: Machine learning in
Python. Journal of Machine Learning Research ,
12:2825–2830.
Thomas Pellissier Tanon, Gerhard Weikum, and Fabian
Suchanek. 2020. Yago 4: A reason-able knowledge
base. In European Semantic Web Conference , pages
583–596. Springer.
Xutan Peng, Yi Zheng, Chenghua Lin, and Advaith
Siddharthan. 2021. Summarising historical text in
modern languages. In Proceedings of the 16th Con-
ference of the European Chapter of the Associationfor Computational Linguistics: Main Volume , pages
3123–3142.
Seth Polsley, Pooja Jhunjhunwala, and Ruihong Huang.
2016. Casesummarizer: a system for automated sum-
marization of legal texts. In Proceedings of COLING
2016, the 26th international conference on Compu-
tational Linguistics: System Demonstrations , pages
258–262.
Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt,
Noah A Smith, and Mike Lewis. 2022. Measuring
and narrowing the compositionality gap in language
models. arXiv preprint arXiv:2210.03350 .
Vinay Venkatesh Ramasesh, Aitor Lewkowycz, and
Ethan Dyer. 2021. Effect of scale on catastrophic
forgetting in neural networks. In International Con-
ference on Learning Representations .
Leonardo F. R. Ribeiro, Mengwen Liu, Iryna Gurevych,
Markus Dreyer, and Mohit Bansal. 2022. FactGraph:
Evaluating factuality in summarization with semantic
graph representations. In Proceedings of the 2022
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies , pages 3238–3253.
Md Rashad Al Hasan Rony, Ricardo Usbeck, and Jens
Lehmann. 2022. DialoKG: Knowledge-structure
aware task-oriented dialogue generation. In Find-
ings of the Association for Computational Linguis-
tics: NAACL 2022 , pages 2557–2571, Seattle, United
States.
Corby Rosset, Chenyan Xiong, Minh Hieu Phan,
Xia Song, Paul Bennett, and Saurabh Tiwary.
2020. Knowledge-aware language model pretraining.
ArXiv , abs/2007.00655.
Sascha Rothe, Joshua Maynez, and Shashi Narayan.
2021. A thorough evaluation of task-specific pre-
training for summarization. In Proceedings of the
2021 Conference on Empirical Methods in Natural
Language Processing , pages 140–145.
Arkadiy Saakyan, Tuhin Chakrabarty, and Smaranda
Muresan. 2021. Covid-fact: Fact extraction and veri-
fication of real-world claims on covid-19 pandemic.
InProceedings of the 59th Annual Meeting of the
Association for Computational Linguistics and the
11th International Joint Conference on Natural Lan-
guage Processing (Volume 1: Long Papers) , pages
2116–2129.
Mourad Sarrouti, Asma Ben Abacha, Yassine M’rabet,
and Dina Demner-Fushman. 2021. Evidence-based
fact-checking of health-related claims. In Findings
of the Association for Computational Linguistics:
EMNLP 2021 , pages 3499–3512.
Thomas Scialom, Paul-Alexis Dray, Sylvain Lamprier,
Benjamin Piwowarski, Jacopo Staiano, Alex Wang,
and Patrick Gallinari. 2021. Questeval: Summariza-
tion asks for fact-based evaluation. In Proceedings
of the 2021 Conference on Empirical Methods in
Natural Language Processing , pages 6594–6604.Omar Shaikh, Hongxin Zhang, William Held, Michael
Bernstein, and Diyi Yang. 2023. On second thought,
let’s not think step by step! bias and toxicity in zero-
shot reasoning. In Proceedings of the 61st Annual
Meeting of the Association for Computational Lin-
guistics (Volume 1: Long Papers) , pages 4454–4470.
Siamak Shakeri, Cicero dos Santos, Henghui Zhu,
Patrick Ng, Feng Nan, Zhiguo Wang, Ramesh Nal-
lapati, and Bing Xiang. 2020. End-to-end synthetic
data generation for domain adaptation of question
answering systems. In Proceedings of the 2020 Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP) , pages 5445–5460.
Robyn Speer, Joshua Chin, and Catherine Havasi. 2017.
Conceptnet 5.5: An open multilingual graph of gen-
eral knowledge. In Thirty-first AAAI conference on
artificial intelligence .
Shahbaz Syed, Michael Völske, Nedim Lipka, Benno
Stein, Hinrich Schütze, and Martin Potthast. 2019.
Towards summarization for social media - results of
the TL;DR challenge. In Proceedings of the 12th
International Conference on Natural Language Gen-
eration , pages 523–528.
Masato Takatsuka, Tetsunori Kobayashi, and Yoshihiko
Hayashi. 2022. Phrase-level localization of inconsis-
tency errors in summarization by weak supervision.
InProceedings of the 29th International Conference
on Computational Linguistics , pages 6151–6164.
Yi Chern Tan and L Elisa Celis. 2019. Assessing so-
cial and intersectional biases in contextualized word
representations. Advances in Neural Information
Processing Systems , 32.
Liyan Tang, Tanya Goyal, Alex Fabbri, Philippe La-
ban, Jiacheng Xu, Semih Yavuz, Wojciech Kryscin-
ski, Justin Rousseau, and Greg Durrett. 2023. Un-
derstanding factual errors in summarization: Errors,
summarizers, datasets, error detectors. In Proceed-
ings of the 61st Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers) ,
pages 11626–11644.
Xiangru Tang, Arjun Nair, Borui Wang, Bingyao Wang,
Jai Desai, Aaron Wade, Haoran Li, Asli Celikyilmaz,
Yashar Mehdad, and Dragomir Radev. 2022. CON-
FIT: Toward faithful dialogue summarization with
linguistically-informed contrastive fine-tuning. In
Proceedings of the 2022 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies ,
pages 5657–5668.
Prasetya Utama, Joshua Bambrick, Nafise Moosavi,
and Iryna Gurevych. 2022. Falsesum: Generating
document-level NLI examples for recognizing fac-
tual inconsistency in summarization. In Proceedings
of the 2022 Conference of the North American Chap-
ter of the Association for Computational Linguistics:
Human Language Technologies , pages 2763–2776.Shikhar Vashishth, Soumya Sanyal, Vikram Nitin, and
Partha Talukdar. 2019. Composition-based multi-
relational graph convolutional networks. In Interna-
tional Conference on Learning Representations .
Ellen V oorhees, Tasmeer Alam, Steven Bedrick, Dina
Demner-Fushman, William R Hersh, Kyle Lo, Kirk
Roberts, Ian Soboroff, and Lucy Lu Wang. 2021.
Trec-covid: constructing a pandemic information re-
trieval test collection. In ACM SIGIR Forum , vol-
ume 54, pages 1–12. ACM New York, NY , USA.
Denny Vrande ˇci´c and Markus Krötzsch. 2014. Wiki-
data: a free collaborative knowledgebase. Communi-
cations of the ACM , 57(10):78–85.
David Wadden, Shanchuan Lin, Kyle Lo, Lucy Lu
Wang, Madeleine van Zuylen, Arman Cohan, and
Hannaneh Hajishirzi. 2020. Fact or fiction: Verifying
scientific claims. In Proceedings of the 2020 Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP) , pages 7534–7550.
David Wadden, Kyle Lo, Lucy Lu Wang, Arman Cohan,
Iz Beltagy, and Hannaneh Hajishirzi. 2022. Mul-
tiVerS: Improving scientific claim verification with
weak supervision and full-document context. In Find-
ings of the Association for Computational Linguistics:
NAACL 2022 , pages 61–76.
Alex Wang, Kyunghyun Cho, and Mike Lewis. 2020a.
Asking and answering questions to evaluate the fac-
tual consistency of summaries. In Proceedings of the
58th Annual Meeting of the Association for Compu-
tational Linguistics , pages 5008–5020.
Lucy Lu Wang, Kyle Lo, Yoganand Chandrasekhar, Rus-
sell Reas, Jiangjiang Yang, Doug Burdick, Darrin
Eide, Kathryn Funk, Yannis Katsis, Rodney Michael
Kinney, et al. 2020b. Cord-19: The covid-19 open
research dataset. In Proceedings of the 1st Workshop
on NLP for COVID-19 at ACL 2020 .
Wenya Wang and Sinno Pan. 2022. Deep inductive
logic reasoning for multi-hop reading comprehension.
InProceedings of the 60th Annual Meeting of the
Association for Computational Linguistics (Volume
1: Long Papers) , pages 4999–5009.
Xiaozhi Wang, Tianyu Gao, Zhaocheng Zhu, Zhengyan
Zhang, Zhiyuan Liu, Juanzi Li, and Jian Tang. 2021.
Kepler: A unified model for knowledge embedding
and pre-trained language representation. Transac-
tions of the Association for Computational Linguis-
tics, 9:176–194.
Peter West, Chandra Bhagavatula, Jack Hessel, Jena
Hwang, Liwei Jiang, Ronan Le Bras, Ximing Lu,
Sean Welleck, and Yejin Choi. 2022. Symbolic
knowledge distillation: from general language mod-
els to commonsense models. In Proceedings of the
2022 Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies , pages 4602–4625.Thomas Wolf, Lysandre Debut, Victor Sanh, Julien
Chaumond, Clement Delangue, Anthony Moi, Pierric
Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz,
et al. 2020. Transformers: State-of-the-art natural
language processing. In Proceedings of the 2020
conference on empirical methods in natural language
processing: system demonstrations , pages 38–45.
Yuexiang Xie, Fei Sun, Yang Deng, Yaliang Li, and
Bolin Ding. 2021. Factual consistency evaluation
for text summarization via counterfactual estimation.
InFindings of the Association for Computational
Linguistics: EMNLP 2021 , pages 100–110.
Xinnuo Xu, Ond ˇrej Dušek, Jingyi Li, Verena Rieser, and
Ioannis Konstas. 2020. Fact-based content weighting
for evaluating abstractive summarisation. In Proceed-
ings of the 58th Annual Meeting of the Association
for Computational Linguistics , pages 5071–5081.
Michihiro Yasunaga, Antoine Bosselut, Hongyu Ren,
Xikun Zhang, Christopher D Manning, Percy S
Liang, and Jure Leskovec. 2022. Deep bidirectional
language-knowledge graph pretraining. Advances in
Neural Information Processing Systems , 35:37309–
37323.
Michihiro Yasunaga, Hongyu Ren, Antoine Bosselut,
Percy Liang, and Jure Leskovec. 2021. Qa-gnn: Rea-
soning with language models and knowledge graphs
for question answering. In Proceedings of the 2021
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies , pages 535–546.
Wenhao Yu, Meng Jiang, Zhiting Hu, Qingyun Wang,
Heng Ji, and Nazneen Rajani. 2021. Knowledge-
enriched natural language generation. In Proceed-
ings of the 2021 Conference on Empirical Methods
in Natural Language Processing: Tutorial Abstracts ,
pages 11–16.
Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Wein-
berger, and Yoav Artzi. 2019. Bertscore: Evaluating
text generation with bert. In International Confer-
ence on Learning Representations .
Wenqian Zhang, Shangbin Feng, Zilong Chen, Zhenyu
Lei, Jundong Li, and Minnan Luo. 2022a. KCD:
Knowledge walks and textual cues enhanced political
perspective detection in news media. In Proceedings
of NAACL 2022 , pages 4129–4140.
X Zhang, A Bosselut, M Yasunaga, H Ren, P Liang,
C Manning, and J Leskovec. 2022b. Greaselm:
Graph reasoning enhanced language models for ques-
tion answering. In International Conference on Rep-
resentation Learning (ICLR) .A Merging the three strategies
We also tried combining the three factuality pre-
training strategies to obtain F ACTKB- COMBINED .
We evaluate it on the FactCollect dataset and
present results in Table 7. It is demonstrated that
FACTKB- COMBINED is not significantly better
than using a single factuality pretraining strategy,
while we will make all versions of FACTKBpub-
licly available.
B Qualitative Analysis
We present examples of (summary, article) pairs
and their factuality scores in Table 9 and 10, where
FACTKBis significantly closer to human judgment
than existing factuality metrics. It is demonstrated
that while existing factuality metrics are insensitive
to major errors in entities and relations, FACTKBis
capable of identifying inconsistencies and enforc-
ing strict factuality standards.
C Dataset Details
We present more details about the adopted datasets
in Table 8. There might be minor differences in
certain numbers with the original dataset as a re-
sult of data preprocessing. FRANK (Pagnoni et al.,
2021) does not explicitly have binary labels such as
{FACTUAL ,NOT FACTUAL }. It also does not have a
training set due to its nature as an evaluation bench-
mark. HealthVer (Sarrouti et al., 2021) and SciFact
(Wadden et al., 2020) originally had NOTENOUGH
INFORMATION labels, while we removed such ex-
amples in the out-of-domain factuality evaluation
to ensure their compatibility with FactCollect.
D Baseline Details
We present more details about baseline factuality
metrics in the following:
•BERTScore (Zhang et al., 2019) is a general
metric for text generation evaluation based on
pretrained BERT (Devlin et al., 2019).
•QAGS (Wang et al., 2020a) is a QA-based factu-
ality metric, asking questions about summaries
and articles while examining whether the answers
are consistent.
•QUALS (Nan et al., 2021) is a QA-based factual-
ity metric that uses QAGen (Shakeri et al., 2020)
to generate both questions and answers from the
summary.•DAE (Goyal and Durrett, 2020) leverages the
dependency structure of the summary and article
to design a factuality metric.
•SummaC (Laban et al., 2022) proposes to revisit
and repurpose NLI models for detecting factual
inconsistencies in text summarization.
•FalseSum (Utama et al., 2022) augments NLI
training data with controllable text generation for
better factuality evaluation.
•FactCC (Kry ´sci´nski et al., 2020) is an
entailment-based factuality metric trained on syn-
thetic data evaluating factuality with binary clas-
sification. FactCC+ is a variant of FactCC pro-
viding explanations. FactCC+ is an enhanced
version trained with human-annotated data.
•FactGraph (Ribeiro et al., 2022) is an
entailment-based factuality metric based on
jointly analyzing the textual content and AMR
graphs of the summary and article. FactGraph-
adapters is an enhanced version with pretrained
adapters for both the text and graph modules.
E LM and KB Details
In Section 5.2, we explored whether FACTKB
is compatible with different language models
and knowledge bases. For LMs, we used the
ROBERTA -BASE , GOOGLE /ELECTRA -BASE -
DISCRIMINATOR , FACEBOOK /BART -BASE ,
ALBERT -BASE -V2,MICROSOFT /DEBERTA -V3-
BASE ,DISTILROBERTA -BASE LM checkpoints
on Huggingface Transformers. For the six KBs,
we used their organized versions: YAGO15k at
Lacroix et al. (2019), Wikidata5M at Wang et al.
(2021), Atomic at West et al. (2022), ConceptNet
at Zhang et al. (2022b), KGAP at Feng et al.
(2021), and UMLS at Zhang et al. (2022b).
F Statistical Significance Test Details
We use the student t-test for statistical significance
analysis throughout the paper. Specifically, the
t-test calculator for 2 independent means3was
adopted for the calculations. We use (*) to denote
statistical significance in Tables 2 and 5.
3https://www.socscistatistics.com/tests/
studentttest/default2.aspxModelAll Data CNN/DM XSUM
BACC F1 BACC F1 BACC F1
FACTKB- WIKI 89.3(±0.4)89.5(±0.5)77.3(±0.3)88.2(±0.6)77.3(±1.3)91.8(±1.2)
FACTKB- EVIDENCE 89.4(±0.2)89.5(±0.3)77.7(±1.4)87.9(±0.7)76.8(±1.9)90.8(±0.8)
FACTKB- WALK 89.1(±0.4)89.3(±0.5)78.3(±1.2)87.7(±0.4)76.4(±0.3)90.4(±1.4)
FACTKB- COMBINED 89.0 89 .7 76 .0 88 .1 74 .2 89 .1
Table 7: Performance of various F ACTKB settings on the FactCollect dataset.
Dataset # Datapoint # Class Class Distribution Train/Dev/Test Split Proposed In
FACTCOLLECT 9,567 2 4994 / 4573 8667 / 300 / 600 Ribeiro et al. (2022)
FRANK 2,246 / / 0 / 671 / 1575 Pagnoni et al. (2021)
COVID FACT 1,257 2 401 / 856 846 / 94 / 317 Saakyan et al. (2021)
HEALTH VER 4,447 3 →2 2,758 / 1,689 3,340 / 508 / 599 Sarrouti et al. (2021)
SCIFACT 773 3 →2 508 / 265 508 / 56 / 209 Wadden et al. (2020)
Table 8: Statistics of the datasets and benchmarks adopted in this work.
G Computational Resources
We used a GPU cluster with 16 NVIDIA A40
GPUs, 1988G memory, and 104 CPU cores for the
experiments. Factuality pretraining with the default
hyperparameters takes around 1.5 hours, while fine-
tuning language models on the FactCollect dataset
takes around 30 minutes.
H Scientific Artifacts
FACTKB would not be possible without many
open-source scientific artifacts, including pytorch
(Paszke et al., 2019), pytorch lightning (Falcon and
The PyTorch Lightning team, 2019), transform-
ers (Wolf et al., 2020), sklearn (Pedregosa et al.,
2011), numpy (Harris et al., 2020), nltk (Bird et al.,
2009), and the six adopted knowledge bases (Pel-
lissier Tanon et al., 2020; Vrande ˇci´c and Krötzsch,
2014; West et al., 2022; Speer et al., 2017; Feng
et al., 2021; Zhang et al., 2022b). We commit to
making our code and data publicly available upon
acceptance to facilitate reproduction and further
research.QAGS DAE FactCC FactKB Gold Summary Article
0.3000 0 .9990 1 .0000 0 .0035 0 plans to build
a new gener-
ation of royal
navy frigates
on the isle
of wight have
been submit-
ted to the gov-
ernment.The decommissioned Type 22 frigates HMS Cumberland, HMS Campbeltown,
HMS Chatham and HMS Cornwall are currently moored in Portsmouth Har-
bour.Bidders had until 23 January to register an interest in the former Devonport-
based ships.The BBC understands no proposals to preserve the ships have been
submitted.Those who have registered an interest are finalising their bids with view-
ings set to take place in late February and March.A final decision is not expected
until the spring.The government’s Disposal Services Authority, which is handling
the sale, wants to award at least one of the frigates to a UK ship recycler to deter-
mine the capacity of the UK’s industry in the field.Penny Mordaunt, Conservative
MP for Portsmouth North, said it was important UK recyclers had the chance to
prove themselves in the field but she was also keen to see at least one of them
saved from the scrapyard.She added: "For anyone that has served on a ship it’s your
home, you’ve literally been through the wars with it... and you want them to have a
noble second life."My preference is to go for the reef and diving attraction."We’ve
got to get best value for the budget but a reef would also generate income for part
of the country through tourism."The Ministry of Defence has previously said it
will "consider all options" for the frigates to ensure "best financial return for the
taxpayer".A spokeswoman would not comment on the number or nature of the bids
received due to "commercial sensitivity".Originally designed as a specialist anti-
submarine ship, the Type 22 frigate evolved into a powerful surface combatant with
substantial anti-surface, anti-submarine and anti-aircraft weapons systems.They
were also known for having excellent command and control, and communication
facilities, making them ideal flagships on deployments, with a complement of
about 280 crew.Last year, the aircraft carrier HMS Ark Royal was sold as scrap for
£3m.
0.5333 0 .9296 1 .0000 0 .0043 0 an elephant
has been hit
by a stone
at a zoo
in western
france after it
was hit by a
tree.The stone got past the elephant’s fence and a ditch separating the animal and
visitors, the zoo said in a statement.The girl was taken to hospital and died within
a few hours, the zoo added.The zoo statement said the enclosure met international
standards and said "this kind of accident is rare, unpredictable and unusual".Africa
Live: More on this and other storiesThe statement went on (in French) to point
out two other recent incidents in the US:Phyllis Lee, Scientific Director of the
Amboseli Trust for Elephants, says that targeted throwing of stones and branches by
elephants is very unusual."It can happen when elephants are frustrated or bored. In
my opinion, it’s unlikely the elephant was directly targeting the girl - but exhibiting
frustration. You can’t predict what animals in captivity will do."The moments
after the girl was struck at Rabat Zoo on Tuesday were filmed by a bystander and
uploaded onto YouTube.The video shows the elephant waving its trunk behind a
fence and swerves round to show a stone on the ground.Metres away people are
gathered around the girl, holding her head and stroking her leg.
0.6000 0 .9994 1 .0000 0 .0037 0 a woman has
been arrested
after a fire
broke out in
a restaurant
in greater
manchester
city centre,
police have
said.The victim was queuing for food at the branch in St George’s Street, Canterbury
at about 02:15 GMT on Friday when the assault occurred.Investigating officers
said three men entered the restaurant and began being noisy and bumping into
people.It is believed one of the group then set light to the woman’s hair.Officers
have released CCTV images of three men they are keen to speak to regarding
the attack.Det Sgt Barry Carr said: "Fortunately the fire was put out quickly and
the victim was not seriously hurt, but things could clearly have turned out much
worse."This was a nasty and extremely dangerous thing to do, and I urge anyone
who recognises the men in the CCTV images to contact me as soon as possible."
0.8000 0 .9974 1 .0000 0 .0044 0 tata steel has
confirmed
it is in talks
with the
company
about selling
its long
products
division.The firm said it had signed a Letter of Intent to enter into exclusive negotiations
with Liberty House Group.More than 1,700 people are employed in the division,
which has factories in Rotherham and Stocksbridge.Steel union Community said
it welcomed news of negotiations following "months of unnecessary stress and
concern".More on this and other South Yorkshire storiesThe union’s general secre-
tary Roy Rickhuss said: "This is a positive step for the UK steel industry; however
there remain huge challenges which government must address."The union said it
would be seeking urgent talks with Liberty House Group and would be asking what
their plans were for investment, protecting jobs and providing decent pensions for
members in retirement.Tata Steel’s UK boss Bimlendra Jha said the announcement
was "an important step forward"."We now look forward to working with Liberty
on the due diligence and other work streams so that the sale can be successfully
concluded," he said.The Speciality Steels unit makes high-end components for
the automotive, aerospace and oil industries.In April, Tata sold its long-products
division, based in Scunthorpe, to Greybull Capital, a UK-based investment firm.
0.3000 0 .9990 1 .0000 0 .0058 0 the site of a
new burial
site in oxford
has been
approved
by the city
council.Oxford City Council said the money had mostly been used for "ground investi-
gations of possible sites" but nowhere suitable had been found.Two cemeteries
still have space, in Wolvercote and Botley, but they are expected to be full by
2018 and 2021.The council said it had not given up and was "still exploring op-
tions".Linda Smith, board member for leisure, parks and sport, said the council
has been "searching for a suitable new burial site for many years".She added: "But
ultimately, as with new housing sites, we have run out of suitable land within
Oxford."So far all the council-owned sites that we have identified have, following
ground investigations and surveys, had to be discounted."Either due to the size of
the site, the ground conditions, a high water table or a covenant restricting the use
of the site."After the two remaining cemeteries are full the council said only the
reopening of family plots, the use of a few reserved plots, and the interment of
ashes would be possible.The last increase in burial space in Oxford was in 1932.
Table 9: Qualitative analysis of F ACTKB and existing factuality metrics, part 1.QAGS DAE FactCC FactKB Gold Summary Article
0.6000 0 .9886 1 .0000 0 .0037 0 plans to
demolish and
demolish
parts of a
seaside resort
and build
more than
1, 000 old
buildings
have been
approved.Three Victorian hotels will go to make way for a six-storey, four star hotel and
two assisted-living apartment blocks, at East Cliff in Bournemouth.English Her-
itage strongly objected to the scale of the development in what is a designated
conservation area.But, councillors voted seven to three in favour saying it would
help tourism.Chair of the planning board and Conservative ward councillor David
Kelsey, said the buildings earmarked for demolition were nice but no longer "nec-
essarily functional"."They’ve come to the end of their working lives, we need to
preserve the tourism aspect while improving living for older people in the town," he
said."The loss of buildings and trees are always regrettable but we can’t stand still,
we need to move forward."The site on Grove Road and East Overcliff Drive will
get a 90-room hotel along with a nine-storey and seven-storey building, comprising
122 assisted-living apartments.Applicants The East Cliff Project LLP will demolish
Bay View Court, The Cottonwood and the Ocean View hotels.The council received
246 letters supporting the plans.Forty-nine residents and the Ancient Monuments
Society wrote to object to the demolition, stating that despite being altered, they
still "give a sense of the historic character of the area".English Heritage said the
scale of the development would cause "severe harm" to the conservation area.
0.6000 0 .9928 1 .0000 0 .0059 0 russia ´s new
president has
called for a
new law to
allow russian
citizens to be
barred from
leaving the
country.Pro-Kremlin party A Just Russia put forward both bills, and linked them directly to
the situation in Ukraine.Separatist and pro-Russian feelings are strong in Ukraine’s
Crimea region, which is now the focus of the crisis.Russian MPs say a referendum
or a plea from a territory’s leaders would be enough to trigger the new provi-
sions.There are already many Russian citizens in Crimea.In Sevastopol, base of
the Russian Black Sea Fleet, a majority hold Russian passports.Under Russia’s
existing law, a neighbouring state would have to sign a treaty with Russia to al-
low part of its territory to become a new "subject" of the Russian Federation.But
Mikhail Yemelyanov, deputy leader of A Just Russia, said the law had been drafted
for peaceful times, and did not go far enough for situations where a state was
falling apart."In conditions where a neighbouring state is disintegrating I don’t
think the Russian Federation should be restricted in its ability to accept a territory
whose people have expressed a clear will and desire to be in Russia," he said.Since
Russia’s war with Georgia in 2008, the breakaway Georgian territories of Abk-
hazia and South Ossetia have come under Moscow’s control.Russia poured troops
into both regions to help pro-Russian separatists who did not recognise Georgia’s
authority.The other bill to be considered by the Duma - Russia’s lower house -
would speed up the procedures for issuing Russian passports.Passport applicants
would not have to pay a state tax, and previous residence in Russia would no longer
be required.In addition, they would not have to have sufficient funds to support
themselves and would not have to give up their Ukrainian citizenship.The bill’s
preamble says it is aimed "at supporting the fraternal people of Ukraine, especially
the Russian-speaking ones, who are defenceless in the face of the ’brown threat’,"
a reference to World War Two fascists who wore brown uniforms.The bill would
allow Ukrainians to apply for Russian passports at Russian diplomatic missions
before 1 August, and they could become citizens after two months, instead of
waiting a year, as is currently the norm.The plan to have a new fast-track procedure
for issuing Russian passports was announced in Sevastopol on Thursday by A Just
Russia leader Sergei Mironov.Several Russian MPs have also gone to Crimea, in-
cluding Russian celebrities - former Olympic ice skating champion Irina Rodnina,
former cosmonaut Valentina Tereshkova and heavyweight boxer Nikolai Valuev.
0.7000 0 .9984 1 .0000 0 .0047 0 a 19-year-old
man has been
arrested in
connection
with the fatal
shooting of
an 18-year-
old student in
the southern
indian state
ofThe shooting occurred at a hostel attached to the private Pragati Residential School
in Bangalore city.Police say the alleged gunman, identified as Mahesh, was working
as an office assistant in the school.Incidents of gun crime at schools and colleges
in India are very rare. It is not clear what prompted the shooting.Police said on
Thursday that Mahesh had been remanded until 12 April.Mahesh is alleged to
have barged into the room of 18-year-old Gautami and shot her in the head with a
pistol on on Tuesday evening.He then shot another student, Sirisha, who suffered
severe injuries but is believed to be out of danger, say police.He was arrested on
Wednesday after a manhunt.India has strict control laws, although a large number
of feuds are settled with firearms.In 2007, a 14-year-old schoolboy was shot dead
by two fellow students at a school campus near the capital, Delhi.
0.5000 0 .9995 1 .0000 0 .0036 0 police have
appealed for
help to trace
two men who
threatened a
woman with
a knife at a
quarry in fife.The men entered the Post Office in Quarrywood Avenue, in the Barmulloch area,
at 07:55 on Friday.They threatened a member of staff with a knife and demanded
money before escaping with the cash.The 27-year-old worker was said by police
to have been badly shaken but otherwise unharmed by the ordeal.Both suspects
are white, and one of them was about 35-40 years old with short brown hair and
wearing a black jumper.Det Sgt Raymond Hunter said officers had been carrying
out door-to-door inquiries and were in the process of collecting CCTV images
from the surrounding area.He added: "There are a number of other shops in this
area and people may have seen the two men prior to or after the incident."I am
therefore appealing to anyone who was in the area or any local residents to contact
us - any information you have could assist our enquiry."
0.5000 0 .9999 1 .0000 0 .0063 0 the number
of people
using plastic
carrier bags
in england
has reached a
record high.The Department for Environment, Food and Rural Affairs found the number had
gone up by 200 million since 2013.There has been a big problem with plastic
carrier bags in the last few years, many of them can’t be recycled and are often
thrown away after they have been used.The bags end up in rubbish dumps and even
rivers causing big problems for the environment.From October people in England
will have to pay 5p for their plastic bags in a bid to encourage them to reuse
the ones that they already have.Supermarkets in Wales, Scotland and Northern
Ireland, where people are charged for carrier bags, have all seen a decrease in bags
used.Campaigners are hoping the charge in England will lessen the amount of bags
being thrown away, helping the environment.
Table 10: Qualitative analysis of F ACTKB and existing factuality metrics, part 2.