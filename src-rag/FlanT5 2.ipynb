{"cells":[{"cell_type":"markdown","metadata":{"id":"hUCaGdAj9-9F"},"source":["Souce:\n","- https://huggingface.co/learn/cookbook/en/advanced_rag\n","- https://arc.net/l/quote/vntkseji"]},{"cell_type":"markdown","metadata":{"id":"pt_BRiBR2tKE"},"source":["# Assumptions\n","- the faiss_index embeddings are up to date"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"MrXGTQoSsiQv"},"outputs":[],"source":["import os\n","from dotenv import load_dotenv\n","load_dotenv('.env')\n","hf_api = os.getenv('HF_API')\n","HUGGINGFACEHUB_API_TOKEN = hf_api"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10559,"status":"ok","timestamp":1709617668179,"user":{"displayName":"Vashisth Tiwari","userId":"14058204908965748495"},"user_tz":300},"id":"AmPefRqf2tKF","outputId":"3b5a2047-bdd6-4229-f014-c6ecc32edf69"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers==4.38.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (4.38.0)\n","Requirement already satisfied: filelock in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from transformers==4.38.0) (3.0.12)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from transformers==4.38.0) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from transformers==4.38.0) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from transformers==4.38.0) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from transformers==4.38.0) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from transformers==4.38.0) (2023.12.25)\n","Requirement already satisfied: requests in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from transformers==4.38.0) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from transformers==4.38.0) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from transformers==4.38.0) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from transformers==4.38.0) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.0) (2023.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.0) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from requests->transformers==4.38.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from requests->transformers==4.38.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from requests->transformers==4.38.0) (2.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from requests->transformers==4.38.0) (2024.2.2)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install transformers==4.38.0"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39064,"status":"ok","timestamp":1709617707240,"user":{"displayName":"Vashisth Tiwari","userId":"14058204908965748495"},"user_tz":300},"id":"m9jP7QzjProY","outputId":"dcd78147-a081-4a6c-d793-a3489d3d01d3"},"outputs":[],"source":["# !pip install -q torch accelerate bitsandbytes langchain sentence-transformers faiss-gpu openpyxl\n","!pip install -q torch accelerate bitsandbytes langchain sentence-transformers faiss-cpu openpyxl"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40514,"status":"ok","timestamp":1709617747751,"user":{"displayName":"Vashisth Tiwari","userId":"14058204908965748495"},"user_tz":300},"id":"EHEfmoGTRsGh","outputId":"06607aec-1cfe-4660-8703-2506142a9807"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: unstructured in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (0.12.4)\n","Requirement already satisfied: ragatouille in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (0.0.7.post5)\n","Requirement already satisfied: chardet in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (5.2.0)\n","Requirement already satisfied: filetype in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (1.2.0)\n","Requirement already satisfied: python-magic in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (0.4.27)\n","Requirement already satisfied: lxml in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (5.1.0)\n","Requirement already satisfied: nltk in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (3.8.1)\n","Requirement already satisfied: tabulate in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (0.9.0)\n","Requirement already satisfied: requests in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (2.31.0)\n","Requirement already satisfied: beautifulsoup4 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (4.12.2)\n","Requirement already satisfied: emoji in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (2.10.1)\n","Requirement already satisfied: dataclasses-json in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (0.6.4)\n","Requirement already satisfied: python-iso639 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (2024.2.7)\n","Requirement already satisfied: langdetect in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (1.0.9)\n","Requirement already satisfied: numpy in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (1.26.4)\n","Requirement already satisfied: rapidfuzz in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (3.6.1)\n","Requirement already satisfied: backoff in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (2.2.1)\n","Requirement already satisfied: typing-extensions in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (4.9.0)\n","Requirement already satisfied: unstructured-client>=0.15.1 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (0.18.0)\n","Requirement already satisfied: wrapt in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (1.16.0)\n","Requirement already satisfied: aiohttp==3.9.1 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from ragatouille) (3.9.1)\n","Requirement already satisfied: colbert-ai==0.2.19 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from ragatouille) (0.2.19)\n","Requirement already satisfied: faiss-cpu<2.0.0,>=1.7.4 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from ragatouille) (1.7.4)\n","Requirement already satisfied: langchain<0.2.0,>=0.1.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from ragatouille) (0.1.9)\n","Requirement already satisfied: langchain_core<0.2.0,>=0.1.4 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from ragatouille) (0.1.26)\n","Requirement already satisfied: llama-index<0.10.0,>=0.9.24 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from ragatouille) (0.9.48)\n","Requirement already satisfied: onnx<2.0.0,>=1.15.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from ragatouille) (1.15.0)\n","Requirement already satisfied: ruff<0.2.0,>=0.1.9 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from ragatouille) (0.1.15)\n","Requirement already satisfied: sentence-transformers<3.0.0,>=2.2.2 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from ragatouille) (2.4.0)\n","Requirement already satisfied: srsly==2.4.8 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from ragatouille) (2.4.8)\n","Requirement already satisfied: torch<3.0.0,>=2.0.1 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from ragatouille) (2.1.2)\n","Requirement already satisfied: transformers<5.0.0,>=4.36.2 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from ragatouille) (4.38.0)\n","Requirement already satisfied: voyager<3.0.0,>=2.0.2 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from ragatouille) (2.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from aiohttp==3.9.1->ragatouille) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from aiohttp==3.9.1->ragatouille) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from aiohttp==3.9.1->ragatouille) (1.9.4)\n","Requirement already satisfied: frozenlist>=1.1.1 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from aiohttp==3.9.1->ragatouille) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from aiohttp==3.9.1->ragatouille) (1.3.1)\n","Requirement already satisfied: bitarray in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from colbert-ai==0.2.19->ragatouille) (2.9.2)\n","Requirement already satisfied: datasets in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from colbert-ai==0.2.19->ragatouille) (2.17.1)\n","Requirement already satisfied: flask in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from colbert-ai==0.2.19->ragatouille) (3.0.2)\n","Requirement already satisfied: git-python in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from colbert-ai==0.2.19->ragatouille) (1.0.3)\n","Requirement already satisfied: python-dotenv in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from colbert-ai==0.2.19->ragatouille) (1.0.1)\n","Requirement already satisfied: ninja in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from colbert-ai==0.2.19->ragatouille) (1.11.1.1)\n","Requirement already satisfied: scipy in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from colbert-ai==0.2.19->ragatouille) (1.12.0)\n","Requirement already satisfied: tqdm in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from colbert-ai==0.2.19->ragatouille) (4.66.1)\n","Requirement already satisfied: ujson in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from colbert-ai==0.2.19->ragatouille) (5.9.0)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from srsly==2.4.8->ragatouille) (2.0.10)\n","Requirement already satisfied: PyYAML>=5.3 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (2.0.27)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (1.33)\n","Requirement already satisfied: langchain-community<0.1,>=0.0.21 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (0.0.24)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (0.1.6)\n","Requirement already satisfied: pydantic<3,>=1 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (2.6.2)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (8.2.3)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from dataclasses-json->unstructured) (3.20.2)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from dataclasses-json->unstructured) (0.9.0)\n","Requirement already satisfied: anyio<5,>=3 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from langchain_core<0.2.0,>=0.1.4->ragatouille) (4.2.0)\n","Requirement already satisfied: packaging<24.0,>=23.2 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from langchain_core<0.2.0,>=0.1.4->ragatouille) (23.2)\n","Requirement already satisfied: deprecated>=1.2.9.3 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (1.2.14)\n","Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (1.0.8)\n","Requirement already satisfied: fsspec>=2023.5.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (2023.10.0)\n","Requirement already satisfied: httpx in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (0.26.0)\n","Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (1.6.0)\n","Requirement already satisfied: networkx>=3.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (3.2.1)\n","Requirement already satisfied: openai>=1.1.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (1.12.0)\n","Requirement already satisfied: pandas in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (2.2.0)\n","Requirement already satisfied: tiktoken>=0.3.3 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (0.6.0)\n","Requirement already satisfied: click in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from nltk->unstructured) (8.1.7)\n","Requirement already satisfied: joblib in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from nltk->unstructured) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from nltk->unstructured) (2023.12.25)\n","Requirement already satisfied: protobuf>=3.20.2 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from onnx<2.0.0,>=1.15.0->ragatouille) (4.25.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from requests->unstructured) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from requests->unstructured) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from requests->unstructured) (2.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from requests->unstructured) (2024.2.2)\n","Requirement already satisfied: scikit-learn in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from sentence-transformers<3.0.0,>=2.2.2->ragatouille) (1.2.2)\n","Requirement already satisfied: huggingface-hub>=0.15.1 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from sentence-transformers<3.0.0,>=2.2.2->ragatouille) (0.20.3)\n","Requirement already satisfied: Pillow in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from sentence-transformers<3.0.0,>=2.2.2->ragatouille) (10.2.0)\n","Requirement already satisfied: filelock in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from torch<3.0.0,>=2.0.1->ragatouille) (3.0.12)\n","Requirement already satisfied: sympy in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from torch<3.0.0,>=2.0.1->ragatouille) (1.12)\n","Requirement already satisfied: jinja2 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from torch<3.0.0,>=2.0.1->ragatouille) (3.1.3)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from transformers<5.0.0,>=4.36.2->ragatouille) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from transformers<5.0.0,>=4.36.2->ragatouille) (0.4.2)\n","Requirement already satisfied: dataclasses-json-speakeasy>=0.5.11 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured) (0.5.11)\n","Requirement already satisfied: jsonpath-python>=1.0.6 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured) (1.0.6)\n","Requirement already satisfied: mypy-extensions>=1.0.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured) (1.0.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured) (2.8.2)\n","Requirement already satisfied: six>=1.16.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured) (1.16.0)\n","Requirement already satisfied: soupsieve>1.2 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from beautifulsoup4->unstructured) (2.5)\n","Requirement already satisfied: sniffio>=1.1 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from anyio<5,>=3->langchain_core<0.2.0,>=0.1.4->ragatouille) (1.3.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain<0.2.0,>=0.1.0->ragatouille) (2.4)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain<0.2.0,>=0.1.0->ragatouille) (3.9.15)\n","Requirement already satisfied: distro<2,>=1.7.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from openai>=1.1.0->llama-index<0.10.0,>=0.9.24->ragatouille) (1.9.0)\n","Requirement already satisfied: httpcore==1.* in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from httpx->llama-index<0.10.0,>=0.9.24->ragatouille) (1.0.3)\n","Requirement already satisfied: h11<0.15,>=0.13 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index<0.10.0,>=0.9.24->ragatouille) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.0->ragatouille) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.3 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.0->ragatouille) (2.16.3)\n","Requirement already satisfied: greenlet!=0.4.17 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index<0.10.0,>=0.9.24->ragatouille) (3.0.3)\n","Requirement already satisfied: pyarrow>=12.0.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from datasets->colbert-ai==0.2.19->ragatouille) (15.0.0)\n","Requirement already satisfied: pyarrow-hotfix in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from datasets->colbert-ai==0.2.19->ragatouille) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from datasets->colbert-ai==0.2.19->ragatouille) (0.3.8)\n","Requirement already satisfied: xxhash in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from datasets->colbert-ai==0.2.19->ragatouille) (3.4.1)\n","Requirement already satisfied: multiprocess in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from datasets->colbert-ai==0.2.19->ragatouille) (0.70.16)\n","Requirement already satisfied: Werkzeug>=3.0.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from flask->colbert-ai==0.2.19->ragatouille) (3.0.1)\n","Requirement already satisfied: itsdangerous>=2.1.2 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from flask->colbert-ai==0.2.19->ragatouille) (2.1.2)\n","Requirement already satisfied: blinker>=1.6.2 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from flask->colbert-ai==0.2.19->ragatouille) (1.7.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from jinja2->torch<3.0.0,>=2.0.1->ragatouille) (2.1.5)\n","Requirement already satisfied: gitpython in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from git-python->colbert-ai==0.2.19->ragatouille) (3.1.41)\n","Requirement already satisfied: pytz>=2020.1 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from pandas->llama-index<0.10.0,>=0.9.24->ragatouille) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.7 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from pandas->llama-index<0.10.0,>=0.9.24->ragatouille) (2024.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from scikit-learn->sentence-transformers<3.0.0,>=2.2.2->ragatouille) (3.2.0)\n","Requirement already satisfied: mpmath>=0.19 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from sympy->torch<3.0.0,>=2.0.1->ragatouille) (1.3.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from gitpython->git-python->colbert-ai==0.2.19->ragatouille) (4.0.11)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython->git-python->colbert-ai==0.2.19->ragatouille) (5.0.1)\n"]}],"source":["!pip install unstructured ragatouille\n","# reranker\n","from ragatouille import RAGPretrainedModel"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42243,"status":"ok","timestamp":1709617789990,"user":{"displayName":"Vashisth Tiwari","userId":"14058204908965748495"},"user_tz":300},"id":"NjDsXe5NaJ4y","outputId":"f557b365-6f37-47ce-ea39-e89886cb3b50"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: numpy in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (1.26.4)\n"]},{"data":{"text/plain":["'1.26.4'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["!pip3 install numpy\n","import numpy as np\n","np.__version__"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"dMOUdS4CaWO3"},"outputs":[],"source":["# fix colab error: https://stackoverflow.com/questions/56081324/why-are-google-colab-shell-commands-not-working\n","import locale\n","def getpreferredencoding(do_setlocale = True):\n","    return \"UTF-8\"\n","locale.getpreferredencoding = getpreferredencoding"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"eoujYMwW9-9J"},"outputs":[],"source":["from tqdm.notebook import tqdm\n","import pandas as pd\n","from typing import Optional, List, Tuple\n","import matplotlib.pyplot as plt\n","pd.set_option(\n","    \"display.max_colwidth\", None\n",")"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"9DLqgmyvsiQw"},"outputs":[],"source":["# Imports\n","import os\n","import pandas as pd\n","\n","# langchain imports\n","from langchain.docstore.document import Document as LangchainDocument\n","from langchain_community.document_loaders import DirectoryLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.vectorstores import FAISS\n","from langchain_community.embeddings import HuggingFaceEmbeddings\n","\n","# hf imports\n","from transformers import pipeline\n","import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","from transformers import T5Tokenizer, T5ForConditionalGeneration\n","\n","# reranking\n","\n","from ragatouille import RAGPretrainedModel\n","from transformers import Pipeline\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15161,"status":"ok","timestamp":1709617909742,"user":{"displayName":"Vashisth Tiwari","userId":"14058204908965748495"},"user_tz":300},"id":"Nqq1MHWNQo7K","outputId":"dd1bb3d7-2412-4464-a4a1-7c58deaccd8e"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":559,"status":"ok","timestamp":1709617913932,"user":{"displayName":"Vashisth Tiwari","userId":"14058204908965748495"},"user_tz":300},"id":"dQ5-vC--Q6Bw","outputId":"c6e541ce-ec56-405c-a35a-cec23f160429"},"outputs":[],"source":["# %cd drive/MyDrive/ANLP/NLP-RAG/src-rag\n","# !ls"]},{"cell_type":"markdown","metadata":{"id":"dcMNNt55siQx"},"source":["# Specify the models/versions"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"FAnu3j0hsiQx","outputId":"157e427f-6b36-4470-b46f-ed62c44e951d"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Mar 11, 22:33:28] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"]},{"name":"stderr","output_type":"stream","text":["/Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n","  warnings.warn(\n"]}],"source":["# give the paths\n","QUESTIONS_FILE = 'data/test/questions_webpages.txt'\n","# OUTPUT_FILE = 'system_outputs/webpages.txt'\n","\n","FAISS_FILE = '../faiss_index_author_papers_natural_language' # it's actually a folder but whatever\n","EMBEDDING_MODEL = \"thenlper/gte-base\" # make sure this matches whatever was used to create the doc embeddings\n","GENERATOR_MODEL = \"google/flan-t5-large\"\n","RERANKER_MODEL = \"colbert-ir/colbertv2.0\"\n","\n","RERANKER = RAGPretrainedModel.from_pretrained(RERANKER_MODEL)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"referenced_widgets":["7d8a9536491b4edbb9b45b1fca65a14a","ea2d43edd2a949e1ba2c9288c77278c8","1264f61a2602416c9707501077cc4ba3","d6a60b7f0f7d42799c8b7a2adfe32b95","3820631823774c52bacb10826096e1f7","50f3e8a8bffa483a996bff8b9fc178e8","af5956998d934d189568b5551262a3cc"]},"id":"M9X3nGPFsiQx","outputId":"866f2588-9d54-41e6-b513-38adee6529e5"},"outputs":[{"name":"stderr","output_type":"stream","text":["You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["# initialize the LLM and its tokenizer, we are using Flan T5 Large for this\n","tokenizer = T5Tokenizer.from_pretrained(GENERATOR_MODEL)\n","model = T5ForConditionalGeneration.from_pretrained(GENERATOR_MODEL)"]},{"cell_type":"markdown","metadata":{"id":"Kr6rN10U9-9J"},"source":["### Load the knowledge base"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"Z14HQGDx2tKI"},"outputs":[],"source":["embedding_model = HuggingFaceEmbeddings(\n","    model_name=EMBEDDING_MODEL,\n","    multi_process=True,\n","    # model_kwargs={\"device\": \"cuda\"},\n","    encode_kwargs={\"normalize_embeddings\": True},  #  True for cosine similarity\n","    )"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"z5cSyyk_siQx"},"outputs":[],"source":["KNOWLEDGE_VECTOR_DATABASE = FAISS.load_local(FAISS_FILE, embedding_model)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"JfDXZPNINnvq"},"outputs":[],"source":["# function to get the prediction and scores from the LLM, given a prompt\n","def get_prediction_and_scores(prompt):\n","    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n","    outputs =  model.generate(input_ids, output_scores=True, return_dict_in_generate=True, max_length=100)\n","                            #   skip_special_tokens=True)\n","    generated_sequence = outputs.sequences[0]\n","\n","    # get the probability scores for each generated token\n","    transition_scores = torch.exp(model.compute_transition_scores(\n","        outputs.sequences, outputs.scores, normalize_logits=True\n","        # , skip_special_tokens = True\n","    )[0])\n","    return tokenizer.decode(generated_sequence), generated_sequence, transition_scores"]},{"cell_type":"markdown","metadata":{"id":"RlfHavRT9-9O"},"source":["## Retrieval and Answer Generation"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"BUQZfctcOkbT"},"outputs":[],"source":["def flanT5_without_threshold(\n","    question: str,\n","    knowledge_index: FAISS,\n","    reranker: Optional[RAGPretrainedModel] = None,\n","    num_retrieved_docs: int = 3,\n","    num_docs_final: int = 2\n","    ):\n","\n","    print(\"=> Retrieving documents...\")\n","    # Gather documents with retriever\n","    relevant_docs_acquired = knowledge_index.similarity_search(query=question, k=num_retrieved_docs)\n","    # print(relevant_docs_acquired)\n","    # print(relevant_docs_acquired)\n","    if reranker:\n","        print(\"=> Reranking documents...\")\n","        relevant_docs = [doc.page_content for doc in relevant_docs_acquired]\n","        relevant_docs = reranker.rerank(question, relevant_docs, k=num_docs_final)\n","        # print(relevant_docs)\n","        relevant_docs_content = [doc[\"content\"] for doc in relevant_docs]\n","        relevant_doc_score = [doc[\"score\"] for doc in relevant_docs]\n","\n","    else:\n","        relevant_docs_content = [doc.page_content for doc in relevant_docs_acquired]\n","\n","    relevant_docs_content = relevant_docs_content[:num_docs_final]\n","    # relevant_doc_id = relevant_doc_id[:num_docs_final]\n","    # relevant_doc_index = relevant_doc_index[:num_docs_final]\n","\n","    # Build the final prompt\n","    context = \"\\nExtracted documents:\\n\"\n","    context += \"\".join([f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(relevant_docs_content)])\n","\n","    context_and_question = f\"Keep your answers short and concise. If the text has date and time include the date, time both. If there are multiple right answers, include them all, but keep it short overall. \\n Given the below context:\\n{context}\\n\\n Answer the following \\n{question}\\n\"\n","\n","    # context_and_question = \"\"\"\n","    # Answer the user's questions based on the below context. Please keep your answers short and concise. Only provide the answer itself.\"\n","    # ------------\n","    # {context}\n","    # ------------\n","    # Question: {question}\n","    # Answer:\n","    # \"\"\"\n","\n","    # Redact an answer\n","    print(\"=> Generating answer...\")\n","    generated_sequence, _, _ = get_prediction_and_scores(context_and_question)\n","    # answer = f\"{question} {generated_sequence}\"\n","\n","    # removing the special tokens and padding\n","    answer = generated_sequence.replace(\"<pad>\", \"\").replace(\"</s>\", \"\").strip()\n","\n","    return answer, relevant_docs_content"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"reUcMJqkRi2m"},"outputs":[],"source":["user_query = 'Who is the first of the paper \"Extracting training data from diffusion models\"?'"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HX130eMiRjXm","outputId":"d415795c-6396-4ec6-adc6-5aaf236ba253"},"outputs":[{"name":"stdout","output_type":"stream","text":["=> Retrieving documents...\n","=> Reranking documents...\n"]},{"name":"stderr","output_type":"stream","text":["/Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n","  warnings.warn(\n","100%|██████████| 1/1 [00:00<00:00, 11.14it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=> Generating answer...\n"]}],"source":["answer, relevant_docs = flanT5_without_threshold(\n","    user_query, KNOWLEDGE_VECTOR_DATABASE, reranker=RERANKER\n",")"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KKCo8SEpRj3i","outputId":"f064de33-4077-435f-d77e-2e02c12c12f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["==================================Answer==================================\n","2\n","Nicholas Carlini\n"]}],"source":["print(\"==================================Answer==================================\")\n","print(len(relevant_docs))\n","print(f\"{answer}\")"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"th4u-kqLRoik","outputId":"fffeab8d-de47-43c5-d2ac-3def6903d71a"},"outputs":[{"name":"stdout","output_type":"stream","text":["==================================Source docs==================================\n","Documet ------------------------------------------------------------\n","Question: Who is the first author of the paper 'Extracting Training Data from Diffusion Models'?\n","Answer: Nicholas Carlini\n","Notes: ##Title: Extracting Training Data from Diffusion Models\n","Documet ------------------------------------------------------------\n","Question: Who are the authors of the paper 'Extracting Training Data from Diffusion Models'?\n","Answer: Nicholas Carlini, Jamie Hayes, Milad Nasr, Matthew Jagielski, Vikash Sehwag, Florian Tramer, B. Balle, Daphne Ippolito, Eric Wallace\n","Notes: ##Title: Extracting Training Data from Diffusion Models\n"]}],"source":["print(\"==================================Source docs==================================\")\n","for  doc in (relevant_docs):\n","    print(f\"Document ------------------------------------------------------------\")\n","    print(f'{doc}')"]},{"cell_type":"markdown","metadata":{"id":"xEsiqSCesiQy"},"source":["## Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aS3tl8emsiQy"},"outputs":[],"source":["def generate_answer(question):\n","    answer, _ = flanT5_without_threshold(\n","        question, KNOWLEDGE_VECTOR_DATABASE, reranker=RERANKER\n","    )\n","    return answer\n","\n","OUTPUT_FILE_WITHOUT_THRESHOLD= 'system_outputs/webpages_no_threshold.txt'\n","\n","# note that this overwrites previously generated answers to the answer file\n","def generate_answers_all(qfile, afile):\n","    questions_file = open(qfile, 'r')\n","    questions = questions_file.readlines()\n","    ans_file = open(afile, \"w+\")\n","    for q in questions:\n","        ans = generate_answer(q)\n","        ans_file.write(ans + '\\n')\n","    questions_file.close()\n","    ans_file.close()\n","\n","generate_answers_all(QUESTIONS_FILE, OUTPUT_FILE_WITHOUT_THRESHOLD)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3k1mPLZAsiQy"},"outputs":[],"source":["from evaluation import total_score\n","\n","print(total_score(OUTPUT_FILE_WITHOUT_THRESHOLD, '../data/test/reference_answers.txt'))"]},{"cell_type":"markdown","metadata":{"id":"jMzFR9rGsiQy"},"source":["---\n","# Leave for now the normal one works just fine"]},{"cell_type":"markdown","metadata":{"id":"iUDUM3Bbt9Hm"},"source":["## Flare\n","- Source: https://ayushtues.medium.com/flare-advanced-rag-implemented-from-scratch-07ca75c89800\n","- essentially an extra acceptance step\n","- </s>\n","  -  is the seperation token (shows the end of a sentence. When we say that we break the generation)\n","  -  if you dont want this remove the if statement where we 'break'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8H2wxME7siQy"},"outputs":[],"source":["# # function to get the prediction and scores from the LLM, given a prompt\n","# def get_prediction_and_score_flare(prompt):\n","#     input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n","#     outputs =  model.generate(input_ids, output_scores=True, return_dict_in_generate=True, max_length=200)\n","#     generated_sequence = outputs.sequences[0]\n","\n","#     # get the probability scores for each generated token\n","#     transition_scores = torch.exp(model.compute_transition_scores(\n","#         outputs.sequences, outputs.scores, normalize_logits=True\n","#     )[0])\n","#     return tokenizer.decode(generated_sequence), generated_sequence, transition_scores"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zxmrk3PPsiQy"},"outputs":[],"source":["# def flanT5_with_threshold(\n","#     input_text: str,\n","#     knowledge_index: FAISS,\n","#     reranker: Optional[RAGPretrainedModel] = None,\n","#     num_retrieved_docs: int = 5,\n","#     num_docs_final: int = 3,\n","#     threshold = .1\n","#     ):\n","\n","#     relevant_docs = None\n","\n","#     while True: # breaks when you have a separation token in the generated sequence\n","\n","#         generated_sequence, tokens, scores = get_prediction_and_scores(input_text)\n","\n","#         if torch.min(scores)< threshold:\n","\n","#             # new query = high confidence tokens\n","#             confident_tokens = tokens[torch.where(scores>threshold)]\n","#             confident_query = tokenizer.decode(confident_tokens)\n","\n","#             # Gather documents with retriever\n","#             relevant_docs_acquired = knowledge_index.similarity_search(query=confident_query, k=num_retrieved_docs)\n","#             # print(relevant_d|ocs_acquired)\n","#             # print(relevant_docs_acquired)\n","#             if reranker:\n","#                 print(\"=> Reranking documents...\")\n","#                 relevant_docs = [doc.page_content for doc in relevant_docs_acquired]\n","\n","#                 relevant_docs = reranker.rerank(confident_query, relevant_docs, k=num_docs_final)\n","#                 # print(relevant_docs)\n","\n","#                 relevant_docs_content = [doc[\"content\"] for doc in relevant_docs]\n","#                 # relevant_doc_score = [doc[\"score\"] for doc in relevant_docs]\n","\n","#             else:\n","#                 relevant_docs_content = [doc.page_content for doc in relevant_docs_acquired]\n","\n","#             relevant_docs_content = relevant_docs_content[:num_docs_final]\n","#             # relevant_doc_score = relevant_doc_score[:num_docs_final]\n","\n","#             # Build the final prompt\n","#             context = \"\\nExtracted documents:\\n\"\n","#             context += \"\".join([f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(relevant_docs_content)])\n","\n","#             # new_input_text = f\"Answer the user's questions based on the below context. Keep your answers short and concise.\\n------------<context>\\n{context}\\n</context>------------\\n<question> Here is the question\\n{input_text}\\n</question>\\n\"\n","\n","#             new_input_text = f\"Keep your answers short and concise. If there are multiple right answers, include them all, but keep it short overall. \\n Given the below context:\\n{context}\\n\\n Answer the following \\n{input_text}\\n\"\n","\n","#             # Redact an answer\n","#             print(\"=> Generating answer...\")\n","#             generated_sequence, seq, _ = get_prediction_and_scores(new_input_text)\n","\n","#             if \"</s>\" in generated_sequence:\n","#                 input_text = tokenizer.decode(seq, skip_special_tokens=True)\n","#                 break\n","\n","#         else: # tokens are already high confidence\n","#             if \"</s>\" in generated_sequence:\n","#                 input_text = tokenizer.decode(tokens, skip_special_tokens=True)\n","#                 break\n","\n","#     # print(relevant_docs_content)\n","#     answer = input_text.replace(\"<pad>\", \"\").replace(\"</s>\", \"\").strip()\n","\n","#     if relevant_docs is None:\n","#         return answer, 'docs not needed'\n","#         # 'id = None', 'index = None'\n","#     return answer, relevant_docs_content"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PL8E1xVJw766"},"outputs":[],"source":["# # user_query = 'What is the Buggy race schedule this year?'\n","# user_query = 'What is the safety gear required by all buggy drivers?'\n","# answer, relevant_docs = flanT5_with_threshold(\n","#     user_query, KNOWLEDGE_VECTOR_DATABASE, reranker=RERANKER\n","# )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dko_REQ9xDXF","outputId":"24775901-bc7b-4cc9-c1c2-4d1306bc7e3f"},"outputs":[{"name":"stdout","output_type":"stream","text":["==================================Answer==================================\n","hat and gloves\n"]}],"source":["# print(\"==================================Answer==================================\")\n","# print(answer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m-sd3UO1yx4J","outputId":"b2852135-42d4-4de3-ff63-d91f6fd93b26"},"outputs":[{"name":"stdout","output_type":"stream","text":["3\n","This manuscript describes the work that has been completed for domain characterization as an early step toward developing standardized PRO measures to evaluate these important outcomes specific to upper extremity transplantation.\n","\n","## AUTHORNAME\n","\n","Lori S. Levin\n","\n","## JOURNAL\n","\n","{'volume': '13', 'name': 'Frontiers in Psychology'}\n","\n","## FIELDSOFSTUDY\n","\n","['Medicine']\n","\n","## URL\n","\n","https://www.semanticscholar.org/paper/52a97ad16605c18e23c9750a388a26a9cdf12200\n","\n","## YEAR\n","\n","2023\n","\n","## TLDR\n","\n","Qualitative work with experts, clinicians, and patients has identified several domains of QOL that are unique to individuals who have received upper extremity transplants, which are distinct from topics covered by existing PRO measures.\n","\n","## VENUE\n","\n","Frontiers in Psychology\n","\n","on, grip strength, pain, and the various activities of\n","\n","daily living that require manual motor function and dexterity to\n","\n","complete. Thus, we believe that assessment of functional ability is\n","\n","best left to existing measures, such as SCI-FI Fine Motor, SCI-FI\n","\n","Self-Care, PROMIS Upper Extremity ( Jette et al., 2012   Tulsky\n","\n","et al., 2012   Kaat et al., 2019 ), or Neuro-QoL Upper ExtremityFine\n","\n","Motor ( Cella et al., 2012   Gershon et al., 2012 ).\n","\n","In contrast, satisfaction  with hand functioning as experienced\n","\n","by UE transplant recipients appears to merit a new HRQOL content\n","\n","domain, as difficulties and frustrations with the responsivity and\n","\n","ease of movement of the transplanted limbs/hands are distinct for\n","\n","this population, where capabilities improve gradually with\n","\n","treatment and nerve regrowth or sometimes not at all. Likewise,\n","\n","the challenges with sensation and aesthetic satisfaction are also\n","\n","unique to UE transplant. Although there are other clinical groups\n","This manuscript describes the work that has been completed for domain characterization as an early step toward developing standardized PRO measures to evaluate these important outcomes specific to upper extremity transplantation.\n","\n","## AUTHORNAME\n","\n","Lori S. Levin\n","\n","## JOURNAL\n","\n","{'volume': '13', 'name': 'Frontiers in Psychology'}\n","\n","## FIELDSOFSTUDY\n","\n","['Medicine']\n","\n","## URL\n","\n","https://www.semanticscholar.org/paper/52a97ad16605c18e23c9750a388a26a9cdf12200\n","\n","## YEAR\n","\n","2023\n","\n","## TLDR\n","\n","Qualitative work with experts, clinicians, and patients has identified several domains of QOL that are unique to individuals who have received upper extremity transplants, which are distinct from topics covered by existing PRO measures.\n","\n","## VENUE\n","\n","Frontiers in Psychology\n","\n","or tertiary goal. Stakeholders also explained that\n","\n","the aesthetic aspects of the transplants were expected to change\n","\n","over time, as follow-up procedures (e.g., debulking) could be done\n","\n","to improve aesthetics.\n","\n","It has been always important for me to have new real hands\n","\n","and not plastic or silicone hands. UE transplant recipient\n","\n","They try to match on skin color as well as [donor] sex.. but\n","\n","there's often a big size discrepancy in the arms  because what's\n","\n","left of [the recipient s] native arm is often very shrunken and\n","\n","small, and then you're transplanting   a normal size forearm.\n","\n","UE transplant expert stakeholder clinician\n","\n","To assess recipients  satisfaction with the external\n","\n","appearance of the transplant, we designed the Satisfaction with\n","\n","Hand Aesthetics domain. Specific subtopics covered in the\n","\n","stakeholder discussions included skin tone of the transplant,\n","\n","size of the transplant, fingernail appearance, forearm bulk, scar\n","## YEAR\n","\n","2023\n","\n","## TLDR\n","\n","Qualitative work with experts, clinicians, and patients has identified several domains of QOL that are unique to individuals who have received upper extremity transplants, which are distinct from topics covered by existing PRO measures.\n","\n","## VENUE\n","\n","Frontiers in Psychology\n","\n","cially relevant sense and was closely tied to the desire for\n","\n","improved social functioning after the transplant.\n","\n","Sensation though is so important. And I can t reinforce that\n","\n","enough as it relates to relationships with those that you love.\n","\n","Your spouse and your children, especially for those that have\n","\n","young children. Hooks don t have any value with young children,\n","\n","and electric hands don t have value with children. UE\n","\n","transplant expert stakeholder\n","\n","I can feel what I touch, I can feel if it is hot or if it is cold, if it is\n","\n","soft, or if it is itchy or anything, and   that is something that is\n","\n","very important for me, and it goes with the fact that I can like\n","\n","touch somebody. So, for example, my boyfriend, I can  put my\n","\n","hand on him and I can touch him or feel him or touch his hair\n","\n","or things like that  that really matters for me currently. UE\n","\n","In response to these stakeholder comments, two HRQOL\n","\n","content domains were developed on the topic of sensation. First,\n","\n","the Hand Function  Sensation domain was designed to evaluate\n","\n","recipients  ability to perceive a variety of sensations in the\n","\n","transplanted limb/hand. These included, for example, light\n","\n","pressure, touch, textures, temperature, and pain. The second\n","\n","domain developed was Satisfaction with Sensation. This domain\n","\n","was designed to assess recipients  satisfaction with their ability to\n","\n","perceive sensation with the transplant, including social touch.\n","\n","These two domains were conceptualized as discrete because\n","\n","stakeholders acknowledged that recipients  degree of satisfaction\n","\n","may not correlate directly with the amount of sensory function\n","\n","they have in the UE transplant. Stakeholders described how\n"]}],"source":["# # print(\"=========================Relevant Documents===========================\")\n","# print(len(relevant_docs))\n","# for i in relevant_docs:\n","#     print(i)"]},{"cell_type":"markdown","metadata":{"id":"zdx4_Ptp2tKT"},"source":["## Generate Answers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zPFTPldT0y05"},"outputs":[],"source":["# def generate_answer(question):\n","#     answer, _ = flanT5_with_threshold(\n","#         question, KNOWLEDGE_VECTOR_DATABASE, reranker=RERANKER\n","#     )\n","#     return answer\n","\n","# OUTPUT_FILE_THRESHOLD= 'system_outputs/webpages_threshold.txt'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fhMx-4pq2tKT"},"outputs":[],"source":["# def generate_answer(question):\n","#     answer, _ = flanT5_with_threshold(\n","#         question, KNOWLEDGE_VECTOR_DATABASE, reranker=RERANKER\n","#     )\n","#     return answer\n","\n","\n","# generate_answers_all(QUESTIONS_FILE, OUTPUT_FILE_THRESHOLD)\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"widgets":{"application/vnd.jupyter.widget-state+json":{}}},"nbformat":4,"nbformat_minor":0}
