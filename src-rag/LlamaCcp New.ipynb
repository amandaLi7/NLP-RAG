{"cells":[{"cell_type":"markdown","metadata":{"id":"jvckNkk2H-Uf"},"source":[]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":805,"status":"ok","timestamp":1710117257071,"user":{"displayName":"Vashisth Tiwari","userId":"14058204908965748495"},"user_tz":240},"id":"_hOLtFMk5Da8","outputId":"94374d01-d7e6-420d-a80b-d0b59c93a242"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":216,"status":"ok","timestamp":1710110535716,"user":{"displayName":"Vashisth Tiwari","userId":"14058204908965748495"},"user_tz":240},"id":"mY6P-Gdd5E7A","outputId":"e3a24a49-34e0-4fbb-81e1-b84da44eb4bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ANLP/NLP-RAG/src-rag\n","database.py\t\t\tFlanT5.ipynb\t\t     __pycache__\n","evaluation.py\t\t\tjson_csv_embedding.ipynb     setup.txt\n","faiss_index_author_papers_json\tLlamaCcp.ipynb\n","faiss_index_author_papers_lang\tLlama_qa_gen_pipeline.ipynb\n"]}],"source":["%cd drive/MyDrive/ANLP/NLP-RAG/src-rag\n","!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s96leWz22vbg"},"outputs":[],"source":["import os\n","# from dotenv import load_dotenv\n","# load_dotenv('.env')\n","# hf_api = os.getenv('HF_API')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18031,"status":"ok","timestamp":1709884858907,"user":{"displayName":"Vashisth Tiwari","userId":"14058204908965748495"},"user_tz":300},"id":"s-iSASxn3CUu","outputId":"6c5d8662-e6ed-45db-fcea-54ea512ec45d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers==4.38.0\n","  Downloading transformers-4.38.0-py3-none-any.whl (8.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.0) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.0) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.0) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.0) (2024.2.2)\n","Installing collected packages: transformers\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.38.2\n","    Uninstalling transformers-4.38.2:\n","      Successfully uninstalled transformers-4.38.2\n","Successfully installed transformers-4.38.0\n"]}],"source":["pip install transformers==4.38.0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22031,"status":"ok","timestamp":1710109841326,"user":{"displayName":"Vashisth Tiwari","userId":"14058204908965748495"},"user_tz":240},"id":"PzQ5HViT2-PN","outputId":"2f0cd23d-8c3a-4734-d5cc-f656d1e97931"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.5/807.5 kB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.9/256.9 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.6/66.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -q torch accelerate bitsandbytes langchain sentence-transformers faiss-gpu openpyxl"]},{"cell_type":"code","source":["# !pip install ctransformers[cuda]\n","!pip3 install numpy==1.26.4\n","import numpy as np\n","np.__version__\n","\n","# restart after"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"id":"VbUAaUUtf1mg","executionInfo":{"status":"ok","timestamp":1710110042978,"user_tz":240,"elapsed":13570,"user":{"displayName":"Vashisth Tiwari","userId":"14058204908965748495"}},"outputId":"f8419cd9-3b78-43bf-cc73-772c118d60fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.10/dist-packages (1.26.4)\n"]},{"output_type":"execute_result","data":{"text/plain":["'1.26.4'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30367,"status":"ok","timestamp":1710110076187,"user":{"displayName":"Vashisth Tiwari","userId":"14058204908965748495"},"user_tz":240},"id":"mH-fC5LR3N4J","outputId":"8066c6c2-7da8-4214-ed92-62f4c4a4689d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: unstructured in /usr/local/lib/python3.10/dist-packages (0.12.6)\n","Requirement already satisfied: ragatouille in /usr/local/lib/python3.10/dist-packages (0.0.7.post9)\n","Requirement already satisfied: backoff==2.2.1 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.2.1)\n","Requirement already satisfied: beautifulsoup4==4.12.3 in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.12.3)\n","Requirement already satisfied: certifi==2024.2.2 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2024.2.2)\n","Requirement already satisfied: chardet==5.2.0 in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.2.0)\n","Requirement already satisfied: charset-normalizer==3.3.2 in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.3.2)\n","Requirement already satisfied: click==8.1.7 in /usr/local/lib/python3.10/dist-packages (from unstructured) (8.1.7)\n","Requirement already satisfied: dataclasses-json==0.6.4 in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.6.4)\n","Requirement already satisfied: dataclasses-json-speakeasy==0.5.11 in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.5.11)\n","Requirement already satisfied: emoji==2.10.1 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.10.1)\n","Requirement already satisfied: filetype==1.2.0 in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.2.0)\n","Requirement already satisfied: idna==3.6 in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.6)\n","Requirement already satisfied: joblib==1.3.2 in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.3.2)\n","Requirement already satisfied: jsonpath-python==1.0.6 in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.0.6)\n","Requirement already satisfied: langdetect==1.0.9 in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.0.9)\n","Requirement already satisfied: lxml==5.1.0 in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.1.0)\n","Requirement already satisfied: marshmallow==3.20.2 in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.20.2)\n","Requirement already satisfied: mypy-extensions==1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.0.0)\n","Requirement already satisfied: nltk==3.8.1 in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n","Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.26.4)\n","Requirement already satisfied: packaging==23.2 in /usr/local/lib/python3.10/dist-packages (from unstructured) (23.2)\n","Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.8.2)\n","Requirement already satisfied: python-iso639==2024.2.7 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2024.2.7)\n","Requirement already satisfied: python-magic==0.4.27 in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.4.27)\n","Requirement already satisfied: rapidfuzz==3.6.1 in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.6.1)\n","Requirement already satisfied: regex==2023.12.25 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2023.12.25)\n","Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.31.0)\n","Requirement already satisfied: six==1.16.0 in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.16.0)\n","Requirement already satisfied: soupsieve==2.5 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.5)\n","Requirement already satisfied: tabulate==0.9.0 in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.9.0)\n","Requirement already satisfied: tqdm==4.66.2 in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.66.2)\n","Requirement already satisfied: typing-extensions==4.9.0 in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.0)\n","Requirement already satisfied: typing-inspect==0.9.0 in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.9.0)\n","Requirement already satisfied: unstructured-client==0.18.0 in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.18.0)\n","Requirement already satisfied: urllib3==1.26.18 in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.26.18)\n","Requirement already satisfied: wrapt==1.16.0 in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.16.0)\n","Requirement already satisfied: aiohttp==3.9.1 in /usr/local/lib/python3.10/dist-packages (from ragatouille) (3.9.1)\n","Requirement already satisfied: colbert-ai==0.2.19 in /usr/local/lib/python3.10/dist-packages (from ragatouille) (0.2.19)\n","Requirement already satisfied: faiss-cpu<2.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from ragatouille) (1.8.0)\n","Requirement already satisfied: langchain<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from ragatouille) (0.1.11)\n","Requirement already satisfied: langchain_core<0.2.0,>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from ragatouille) (0.1.30)\n","Requirement already satisfied: llama-index<0.10.0,>=0.9.24 in /usr/local/lib/python3.10/dist-packages (from ragatouille) (0.9.48)\n","Requirement already satisfied: onnx<2.0.0,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from ragatouille) (1.15.0)\n","Requirement already satisfied: ruff<0.2.0,>=0.1.9 in /usr/local/lib/python3.10/dist-packages (from ragatouille) (0.1.15)\n","Requirement already satisfied: sentence-transformers<3.0.0,>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from ragatouille) (2.5.1)\n","Requirement already satisfied: srsly==2.4.8 in /usr/local/lib/python3.10/dist-packages (from ragatouille) (2.4.8)\n","Requirement already satisfied: torch<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from ragatouille) (2.1.0+cu121)\n","Requirement already satisfied: transformers<5.0.0,>=4.36.2 in /usr/local/lib/python3.10/dist-packages (from ragatouille) (4.38.2)\n","Requirement already satisfied: voyager<3.0.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from ragatouille) (2.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.9.1->ragatouille) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.9.1->ragatouille) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.9.1->ragatouille) (1.9.4)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.9.1->ragatouille) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.9.1->ragatouille) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.9.1->ragatouille) (4.0.3)\n","Requirement already satisfied: bitarray in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragatouille) (2.9.2)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragatouille) (2.18.0)\n","Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragatouille) (2.2.5)\n","Requirement already satisfied: git-python in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragatouille) (1.0.3)\n","Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragatouille) (1.0.1)\n","Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragatouille) (1.11.1.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragatouille) (1.11.4)\n","Requirement already satisfied: ujson in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragatouille) (5.9.0)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from srsly==2.4.8->ragatouille) (2.0.10)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (2.0.28)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (1.33)\n","Requirement already satisfied: langchain-community<0.1,>=0.0.25 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (0.0.27)\n","Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (0.0.1)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (0.1.23)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (2.6.3)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (8.2.3)\n","Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain_core<0.2.0,>=0.1.4->ragatouille) (3.7.1)\n","Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (1.2.14)\n","Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (1.0.8)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (2023.6.0)\n","Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (0.27.0)\n","Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (1.6.0)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (3.2.1)\n","Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (1.13.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (1.5.3)\n","Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (0.6.0)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx<2.0.0,>=1.15.0->ragatouille) (3.20.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.2.2->ragatouille) (1.2.2)\n","Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.2.2->ragatouille) (0.20.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.2.2->ragatouille) (9.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.1->ragatouille) (3.13.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.1->ragatouille) (1.12)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.1->ragatouille) (3.1.3)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.1->ragatouille) (2.1.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.36.2->ragatouille) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.36.2->ragatouille) (0.4.2)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain_core<0.2.0,>=0.1.4->ragatouille) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain_core<0.2.0,>=0.1.4->ragatouille) (1.2.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain<0.2.0,>=0.1.0->ragatouille) (2.4)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.0->ragatouille) (3.9.15)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index<0.10.0,>=0.9.24->ragatouille) (1.7.0)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index<0.10.0,>=0.9.24->ragatouille) (1.0.4)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index<0.10.0,>=0.9.24->ragatouille) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.0->ragatouille) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.0->ragatouille) (2.16.3)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain<0.2.0,>=0.1.0->ragatouille) (3.0.3)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.19->ragatouille) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.19->ragatouille) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.19->ragatouille) (0.3.8)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.19->ragatouille) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.19->ragatouille) (0.70.16)\n","Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask->colbert-ai==0.2.19->ragatouille) (3.0.1)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->colbert-ai==0.2.19->ragatouille) (2.1.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3.0.0,>=2.0.1->ragatouille) (2.1.5)\n","Requirement already satisfied: gitpython in /usr/local/lib/python3.10/dist-packages (from git-python->colbert-ai==0.2.19->ragatouille) (3.1.42)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index<0.10.0,>=0.9.24->ragatouille) (2023.4)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers<3.0.0,>=2.2.2->ragatouille) (3.3.0)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3.0.0,>=2.0.1->ragatouille) (1.3.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython->git-python->colbert-ai==0.2.19->ragatouille) (4.0.11)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython->git-python->colbert-ai==0.2.19->ragatouille) (5.0.1)\n"]}],"source":["!pip install unstructured ragatouille\n","# reranker\n","from ragatouille import RAGPretrainedModel"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":275993,"status":"ok","timestamp":1710110355792,"user":{"displayName":"Vashisth Tiwari","userId":"14058204908965748495"},"user_tz":240},"id":"-hsCAcjxIP19","outputId":"128ca964-5cf2-4f00-cfa4-2ec234a65bdd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting llama-cpp-python\n","  Downloading llama_cpp_python-0.2.56.tar.gz (36.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.9/36.9 MB\u001b[0m \u001b[31m145.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting typing-extensions>=4.5.0 (from llama-cpp-python)\n","  Downloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n","Collecting numpy>=1.20.0 (from llama-cpp-python)\n","  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m269.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting diskcache>=5.6.1 (from llama-cpp-python)\n","  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m136.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jinja2>=2.11.3 (from llama-cpp-python)\n","  Downloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 kB\u001b[0m \u001b[31m295.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting MarkupSafe>=2.0 (from jinja2>=2.11.3->llama-cpp-python)\n","  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n","Building wheels for collected packages: llama-cpp-python\n","  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.56-cp310-cp310-manylinux_2_35_x86_64.whl size=22622726 sha256=cc90f00f6e6a7b1ae84d63c0d04a8f9ad2e2a2e48f4b9d63c125afc50276fd6c\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-t86dw4_u/wheels/e5/09/9d/c413053f6258cb2546cc792418c595e276f9efd5db31a80377\n","Successfully built llama-cpp-python\n","Installing collected packages: typing-extensions, numpy, MarkupSafe, diskcache, jinja2, llama-cpp-python\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.9.0\n","    Uninstalling typing_extensions-4.9.0:\n","      Successfully uninstalled typing_extensions-4.9.0\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.26.4\n","    Uninstalling numpy-1.26.4:\n","      Successfully uninstalled numpy-1.26.4\n","  Attempting uninstall: MarkupSafe\n","    Found existing installation: MarkupSafe 2.1.5\n","    Uninstalling MarkupSafe-2.1.5:\n","      Successfully uninstalled MarkupSafe-2.1.5\n","  Attempting uninstall: jinja2\n","    Found existing installation: Jinja2 3.1.3\n","    Uninstalling Jinja2-3.1.3:\n","      Successfully uninstalled Jinja2-3.1.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.15.0 requires wrapt<1.15,>=1.11.0, but you have wrapt 1.16.0 which is incompatible.\n","unstructured 0.12.6 requires typing-extensions==4.9.0, but you have typing-extensions 4.10.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed MarkupSafe-2.1.5 diskcache-5.6.3 jinja2-3.1.3 llama-cpp-python-0.2.56 numpy-1.26.4 typing-extensions-4.10.0\n"]}],"source":["# this will take time :c\n","!CUDACXX=/usr/local/cuda-12/bin/nvcc CMAKE_ARGS=\"-DLLAMA_CUBLAS=on -DCMAKE_CUDA_ARCHITECTURES=all-major\" FORCE_CMAKE=1 pip install llama-cpp-python --no-cache-dir --force-reinstall --upgrade"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4ItWW1Es3OX_"},"outputs":[],"source":["# fix colab error: https://stackoverflow.com/questions/56081324/why-are-google-colab-shell-commands-not-working\n","import locale\n","def getpreferredencoding(do_setlocale = True):\n","    return \"UTF-8\"\n","locale.getpreferredencoding = getpreferredencoding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CB6DVShA2vbh"},"outputs":[],"source":["from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n","from langchain.docstore.document import Document as LangchainDocument\n","from langchain.chains.summarize import load_summarize_chain\n","from langchain.chains import RetrievalQA\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.vectorstores import Chroma\n","from langchain.llms import LlamaCpp\n","from langchain.prompts import PromptTemplate, ChatPromptTemplate\n","import os\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GrqalAohmDnp"},"outputs":[],"source":["from huggingface_hub import hf_hub_download\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m1Dm1uHk2vbh"},"outputs":[],"source":["from langchain.vectorstores import FAISS\n","from langchain_community.embeddings import HuggingFaceEmbeddings\n","from tqdm.notebook import tqdm\n","import pandas as pd\n","from typing import Optional, List, Tuple\n","import matplotlib.pyplot as plt\n","pd.set_option(\n","    \"display.max_colwidth\", None\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ti-G7vMdASy"},"outputs":[],"source":["# pip list --outdated"]},{"cell_type":"markdown","metadata":{"id":"pO3SVhxSshpo"},"source":["# Specify the model/versions, etc.\n","## also specify the knowledge base file and the reference answer directory"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6034,"status":"ok","timestamp":1710110390648,"user":{"displayName":"Vashisth Tiwari","userId":"14058204908965748495"},"user_tz":240},"id":"SscMCDYU2vbh","colab":{"base_uri":"https://localhost:8080/","height":365,"referenced_widgets":["800014039af04d66adc94131a8ab568e","f741891d16434e959971b6331ab7a09e","20619dd814a245cb96eed1ffd6d23793","f91289ae253446ed90b7c9260d85ac2c","3088fb3c8cc74d7c97d9cbacc5b20c03","234ab5cd38b14aec8426fcc28dfc4952","b8d486c46bbc4a6abdb3b0af3dbc4c04","be42d78fa32c44f4ba983327b2f2b0ae","d696cc22200743caaaa0d70de5f29eaf","2d7b6a6ffb3849ec9828e24f4e193840","718e83bf80b74bbb9e28a9a2473ab8db","9561e20747684a1a878a637d00c946fa","b5cfff7bf253443682d8051953740ad2","d2b20654e6aa49359b678e198cc55a73","5fca46bd83bd4f95ae25eecf342ff20f","63a47d5282db441a8e5732ab3266af33","8d567a74de4843a4b50292512c7d0ebe","e4710695ec874eada402065fe800edd5","9b8ebc99d0ed4d9fb6f873f06a638318","2750e13775ad4cc5a1ca97abd23a7fa4","fc979bda6f3c486e8108945371fee26e","5de0a6a267a24518ac2857b47c4d2d4e","fc6ba90ca08747e1bace0a55d1eeed55","5e9df76d9eb04c3cacc9caf4edacb913","091d085339a14a0ab5a23a60b24508f6","1191b9f6ca7e491c91a54648d9a95740","b106e671bf2040ff85286339391cacce","25d444efba4c4f8ea2a15c4a197e83fa","fa2721e59a714068a0a5918cd7ec3246","8041af99466c478ab32dcb07ff597d41","ec25bd06a00e4e2cab1b9f62905449ca","d3e5436855af42a5b2f170b44388e4a8","195ac8d683264e9999a419b94e60bdc1","08e5c13a33c442d69db6a4e5cb1aefd8","486f19f393194214820b2e4719793822","82baa3fb82e24827b49b6bda22f72d78","a2c29ede70564d5b879b4084453d753f","bb8b2e9c41ea45dfa6fe7dff8a934fa2","6257ec67ee0043adab5a9e24a4f709a8","df62dad6b54444659f23d7cca3ddaa70","2c938e4d55734c248ffb292415aa5f5b","5582c1c8145b4fe786ba967188680aa7","b5693df9d1cf458e9c7dabfba2331102","4c7a193e4d3349dc8c2ff58c7137e77e","c1225405706548aa86f466345ba78795","f9124d67aef64019a437baa8eef8e54e","7a6d685007704814a51a027b060ba1b0","c87f3b6818934457af1827e01f4924ba","cfab7d69b2634082805f101090dcbd04","9553bb69e7c5479ebbf73787d3fc8b14","0eae622975df4cfaaa2e54cde12fecc2","b599c45a81df44619d92a3ac8ad41b0f","c2cf8f815146436e86373dd6f02e94aa","b02abbcd98d94732961735247946d2d4","666d42ef1a74402fb13ea79db36c1287","c28b40c65c1f450988dfb834ccbf1526","1257cd90321540d8b5530c35b672ac38","365523a881584181973972b7df86c3eb","6023241ffbf740ec871828d6276cccb8","863ed2e3ac1e4670b7850cf4deafc867","890443b9c63d42b597b1fce37ed2612f","e7bc53149d98433785d628cd3783cbdb","3a1808fea5884186924c50c1d44cdb2b","6cb72ab4081a44fd8462b7d58da7236c","d9d79532e89447e1ae295ea296d33dbf","4663ab81441947f7bd1b86a08d82a6b2","b14e572db35545c58c413b5313c230d0","26f3de4a37ed42c783b8cc8496a8830e","25ea5fce0d51425ca66647c86a69054d","1d5d56be1f3e4e06ad05b7a61c073773","0e6e63ccb1164deab11b438e7059d69f","e5ff1078ea2d454ba88d92b978bee13f","97d0ee251daa487db840ba561a36d4a8","572f1df5c7904ccf939d45356997f7a7","abe064fd2d2943cc9658631022e7dfbe","37bbe9f296674040a1e4e6f414645aee","0567916024824a5cb153ee96ae90bcfd"]},"outputId":"83e0ecb7-0a38-489a-ec55-a9c7d22fc51f"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["artifact.metadata:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"800014039af04d66adc94131a8ab568e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9561e20747684a1a878a637d00c946fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc6ba90ca08747e1bace0a55d1eeed55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/405 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08e5c13a33c442d69db6a4e5cb1aefd8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1225405706548aa86f466345ba78795"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c28b40c65c1f450988dfb834ccbf1526"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b14e572db35545c58c413b5313c230d0"}},"metadata":{}}],"source":["EMBEDDING_MODEL = \"thenlper/gte-base\"\n","RERANKER_MODEL = \"colbert-ir/colbertv2.0\"\n","RERANKER = RAGPretrainedModel.from_pretrained(RERANKER_MODEL)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337,"referenced_widgets":["cb37e6988db144ac9e6b615b71705c3d","58f1227b067740c99856d28d1b3535f0","a68946ee535e4693955f8292b47c5b6c","72f6e2507a5c49338610f22446087687","f7afe5336f9645bbaa3da495dad04c6f","f4c9a624ca3342adbdda81d0c505d540","7b9187f7562945ba813032f73d5fed96","755d31fc51614b78a6798a1f45d66a29","46b7f140d4134097a8f6c7dd41d9acd3","784f6571b15c4ac19ca2e1b1a913f318","42c591eaee9f42f8ad965372898e3bdd","7a550bf2dc964d0caafc8aed54d187a6","5bf549707f604a99a4743166718cd720","bac9a59f6a1244d8a6e37795e0383e30","a113bb38b1f7458cae5e7825d6a65b3c","cda8adeebae9484c9399422c870aa7cf","b524e9e4f75a45aba71a8a2b68557700","fdbe596b18164389a51d860b24f3b15b","e55c826128994d0a8b67885f40574fae","836f49316d114d37846143df795ba15a","1ad12046944a468297e3c982794251ef","c0d3f59319544daa858e76bf490ac735","f8c3f5363e824e338cf4b7ea0f09b92a","6aaf81405fa24b0e93a858d609b85036","4977730998754c6d82831b47a647b428","9dc189ff36034264b081ca782c0bc1ed","91b7390bb1d94bd6be84496ed73052ee","7e04af96adae41a6b05ecc7bfe5a9fd9","b13c2b7166784d0f8d8a1ee231fe3235","761b0c7bec0f4ea98fff4469f3e147e1","2f225874a7174aae9695b521d33eb563","0e167716cc6941e2aaa5e85a476f1b1a","9ce3da5248a34146945e40a660ed455d","6584fa0193f0433ead447e60d2c82607","47d8987c94434ddb89281035f30e9d4f","cf1bd11c82b44b99ac40e8abbec3785f","7e069a6942cb4cb09ef6aa3661844f88","7e0b008fb7294404a73b8341c1230125","45c9710ebd6e45ddaa72f349380c5e16","9defae4a31724cc1b6c0128b76bae404","3332c9a35d2e40ac860233ebfb8c64c7","e0686b63c9374bcda05c70aeffbcda03","f5553c33eefd47eea49e0e3901bf51f5","fc2843b06e0f4b6ca2a7d1d5fcde23d6","7b70f0bd5409433e93719cd05441e473","83665867accd4853b6efe68a06f7f403","66b76f1f830445e98fb9c1acc1683cde","26f97033c9e5479da8dca6f7dc642ece","6da0a949eaf1499094fa4e264e1929ca","0b946716322e43bb9f4213087c6ee1de","c3cb074231f84c169f31afa3baf84fc9","aee8fac5931844c5a88f651e7f854362","e39705238d474d5a99f0a49832b408ed","45d616297f6d42fc89f2b28c6fc10c90","58bdc5e07c694b4f9fc4e6612c1de4c5","0d0fbbe470054b0b879c1a62c411dc0c","6efb365326c24c339085be28cc203fdc","df4976d8d7ec47e4986f5e9c0395c3a9","e249235d4bb14478a802d3fc362fe215","ea2f3d5138cb4d3eb4b5f50122c42634","0bce7925eb1f4323a482bb90467bbc66","392ee34639024892a83a85f6878b60ef","ba96d1c92aeb4a9584f700869c028ace","c8c4de2dd87b409ab14e3bbd4f8ff777","355092a75fa445ddb58c3c0e6c7c87f7","a77de46019434b2182d8ace90729411d","3f54b0320e054ef4ab7cc33ca97ad75c","13c4cd250f4c49169902a77e3b76727c","9100526f824f4e2298b22f43461c6daa","5e7028e3f8f6469086b2b94066dc9526","6901a356aa2c4361953ba9b44065710b","b215c0274af9444c9265aa576d33f6d5","f46f3a7030a34d3894d97214fb03e1c2","34f2229c854f4695b5aba5d5afe772f5","38344f64512b421aa12ac82fcf4b195d","11e9dc55ddd64166a23b389ef4115bc5","090fd1cdc0694112b57d28e833932350","0c73d54adcb74546b98a15ff898640d2","8cd319e80b28462698e8adb196302802","4016322235e5422687997b6c942b8684","90efeff073a541e3ace582146fd5fd45","4da4cc126514421ebb1cd20eff5544f9","255d439785a54b9b8f37be9730c5b9f9","e3ea567b814a4d949a018e39137923fd","ea9b31c529f0482c99ac5ede1b0c2437","2f08477187154be899c3a1378e703260","183c14e615d6471c9fe4b9a56d13f85a","e15406eedc3b4b10b5d8c32d2ba5f1cd","f82609221b714ae58214a6f6745526b3","6f038781e3a5498a9823999548de18fd","8110d80f4fe94d499834b799c85667ad","e7816626014f47fbb744f707990f3c0b","65617f6c0a3f40f1bb7198eadb9757da","1efc8ad79138462e97c1bf5f00d8a210","4e8321573083413d80d545eb711dabcb","ca2e4e27247949fd96c09ca0084eb8d5","ab3716a57cb1461ca4b89d3e2af60aa1","e7096ed061374902935f3363540caa56","3e583707d8f7457bb3a5433440f3a6cb","200a894d245143b59503f70bbe099655","e68e4e022b7946139920753c55012db2","1d9cc219294748d7a4d06a0ef220d034","61055f305b414a9995dd0093c8dd085b","6793b20c68004ef6806c0719d850ee07","45045e6a12e041e1b2b2713ff59ef938","0f57c3f8ee4d42b3b02aba300b4fe271","bfd5578f1cc3406b9b6e49540918dffd","0fab8e8ae3fd4f47b43ee00df8a80deb","f4388ee32ed9434ea5e756c22fb61002","eac3132f4d9349cfa6f1422686ae7bd5"]},"executionInfo":{"elapsed":5437,"status":"ok","timestamp":1710110400718,"user":{"displayName":"Vashisth Tiwari","userId":"14058204908965748495"},"user_tz":240},"id":"zliNdIDo2vbh","outputId":"7302e1a2-7bee-4b0e-8fcd-074783531201"},"outputs":[{"output_type":"display_data","data":{"text/plain":["modules.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb37e6988db144ac9e6b615b71705c3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["README.md:   0%|          | 0.00/68.1k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a550bf2dc964d0caafc8aed54d187a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8c3f5363e824e338cf4b7ea0f09b92a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/618 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6584fa0193f0433ead447e60d2c82607"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/219M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b70f0bd5409433e93719cd05441e473"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d0fbbe470054b0b879c1a62c411dc0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f54b0320e054ef4ab7cc33ca97ad75c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c73d54adcb74546b98a15ff898640d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f82609221b714ae58214a6f6745526b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"200a894d245143b59503f70bbe099655"}},"metadata":{}}],"source":["EMBEDDING_MODEL_NAME = EMBEDDING_MODEL\n","embedding_model = HuggingFaceEmbeddings(\n","    model_name=EMBEDDING_MODEL_NAME,\n","    multi_process=True,\n","    model_kwargs={\"device\": \"cuda\"},\n","    encode_kwargs={\"normalize_embeddings\": True},\n",")"]},{"cell_type":"code","source":["!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JIaPbE2th0I5","executionInfo":{"status":"ok","timestamp":1710111573183,"user_tz":240,"elapsed":181,"user":{"displayName":"Vashisth Tiwari","userId":"14058204908965748495"}},"outputId":"98ab622e-0a7f-4d29-f1ba-af5c6360d978"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ANLP/NLP-RAG/src-rag\n"]}]},{"cell_type":"code","source":["FAISS_FILE = '../faiss_index_webpages'\n","# num_retrieved_docs: int = 5\n","# num_docs_final: int = 3\n","KNOWLEDGE_VECTOR_DATABASE = FAISS.load_local(FAISS_FILE, embedding_model, allow_dangerous_deserialization = True)"],"metadata":{"id":"0jF7haihucN6"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pHsA8wuz4eE7"},"outputs":[],"source":["model_path = \"TheBloke/Llama-2-7B-Chat-GGUF\"\n","model_basename = \"llama-2-7b-chat.Q4_K_M.gguf\"\n","model_path = hf_hub_download(repo_id=model_path, filename=model_basename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bAY0-o-B2vbh"},"outputs":[],"source":["# # databse imports\n","# from database import split_documents, create_db"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NmW3sJU22vbi"},"outputs":[],"source":["# directory = '../data/webpages/'\n","# loader = DirectoryLoader(directory, glob=\"**/*.txt\")\n","# docs = loader.load()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b6c5BgRZ2vbi"},"outputs":[],"source":["# docs_processed = split_documents(\n","#     chunk_size = 512,\n","#     chunk_overlap = 50,\n","#     knowledge_base = docs,\n","#     tokenizer_name=EMBEDDING_MODEL_NAME,\n","# )\n","# embedding_model = HuggingFaceEmbeddings(\n","#     model_name=EMBEDDING_MODEL_NAME,\n","#     multi_process=True,\n","#     model_kwargs={\"device\": \"cuda\"},\n","#     encode_kwargs={\"normalize_embeddings\": True},  #  True for cosine similarity\n","# )"]},{"cell_type":"markdown","metadata":{"id":"i_27tccjshpp"},"source":["# Reader LLM"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3662,"status":"ok","timestamp":1710110638040,"user":{"displayName":"Vashisth Tiwari","userId":"14058204908965748495"},"user_tz":240},"id":"7H5oLKT72vbi","outputId":"68c9a4ec-8d72-46c7-994a-55322496e435"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! repetition_penalty is not default parameter.\n","                repetition_penalty was transferred to model_kwargs.\n","                Please confirm that repetition_penalty is what you intended.\n","  warnings.warn(\n","llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /root/.cache/huggingface/hub/models--TheBloke--Llama-2-7B-Chat-GGUF/snapshots/191239b3e26b2882fb562ffccdd1cf0f65402adb/llama-2-7b-chat.Q4_K_M.gguf (version GGUF V2)\n","llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n","llama_model_loader: - kv   0:                       general.architecture str              = llama\n","llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n","llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n","llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n","llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n","llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n","llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n","llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n","llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n","llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n","llama_model_loader: - kv  10:                          general.file_type u32              = 15\n","llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n","llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n","llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n","llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n","llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n","llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n","llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n","llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n","llama_model_loader: - type  f32:   65 tensors\n","llama_model_loader: - type q4_K:  193 tensors\n","llama_model_loader: - type q6_K:   33 tensors\n","llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n","llm_load_print_meta: format           = GGUF V2\n","llm_load_print_meta: arch             = llama\n","llm_load_print_meta: vocab type       = SPM\n","llm_load_print_meta: n_vocab          = 32000\n","llm_load_print_meta: n_merges         = 0\n","llm_load_print_meta: n_ctx_train      = 4096\n","llm_load_print_meta: n_embd           = 4096\n","llm_load_print_meta: n_head           = 32\n","llm_load_print_meta: n_head_kv        = 32\n","llm_load_print_meta: n_layer          = 32\n","llm_load_print_meta: n_rot            = 128\n","llm_load_print_meta: n_embd_head_k    = 128\n","llm_load_print_meta: n_embd_head_v    = 128\n","llm_load_print_meta: n_gqa            = 1\n","llm_load_print_meta: n_embd_k_gqa     = 4096\n","llm_load_print_meta: n_embd_v_gqa     = 4096\n","llm_load_print_meta: f_norm_eps       = 0.0e+00\n","llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n","llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n","llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n","llm_load_print_meta: n_ff             = 11008\n","llm_load_print_meta: n_expert         = 0\n","llm_load_print_meta: n_expert_used    = 0\n","llm_load_print_meta: pooling type     = 0\n","llm_load_print_meta: rope type        = 0\n","llm_load_print_meta: rope scaling     = linear\n","llm_load_print_meta: freq_base_train  = 10000.0\n","llm_load_print_meta: freq_scale_train = 1\n","llm_load_print_meta: n_yarn_orig_ctx  = 4096\n","llm_load_print_meta: rope_finetuned   = unknown\n","llm_load_print_meta: ssm_d_conv       = 0\n","llm_load_print_meta: ssm_d_inner      = 0\n","llm_load_print_meta: ssm_d_state      = 0\n","llm_load_print_meta: ssm_dt_rank      = 0\n","llm_load_print_meta: model type       = 7B\n","llm_load_print_meta: model ftype      = Q4_K - Medium\n","llm_load_print_meta: model params     = 6.74 B\n","llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n","llm_load_print_meta: general.name     = LLaMA v2\n","llm_load_print_meta: BOS token        = 1 '<s>'\n","llm_load_print_meta: EOS token        = 2 '</s>'\n","llm_load_print_meta: UNK token        = 0 '<unk>'\n","llm_load_print_meta: LF token         = 13 '<0x0A>'\n","llm_load_tensors: ggml ctx size =    0.22 MiB\n","llm_load_tensors: offloading 32 repeating layers to GPU\n","llm_load_tensors: offloading non-repeating layers to GPU\n","llm_load_tensors: offloaded 33/33 layers to GPU\n","llm_load_tensors:        CPU buffer size =    70.31 MiB\n","llm_load_tensors:      CUDA0 buffer size =  3820.94 MiB\n","..................................................................................................\n","llama_new_context_with_model: n_ctx      = 2400\n","llama_new_context_with_model: freq_base  = 10000.0\n","llama_new_context_with_model: freq_scale = 1\n","llama_kv_cache_init:      CUDA0 KV buffer size =  1200.00 MiB\n","llama_new_context_with_model: KV self size  = 1200.00 MiB, K (f16):  600.00 MiB, V (f16):  600.00 MiB\n","llama_new_context_with_model:  CUDA_Host input buffer size   =     0.22 MiB\n","llama_new_context_with_model:      CUDA0 compute buffer size =     2.92 MiB\n","llama_new_context_with_model:  CUDA_Host compute buffer size =     0.12 MiB\n","llama_new_context_with_model: graph splits (measure): 2\n","AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n","Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n","Using fallback chat format: None\n"]}],"source":["# https://www.reddit.com/r/LocalLLaMA/comments/1343bgz/what_model_parameters_is_everyone_using/\n","# temperature\t0.7\n","# repetition_penalty=\t1.176\n","# top_k\t= 40\n","# top_p= 0.1\n","\n","# Initialize Large Language Model for answer generation\n","llm_answer_gen = LlamaCpp(\n","streaming = True,\n","model_path = model_path,\n","temperature=.2,\n","n_gpu_layers=-1,\n","top_p=.1,\n","top_k\t= 40,\n","repetition_penalty=\t1.176,\n","verbose=True,\n","n_ctx=2400\n",")"]},{"cell_type":"code","source":["# Initialize Large Language Model for answer generation\n","\n","# Known error when you rerun: ValidationError: 1 validation error for LlamaCpp  __root__ Could not load Llama model from path:\n","llm_answer_gen_default = LlamaCpp(\n","streaming = True,\n","model_path = model_path,\n","n_gpu_layers=-1,\n","# temperature=.7,\n","# top_p=.1,\n","# top_k\t= 40,\n","# repetition_penalty=\t1.176,\n","verbose=True,\n","n_ctx=2400\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"383D-ace5lTV","executionInfo":{"status":"ok","timestamp":1710110648755,"user_tz":240,"elapsed":1814,"user":{"displayName":"Vashisth Tiwari","userId":"14058204908965748495"}},"outputId":"880f3d94-e71e-4698-946a-080ef4257ce0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /root/.cache/huggingface/hub/models--TheBloke--Llama-2-7B-Chat-GGUF/snapshots/191239b3e26b2882fb562ffccdd1cf0f65402adb/llama-2-7b-chat.Q4_K_M.gguf (version GGUF V2)\n","llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n","llama_model_loader: - kv   0:                       general.architecture str              = llama\n","llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n","llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n","llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n","llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n","llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n","llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n","llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n","llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n","llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n","llama_model_loader: - kv  10:                          general.file_type u32              = 15\n","llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n","llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n","llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n","llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n","llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n","llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n","llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n","llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n","llama_model_loader: - type  f32:   65 tensors\n","llama_model_loader: - type q4_K:  193 tensors\n","llama_model_loader: - type q6_K:   33 tensors\n","llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n","llm_load_print_meta: format           = GGUF V2\n","llm_load_print_meta: arch             = llama\n","llm_load_print_meta: vocab type       = SPM\n","llm_load_print_meta: n_vocab          = 32000\n","llm_load_print_meta: n_merges         = 0\n","llm_load_print_meta: n_ctx_train      = 4096\n","llm_load_print_meta: n_embd           = 4096\n","llm_load_print_meta: n_head           = 32\n","llm_load_print_meta: n_head_kv        = 32\n","llm_load_print_meta: n_layer          = 32\n","llm_load_print_meta: n_rot            = 128\n","llm_load_print_meta: n_embd_head_k    = 128\n","llm_load_print_meta: n_embd_head_v    = 128\n","llm_load_print_meta: n_gqa            = 1\n","llm_load_print_meta: n_embd_k_gqa     = 4096\n","llm_load_print_meta: n_embd_v_gqa     = 4096\n","llm_load_print_meta: f_norm_eps       = 0.0e+00\n","llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n","llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n","llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n","llm_load_print_meta: n_ff             = 11008\n","llm_load_print_meta: n_expert         = 0\n","llm_load_print_meta: n_expert_used    = 0\n","llm_load_print_meta: pooling type     = 0\n","llm_load_print_meta: rope type        = 0\n","llm_load_print_meta: rope scaling     = linear\n","llm_load_print_meta: freq_base_train  = 10000.0\n","llm_load_print_meta: freq_scale_train = 1\n","llm_load_print_meta: n_yarn_orig_ctx  = 4096\n","llm_load_print_meta: rope_finetuned   = unknown\n","llm_load_print_meta: ssm_d_conv       = 0\n","llm_load_print_meta: ssm_d_inner      = 0\n","llm_load_print_meta: ssm_d_state      = 0\n","llm_load_print_meta: ssm_dt_rank      = 0\n","llm_load_print_meta: model type       = 7B\n","llm_load_print_meta: model ftype      = Q4_K - Medium\n","llm_load_print_meta: model params     = 6.74 B\n","llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n","llm_load_print_meta: general.name     = LLaMA v2\n","llm_load_print_meta: BOS token        = 1 '<s>'\n","llm_load_print_meta: EOS token        = 2 '</s>'\n","llm_load_print_meta: UNK token        = 0 '<unk>'\n","llm_load_print_meta: LF token         = 13 '<0x0A>'\n","llm_load_tensors: ggml ctx size =    0.22 MiB\n","llm_load_tensors: offloading 32 repeating layers to GPU\n","llm_load_tensors: offloading non-repeating layers to GPU\n","llm_load_tensors: offloaded 33/33 layers to GPU\n","llm_load_tensors:        CPU buffer size =    70.31 MiB\n","llm_load_tensors:      CUDA0 buffer size =  3820.94 MiB\n","..................................................................................................\n","llama_new_context_with_model: n_ctx      = 2400\n","llama_new_context_with_model: freq_base  = 10000.0\n","llama_new_context_with_model: freq_scale = 1\n","llama_kv_cache_init:      CUDA0 KV buffer size =  1200.00 MiB\n","llama_new_context_with_model: KV self size  = 1200.00 MiB, K (f16):  600.00 MiB, V (f16):  600.00 MiB\n","llama_new_context_with_model:  CUDA_Host input buffer size   =     0.22 MiB\n","llama_new_context_with_model:      CUDA0 compute buffer size =     2.92 MiB\n","llama_new_context_with_model:  CUDA_Host compute buffer size =     0.12 MiB\n","llama_new_context_with_model: graph splits (measure): 2\n","AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n","Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n","Using fallback chat format: None\n"]}]},{"cell_type":"code","source":["llm_answer_gen_default"],"metadata":{"id":"iP-y-xsbFPH4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710113141559,"user_tz":240,"elapsed":201,"user":{"displayName":"Vashisth Tiwari","userId":"14058204908965748495"}},"outputId":"577fd816-4137-4e32-93de-9af7ad1e8db1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LlamaCpp(client=<llama_cpp.llama.Llama object at 0x7a6a9db840d0>, model_path='/root/.cache/huggingface/hub/models--TheBloke--Llama-2-7B-Chat-GGUF/snapshots/191239b3e26b2882fb562ffccdd1cf0f65402adb/llama-2-7b-chat.Q4_K_M.gguf', n_ctx=2400, n_gpu_layers=-1)"]},"metadata":{},"execution_count":71}]},{"cell_type":"code","source":["llm_answer_gen"],"metadata":{"id":"l8bKX1rXFQBv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710113142107,"user_tz":240,"elapsed":3,"user":{"displayName":"Vashisth Tiwari","userId":"14058204908965748495"}},"outputId":"9d39a40d-28e7-4025-b401-052cc9b2f1c3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LlamaCpp(client=<llama_cpp.llama.Llama object at 0x7a6af3c97c70>, model_path='/root/.cache/huggingface/hub/models--TheBloke--Llama-2-7B-Chat-GGUF/snapshots/191239b3e26b2882fb562ffccdd1cf0f65402adb/llama-2-7b-chat.Q4_K_M.gguf', n_ctx=2400, n_gpu_layers=-1, temperature=0.2, top_p=0.1, model_kwargs={'repetition_penalty': 1.176})"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","source":["# Initialize Large Language Model for answer generation\n","llm_answer_gen_final = LlamaCpp(\n","streaming = True,\n","model_path = model_path,\n","temperature=.2,\n","n_gpu_layers=-1,\n","top_p=.1,\n","top_k\t= 40,\n","repetition_penalty=\t1.176,\n","verbose=False,\n","n_ctx=2400\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":654},"id":"uXmu2X2w6dk_","executionInfo":{"status":"error","timestamp":1710116971995,"user_tz":240,"elapsed":1165,"user":{"displayName":"Vashisth Tiwari","userId":"14058204908965748495"}},"outputId":"3e78e909-115c-49fe-e735-82bb552069c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! repetition_penalty is not default parameter.\n","                repetition_penalty was transferred to model_kwargs.\n","                Please confirm that repetition_penalty is what you intended.\n","  warnings.warn(\n","llama_model_load: error loading model: failed to allocate buffer\n","llama_load_model_from_file: failed to load model\n"]},{"output_type":"error","ename":"ValidationError","evalue":"1 validation error for LlamaCpp\n__root__\n  Could not load Llama model from path: /root/.cache/huggingface/hub/models--TheBloke--Llama-2-7B-Chat-GGUF/snapshots/191239b3e26b2882fb562ffccdd1cf0f65402adb/llama-2-7b-chat.Q4_K_M.gguf. Received error Failed to load model from file: /root/.cache/huggingface/hub/models--TheBloke--Llama-2-7B-Chat-GGUF/snapshots/191239b3e26b2882fb562ffccdd1cf0f65402adb/llama-2-7b-chat.Q4_K_M.gguf (type=value_error)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-82-c5ac54260507>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Initialize Large Language Model for answer generation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m llm_answer_gen_final = LlamaCpp(\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mstreaming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/load/serializable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lc_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/v1/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__pydantic_self__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalidation_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mobject_setattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__pydantic_self__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__dict__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValidationError\u001b[0m: 1 validation error for LlamaCpp\n__root__\n  Could not load Llama model from path: /root/.cache/huggingface/hub/models--TheBloke--Llama-2-7B-Chat-GGUF/snapshots/191239b3e26b2882fb562ffccdd1cf0f65402adb/llama-2-7b-chat.Q4_K_M.gguf. Received error Failed to load model from file: /root/.cache/huggingface/hub/models--TheBloke--Llama-2-7B-Chat-GGUF/snapshots/191239b3e26b2882fb562ffccdd1cf0f65402adb/llama-2-7b-chat.Q4_K_M.gguf (type=value_error)"]}]},{"cell_type":"markdown","metadata":{"id":"TCp6KhE0LXh4"},"source":["# RAG Function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KX1iEQA7KghD"},"outputs":[],"source":["# link: https://python.langchain.com/docs/use_cases/chatbots/retrieval\n","\n","from langchain.chains.combine_documents import create_stuff_documents_chain\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","from langchain_core.messages import HumanMessage\n","\n","def answer_llama(\n","    question: str,\n","    knowledge_index: FAISS,\n","    reranker: RAGPretrainedModel,\n","    num_retrieved_docs: int = 5,\n","    num_docs_final: int = 3,\n","    llm: LlamaCpp = llm_answer_gen,\n","    ): #-> Tuple[str, List[LangchainDocument]]\n","\n","    # https://stackoverflow.com/questions/76551067/how-to-create-a-langchain-doc-from-an-str\n","\n","    print(\"=> Retrieving documents...\")\n","    relevant_docs_acquired = knowledge_index.similarity_search(query=question, k=num_retrieved_docs)\n","    relevant_doc_id = [doc.metadata['source'] for doc in relevant_docs_acquired]\n","\n","    if reranker:\n","        print(\"=> Reranking documents...\")\n","        relevant_docs = [doc.page_content for doc in relevant_docs_acquired]\n","        relevant_docs = reranker.rerank(question, relevant_docs, k=num_docs_final)\n","\n","        relevant_docs = [LangchainDocument(page_content=doc[\"content\"],\n","                                           metadata={'source': relevant_doc_id[ doc['result_index']] } ) for doc in relevant_docs]\n","\n","        relevant_docs_content = [doc.page_content for doc in relevant_docs]\n","        relevant_doc_id = [doc.metadata for doc in relevant_docs]\n","\n","    else:\n","        relevant_docs_content = [doc.page_content for doc in relevant_docs_acquired]\n","        relevant_docs = relevant_docs_acquired\n","\n","    relevant_docs_content = relevant_docs_content[:num_docs_final]\n","    relevant_docs_indexed = relevant_docs[:num_docs_final]\n","\n","    # Build the final prompt\n","    context = \"\\nExtracted documents:\\n\"\n","    context += \"\".join([f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(relevant_docs_content)])\n","\n","    SYSTEM_TEMPLATE = \"\"\"\n","    Answer the user's questions based on the below context. Please keep them to the point and concise, and only give the answer.\n","    If the context doesn't contain any relevant information to the question, don't make something up and just say \"I don't know\":\n","    No need to include starting phrases like 'based on the text, based on the context', etc.\n","    ------------\n","    <context>\n","    {context}\n","    </context>\n","    ------------\n","    Based on the context answer the question given by the user.\n","    \"\"\"\n","    # no output for one of the questions for the answer is\n","\n","    question_answering_prompt = ChatPromptTemplate.from_messages(\n","        [\n","            (\n","                \"system\",\n","                SYSTEM_TEMPLATE,\n","            ),\n","            MessagesPlaceholder(variable_name=\"messages\"),\n","        ]\n","    )\n","\n","    document_chain = create_stuff_documents_chain(llm, question_answering_prompt)\n","\n","    print(\"=> Generating answer...\")\n","\n","    # print(f'context {context}')\n","\n","    answer = document_chain.invoke(\n","        {\n","            \"context\": relevant_docs_indexed,\n","            \"messages\": [\n","                HumanMessage(content=question)\n","            ],\n","        }\n","    )\n","    # print(f'Answer before ({answer})')\n","    if answer is not None:\n","      new_answer = answer.split(': ', 1)\n","      if len(new_answer)>1:\n","        answer = new_answer[1]\n","\n","    print(f\"Question: {question}\")\n","    print(f\"Answer: {new_answer}\")\n","\n","    # doing this for higher recall value\n","    forbidden_list = [\"According to the provided context, \", \"Based on the provided context,\", '\\n']\n","    for phrase in forbidden_list:\n","          answer = answer.replace(phrase, \"\").replace(\"</s>\", \"\").strip()\n","          answer = answer.replace(phrase, \"\\n\").strip()\n","\n","    return answer, relevant_docs_content\n","# relevant_doc_id, relevant_doc_index"]},{"cell_type":"code","source":["# link: https://python.langchain.com/docs/use_cases/chatbots/retrieval\n","\n","from langchain.chains.combine_documents import create_stuff_documents_chain\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","from langchain_core.messages import HumanMessage\n","\n","def answer_llama_new(\n","    question: str,\n","    knowledge_index: FAISS,\n","    reranker: RAGPretrainedModel,\n","    num_retrieved_docs: int = 5,\n","    num_docs_final: int = 3,\n","    llm: LlamaCpp = llm_answer_gen,\n","    ): #-> Tuple[str, List[LangchainDocument]]\n","\n","    # https://stackoverflow.com/questions/76551067/how-to-create-a-langchain-doc-from-an-str\n","\n","    print(\"=> Retrieving documents...\")\n","    relevant_docs_acquired = knowledge_index.similarity_search(query=question, k=num_retrieved_docs)\n","    relevant_doc_id = [doc.metadata['source'] for doc in relevant_docs_acquired]\n","\n","    if reranker:\n","        print(\"=> Reranking documents...\")\n","        relevant_docs = [doc.page_content for doc in relevant_docs_acquired]\n","        relevant_docs = reranker.rerank(question, relevant_docs, k=num_docs_final)\n","\n","        relevant_docs = [LangchainDocument(page_content=doc[\"content\"],\n","                                           metadata={'source': relevant_doc_id[ doc['result_index']] } ) for doc in relevant_docs]\n","\n","        relevant_docs_content = [doc.page_content for doc in relevant_docs]\n","        relevant_doc_id = [doc.metadata for doc in relevant_docs]\n","\n","    else:\n","        relevant_docs_content = [doc.page_content for doc in relevant_docs_acquired]\n","        relevant_docs = relevant_docs_acquired\n","\n","    relevant_docs_content = relevant_docs_content[:num_docs_final]\n","    relevant_docs_indexed = relevant_docs[:num_docs_final]\n","\n","    # Build the final prompt\n","    context = \"\\nExtracted documents:\\n\"\n","    context += \"\".join([f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(relevant_docs_content)])\n","\n","    SYSTEM_TEMPLATE = \"\"\"\n","    Answer the user's questions based on the below context. Please keep them to the point and concise, and only give the answer.\n","    If the context doesn't contain any relevant information to the question, don't make something up and just say \"I don't know\":\n","    No need to include starting phrases like 'based on the text, based on the context', etc.\n","    ------------\n","    <context>\n","    {context}\n","    </context>\n","    ------------\n","    Based on the context answer the question given by the user.\n","    \"\"\"\n","    # no output for one of the questions for the answer is\n","\n","    # question_answering_prompt = ChatPromptTemplate.from_messages(\n","    #     [\n","    #         (\n","    #             \"system\",\n","    #             SYSTEM_TEMPLATE,\n","    #         ),\n","    #         MessagesPlaceholder(variable_name=\"messages\"),\n","    #     ]\n","    # )\n","\n","    # document_chain = create_stuff_documents_chain(llm, question_answering_prompt)\n","\n","    # print(\"=> Generating answer...\")\n","\n","    # # print(f'context {context}')\n","\n","    # answer = document_chain.invoke(\n","    #     {\n","    #         \"context\": relevant_docs_indexed,\n","    #         \"messages\": [\n","    #             HumanMessage(content=question)\n","    #         ],\n","    #     }\n","    # )\n","    # print(f'Answer before ({answer})')\n","\n","    context_and_question = f\"Keep your answers short and concise. If the text has date and time include the date, time both. If there are multiple right answers, include them all, but keep it short overall. \\n Given the below context:\\n{context}\\n\\n Answer the following \\n{question}\\n\"\n","\n","    if answer is not None:\n","      new_answer = answer.split(': ', 1)\n","      if len(new_answer)>1:\n","        answer = new_answer[1]\n","\n","    print(f\"Question: {question}\")\n","    print(f\"Answer: {new_answer}\")\n","\n","    # doing this for higher recall value\n","    forbidden_list = [\"According to the provided context, \", \"Based on the provided context,\", '\\n']\n","    for phrase in forbidden_list:\n","          answer = answer.replace(phrase, \"\").replace(\"</s>\", \"\").strip()\n","          answer = answer.replace(phrase, \"\\n\").strip()\n","\n","    return answer, relevant_docs_content\n","# relevant_doc_id, relevant_doc_index"],"metadata":{"id":"VhwgRYB467Gt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5VaFc5mg2vbk"},"source":["## Evaluation"]},{"cell_type":"code","source":["context = 'Andrew Carnegie, a billionaire, was born in Scotland in 2004'\n","question = 'When was andrew carnegie born?'\n","context_and_question = f\"Keep your answers short and concise. If the text has date and time include the date, time both. If there are multiple right answers, include them all, but keep it short overall. \\n Given the below context:\\n{context}\\n\\n Answer the following \\n{question}\\n\"\n","\n","llm_answer_gen.invoke(context_and_question)"],"metadata":{"id":"qH40Baoa7MNC"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"97CmQOe4shpp"},"outputs":[],"source":["# Function to run over a list of questions and return the answers\n","# user_query = 'What is the safety gear required by all buggy drivers?'\n","\n","def generate_answer(question, return_relevant_docs = False, llm = llm_answer_gen_default):\n","  answer, relevant_docs = answer_llama(question, KNOWLEDGE_VECTOR_DATABASE,\n","                            reranker=RERANKER, llm = llm)\n","  if return_relevant_docs:\n","    return answer, relevant_docs\n","\n","  return answer\n","\n","OUTPUT_FILE_LLAMACCP= '../webpages_llamaccp.txt'\n","\n","# note that this overwrites previously generated answers to the answer file\n","def generate_answers_all(qfile, afile):\n","    questions_file = open(qfile, 'r')\n","    questions = questions_file.readlines()\n","    ans_file = open(afile, \"w+\")\n","    for q in questions:\n","        ans = generate_answer(q)\n","        ans_file.write(ans + '\\n')\n","    questions_file.close()\n","    ans_file.close()"]},{"cell_type":"markdown","source":["# running for all files"],"metadata":{"id":"y1b0fqSYIB93"}},{"cell_type":"code","source":["QUESTIONS_FILE = '../data/test/questions_webpages.txt' # change when we have all the test ones / for the category wise performance analysis"],"metadata":{"id":"drdoGkF3wja4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generate_answers_all(QUESTIONS_FILE, OUTPUT_FILE_LLAMACCP)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XpjioVMO1BXS","executionInfo":{"status":"ok","timestamp":1710116281552,"user_tz":240,"elapsed":1614463,"user":{"displayName":"Vashisth Tiwari","userId":"14058204908965748495"}},"outputId":"7f3cd626-15a9-46ca-8439-e7a7f3e4a4f8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 290.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 11.34it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      13.85 ms /    26 runs   (    0.53 ms per token,  1877.26 tokens per second)\n","llama_print_timings: prompt eval time =   16606.99 ms /  1528 tokens (   10.87 ms per token,    92.01 tokens per second)\n","llama_print_timings:        eval time =     736.14 ms /    25 runs   (   29.45 ms per token,    33.96 tokens per second)\n","llama_print_timings:       total time =   18051.13 ms /  1553 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: Do students in Kiltie have to memorize music?\n","\n","Answer: ['\\nMachine', 'No, the music is changed for every show. You should invest in a good and trusty lyre.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 271.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 13.76it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      73.17 ms /   122 runs   (    0.60 ms per token,  1667.30 tokens per second)\n","llama_print_timings: prompt eval time =     301.83 ms /    23 tokens (   13.12 ms per token,    76.20 tokens per second)\n","llama_print_timings:        eval time =    3553.76 ms /   121 runs   (   29.37 ms per token,    34.05 tokens per second)\n","llama_print_timings:       total time =    4476.34 ms /   144 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: Do I need to email my home address to the Kiltie Band Director if I'm interested in joining?\n","\n","Answer: ['Bot', 'According to the text, you do not need to email your home address to the Kiltie Band Director if you are interested in joining. The text states that you can email the following information to Kiltie Band Director Jeremy Olisar: name, high school, address at Carnegie Mellon (if known), cell number, home number, whether you plan on being in the band or colorguard, and whether you need to borrow an instrument or equipment. However, it does not mention emailing your home address as one of the required pieces of information.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 290.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 11.56it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      17.72 ms /    31 runs   (    0.57 ms per token,  1749.44 tokens per second)\n","llama_print_timings: prompt eval time =    7592.10 ms /   632 tokens (   12.01 ms per token,    83.24 tokens per second)\n","llama_print_timings:        eval time =     927.47 ms /    30 runs   (   30.92 ms per token,    32.35 tokens per second)\n","llama_print_timings:       total time =    8884.20 ms /   662 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: Do I need to audition to join the Kiltie Band?\n","\n","Answer: ['\\nBot', 'According to the context, no, any member of the campus community with music experience is able to join the Kiltie Band!']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 290.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 11.56it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      19.69 ms /    26 runs   (    0.76 ms per token,  1320.74 tokens per second)\n","llama_print_timings: prompt eval time =    6859.39 ms /   568 tokens (   12.08 ms per token,    82.81 tokens per second)\n","llama_print_timings:        eval time =     762.17 ms /    25 runs   (   30.49 ms per token,    32.80 tokens per second)\n","llama_print_timings:       total time =    8039.92 ms /   593 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: Where does the Kiltie Band rehearse?\n","\n","Answer: ['AI Assistant', 'Based on the context, the Kiltie Band rehearses at the CUC Studio Theater.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 290.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 11.57it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      39.04 ms /    70 runs   (    0.56 ms per token,  1793.03 tokens per second)\n","llama_print_timings: prompt eval time =    7994.83 ms /   635 tokens (   12.59 ms per token,    79.43 tokens per second)\n","llama_print_timings:        eval time =    2372.66 ms /    69 runs   (   34.39 ms per token,    29.08 tokens per second)\n","llama_print_timings:       total time =   10864.06 ms /   704 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: When should I get an instrument from the Kiltie Band if I need one?\n","\n","Answer: ['Bot', 'Based on the context, you can get an instrument from the Kiltie Band starting from 4:30 pm before the first rehearsal which is on Monday at 5:30 pm in the CUC Studio Theater. You can also visit their website for more information on how to join and borrow instruments.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 359.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 11.49it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      15.33 ms /    29 runs   (    0.53 ms per token,  1891.22 tokens per second)\n","llama_print_timings: prompt eval time =   23405.67 ms /  1840 tokens (   12.72 ms per token,    78.61 tokens per second)\n","llama_print_timings:        eval time =    1036.10 ms /    28 runs   (   37.00 ms per token,    27.02 tokens per second)\n","llama_print_timings:       total time =   25128.47 ms /  1868 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: When is Andrew Carnegie's birthday?\n","\n","Answer: ['\\nBot', \"I don't know. According to the provided context, Andrew Carnegie's birthday is not mentioned.\"]\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 290.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 11.40it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      16.87 ms /    32 runs   (    0.53 ms per token,  1896.63 tokens per second)\n","llama_print_timings: prompt eval time =   18257.13 ms /  1533 tokens (   11.91 ms per token,    83.97 tokens per second)\n","llama_print_timings:        eval time =     978.30 ms /    31 runs   (   31.56 ms per token,    31.69 tokens per second)\n","llama_print_timings:       total time =   19857.80 ms /  1564 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: What time are rehearsals on Game Days for the Kiltie Band?\n","\n","Answer: ['\\nAnswer', 'Rehearsals for the Kiltie Band on Game Days are from 9:30-11:00 am.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 290.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 11.52it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      65.88 ms /   105 runs   (    0.63 ms per token,  1593.93 tokens per second)\n","llama_print_timings: prompt eval time =     224.56 ms /    16 tokens (   14.03 ms per token,    71.25 tokens per second)\n","llama_print_timings:        eval time =    3120.96 ms /   104 runs   (   30.01 ms per token,    33.32 tokens per second)\n","llama_print_timings:       total time =    3929.82 ms /   120 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: How should Kilties promote the success of the Kiltie Band?\n","\n","Answer: ['\\nAI Assistant', \"Based on the provided context, there is no direct answer to your question as it is not mentioned anywhere in the provided text. However, I can suggest that Kilties can promote the success of the Kiltie Band by attending rehearsals regularly, being punctual, and maintaining a positive attitude towards the band's goals and objectives. Additionally, they can encourage others to join the band by sharing their experiences and promoting the band's achievements.\"]\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 271.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 13.75it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      62.09 ms /    99 runs   (    0.63 ms per token,  1594.59 tokens per second)\n","llama_print_timings: prompt eval time =   18251.94 ms /  1536 tokens (   11.88 ms per token,    84.16 tokens per second)\n","llama_print_timings:        eval time =    3248.51 ms /    99 runs   (   32.81 ms per token,    30.48 tokens per second)\n","llama_print_timings:       total time =   22502.67 ms /  1635 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: What should I email to the band director if I'm interested in joining the Kiltie Band?\n","\n","Answer: ['Bot', 'Based on the context, you should email the following information to Kiltie Band Director Jeremy Olisar:\\nName\\nHigh School\\nAddress at Carnegie Mellon (if known)\\n\\nHome address\\nCell number\\n\\nHome number\\n\\nWhether you plan on being in the band or colorguard\\n\\nIf in the band what instrument(s) you play\\n\\nWhether you need to borrow an instrument or equipment\\n\\n']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 271.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 13.72it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =       8.34 ms /    13 runs   (    0.64 ms per token,  1559.13 tokens per second)\n","llama_print_timings: prompt eval time =   17186.38 ms /  1404 tokens (   12.24 ms per token,    81.69 tokens per second)\n","llama_print_timings:        eval time =     395.49 ms /    12 runs   (   32.96 ms per token,    30.34 tokens per second)\n","llama_print_timings:       total time =   18136.20 ms /  1416 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: What university is the Kiltie Band a part of?\n","\n","Answer: ['\\nMachine Learning Model', 'Carnegie Mellon University']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 283.0 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 14.84it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      39.18 ms /    75 runs   (    0.52 ms per token,  1914.24 tokens per second)\n","llama_print_timings: prompt eval time =   14339.21 ms /  1187 tokens (   12.08 ms per token,    82.78 tokens per second)\n","llama_print_timings:        eval time =    2376.45 ms /    74 runs   (   32.11 ms per token,    31.14 tokens per second)\n","llama_print_timings:       total time =   17336.19 ms /  1261 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: Was the Scottish terrier a familiar figure at CMU before it officially became a mascot?\n","\n","Answer: ['\\nAssistant', \"Yes, according to the context, the Scottish terrier has been a familiar figure around Carnegie Mellon's campus for years before it officially became a mascot in 2007. The students have been suiting up in an unofficial Scottish terrier costume to excite fans at athletic events for decades.\"]\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 309.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 11.77it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      31.06 ms /    60 runs   (    0.52 ms per token,  1931.50 tokens per second)\n","llama_print_timings: prompt eval time =   15694.63 ms /  1319 tokens (   11.90 ms per token,    84.04 tokens per second)\n","llama_print_timings:        eval time =    1857.88 ms /    59 runs   (   31.49 ms per token,    31.76 tokens per second)\n","llama_print_timings:       total time =   18165.59 ms /  1378 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: Is there an official mascot costume of Scotty?\n","\n","Answer: ['\\nAI Assistant', 'Yes, according to the context, in 2007 Carnegie Mellon partnered with a mascot costume company to design an official Scotty costume, which was unveiled at the 2008 Spring Carnival.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 324.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 13.00it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      25.56 ms /    48 runs   (    0.53 ms per token,  1877.86 tokens per second)\n","llama_print_timings: prompt eval time =   15825.43 ms /  1328 tokens (   11.92 ms per token,    83.92 tokens per second)\n","llama_print_timings:        eval time =    1496.02 ms /    47 runs   (   31.83 ms per token,    31.42 tokens per second)\n","llama_print_timings:       total time =   17946.76 ms /  1375 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: Who led the effort to make Carnegie Mellon's mascot the Scottish Terrier?\n","\n","Answer: ['\\n\\nAssistant', \"The Task Force co-chaired by Director of Athletics Susan Bassett and Dean of Student Affairs Jennifer Church led the effort to make Carnegie Mellon's mascot the Scottish Terrier.\"]\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 296.0 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 11.49it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      24.56 ms /    44 runs   (    0.56 ms per token,  1791.60 tokens per second)\n","llama_print_timings: prompt eval time =   18460.04 ms /  1522 tokens (   12.13 ms per token,    82.45 tokens per second)\n","llama_print_timings:        eval time =    1436.45 ms /    43 runs   (   33.41 ms per token,    29.93 tokens per second)\n","llama_print_timings:       total time =   20576.69 ms /  1565 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: Where did Scotty debug as CMU's official mascot?\n","\n","Answer: ['\\nAssistant', \"Based on the text provided in the context, Scotty debuted as CMU's official mascot at the Nov. 10, 2007 home football game.\"]\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 258.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 13.90it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =       4.22 ms /     8 runs   (    0.53 ms per token,  1893.49 tokens per second)\n","llama_print_timings: prompt eval time =   15842.96 ms /  1323 tokens (   11.98 ms per token,    83.51 tokens per second)\n","llama_print_timings:        eval time =     228.32 ms /     7 runs   (   32.62 ms per token,    30.66 tokens per second)\n","llama_print_timings:       total time =   16562.69 ms /  1330 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: Who did CMU partner with to create the Scotty mascot graphics?\n","\n","Answer: ['\\nA. SME Branding']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 283.0 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 14.56it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      11.69 ms /    22 runs   (    0.53 ms per token,  1882.43 tokens per second)\n","llama_print_timings: prompt eval time =     219.50 ms /    15 tokens (   14.63 ms per token,    68.34 tokens per second)\n","llama_print_timings:        eval time =     638.22 ms /    21 runs   (   30.39 ms per token,    32.90 tokens per second)\n","llama_print_timings:       total time =     940.61 ms /    36 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: What month and year was the Mascot Identity Task Force formed?\n","\n","Answer: ['\\nMachine Answer', 'The Mascot Identity Task Force was formed in November 2006.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 299.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 11.55it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      22.92 ms /    35 runs   (    0.65 ms per token,  1527.12 tokens per second)\n","llama_print_timings: prompt eval time =    4459.46 ms /   376 tokens (   11.86 ms per token,    84.32 tokens per second)\n","llama_print_timings:        eval time =     981.39 ms /    34 runs   (   28.86 ms per token,    34.64 tokens per second)\n","llama_print_timings:       total time =    5760.98 ms /   410 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: When did Scotty debut as CMU's official mascot?\n","\n","Answer: ['\\nAssistant', \"Scotty debuted as CMU's official mascot at the Nov. 10, 2007 home football game.\"]\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 287.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 13.60it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =       1.08 ms /     2 runs   (    0.54 ms per token,  1846.72 tokens per second)\n","llama_print_timings: prompt eval time =   15933.42 ms /  1316 tokens (   12.11 ms per token,    82.59 tokens per second)\n","llama_print_timings:        eval time =      38.19 ms /     1 runs   (   38.19 ms per token,    26.19 tokens per second)\n","llama_print_timings:       total time =   16385.20 ms /  1317 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: What characteristics does the Scottish terrier represent?\n","\n","Answer: ['\\n']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 304.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 11.74it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      42.97 ms /    81 runs   (    0.53 ms per token,  1885.26 tokens per second)\n","llama_print_timings: prompt eval time =   12647.64 ms /  1055 tokens (   11.99 ms per token,    83.41 tokens per second)\n","llama_print_timings:        eval time =    2493.80 ms /    80 runs   (   31.17 ms per token,    32.08 tokens per second)\n","llama_print_timings:       total time =   15757.71 ms /  1135 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: Where did the athletic director of CMU graduate from?\n","\n","Answer: ['\\nChatbot', 'Based on the provided context, the athletic director of CMU graduated from Naval ROTC Commissioning Ceremony: 1:30-2:30 p.m. Auditorium, Soldiers & Sailors Memorial Hall & Museum * 4141 Fifth Avenue, Pittsburgh, PA 15213.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 359.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 11.96it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      13.42 ms /    26 runs   (    0.52 ms per token,  1938.13 tokens per second)\n","llama_print_timings: prompt eval time =   22595.27 ms /  1840 tokens (   12.28 ms per token,    81.43 tokens per second)\n","llama_print_timings:        eval time =     846.61 ms /    25 runs   (   33.86 ms per token,    29.53 tokens per second)\n","llama_print_timings:       total time =   24122.23 ms /  1865 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: When was Carnegie Technical Schools founded?\n","\n","Answer: ['\\nBot', 'Carnegie Technical Schools was founded in 1900 by Andrew Carnegie.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 320.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 13.17it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      70.56 ms /   113 runs   (    0.62 ms per token,  1601.45 tokens per second)\n","llama_print_timings: prompt eval time =   11542.24 ms /   951 tokens (   12.14 ms per token,    82.39 tokens per second)\n","llama_print_timings:        eval time =    3492.19 ms /   112 runs   (   31.18 ms per token,    32.07 tokens per second)\n","llama_print_timings:       total time =   16033.67 ms /  1063 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: Was Andrew Carnegie ever the president of CMU?\n","\n","Answer: ['\\n\\n\\nBot', \"I don't know. The context provided does not mention Andrew Carnegie ever being the president of Carnegie Mellon University (CMU). According to the context, Carnegie Technical Schools was founded in 1900 by Andrew Carnegie, and it later became known as the Carnegie Institute of Technology in 1967 before merging with Mellon Institute in 1967 to form what is known today as Carnegie Mellon University.\"]\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 283.0 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 14.73it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      11.31 ms /    22 runs   (    0.51 ms per token,  1944.32 tokens per second)\n","llama_print_timings: prompt eval time =   21374.67 ms /  1757 tokens (   12.17 ms per token,    82.20 tokens per second)\n","llama_print_timings:        eval time =     773.02 ms /    21 runs   (   36.81 ms per token,    27.17 tokens per second)\n","llama_print_timings:       total time =   22817.04 ms /  1778 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: Is the Scotty mascot wearing tartan or plaid around its neck?\n","\n","Answer: ['\\n\\nBot', 'Based on the text, Scotty is wearing tartan around its neck.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 313.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 12.16it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      70.77 ms /   135 runs   (    0.52 ms per token,  1907.64 tokens per second)\n","llama_print_timings: prompt eval time =   19488.45 ms /  1602 tokens (   12.17 ms per token,    82.20 tokens per second)\n","llama_print_timings:        eval time =    4495.57 ms /   134 runs   (   33.55 ms per token,    29.81 tokens per second)\n","llama_print_timings:       total time =   25012.75 ms /  1736 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: What is a Tartan?\n","\n","Answer: ['\\nAssistant', \"A tartan is a twilled woolen fabric with a plaid design, often misrepresented as a fierce warrior from either the Asian tundra or Scottish highlands. It is of Scottish origin and consists of stripes of various colors and widths against a solid ground, denoting a particular family lineage. The school's founder, Andrew Carnegie, was born in Dunfermline, Scotland, in 1835. Carnegie came to the United States in 1848 and founded Carnegie Technical Schools in Pittsburgh in 1900.\"]\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 354.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 12.25it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      23.21 ms /    44 runs   (    0.53 ms per token,  1895.41 tokens per second)\n","llama_print_timings: prompt eval time =   22269.18 ms /  1842 tokens (   12.09 ms per token,    82.72 tokens per second)\n","llama_print_timings:        eval time =    1476.27 ms /    43 runs   (   34.33 ms per token,    29.13 tokens per second)\n","llama_print_timings:       total time =   24543.34 ms /  1885 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: How many graduate and doctoral students were there at CMU in fall 2021?\n","\n","Answer: ['\\n\\nBot', \"I don't know. According to the provided context, there is no information about the number of graduate and doctoral students at CMU in fall 2021.\"]\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 318.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 12.10it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      21.69 ms /    31 runs   (    0.70 ms per token,  1429.23 tokens per second)\n","llama_print_timings: prompt eval time =   20973.57 ms /  1726 tokens (   12.15 ms per token,    82.29 tokens per second)\n","llama_print_timings:        eval time =     968.94 ms /    30 runs   (   32.30 ms per token,    30.96 tokens per second)\n","llama_print_timings:       total time =   22723.80 ms /  1756 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: What sports conference does CMU play in?\n","\n","Answer: ['\\nAI Assistant', 'The CMU Tartans play in the NCAA Division I as part of the University Athletic Association (UAA).']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 335.0 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 11.61it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      17.89 ms /    33 runs   (    0.54 ms per token,  1844.71 tokens per second)\n","llama_print_timings: prompt eval time =   17507.23 ms /  1456 tokens (   12.02 ms per token,    83.17 tokens per second)\n","llama_print_timings:        eval time =    1032.14 ms /    32 runs   (   32.25 ms per token,    31.00 tokens per second)\n","llama_print_timings:       total time =   19119.87 ms /  1488 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: When did CMU's founder move to the United States?\n","\n","Answer: ['\\nBot', \"Based on the provided context, CMU's founder Andrew Carnegie moved to the United States in 1848.\"]\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 311.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 13.04it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      39.95 ms /    69 runs   (    0.58 ms per token,  1727.25 tokens per second)\n","llama_print_timings: prompt eval time =   18427.51 ms /  1536 tokens (   12.00 ms per token,    83.35 tokens per second)\n","llama_print_timings:        eval time =    2297.30 ms /    69 runs   (   33.29 ms per token,    30.04 tokens per second)\n","llama_print_timings:       total time =   21500.61 ms /  1605 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: In buggy, what is the chute?\n","\n","Answer: ['\\nAI Assistant', 'The chute in buggy racing refers to a section of the freeroll portion of the buggy course near the southwestern end of Frew Street at its intersection with Schenley Drive. It is where buggies make a sharp right-hand turn from Schenley Drive onto Frew Street.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 311.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 13.39it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      21.36 ms /    36 runs   (    0.59 ms per token,  1685.63 tokens per second)\n","llama_print_timings: prompt eval time =   18707.23 ms /  1539 tokens (   12.16 ms per token,    82.27 tokens per second)\n","llama_print_timings:        eval time =    1118.96 ms /    35 runs   (   31.97 ms per token,    31.28 tokens per second)\n","llama_print_timings:       total time =   20468.96 ms /  1574 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: What can be a challenging aspect of the buggy course?\n","\n","Answer: ['\\nAI Assistant', 'Based on the provided context, one challenging aspect of the buggy course is the potholes, which can make or break a fast run.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 326.0 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 11.85it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      92.56 ms /   131 runs   (    0.71 ms per token,  1415.31 tokens per second)\n","llama_print_timings: prompt eval time =   19467.85 ms /  1607 tokens (   12.11 ms per token,    82.55 tokens per second)\n","llama_print_timings:        eval time =    4184.63 ms /   130 runs   (   32.19 ms per token,    31.07 tokens per second)\n","llama_print_timings:       total time =   24849.64 ms /  1737 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: What is the purpose of fairings on a buggy?\n","\n","Answer: ['\\nBot Response', 'According to the context, fairings have been a key feature for the Fringe team in recent years, which is celebrating its 50th anniversary of Buggy. The basics of a buggy are straightforward, but teams are often secretive in how they build the machines, in particular the way they brake, steer and what types of wheels are used. Fairings have been a key feature for the Fringe team in recent years, which is celebrating its 50th anniversary of Buggy. The Fringe team has a reputation of being the quietest on the course.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 328.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 12.43it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      29.92 ms /    57 runs   (    0.52 ms per token,  1905.27 tokens per second)\n","llama_print_timings: prompt eval time =   19375.51 ms /  1615 tokens (   12.00 ms per token,    83.35 tokens per second)\n","llama_print_timings:        eval time =    1904.03 ms /    56 runs   (   34.00 ms per token,    29.41 tokens per second)\n","llama_print_timings:       total time =   22021.48 ms /  1671 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: What is the \"froom\"?\n","\n","Answer: ['Assistant', 'Based on the context, it seems that the \"froom\" is a workshop or facility located in the East Campus Garage where members of Fringe, a buggy racing team at Carnegie Mellon University, build and maintain their vehicles.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 349.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 12.26it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      14.59 ms /    28 runs   (    0.52 ms per token,  1919.78 tokens per second)\n","llama_print_timings: prompt eval time =   20557.80 ms /  1690 tokens (   12.16 ms per token,    82.21 tokens per second)\n","llama_print_timings:        eval time =     968.79 ms /    27 runs   (   35.88 ms per token,    27.87 tokens per second)\n","llama_print_timings:       total time =   22176.52 ms /  1717 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: What major did the social chair for Fringe in 2019 study?\n","\n","Answer: ['AI Assistant', 'Based on the provided context, the social chair for Fringe in 2019 studied neuroscience.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 326.0 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 12.34it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      19.05 ms /    37 runs   (    0.51 ms per token,  1942.56 tokens per second)\n","llama_print_timings: prompt eval time =    5798.32 ms /   468 tokens (   12.39 ms per token,    80.71 tokens per second)\n","llama_print_timings:        eval time =    1160.01 ms /    36 runs   (   32.22 ms per token,    31.03 tokens per second)\n","llama_print_timings:       total time =    7260.70 ms /   504 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: What are some Fringe racing buggies that have start with the letter B?\n","\n","Answer: ['Ai', 'Based on the provided context, Fringe racing buggies that start with the letter B are Boson, Blueshift, Bissa and Bumper.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 356.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 12.33it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      19.76 ms /    36 runs   (    0.55 ms per token,  1821.68 tokens per second)\n","llama_print_timings: prompt eval time =   17619.56 ms /  1471 tokens (   11.98 ms per token,    83.49 tokens per second)\n","llama_print_timings:        eval time =    1184.44 ms /    35 runs   (   33.84 ms per token,    29.55 tokens per second)\n","llama_print_timings:       total time =   19434.82 ms /  1506 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: What did the first doctorate graduate from CMU study?\n","\n","Answer: ['\\n\\nAssistant', 'The first doctorate graduate from CMU (Carnegie Mellon University) studied civil engineering in 1919.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 359.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 11.40it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =       9.84 ms /    16 runs   (    0.62 ms per token,  1625.85 tokens per second)\n","llama_print_timings: prompt eval time =   22481.33 ms /  1837 tokens (   12.24 ms per token,    81.71 tokens per second)\n","llama_print_timings:        eval time =     512.75 ms /    15 runs   (   34.18 ms per token,    29.25 tokens per second)\n","llama_print_timings:       total time =   23705.33 ms /  1852 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: When did Andrew Carnegie die?\n","\n","Answer: ['\\nAnswer', 'Andrew Carnegie died in 1919.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 359.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 12.15it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      20.13 ms /    39 runs   (    0.52 ms per token,  1937.50 tokens per second)\n","llama_print_timings: prompt eval time =   20228.02 ms /  1674 tokens (   12.08 ms per token,    82.76 tokens per second)\n","llama_print_timings:        eval time =    1285.13 ms /    38 runs   (   33.82 ms per token,    29.57 tokens per second)\n","llama_print_timings:       total time =   22219.74 ms /  1712 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: When did the Carnegie Tech school for women close to join the one for males?\n","\n","Answer: ['AI Assistant', 'According to the provided context, Carnegie Tech school for women (Margaret Morrison Carnegie College) closed in 1973.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 359.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 11.72it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      51.25 ms /    80 runs   (    0.64 ms per token,  1561.01 tokens per second)\n","llama_print_timings: prompt eval time =   11880.90 ms /   968 tokens (   12.27 ms per token,    81.48 tokens per second)\n","llama_print_timings:        eval time =    2496.73 ms /    79 runs   (   31.60 ms per token,    31.64 tokens per second)\n","llama_print_timings:       total time =   15122.35 ms /  1047 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: When did Carnegie Tech start to become a research institution?\n","\n","Answer: ['AI Assistant', 'According to the context, Carnegie Tech laid the groundwork for a research institution in 1919, recruiting leading scientists, offering sponsored fellowships with government and industry leaders, and pioneering nontraditional interdisciplinary research. Therefore, Carnegie Tech started to become a research institution in 1919.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 359.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 12.13it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      17.65 ms /    34 runs   (    0.52 ms per token,  1926.02 tokens per second)\n","llama_print_timings: prompt eval time =   22695.57 ms /  1846 tokens (   12.29 ms per token,    81.34 tokens per second)\n","llama_print_timings:        eval time =    1201.13 ms /    33 runs   (   36.40 ms per token,    27.47 tokens per second)\n","llama_print_timings:       total time =   24609.96 ms /  1879 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: What is the name of the Carnegie Technical Schools for only women?\n","\n","Answer: ['\\nAI', 'Based on the provided context, the name of the Carnegie Technical Schools for only women is Margaret Morrison Carnegie College.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 320.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 13.21it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      17.39 ms /    30 runs   (    0.58 ms per token,  1725.63 tokens per second)\n","llama_print_timings: prompt eval time =   11722.16 ms /   952 tokens (   12.31 ms per token,    81.21 tokens per second)\n","llama_print_timings:        eval time =     958.95 ms /    30 runs   (   31.96 ms per token,    31.28 tokens per second)\n","llama_print_timings:       total time =   13119.14 ms /   982 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: How much money did Carnegie donate to start CMU?\n","\n","Answer: ['\\nAnswer', 'Carnegie donated $1 million for the creation of Carnegie Technical Schools in 1900.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 359.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 11.75it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      34.54 ms /    60 runs   (    0.58 ms per token,  1737.07 tokens per second)\n","llama_print_timings: prompt eval time =   21124.32 ms /  1739 tokens (   12.15 ms per token,    82.32 tokens per second)\n","llama_print_timings:        eval time =    2109.94 ms /    59 runs   (   35.76 ms per token,    27.96 tokens per second)\n","llama_print_timings:       total time =   24093.45 ms /  1798 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: What was the Carnegie Plan?\n","\n","Answer: ['AI Assistant', \"The Carnegie Plan was a new curriculum introduced by Carnegie Tech in 1938, requiring science and engineering students to take courses in humanities and social sciences to better understand society's needs. (Answer taken from the provided context)\"]\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 359.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 12.11it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      29.98 ms /    58 runs   (    0.52 ms per token,  1934.88 tokens per second)\n","llama_print_timings: prompt eval time =     120.55 ms /     8 tokens (   15.07 ms per token,    66.36 tokens per second)\n","llama_print_timings:        eval time =    1877.86 ms /    58 runs   (   32.38 ms per token,    30.89 tokens per second)\n","llama_print_timings:       total time =    2199.38 ms /    66 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: What was the purpose of the Carnegie Plan?\n","\n","Answer: ['\\nAssistant', 'Based on the provided context, the Carnegie Plan was introduced in 1938 with the aim of requiring science and engineering students at Carnegie Mellon University to take courses in humanities and social sciences to better understand the needs of society.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 340.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 12.33it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      20.32 ms /    37 runs   (    0.55 ms per token,  1821.14 tokens per second)\n","llama_print_timings: prompt eval time =   17835.67 ms /  1486 tokens (   12.00 ms per token,    83.32 tokens per second)\n","llama_print_timings:        eval time =    1243.95 ms /    36 runs   (   34.55 ms per token,    28.94 tokens per second)\n","llama_print_timings:       total time =   19713.91 ms /  1522 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: Who joined CMU's Computer Science Department after it's first crisis?\n","\n","Answer: ['AI', \"Based on the context, Joe Traub joined CMU's Computer Science Department after its first crisis in 1970 and 1971.\"]\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 338.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 13.19it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      17.26 ms /    29 runs   (    0.60 ms per token,  1680.38 tokens per second)\n","llama_print_timings: prompt eval time =   16163.63 ms /  1344 tokens (   12.03 ms per token,    83.15 tokens per second)\n","llama_print_timings:        eval time =     855.46 ms /    28 runs   (   30.55 ms per token,    32.73 tokens per second)\n","llama_print_timings:       total time =   17615.36 ms /  1372 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: How did Allen Newell describe the Andrew Project?\n","\n","Answer: ['AI Assistant', 'According to the provided context, Allen Newell described the Andrew Project as “greening up the campus with computer science.”']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 335.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 12.15it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      16.56 ms /    32 runs   (    0.52 ms per token,  1932.25 tokens per second)\n","llama_print_timings: prompt eval time =   15054.85 ms /  1262 tokens (   11.93 ms per token,    83.83 tokens per second)\n","llama_print_timings:        eval time =     978.33 ms /    31 runs   (   31.56 ms per token,    31.69 tokens per second)\n","llama_print_timings:       total time =   16536.60 ms /  1293 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: What specific date was CMU's SCS announced?\n","\n","Answer: ['AI Assistant', \"Based on the given context, CMU's SCS was announced on Jan. 3, 1989.\"]\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 381.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 10.88it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      39.01 ms /    59 runs   (    0.66 ms per token,  1512.51 tokens per second)\n","llama_print_timings: prompt eval time =   21151.22 ms /  1739 tokens (   12.16 ms per token,    82.22 tokens per second)\n","llama_print_timings:        eval time =    1905.21 ms /    58 runs   (   32.85 ms per token,    30.44 tokens per second)\n","llama_print_timings:       total time =   23939.65 ms /  1797 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: In fall 2013, what percent did the undergraduates and master's degree students make up out of total student enrollment at SCS?\n","\n","Answer: ['\\nBot', \"According to the context, in fall 2013, undergraduates made up approximately 37% of total student enrollment at SCS, while master's degree students made up around 60% of total student enrollment.\"]\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 301.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 12.32it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =       1.08 ms /     2 runs   (    0.54 ms per token,  1857.01 tokens per second)\n","llama_print_timings: prompt eval time =   15864.45 ms /  1328 tokens (   11.95 ms per token,    83.71 tokens per second)\n","llama_print_timings:        eval time =      67.05 ms /     2 runs   (   33.52 ms per token,    29.83 tokens per second)\n","llama_print_timings:       total time =   16372.42 ms /  1330 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: Was the undergraduate SCS program established before the graduate SCS program at CMU?\n","\n","Answer: ['\\n']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 342.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 12.32it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      20.28 ms /    39 runs   (    0.52 ms per token,  1923.36 tokens per second)\n","llama_print_timings: prompt eval time =   18087.72 ms /  1499 tokens (   12.07 ms per token,    82.87 tokens per second)\n","llama_print_timings:        eval time =    1257.58 ms /    38 runs   (   33.09 ms per token,    30.22 tokens per second)\n","llama_print_timings:       total time =   19931.39 ms /  1537 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: What did Raj Reddy research in?\n","\n","Answer: ['AI Assistant', 'Based on the provided context, Raj Reddy researched speech, language, and computer vision in the field of computer science. (Year: 1969)']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 342.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 11.99it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      14.53 ms /    28 runs   (    0.52 ms per token,  1926.52 tokens per second)\n","llama_print_timings: prompt eval time =   17355.38 ms /  1442 tokens (   12.04 ms per token,    83.09 tokens per second)\n","llama_print_timings:        eval time =     902.03 ms /    27 runs   (   33.41 ms per token,    29.93 tokens per second)\n","llama_print_timings:       total time =   18793.59 ms /  1469 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: When did the CMU graduate student who developed Java graduate from the university?\n","\n","Answer: ['\\nAssistant', 'Based on the context, the CMU graduate student who developed Java graduated in 1983.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 312.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 11.42it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      16.24 ms /    31 runs   (    0.52 ms per token,  1908.87 tokens per second)\n","llama_print_timings: prompt eval time =   17564.48 ms /  1466 tokens (   11.98 ms per token,    83.46 tokens per second)\n","llama_print_timings:        eval time =     974.49 ms /    30 runs   (   32.48 ms per token,    30.79 tokens per second)\n","llama_print_timings:       total time =   19137.41 ms /  1496 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: When were emoticons invented?\n","\n","Answer: ['Bot', '😊 Emoticons were created in 1982 by CMU researcher Scott Fahlman.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 342.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 12.33it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      18.58 ms /    31 runs   (    0.60 ms per token,  1668.28 tokens per second)\n","llama_print_timings: prompt eval time =   18914.01 ms /  1573 tokens (   12.02 ms per token,    83.17 tokens per second)\n","llama_print_timings:        eval time =     953.35 ms /    30 runs   (   31.78 ms per token,    31.47 tokens per second)\n","llama_print_timings:       total time =   20589.64 ms /  1603 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: Who developed the first computer to achieve chess grandmaster status?\n","\n","Answer: ['AI Assistant', 'The first computer to achieve chess grandmaster status was developed by CMU researcher Hans Berliner (CS’74).']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 278.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 13.76it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      35.84 ms /    59 runs   (    0.61 ms per token,  1646.16 tokens per second)\n","llama_print_timings: prompt eval time =   15427.24 ms /  1302 tokens (   11.85 ms per token,    84.40 tokens per second)\n","llama_print_timings:        eval time =    1784.67 ms /    58 runs   (   30.77 ms per token,    32.50 tokens per second)\n","llama_print_timings:       total time =   17930.26 ms /  1360 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: When are the diploma ceremonies held?\n","\n","Answer: ['\\nAI', 'Based on the provided context, diploma ceremonies will be held over the course of the weekend (Friday, May 10–Sunday, May 12). Exact times for each diploma ceremony will be provided soon.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 346.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 11.21it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      19.85 ms /    32 runs   (    0.62 ms per token,  1612.42 tokens per second)\n","llama_print_timings: prompt eval time =    6961.98 ms /   574 tokens (   12.13 ms per token,    82.45 tokens per second)\n","llama_print_timings:        eval time =     932.80 ms /    31 runs   (   30.09 ms per token,    33.23 tokens per second)\n","llama_print_timings:       total time =    8232.59 ms /   605 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: What is the last event on the Saturday of commencement weekend?\n","\n","Answer: ['AI', 'Based on the provided context, the last event on Saturday of commencement weekend is \"Diploma Ceremonies Various times\".']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 301.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 11.55it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      20.27 ms /    39 runs   (    0.52 ms per token,  1924.31 tokens per second)\n","llama_print_timings: prompt eval time =   15694.60 ms /  1304 tokens (   12.04 ms per token,    83.09 tokens per second)\n","llama_print_timings:        eval time =    1316.92 ms /    39 runs   (   33.77 ms per token,    29.61 tokens per second)\n","llama_print_timings:       total time =   17547.22 ms /  1343 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: By when must guests be seated for the commencement ceremony?\n","\n","Answer: ['AI', 'Based on the provided context, guests must be seated by 9:15 a.m. for the start of the student procession during the commencement ceremony.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 282.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 13.75it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      28.57 ms /    55 runs   (    0.52 ms per token,  1925.23 tokens per second)\n","llama_print_timings: prompt eval time =   15666.08 ms /  1306 tokens (   12.00 ms per token,    83.36 tokens per second)\n","llama_print_timings:        eval time =    1744.24 ms /    54 runs   (   32.30 ms per token,    30.96 tokens per second)\n","llama_print_timings:       total time =   18005.13 ms /  1360 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: Is there a commencement event specifically for Teaching Assistants?\n","\n","Answer: ['\\nAI Assistant', 'Based on the provided context, there is no specific commencement event for Teaching Assistants. The only event mentioned is the main commencement ceremony, which is open to all graduating students, including those in teaching assistant roles.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 317.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 12.01it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      31.93 ms /    57 runs   (    0.56 ms per token,  1785.21 tokens per second)\n","llama_print_timings: prompt eval time =    8848.66 ms /   728 tokens (   12.15 ms per token,    82.27 tokens per second)\n","llama_print_timings:        eval time =    1722.20 ms /    56 runs   (   30.75 ms per token,    32.52 tokens per second)\n","llama_print_timings:       total time =   11007.11 ms /   784 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: What day and time is the event for first generation graduates during commencement weekend?\n","\n","Answer: ['\\nAI', 'According to the context, the event for first generation graduates during commencement weekend is scheduled for Friday, May 10th from 5-5:30 p.m. The event will take place in Alumni Concert Hall.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 348.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 11.21it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      31.76 ms /    48 runs   (    0.66 ms per token,  1511.53 tokens per second)\n","llama_print_timings: prompt eval time =   19805.26 ms /  1631 tokens (   12.14 ms per token,    82.35 tokens per second)\n","llama_print_timings:        eval time =    1558.36 ms /    47 runs   (   33.16 ms per token,    30.16 tokens per second)\n","llama_print_timings:       total time =   22203.42 ms /  1678 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: What are the full names of the Master's programs that LTI offers?\n","\n","Answer: ['Bot', 'The LTI offers two Master’s programs: Master of Language Technologies (MLT) and Dual-Degree Ph.D. in Language and Information Technologies (Portugal Partnership).']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 363.0 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 10.69it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      25.42 ms /    43 runs   (    0.59 ms per token,  1691.51 tokens per second)\n","llama_print_timings: prompt eval time =   17046.48 ms /  1415 tokens (   12.05 ms per token,    83.01 tokens per second)\n","llama_print_timings:        eval time =    1359.89 ms /    42 runs   (   32.38 ms per token,    30.88 tokens per second)\n","llama_print_timings:       total time =   19021.31 ms /  1457 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: What should MIIS students who are interested in voice-based systems take their 2nd year Spring semester?\n","\n","Answer: ['\\nAI Assistant', 'Based on the provided context, MIIS students who are interested in voice-based systems should take the course “Conversational Interfaces” in their second year spring semester.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 385.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 10.66it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      24.28 ms /    42 runs   (    0.58 ms per token,  1730.18 tokens per second)\n","llama_print_timings: prompt eval time =   21797.21 ms /  1790 tokens (   12.18 ms per token,    82.12 tokens per second)\n","llama_print_timings:        eval time =    1355.49 ms /    41 runs   (   33.06 ms per token,    30.25 tokens per second)\n","llama_print_timings:       total time =   23933.26 ms /  1831 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: If I were a MCDS student and Systems major, when should I take Advanced Databases?\n","\n","Answer: ['\\nAI Assistant', 'I can help you with that! Based on the provided context, Advanced Databases is typically taken in the spring semester of the second year of the MCDS program.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 297.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 11.55it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =     100.91 ms /   188 runs   (    0.54 ms per token,  1863.08 tokens per second)\n","llama_print_timings: prompt eval time =   19191.14 ms /  1603 tokens (   11.97 ms per token,    83.53 tokens per second)\n","llama_print_timings:        eval time =    6264.42 ms /   187 runs   (   33.50 ms per token,    29.85 tokens per second)\n","llama_print_timings:       total time =   26702.63 ms /  1790 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: What classes do I have to take before declaring an LT concentration?\n","\n","Answer: ['\\nAssistant', 'According to the context, you must complete the following courses before declaring an LT concentration: Principles of Imperative Computation (15-122), Principles of Functional Programming (15-150), Differential and Integral Calculus (21-120), Integration and Approximation (21-122), Matrices and Linear Transformations (21-241) or Matrix Theory (21-242), Probability and Computing (15-259) or Probability (21-325) or Probability Theory for Computer Scientists (36-218) or Introduction to Probability Theory (36-225). You must also complete an undergraduate research project for at least 9 units to complete your concentration.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 312.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 12.24it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      19.03 ms /    37 runs   (    0.51 ms per token,  1943.99 tokens per second)\n","llama_print_timings: prompt eval time =   16817.04 ms /  1404 tokens (   11.98 ms per token,    83.49 tokens per second)\n","llama_print_timings:        eval time =    1203.11 ms /    36 runs   (   33.42 ms per token,    29.92 tokens per second)\n","llama_print_timings:       total time =   18611.57 ms /  1440 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: What is the GRE code for Carnegie Mellon?\n","\n","Answer: ['\\nBot', 'Based on the context, the GRE code for Carnegie Mellon is 2074; Department Code is 0402.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 348.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 11.46it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      16.45 ms /    31 runs   (    0.53 ms per token,  1884.15 tokens per second)\n","llama_print_timings: prompt eval time =   15923.08 ms /  1334 tokens (   11.94 ms per token,    83.78 tokens per second)\n","llama_print_timings:        eval time =     964.31 ms /    30 runs   (   32.14 ms per token,    31.11 tokens per second)\n","llama_print_timings:       total time =   17455.71 ms /  1364 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: How long is the typical PhD plan for those in LTI?\n","\n","Answer: ['\\nAI Assistant', 'Based on the provided context, the typical PhD plan for those in LTI lasts for five years (5 years).']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 327.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 11.65it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      45.40 ms /    80 runs   (    0.57 ms per token,  1762.31 tokens per second)\n","llama_print_timings: prompt eval time =   15038.53 ms /  1261 tokens (   11.93 ms per token,    83.85 tokens per second)\n","llama_print_timings:        eval time =    2497.10 ms /    79 runs   (   31.61 ms per token,    31.64 tokens per second)\n","llama_print_timings:       total time =   18271.48 ms /  1340 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: How do I demonstrate Engish proficiency for a F-1 or J-1 visa?\n","\n","Answer: ['\\nBot', 'Based on the provided context, you must submit scores from an English proficiency exam taken within the last two years if you will be studying on an F-1 or J-1 visa and English is not a native language. TOEFL (preferred), IELTS, or Duolingo are accepted as standardized tests for English proficiency evaluation.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 383.0 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 10.90it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      24.59 ms /    47 runs   (    0.52 ms per token,  1911.27 tokens per second)\n","llama_print_timings: prompt eval time =   16931.74 ms /  1415 tokens (   11.97 ms per token,    83.57 tokens per second)\n","llama_print_timings:        eval time =    1512.95 ms /    46 runs   (   32.89 ms per token,    30.40 tokens per second)\n","llama_print_timings:       total time =   19035.89 ms /  1461 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: How do LTI PhD and Master's students typically spend their summer?\n","\n","Answer: ['AI Assistant', \"Based on the provided context, LTI PhD and Master's students typically spend their summer in research with their faculty advisor. During their second year, they spend their summer entirely devoted to research.\"]\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 312.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 11.55it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =       7.72 ms /    15 runs   (    0.51 ms per token,  1943.01 tokens per second)\n","llama_print_timings: prompt eval time =   17853.45 ms /  1479 tokens (   12.07 ms per token,    82.84 tokens per second)\n","llama_print_timings:        eval time =     493.26 ms /    14 runs   (   35.23 ms per token,    28.38 tokens per second)\n","llama_print_timings:       total time =   18848.00 ms /  1493 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: What is David Mortensen's title?\n","\n","Answer: ['\\nAI Assistant', \"David Mortensen's title is professor.\"]\n","=> Retrieving documents...\n","=> Reranking documents...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 26.35it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      97.95 ms /   163 runs   (    0.60 ms per token,  1664.03 tokens per second)\n","llama_print_timings: prompt eval time =   16260.38 ms /  1363 tokens (   11.93 ms per token,    83.82 tokens per second)\n","llama_print_timings:        eval time =    5058.80 ms /   162 runs   (   31.23 ms per token,    32.02 tokens per second)\n","llama_print_timings:       total time =   22601.03 ms /  1525 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: Who works on Text Mining and Analytics within LTI at CMU?\n","\n","Answer: ['\\nAssistant', 'I can provide you with the names of faculty members who work on Text Mining and Analytics within the Language Technologies Institute (LTI) at Carnegie Mellon University (CMU). Based on the provided context, the following are the names of faculty members who work in this area:\\n\\nYonatan Bisk, Ralf Brown, Jamie Callan, Justine Cassell, Fernando Diaz, Scott Fahlman, Daphne Ippolito, Lori Levin, Lei Li, Teruko Mitamura, Louis-Philippe Morency, David Mortensen, Graham Neubig, Eric Nyberg, and Kemal Oflaz.\\n\\nPlease let me know if you need more assistance.']\n","=> Retrieving documents...\n","=> Reranking documents...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 26.22it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      23.16 ms /    44 runs   (    0.53 ms per token,  1899.75 tokens per second)\n","llama_print_timings: prompt eval time =   13568.07 ms /  1149 tokens (   11.81 ms per token,    84.68 tokens per second)\n","llama_print_timings:        eval time =    1327.51 ms /    43 runs   (   30.87 ms per token,    32.39 tokens per second)\n","llama_print_timings:       total time =   15465.63 ms /  1192 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: How can I contact Professor Yiming Yang?\n","\n","Answer: ['\\nBot', \"Professor Yiming Yang's email address is yiming@cs.cmu.edu. His phone number is 412-268-7641.\"]\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 318.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 12.35it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      99.44 ms /   169 runs   (    0.59 ms per token,  1699.57 tokens per second)\n","llama_print_timings: prompt eval time =   23093.12 ms /  1878 tokens (   12.30 ms per token,    81.32 tokens per second)\n","llama_print_timings:        eval time =    5860.07 ms /   168 runs   (   34.88 ms per token,    28.67 tokens per second)\n","llama_print_timings:       total time =   30411.38 ms /  2046 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: Are there events that time conflict with Douse a Dean event at carnival, and if so, what are they?\n","\n","Answer: ['\\nAssistant', \"Yes, there are events that conflict with the Douse a Dean event at Carnival. On Thursday, April 11th, there are several events happening at the same time as Douse a Dean, including Buggy Races and Donut Tent, Scotch'n'Soda Performance of The Little Mermaid, and Carnival Activities Tent. On Friday and Saturday, April 12th and 13th, there are multiple events happening at the same time as Douse a Dean, including Booth! , Carnival Rides , Dog Houses Display , Meet & Greet with the Beep-Boop , Veteran Boopers , Carnival Activities Tent, and Carnival Wellness Tent .\"]\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 302.0 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 11.57it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      18.67 ms /    36 runs   (    0.52 ms per token,  1928.12 tokens per second)\n","llama_print_timings: prompt eval time =   20701.06 ms /  1718 tokens (   12.05 ms per token,    82.99 tokens per second)\n","llama_print_timings:        eval time =    1217.71 ms /    35 runs   (   34.79 ms per token,    28.74 tokens per second)\n","llama_print_timings:       total time =   22618.88 ms /  1753 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: What does the KidZone Tent at Carnival encompass?\n","\n","Answer: ['Machine', 'The KidZone Tent at Carnival encompasses games and activities specifically geared toward the younger CMU community members ages 8 and under.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 356.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 11.04it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      28.44 ms /    53 runs   (    0.54 ms per token,  1863.31 tokens per second)\n","llama_print_timings: prompt eval time =   22847.98 ms /  1871 tokens (   12.21 ms per token,    81.89 tokens per second)\n","llama_print_timings:        eval time =    1840.30 ms /    52 runs   (   35.39 ms per token,    28.26 tokens per second)\n","llama_print_timings:       total time =   25510.11 ms /  1923 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: How much are tickets for the Little Mermaid show?\n","\n","Answer: ['AI Assistant', 'The cost of tickets for the Little Mermaid show is $5 for students/faculty/staff; $10 for alumni and guests. Tickets will be available online in March and at the door.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 327.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 12.23it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      28.43 ms /    51 runs   (    0.56 ms per token,  1794.07 tokens per second)\n","llama_print_timings: prompt eval time =   20627.40 ms /  1702 tokens (   12.12 ms per token,    82.51 tokens per second)\n","llama_print_timings:        eval time =    1743.32 ms /    50 runs   (   34.87 ms per token,    28.68 tokens per second)\n","llama_print_timings:       total time =   23112.17 ms /  1752 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: What day and time is the Tartans Got Talent event at Carnival?\n","\n","Answer: ['\\nAIDA', 'Based on the context provided, the Tartans Got Talent event is scheduled for 8:30 PM-10:00 PM ET on April 12th during the Spring Carnival.']\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 317.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 12.54it/s]"]},{"output_type":"stream","name":"stdout","text":["=> Generating answer...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     201.21 ms\n","llama_print_timings:      sample time =      45.22 ms /    69 runs   (    0.66 ms per token,  1526.01 tokens per second)\n","llama_print_timings: prompt eval time =   19262.58 ms /  1596 tokens (   12.07 ms per token,    82.85 tokens per second)\n","llama_print_timings:        eval time =    2155.66 ms /    68 runs   (   31.70 ms per token,    31.54 tokens per second)\n","llama_print_timings:       total time =   22323.23 ms /  1664 tokens\n"]},{"output_type":"stream","name":"stdout","text":["Question: What is the Buggy race schedule this year?\n","Answer: ['\\n\\nAssistant', 'Based on the provided context, there is no mention of the Buggy race schedule this year. The article only provides information about the history of Buggy races at Carnegie Mellon University and the safety measures in place for drivers. Therefore, I cannot provide you with the Buggy race schedule this year.']\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1dUqDFQE2vbk","executionInfo":{"status":"error","timestamp":1710116298537,"user_tz":240,"elapsed":832,"user":{"displayName":"Vashisth Tiwari","userId":"14058204908965748495"}},"colab":{"base_uri":"https://localhost:8080/","height":332},"outputId":"5f7ff357-c03c-43e8-f679-fe3a7cbbc848"},"outputs":[{"output_type":"error","ename":"AssertionError","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-81-aee683d49226>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtotal_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTPUT_FILE_LLAMACCP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../data/test/reference_answers_webpages.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/drive/MyDrive/ANLP/NLP-RAG/src-rag/evaluation.py\u001b[0m in \u001b[0;36mtotal_score\u001b[0;34m(predictions_file, ground_truths_file)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mrag_answers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mrag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrag_answers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrag\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mexact_match_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: "]}],"source":["from evaluation import total_score\n","\n","print(total_score(OUTPUT_FILE_LLAMACCP, '../data/test/reference_answers_webpages.txt'))"]},{"cell_type":"code","source":[],"metadata":{"id":"D2T8to5h39kK"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"widgets":{"application/vnd.jupyter.widget-state+json":{"800014039af04d66adc94131a8ab568e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f741891d16434e959971b6331ab7a09e","IPY_MODEL_20619dd814a245cb96eed1ffd6d23793","IPY_MODEL_f91289ae253446ed90b7c9260d85ac2c"],"layout":"IPY_MODEL_3088fb3c8cc74d7c97d9cbacc5b20c03"}},"f741891d16434e959971b6331ab7a09e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_234ab5cd38b14aec8426fcc28dfc4952","placeholder":"​","style":"IPY_MODEL_b8d486c46bbc4a6abdb3b0af3dbc4c04","value":"artifact.metadata: 100%"}},"20619dd814a245cb96eed1ffd6d23793":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_be42d78fa32c44f4ba983327b2f2b0ae","max":1633,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d696cc22200743caaaa0d70de5f29eaf","value":1633}},"f91289ae253446ed90b7c9260d85ac2c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d7b6a6ffb3849ec9828e24f4e193840","placeholder":"​","style":"IPY_MODEL_718e83bf80b74bbb9e28a9a2473ab8db","value":" 1.63k/1.63k [00:00&lt;00:00, 59.6kB/s]"}},"3088fb3c8cc74d7c97d9cbacc5b20c03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"234ab5cd38b14aec8426fcc28dfc4952":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8d486c46bbc4a6abdb3b0af3dbc4c04":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be42d78fa32c44f4ba983327b2f2b0ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d696cc22200743caaaa0d70de5f29eaf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2d7b6a6ffb3849ec9828e24f4e193840":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"718e83bf80b74bbb9e28a9a2473ab8db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9561e20747684a1a878a637d00c946fa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b5cfff7bf253443682d8051953740ad2","IPY_MODEL_d2b20654e6aa49359b678e198cc55a73","IPY_MODEL_5fca46bd83bd4f95ae25eecf342ff20f"],"layout":"IPY_MODEL_63a47d5282db441a8e5732ab3266af33"}},"b5cfff7bf253443682d8051953740ad2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d567a74de4843a4b50292512c7d0ebe","placeholder":"​","style":"IPY_MODEL_e4710695ec874eada402065fe800edd5","value":"config.json: 100%"}},"d2b20654e6aa49359b678e198cc55a73":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b8ebc99d0ed4d9fb6f873f06a638318","max":743,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2750e13775ad4cc5a1ca97abd23a7fa4","value":743}},"5fca46bd83bd4f95ae25eecf342ff20f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc979bda6f3c486e8108945371fee26e","placeholder":"​","style":"IPY_MODEL_5de0a6a267a24518ac2857b47c4d2d4e","value":" 743/743 [00:00&lt;00:00, 31.0kB/s]"}},"63a47d5282db441a8e5732ab3266af33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d567a74de4843a4b50292512c7d0ebe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4710695ec874eada402065fe800edd5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b8ebc99d0ed4d9fb6f873f06a638318":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2750e13775ad4cc5a1ca97abd23a7fa4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fc979bda6f3c486e8108945371fee26e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5de0a6a267a24518ac2857b47c4d2d4e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc6ba90ca08747e1bace0a55d1eeed55":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5e9df76d9eb04c3cacc9caf4edacb913","IPY_MODEL_091d085339a14a0ab5a23a60b24508f6","IPY_MODEL_1191b9f6ca7e491c91a54648d9a95740"],"layout":"IPY_MODEL_b106e671bf2040ff85286339391cacce"}},"5e9df76d9eb04c3cacc9caf4edacb913":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25d444efba4c4f8ea2a15c4a197e83fa","placeholder":"​","style":"IPY_MODEL_fa2721e59a714068a0a5918cd7ec3246","value":"model.safetensors: 100%"}},"091d085339a14a0ab5a23a60b24508f6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8041af99466c478ab32dcb07ff597d41","max":438349816,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ec25bd06a00e4e2cab1b9f62905449ca","value":438349816}},"1191b9f6ca7e491c91a54648d9a95740":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3e5436855af42a5b2f170b44388e4a8","placeholder":"​","style":"IPY_MODEL_195ac8d683264e9999a419b94e60bdc1","value":" 438M/438M [00:02&lt;00:00, 233MB/s]"}},"b106e671bf2040ff85286339391cacce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25d444efba4c4f8ea2a15c4a197e83fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa2721e59a714068a0a5918cd7ec3246":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8041af99466c478ab32dcb07ff597d41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec25bd06a00e4e2cab1b9f62905449ca":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d3e5436855af42a5b2f170b44388e4a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"195ac8d683264e9999a419b94e60bdc1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08e5c13a33c442d69db6a4e5cb1aefd8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_486f19f393194214820b2e4719793822","IPY_MODEL_82baa3fb82e24827b49b6bda22f72d78","IPY_MODEL_a2c29ede70564d5b879b4084453d753f"],"layout":"IPY_MODEL_bb8b2e9c41ea45dfa6fe7dff8a934fa2"}},"486f19f393194214820b2e4719793822":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6257ec67ee0043adab5a9e24a4f709a8","placeholder":"​","style":"IPY_MODEL_df62dad6b54444659f23d7cca3ddaa70","value":"tokenizer_config.json: 100%"}},"82baa3fb82e24827b49b6bda22f72d78":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c938e4d55734c248ffb292415aa5f5b","max":405,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5582c1c8145b4fe786ba967188680aa7","value":405}},"a2c29ede70564d5b879b4084453d753f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5693df9d1cf458e9c7dabfba2331102","placeholder":"​","style":"IPY_MODEL_4c7a193e4d3349dc8c2ff58c7137e77e","value":" 405/405 [00:00&lt;00:00, 24.3kB/s]"}},"bb8b2e9c41ea45dfa6fe7dff8a934fa2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6257ec67ee0043adab5a9e24a4f709a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df62dad6b54444659f23d7cca3ddaa70":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c938e4d55734c248ffb292415aa5f5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5582c1c8145b4fe786ba967188680aa7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b5693df9d1cf458e9c7dabfba2331102":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c7a193e4d3349dc8c2ff58c7137e77e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1225405706548aa86f466345ba78795":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f9124d67aef64019a437baa8eef8e54e","IPY_MODEL_7a6d685007704814a51a027b060ba1b0","IPY_MODEL_c87f3b6818934457af1827e01f4924ba"],"layout":"IPY_MODEL_cfab7d69b2634082805f101090dcbd04"}},"f9124d67aef64019a437baa8eef8e54e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9553bb69e7c5479ebbf73787d3fc8b14","placeholder":"​","style":"IPY_MODEL_0eae622975df4cfaaa2e54cde12fecc2","value":"vocab.txt: 100%"}},"7a6d685007704814a51a027b060ba1b0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b599c45a81df44619d92a3ac8ad41b0f","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c2cf8f815146436e86373dd6f02e94aa","value":231508}},"c87f3b6818934457af1827e01f4924ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b02abbcd98d94732961735247946d2d4","placeholder":"​","style":"IPY_MODEL_666d42ef1a74402fb13ea79db36c1287","value":" 232k/232k [00:00&lt;00:00, 3.33MB/s]"}},"cfab7d69b2634082805f101090dcbd04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9553bb69e7c5479ebbf73787d3fc8b14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0eae622975df4cfaaa2e54cde12fecc2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b599c45a81df44619d92a3ac8ad41b0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2cf8f815146436e86373dd6f02e94aa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b02abbcd98d94732961735247946d2d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"666d42ef1a74402fb13ea79db36c1287":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c28b40c65c1f450988dfb834ccbf1526":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1257cd90321540d8b5530c35b672ac38","IPY_MODEL_365523a881584181973972b7df86c3eb","IPY_MODEL_6023241ffbf740ec871828d6276cccb8"],"layout":"IPY_MODEL_863ed2e3ac1e4670b7850cf4deafc867"}},"1257cd90321540d8b5530c35b672ac38":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_890443b9c63d42b597b1fce37ed2612f","placeholder":"​","style":"IPY_MODEL_e7bc53149d98433785d628cd3783cbdb","value":"tokenizer.json: 100%"}},"365523a881584181973972b7df86c3eb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a1808fea5884186924c50c1d44cdb2b","max":466081,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6cb72ab4081a44fd8462b7d58da7236c","value":466081}},"6023241ffbf740ec871828d6276cccb8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d9d79532e89447e1ae295ea296d33dbf","placeholder":"​","style":"IPY_MODEL_4663ab81441947f7bd1b86a08d82a6b2","value":" 466k/466k [00:00&lt;00:00, 2.32MB/s]"}},"863ed2e3ac1e4670b7850cf4deafc867":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"890443b9c63d42b597b1fce37ed2612f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7bc53149d98433785d628cd3783cbdb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a1808fea5884186924c50c1d44cdb2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6cb72ab4081a44fd8462b7d58da7236c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d9d79532e89447e1ae295ea296d33dbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4663ab81441947f7bd1b86a08d82a6b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b14e572db35545c58c413b5313c230d0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_26f3de4a37ed42c783b8cc8496a8830e","IPY_MODEL_25ea5fce0d51425ca66647c86a69054d","IPY_MODEL_1d5d56be1f3e4e06ad05b7a61c073773"],"layout":"IPY_MODEL_0e6e63ccb1164deab11b438e7059d69f"}},"26f3de4a37ed42c783b8cc8496a8830e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5ff1078ea2d454ba88d92b978bee13f","placeholder":"​","style":"IPY_MODEL_97d0ee251daa487db840ba561a36d4a8","value":"special_tokens_map.json: 100%"}},"25ea5fce0d51425ca66647c86a69054d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_572f1df5c7904ccf939d45356997f7a7","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_abe064fd2d2943cc9658631022e7dfbe","value":112}},"1d5d56be1f3e4e06ad05b7a61c073773":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_37bbe9f296674040a1e4e6f414645aee","placeholder":"​","style":"IPY_MODEL_0567916024824a5cb153ee96ae90bcfd","value":" 112/112 [00:00&lt;00:00, 6.75kB/s]"}},"0e6e63ccb1164deab11b438e7059d69f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5ff1078ea2d454ba88d92b978bee13f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97d0ee251daa487db840ba561a36d4a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"572f1df5c7904ccf939d45356997f7a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abe064fd2d2943cc9658631022e7dfbe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"37bbe9f296674040a1e4e6f414645aee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0567916024824a5cb153ee96ae90bcfd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb37e6988db144ac9e6b615b71705c3d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_58f1227b067740c99856d28d1b3535f0","IPY_MODEL_a68946ee535e4693955f8292b47c5b6c","IPY_MODEL_72f6e2507a5c49338610f22446087687"],"layout":"IPY_MODEL_f7afe5336f9645bbaa3da495dad04c6f"}},"58f1227b067740c99856d28d1b3535f0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4c9a624ca3342adbdda81d0c505d540","placeholder":"​","style":"IPY_MODEL_7b9187f7562945ba813032f73d5fed96","value":"modules.json: 100%"}},"a68946ee535e4693955f8292b47c5b6c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_755d31fc51614b78a6798a1f45d66a29","max":385,"min":0,"orientation":"horizontal","style":"IPY_MODEL_46b7f140d4134097a8f6c7dd41d9acd3","value":385}},"72f6e2507a5c49338610f22446087687":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_784f6571b15c4ac19ca2e1b1a913f318","placeholder":"​","style":"IPY_MODEL_42c591eaee9f42f8ad965372898e3bdd","value":" 385/385 [00:00&lt;00:00, 26.4kB/s]"}},"f7afe5336f9645bbaa3da495dad04c6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4c9a624ca3342adbdda81d0c505d540":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b9187f7562945ba813032f73d5fed96":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"755d31fc51614b78a6798a1f45d66a29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46b7f140d4134097a8f6c7dd41d9acd3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"784f6571b15c4ac19ca2e1b1a913f318":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42c591eaee9f42f8ad965372898e3bdd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a550bf2dc964d0caafc8aed54d187a6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5bf549707f604a99a4743166718cd720","IPY_MODEL_bac9a59f6a1244d8a6e37795e0383e30","IPY_MODEL_a113bb38b1f7458cae5e7825d6a65b3c"],"layout":"IPY_MODEL_cda8adeebae9484c9399422c870aa7cf"}},"5bf549707f604a99a4743166718cd720":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b524e9e4f75a45aba71a8a2b68557700","placeholder":"​","style":"IPY_MODEL_fdbe596b18164389a51d860b24f3b15b","value":"README.md: 100%"}},"bac9a59f6a1244d8a6e37795e0383e30":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e55c826128994d0a8b67885f40574fae","max":68075,"min":0,"orientation":"horizontal","style":"IPY_MODEL_836f49316d114d37846143df795ba15a","value":68075}},"a113bb38b1f7458cae5e7825d6a65b3c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ad12046944a468297e3c982794251ef","placeholder":"​","style":"IPY_MODEL_c0d3f59319544daa858e76bf490ac735","value":" 68.1k/68.1k [00:00&lt;00:00, 4.12MB/s]"}},"cda8adeebae9484c9399422c870aa7cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b524e9e4f75a45aba71a8a2b68557700":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdbe596b18164389a51d860b24f3b15b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e55c826128994d0a8b67885f40574fae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"836f49316d114d37846143df795ba15a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1ad12046944a468297e3c982794251ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0d3f59319544daa858e76bf490ac735":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f8c3f5363e824e338cf4b7ea0f09b92a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6aaf81405fa24b0e93a858d609b85036","IPY_MODEL_4977730998754c6d82831b47a647b428","IPY_MODEL_9dc189ff36034264b081ca782c0bc1ed"],"layout":"IPY_MODEL_91b7390bb1d94bd6be84496ed73052ee"}},"6aaf81405fa24b0e93a858d609b85036":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e04af96adae41a6b05ecc7bfe5a9fd9","placeholder":"​","style":"IPY_MODEL_b13c2b7166784d0f8d8a1ee231fe3235","value":"sentence_bert_config.json: 100%"}},"4977730998754c6d82831b47a647b428":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_761b0c7bec0f4ea98fff4469f3e147e1","max":57,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2f225874a7174aae9695b521d33eb563","value":57}},"9dc189ff36034264b081ca782c0bc1ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e167716cc6941e2aaa5e85a476f1b1a","placeholder":"​","style":"IPY_MODEL_9ce3da5248a34146945e40a660ed455d","value":" 57.0/57.0 [00:00&lt;00:00, 4.50kB/s]"}},"91b7390bb1d94bd6be84496ed73052ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e04af96adae41a6b05ecc7bfe5a9fd9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b13c2b7166784d0f8d8a1ee231fe3235":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"761b0c7bec0f4ea98fff4469f3e147e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f225874a7174aae9695b521d33eb563":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0e167716cc6941e2aaa5e85a476f1b1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ce3da5248a34146945e40a660ed455d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6584fa0193f0433ead447e60d2c82607":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_47d8987c94434ddb89281035f30e9d4f","IPY_MODEL_cf1bd11c82b44b99ac40e8abbec3785f","IPY_MODEL_7e069a6942cb4cb09ef6aa3661844f88"],"layout":"IPY_MODEL_7e0b008fb7294404a73b8341c1230125"}},"47d8987c94434ddb89281035f30e9d4f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45c9710ebd6e45ddaa72f349380c5e16","placeholder":"​","style":"IPY_MODEL_9defae4a31724cc1b6c0128b76bae404","value":"config.json: 100%"}},"cf1bd11c82b44b99ac40e8abbec3785f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3332c9a35d2e40ac860233ebfb8c64c7","max":618,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e0686b63c9374bcda05c70aeffbcda03","value":618}},"7e069a6942cb4cb09ef6aa3661844f88":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5553c33eefd47eea49e0e3901bf51f5","placeholder":"​","style":"IPY_MODEL_fc2843b06e0f4b6ca2a7d1d5fcde23d6","value":" 618/618 [00:00&lt;00:00, 56.6kB/s]"}},"7e0b008fb7294404a73b8341c1230125":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45c9710ebd6e45ddaa72f349380c5e16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9defae4a31724cc1b6c0128b76bae404":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3332c9a35d2e40ac860233ebfb8c64c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0686b63c9374bcda05c70aeffbcda03":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f5553c33eefd47eea49e0e3901bf51f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc2843b06e0f4b6ca2a7d1d5fcde23d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b70f0bd5409433e93719cd05441e473":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_83665867accd4853b6efe68a06f7f403","IPY_MODEL_66b76f1f830445e98fb9c1acc1683cde","IPY_MODEL_26f97033c9e5479da8dca6f7dc642ece"],"layout":"IPY_MODEL_6da0a949eaf1499094fa4e264e1929ca"}},"83665867accd4853b6efe68a06f7f403":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b946716322e43bb9f4213087c6ee1de","placeholder":"​","style":"IPY_MODEL_c3cb074231f84c169f31afa3baf84fc9","value":"model.safetensors: 100%"}},"66b76f1f830445e98fb9c1acc1683cde":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aee8fac5931844c5a88f651e7f854362","max":218990904,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e39705238d474d5a99f0a49832b408ed","value":218990904}},"26f97033c9e5479da8dca6f7dc642ece":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45d616297f6d42fc89f2b28c6fc10c90","placeholder":"​","style":"IPY_MODEL_58bdc5e07c694b4f9fc4e6612c1de4c5","value":" 219M/219M [00:01&lt;00:00, 174MB/s]"}},"6da0a949eaf1499094fa4e264e1929ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b946716322e43bb9f4213087c6ee1de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3cb074231f84c169f31afa3baf84fc9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aee8fac5931844c5a88f651e7f854362":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e39705238d474d5a99f0a49832b408ed":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"45d616297f6d42fc89f2b28c6fc10c90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58bdc5e07c694b4f9fc4e6612c1de4c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d0fbbe470054b0b879c1a62c411dc0c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6efb365326c24c339085be28cc203fdc","IPY_MODEL_df4976d8d7ec47e4986f5e9c0395c3a9","IPY_MODEL_e249235d4bb14478a802d3fc362fe215"],"layout":"IPY_MODEL_ea2f3d5138cb4d3eb4b5f50122c42634"}},"6efb365326c24c339085be28cc203fdc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0bce7925eb1f4323a482bb90467bbc66","placeholder":"​","style":"IPY_MODEL_392ee34639024892a83a85f6878b60ef","value":"tokenizer_config.json: 100%"}},"df4976d8d7ec47e4986f5e9c0395c3a9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba96d1c92aeb4a9584f700869c028ace","max":314,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c8c4de2dd87b409ab14e3bbd4f8ff777","value":314}},"e249235d4bb14478a802d3fc362fe215":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_355092a75fa445ddb58c3c0e6c7c87f7","placeholder":"​","style":"IPY_MODEL_a77de46019434b2182d8ace90729411d","value":" 314/314 [00:00&lt;00:00, 15.5kB/s]"}},"ea2f3d5138cb4d3eb4b5f50122c42634":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bce7925eb1f4323a482bb90467bbc66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"392ee34639024892a83a85f6878b60ef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba96d1c92aeb4a9584f700869c028ace":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8c4de2dd87b409ab14e3bbd4f8ff777":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"355092a75fa445ddb58c3c0e6c7c87f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a77de46019434b2182d8ace90729411d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f54b0320e054ef4ab7cc33ca97ad75c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_13c4cd250f4c49169902a77e3b76727c","IPY_MODEL_9100526f824f4e2298b22f43461c6daa","IPY_MODEL_5e7028e3f8f6469086b2b94066dc9526"],"layout":"IPY_MODEL_6901a356aa2c4361953ba9b44065710b"}},"13c4cd250f4c49169902a77e3b76727c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b215c0274af9444c9265aa576d33f6d5","placeholder":"​","style":"IPY_MODEL_f46f3a7030a34d3894d97214fb03e1c2","value":"vocab.txt: 100%"}},"9100526f824f4e2298b22f43461c6daa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_34f2229c854f4695b5aba5d5afe772f5","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_38344f64512b421aa12ac82fcf4b195d","value":231508}},"5e7028e3f8f6469086b2b94066dc9526":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_11e9dc55ddd64166a23b389ef4115bc5","placeholder":"​","style":"IPY_MODEL_090fd1cdc0694112b57d28e833932350","value":" 232k/232k [00:00&lt;00:00, 1.78MB/s]"}},"6901a356aa2c4361953ba9b44065710b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b215c0274af9444c9265aa576d33f6d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f46f3a7030a34d3894d97214fb03e1c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"34f2229c854f4695b5aba5d5afe772f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38344f64512b421aa12ac82fcf4b195d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"11e9dc55ddd64166a23b389ef4115bc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"090fd1cdc0694112b57d28e833932350":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c73d54adcb74546b98a15ff898640d2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8cd319e80b28462698e8adb196302802","IPY_MODEL_4016322235e5422687997b6c942b8684","IPY_MODEL_90efeff073a541e3ace582146fd5fd45"],"layout":"IPY_MODEL_4da4cc126514421ebb1cd20eff5544f9"}},"8cd319e80b28462698e8adb196302802":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_255d439785a54b9b8f37be9730c5b9f9","placeholder":"​","style":"IPY_MODEL_e3ea567b814a4d949a018e39137923fd","value":"tokenizer.json: 100%"}},"4016322235e5422687997b6c942b8684":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea9b31c529f0482c99ac5ede1b0c2437","max":711661,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2f08477187154be899c3a1378e703260","value":711661}},"90efeff073a541e3ace582146fd5fd45":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_183c14e615d6471c9fe4b9a56d13f85a","placeholder":"​","style":"IPY_MODEL_e15406eedc3b4b10b5d8c32d2ba5f1cd","value":" 712k/712k [00:00&lt;00:00, 3.68MB/s]"}},"4da4cc126514421ebb1cd20eff5544f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"255d439785a54b9b8f37be9730c5b9f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3ea567b814a4d949a018e39137923fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea9b31c529f0482c99ac5ede1b0c2437":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f08477187154be899c3a1378e703260":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"183c14e615d6471c9fe4b9a56d13f85a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e15406eedc3b4b10b5d8c32d2ba5f1cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f82609221b714ae58214a6f6745526b3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6f038781e3a5498a9823999548de18fd","IPY_MODEL_8110d80f4fe94d499834b799c85667ad","IPY_MODEL_e7816626014f47fbb744f707990f3c0b"],"layout":"IPY_MODEL_65617f6c0a3f40f1bb7198eadb9757da"}},"6f038781e3a5498a9823999548de18fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1efc8ad79138462e97c1bf5f00d8a210","placeholder":"​","style":"IPY_MODEL_4e8321573083413d80d545eb711dabcb","value":"special_tokens_map.json: 100%"}},"8110d80f4fe94d499834b799c85667ad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca2e4e27247949fd96c09ca0084eb8d5","max":125,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ab3716a57cb1461ca4b89d3e2af60aa1","value":125}},"e7816626014f47fbb744f707990f3c0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7096ed061374902935f3363540caa56","placeholder":"​","style":"IPY_MODEL_3e583707d8f7457bb3a5433440f3a6cb","value":" 125/125 [00:00&lt;00:00, 7.81kB/s]"}},"65617f6c0a3f40f1bb7198eadb9757da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1efc8ad79138462e97c1bf5f00d8a210":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e8321573083413d80d545eb711dabcb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca2e4e27247949fd96c09ca0084eb8d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab3716a57cb1461ca4b89d3e2af60aa1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e7096ed061374902935f3363540caa56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e583707d8f7457bb3a5433440f3a6cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"200a894d245143b59503f70bbe099655":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e68e4e022b7946139920753c55012db2","IPY_MODEL_1d9cc219294748d7a4d06a0ef220d034","IPY_MODEL_61055f305b414a9995dd0093c8dd085b"],"layout":"IPY_MODEL_6793b20c68004ef6806c0719d850ee07"}},"e68e4e022b7946139920753c55012db2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45045e6a12e041e1b2b2713ff59ef938","placeholder":"​","style":"IPY_MODEL_0f57c3f8ee4d42b3b02aba300b4fe271","value":"1_Pooling/config.json: 100%"}},"1d9cc219294748d7a4d06a0ef220d034":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bfd5578f1cc3406b9b6e49540918dffd","max":190,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0fab8e8ae3fd4f47b43ee00df8a80deb","value":190}},"61055f305b414a9995dd0093c8dd085b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4388ee32ed9434ea5e756c22fb61002","placeholder":"​","style":"IPY_MODEL_eac3132f4d9349cfa6f1422686ae7bd5","value":" 190/190 [00:00&lt;00:00, 11.7kB/s]"}},"6793b20c68004ef6806c0719d850ee07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45045e6a12e041e1b2b2713ff59ef938":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f57c3f8ee4d42b3b02aba300b4fe271":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bfd5578f1cc3406b9b6e49540918dffd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0fab8e8ae3fd4f47b43ee00df8a80deb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f4388ee32ed9434ea5e756c22fb61002":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eac3132f4d9349cfa6f1422686ae7bd5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}