{"cells":[{"cell_type":"markdown","metadata":{"id":"hUCaGdAj9-9F"},"source":["Souce:\n","- https://huggingface.co/learn/cookbook/en/advanced_rag\n","- https://arc.net/l/quote/vntkseji"]},{"cell_type":"markdown","metadata":{"id":"pt_BRiBR2tKE"},"source":["# Assumptions\n","- the faiss_index embeddings are up to date"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"MrXGTQoSsiQv"},"outputs":[],"source":["import os\n","from dotenv import load_dotenv\n","load_dotenv('.env')\n","hf_api = os.getenv('HF_API')\n","HUGGINGFACEHUB_API_TOKEN = hf_api"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: numpy in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (1.26.4)\n"]},{"data":{"text/plain":["'1.26.4'"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["!pip3 install numpy\n","import numpy as np\n","np.__version__"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10559,"status":"ok","timestamp":1709617668179,"user":{"displayName":"Vashisth Tiwari","userId":"14058204908965748495"},"user_tz":300},"id":"AmPefRqf2tKF","outputId":"3b5a2047-bdd6-4229-f014-c6ecc32edf69"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers==4.38.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (4.38.0)\n","Requirement already satisfied: filelock in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from transformers==4.38.0) (3.0.12)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from transformers==4.38.0) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from transformers==4.38.0) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from transformers==4.38.0) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from transformers==4.38.0) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from transformers==4.38.0) (2023.12.25)\n","Requirement already satisfied: requests in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from transformers==4.38.0) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from transformers==4.38.0) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from transformers==4.38.0) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from transformers==4.38.0) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.0) (2023.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.0) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from requests->transformers==4.38.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from requests->transformers==4.38.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from requests->transformers==4.38.0) (2.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from requests->transformers==4.38.0) (2024.2.2)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install transformers==4.38.0"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39064,"status":"ok","timestamp":1709617707240,"user":{"displayName":"Vashisth Tiwari","userId":"14058204908965748495"},"user_tz":300},"id":"m9jP7QzjProY","outputId":"dcd78147-a081-4a6c-d793-a3489d3d01d3"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[31mERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for faiss-gpu\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install -q torch accelerate bitsandbytes langchain sentence-transformers faiss-gpu openpyxl"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40514,"status":"ok","timestamp":1709617747751,"user":{"displayName":"Vashisth Tiwari","userId":"14058204908965748495"},"user_tz":300},"id":"EHEfmoGTRsGh","outputId":"06607aec-1cfe-4660-8703-2506142a9807"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: unstructured in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (0.12.4)\n","Requirement already satisfied: ragatouille in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (0.0.7.post5)\n","Requirement already satisfied: chardet in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (5.2.0)\n","Requirement already satisfied: filetype in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (1.2.0)\n","Requirement already satisfied: python-magic in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (0.4.27)\n","Requirement already satisfied: lxml in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (5.1.0)\n","Requirement already satisfied: nltk in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (3.8.1)\n","Requirement already satisfied: tabulate in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (0.9.0)\n","Requirement already satisfied: requests in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (2.31.0)\n","Requirement already satisfied: beautifulsoup4 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (4.12.2)\n","Requirement already satisfied: emoji in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (2.10.1)\n","Requirement already satisfied: dataclasses-json in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (0.6.4)\n","Requirement already satisfied: python-iso639 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (2024.2.7)\n","Requirement already satisfied: langdetect in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (1.0.9)\n","Requirement already satisfied: numpy in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (1.26.4)\n","Requirement already satisfied: rapidfuzz in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (3.6.1)\n","Requirement already satisfied: backoff in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (2.2.1)\n","Requirement already satisfied: typing-extensions in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (4.9.0)\n","Requirement already satisfied: unstructured-client>=0.15.1 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (0.18.0)\n","Requirement already satisfied: wrapt in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured) (1.16.0)\n","Requirement already satisfied: aiohttp==3.9.1 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from ragatouille) (3.9.1)\n","Requirement already satisfied: colbert-ai==0.2.19 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from ragatouille) (0.2.19)\n","Requirement already satisfied: faiss-cpu<2.0.0,>=1.7.4 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from ragatouille) (1.7.4)\n","Requirement already satisfied: langchain<0.2.0,>=0.1.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from ragatouille) (0.1.9)\n","Requirement already satisfied: langchain_core<0.2.0,>=0.1.4 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from ragatouille) (0.1.26)\n","Requirement already satisfied: llama-index<0.10.0,>=0.9.24 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from ragatouille) (0.9.48)\n","Requirement already satisfied: onnx<2.0.0,>=1.15.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from ragatouille) (1.15.0)\n","Requirement already satisfied: ruff<0.2.0,>=0.1.9 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from ragatouille) (0.1.15)\n","Requirement already satisfied: sentence-transformers<3.0.0,>=2.2.2 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from ragatouille) (2.4.0)\n","Requirement already satisfied: srsly==2.4.8 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from ragatouille) (2.4.8)\n","Requirement already satisfied: torch<3.0.0,>=2.0.1 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from ragatouille) (2.1.2)\n","Requirement already satisfied: transformers<5.0.0,>=4.36.2 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from ragatouille) (4.38.0)\n","Requirement already satisfied: voyager<3.0.0,>=2.0.2 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from ragatouille) (2.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from aiohttp==3.9.1->ragatouille) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from aiohttp==3.9.1->ragatouille) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from aiohttp==3.9.1->ragatouille) (1.9.4)\n","Requirement already satisfied: frozenlist>=1.1.1 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from aiohttp==3.9.1->ragatouille) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from aiohttp==3.9.1->ragatouille) (1.3.1)\n","Requirement already satisfied: bitarray in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from colbert-ai==0.2.19->ragatouille) (2.9.2)\n","Requirement already satisfied: datasets in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from colbert-ai==0.2.19->ragatouille) (2.17.1)\n","Requirement already satisfied: flask in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from colbert-ai==0.2.19->ragatouille) (3.0.2)\n","Requirement already satisfied: git-python in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from colbert-ai==0.2.19->ragatouille) (1.0.3)\n","Requirement already satisfied: python-dotenv in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from colbert-ai==0.2.19->ragatouille) (1.0.1)\n","Requirement already satisfied: ninja in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from colbert-ai==0.2.19->ragatouille) (1.11.1.1)\n","Requirement already satisfied: scipy in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from colbert-ai==0.2.19->ragatouille) (1.12.0)\n","Requirement already satisfied: tqdm in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from colbert-ai==0.2.19->ragatouille) (4.66.1)\n","Requirement already satisfied: ujson in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from colbert-ai==0.2.19->ragatouille) (5.9.0)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from srsly==2.4.8->ragatouille) (2.0.10)\n","Requirement already satisfied: PyYAML>=5.3 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (2.0.27)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (1.33)\n","Requirement already satisfied: langchain-community<0.1,>=0.0.21 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (0.0.24)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (0.1.6)\n","Requirement already satisfied: pydantic<3,>=1 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (2.6.2)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (8.2.3)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from dataclasses-json->unstructured) (3.20.2)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from dataclasses-json->unstructured) (0.9.0)\n","Requirement already satisfied: anyio<5,>=3 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from langchain_core<0.2.0,>=0.1.4->ragatouille) (4.2.0)\n","Requirement already satisfied: packaging<24.0,>=23.2 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from langchain_core<0.2.0,>=0.1.4->ragatouille) (23.2)\n","Requirement already satisfied: deprecated>=1.2.9.3 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (1.2.14)\n","Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (1.0.8)\n","Requirement already satisfied: fsspec>=2023.5.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (2023.10.0)\n","Requirement already satisfied: httpx in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (0.26.0)\n","Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (1.6.0)\n","Requirement already satisfied: networkx>=3.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (3.2.1)\n","Requirement already satisfied: openai>=1.1.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (1.12.0)\n","Requirement already satisfied: pandas in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (2.2.0)\n","Requirement already satisfied: tiktoken>=0.3.3 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (0.6.0)\n","Requirement already satisfied: click in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from nltk->unstructured) (8.1.7)\n","Requirement already satisfied: joblib in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from nltk->unstructured) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from nltk->unstructured) (2023.12.25)\n","Requirement already satisfied: protobuf>=3.20.2 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from onnx<2.0.0,>=1.15.0->ragatouille) (4.25.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from requests->unstructured) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from requests->unstructured) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from requests->unstructured) (2.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from requests->unstructured) (2024.2.2)\n","Requirement already satisfied: scikit-learn in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from sentence-transformers<3.0.0,>=2.2.2->ragatouille) (1.2.2)\n","Requirement already satisfied: huggingface-hub>=0.15.1 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from sentence-transformers<3.0.0,>=2.2.2->ragatouille) (0.20.3)\n","Requirement already satisfied: Pillow in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from sentence-transformers<3.0.0,>=2.2.2->ragatouille) (10.2.0)\n","Requirement already satisfied: filelock in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from torch<3.0.0,>=2.0.1->ragatouille) (3.0.12)\n","Requirement already satisfied: sympy in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from torch<3.0.0,>=2.0.1->ragatouille) (1.12)\n","Requirement already satisfied: jinja2 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from torch<3.0.0,>=2.0.1->ragatouille) (3.1.3)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from transformers<5.0.0,>=4.36.2->ragatouille) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from transformers<5.0.0,>=4.36.2->ragatouille) (0.4.2)\n","Requirement already satisfied: dataclasses-json-speakeasy>=0.5.11 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured) (0.5.11)\n","Requirement already satisfied: jsonpath-python>=1.0.6 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured) (1.0.6)\n","Requirement already satisfied: mypy-extensions>=1.0.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured) (1.0.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured) (2.8.2)\n","Requirement already satisfied: six>=1.16.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured) (1.16.0)\n","Requirement already satisfied: soupsieve>1.2 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from beautifulsoup4->unstructured) (2.5)\n","Requirement already satisfied: sniffio>=1.1 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from anyio<5,>=3->langchain_core<0.2.0,>=0.1.4->ragatouille) (1.3.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain<0.2.0,>=0.1.0->ragatouille) (2.4)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain<0.2.0,>=0.1.0->ragatouille) (3.9.15)\n","Requirement already satisfied: distro<2,>=1.7.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from openai>=1.1.0->llama-index<0.10.0,>=0.9.24->ragatouille) (1.9.0)\n","Requirement already satisfied: httpcore==1.* in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from httpx->llama-index<0.10.0,>=0.9.24->ragatouille) (1.0.3)\n","Requirement already satisfied: h11<0.15,>=0.13 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index<0.10.0,>=0.9.24->ragatouille) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.0->ragatouille) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.3 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.0->ragatouille) (2.16.3)\n","Requirement already satisfied: greenlet!=0.4.17 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index<0.10.0,>=0.9.24->ragatouille) (3.0.3)\n","Requirement already satisfied: pyarrow>=12.0.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from datasets->colbert-ai==0.2.19->ragatouille) (15.0.0)\n","Requirement already satisfied: pyarrow-hotfix in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from datasets->colbert-ai==0.2.19->ragatouille) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from datasets->colbert-ai==0.2.19->ragatouille) (0.3.8)\n","Requirement already satisfied: xxhash in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from datasets->colbert-ai==0.2.19->ragatouille) (3.4.1)\n","Requirement already satisfied: multiprocess in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from datasets->colbert-ai==0.2.19->ragatouille) (0.70.16)\n","Requirement already satisfied: Werkzeug>=3.0.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from flask->colbert-ai==0.2.19->ragatouille) (3.0.1)\n","Requirement already satisfied: itsdangerous>=2.1.2 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from flask->colbert-ai==0.2.19->ragatouille) (2.1.2)\n","Requirement already satisfied: blinker>=1.6.2 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from flask->colbert-ai==0.2.19->ragatouille) (1.7.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from jinja2->torch<3.0.0,>=2.0.1->ragatouille) (2.1.5)\n","Requirement already satisfied: gitpython in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from git-python->colbert-ai==0.2.19->ragatouille) (3.1.41)\n","Requirement already satisfied: pytz>=2020.1 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from pandas->llama-index<0.10.0,>=0.9.24->ragatouille) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.7 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from pandas->llama-index<0.10.0,>=0.9.24->ragatouille) (2024.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from scikit-learn->sentence-transformers<3.0.0,>=2.2.2->ragatouille) (3.2.0)\n","Requirement already satisfied: mpmath>=0.19 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from sympy->torch<3.0.0,>=2.0.1->ragatouille) (1.3.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from gitpython->git-python->colbert-ai==0.2.19->ragatouille) (4.0.11)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython->git-python->colbert-ai==0.2.19->ragatouille) (5.0.1)\n"]}],"source":["!pip install unstructured ragatouille\n","# reranker\n","from ragatouille import RAGPretrainedModel"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"dMOUdS4CaWO3"},"outputs":[],"source":["# fix colab error: https://stackoverflow.com/questions/56081324/why-are-google-colab-shell-commands-not-working\n","import locale\n","def getpreferredencoding(do_setlocale = True):\n","    return \"UTF-8\"\n","locale.getpreferredencoding = getpreferredencoding"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"eoujYMwW9-9J"},"outputs":[],"source":["from tqdm.notebook import tqdm\n","import pandas as pd\n","from typing import Optional, List, Tuple\n","import matplotlib.pyplot as plt\n","pd.set_option(\n","    \"display.max_colwidth\", None\n",")"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"9DLqgmyvsiQw"},"outputs":[],"source":["# Imports\n","import os\n","import pandas as pd\n","\n","# langchain imports\n","from langchain.docstore.document import Document as LangchainDocument\n","from langchain_community.document_loaders import DirectoryLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.vectorstores import FAISS\n","from langchain_community.embeddings import HuggingFaceEmbeddings\n","\n","# hf imports\n","from transformers import pipeline\n","import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","from transformers import T5Tokenizer, T5ForConditionalGeneration\n","\n","# reranking\n","\n","from ragatouille import RAGPretrainedModel\n","from transformers import Pipeline\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dcMNNt55siQx"},"source":["# Specify the models/versions"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"FAnu3j0hsiQx","outputId":"157e427f-6b36-4470-b46f-ed62c44e951d"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Mar 12, 02:55:17] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"]},{"name":"stderr","output_type":"stream","text":["/Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n","  warnings.warn(\n"]}],"source":["# give the paths\n","# QUESTIONS_FILE = 'data/test/questions_webpages.txt'\n","# OUTPUT_FILE = 'system_outputs/webpages.txt'\n","\n","# FAISS_FILE = '../faiss_index_author_papers_natural_language' # it's actually a folder but whatever\n","FAISS_FILE = '../faiss_index_total_final' # it's actually a folder but whatever\n","\n","EMBEDDING_MODEL = \"thenlper/gte-base\" # make sure this matches whatever was used to create the doc embeddings\n","GENERATOR_MODEL = \"google/flan-t5-large\"\n","RERANKER_MODEL = \"colbert-ir/colbertv2.0\"\n","\n","RERANKER = RAGPretrainedModel.from_pretrained(RERANKER_MODEL)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"referenced_widgets":["7d8a9536491b4edbb9b45b1fca65a14a","ea2d43edd2a949e1ba2c9288c77278c8","1264f61a2602416c9707501077cc4ba3","d6a60b7f0f7d42799c8b7a2adfe32b95","3820631823774c52bacb10826096e1f7","50f3e8a8bffa483a996bff8b9fc178e8","af5956998d934d189568b5551262a3cc"]},"id":"M9X3nGPFsiQx","outputId":"866f2588-9d54-41e6-b513-38adee6529e5"},"outputs":[{"name":"stderr","output_type":"stream","text":["You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["# initialize the LLM and its tokenizer, we are using Flan T5 Large for this\n","tokenizer = T5Tokenizer.from_pretrained(GENERATOR_MODEL)\n","model = T5ForConditionalGeneration.from_pretrained(GENERATOR_MODEL)"]},{"cell_type":"markdown","metadata":{"id":"Kr6rN10U9-9J"},"source":["### Load the knowledge base"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"Z14HQGDx2tKI"},"outputs":[],"source":["embedding_model = HuggingFaceEmbeddings(\n","    model_name=EMBEDDING_MODEL,\n","    multi_process=True,\n","    model_kwargs={\"device\": \"cuda\"},\n","    encode_kwargs={\"normalize_embeddings\": True},  #  True for cosine similarity\n","    )"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"z5cSyyk_siQx"},"outputs":[],"source":["KNOWLEDGE_VECTOR_DATABASE = FAISS.load_local(FAISS_FILE, embedding_model)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"JfDXZPNINnvq"},"outputs":[],"source":["# function to get the prediction and scores from the LLM, given a prompt\n","def get_prediction_and_scores(prompt):\n","    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n","    outputs =  model.generate(input_ids, output_scores=True, return_dict_in_generate=True, max_length=100)\n","                            #   skip_special_tokens=True)\n","    generated_sequence = outputs.sequences[0]\n","\n","    # get the probability scores for each generated token\n","    transition_scores = torch.exp(model.compute_transition_scores(\n","        outputs.sequences, outputs.scores, normalize_logits=True\n","        # , skip_special_tokens = True\n","    )[0])\n","    return tokenizer.decode(generated_sequence), generated_sequence, transition_scores"]},{"cell_type":"markdown","metadata":{"id":"RlfHavRT9-9O"},"source":["## Retrieval and Answer Generation"]},{"cell_type":"code","execution_count":69,"metadata":{"id":"BUQZfctcOkbT"},"outputs":[],"source":["def flanT5_without_threshold(\n","    question: str,\n","    knowledge_index: FAISS,\n","    reranker: Optional[RAGPretrainedModel] = None,\n","    num_retrieved_docs: int = 5,\n","    num_docs_final: int = 3\n","    ):\n","\n","    print(\"=> Retrieving documents...\")\n","    # Gather documents with retriever\n","    relevant_docs_acquired = knowledge_index.similarity_search(query=question, k=num_retrieved_docs)\n","    # print(relevant_docs_acquired)\n","    # print(relevant_docs_acquired)\n","    if reranker:\n","        print(\"=> Reranking documents...\")\n","        relevant_docs = [doc.page_content for doc in relevant_docs_acquired]\n","        relevant_docs = reranker.rerank(question, relevant_docs, k=num_docs_final)\n","        # print(relevant_docs)\n","        relevant_docs_content = [doc[\"content\"] for doc in relevant_docs]\n","        relevant_doc_score = [doc[\"score\"] for doc in relevant_docs]\n","\n","    else:\n","        relevant_docs_content = [doc.page_content for doc in relevant_docs_acquired]\n","\n","    relevant_docs_content = relevant_docs_content[:num_docs_final]\n","    # relevant_doc_id = relevant_doc_id[:num_docs_final]\n","    # relevant_doc_index = relevant_doc_index[:num_docs_final]\n","\n","    # Build the final prompt\n","    context = \"\\nExtracted documents:\\n\"\n","    context += \"\".join([f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(relevant_docs_content)])\n","\n","    context_and_question = f\"Keep your answers short and concise. If the text has date and time include the date, time both. If there are multiple right answers, include them all, but keep it short overall. If the question cannot be answered from the context, say 'I don't know'. \\n Given the below context:\\n{context}\\n\\n Answer the following \\n{question}\\n\"\n","\n","    # context_and_question = \"\"\"\n","    # Answer the user's questions based on the below context. Please keep your answers short and concise. Only provide the answer itself.\"\n","    # ------------\n","    # {context}\n","    # ------------\n","    # Question: {question}\n","    # Answer:\n","    # \"\"\"\n","\n","    # Redact an answer\n","    print(\"=> Generating answer...\")\n","    generated_sequence, _, _ = get_prediction_and_scores(context_and_question)\n","    # answer = f\"{question} {generated_sequence}\"\n","\n","    # removing the special tokens and padding\n","    answer = generated_sequence.replace(\"<pad>\", \"\").replace(\"</s>\", \"\").replace(\"\\n\", \"\").strip()\n","\n","    return answer, relevant_docs_content"]},{"cell_type":"code","execution_count":71,"metadata":{"id":"reUcMJqkRi2m"},"outputs":[],"source":["user_query = 'Who is the first of the paper \"Extracting training data from diffusion models\"?'\n","# user_query = 'Was carnegie the best man alive\"?'"]},{"cell_type":"code","execution_count":72,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HX130eMiRjXm","outputId":"d415795c-6396-4ec6-adc6-5aaf236ba253"},"outputs":[{"name":"stdout","output_type":"stream","text":["=> Retrieving documents...\n"]},{"name":"stderr","output_type":"stream","text":["/Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["=> Reranking documents...\n","Your documents are roughly 262.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=> Generating answer...\n"]}],"source":["answer, relevant_docs = flanT5_without_threshold(\n","    user_query, KNOWLEDGE_VECTOR_DATABASE, reranker=RERANKER\n",")"]},{"cell_type":"code","execution_count":73,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KKCo8SEpRj3i","outputId":"f064de33-4077-435f-d77e-2e02c12c12f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["==================================Answer==================================\n","3\n","Aditya Ramesh\n"]}],"source":["print(\"==================================Answer==================================\")\n","print(len(relevant_docs))\n","print(f\"{answer}\")"]},{"cell_type":"code","execution_count":74,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"th4u-kqLRoik","outputId":"fffeab8d-de47-43c5-d2ac-3def6903d71a"},"outputs":[{"name":"stdout","output_type":"stream","text":["==================================Source docs==================================\n","Document ------------------------------------------------------------\n","## TITLE\n","Extracting Training Data from Diffusion Models\n","Milad ran the membership inference experiments on Vikash ran extraction experiments on pretrained Daphne and Florian improved  gure clarity and presentation. Daphne, Borja, and Eric edited the paper and contributed Nicholas organized the project and wrote the initial paper draft.\n","\n","Acknowledgements and Con icts of Interest The authors are grateful to Tom Goldstein, Olivia Wiles, Katherine Lee, Austin Tarango, Ian Wilbur, Jeff Dean, Andreas Terzis, Robin Rombach, and Andreas Blattmann for comments on early drafts of this paper.\n","\n","Nicholas, Milad, Matthew, and Daphne are employed at Google, and Jamie and Borja are employed at DeepMind, companies that both train large machine learning models (including diffusion models) on both public and Eric Wallace is supported by the Apple Scholars in [1] Mart  n Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. Deep learning with differential privacy. [2] Hazrat Ali, Shafaq Murad, and Zubair Shah.\n","\n","Spot the fake lungs: Generating synthetic medical images using neural diffusion models. arXiv preprint arXiv:2211.00902 , 2022. [3] Sanjeev Arora, Andrej Risteski, and Yi Zhang. Do GANs learn the distribution? Some theory and empirics. In International Conference on Learning Representations , 2018. [4] Yogesh Balaji, Hamed Hassani, Rama Chellappa, and Soheil Feizi. Entropic GANs meet V AEs: A statistical approach to compute sample likelihoods in GANs.\n","\n","In International Conference on Machine 16[5] Borja Balle, Giovanni Cherubin, and Jamie Hayes. Reconstructing training data with informed adversaries. In IEEE Symposium on Security and Privacy, [6] Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale GAN training for high  delity natural image synthesis. In International Conference on Learning Representations , 2019. [7] Hannah Brown, Katherine Lee, Fatemehsadat Mireshghallah, Reza Shokri, and Florian Tram `er.\n","Document ------------------------------------------------------------\n","## TITLE\n","Extracting Training Data from Diffusion Models\n","[57] Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea V oss, Alec Radford, Mark Chen, and Ilya Sutskever. Zero-shot text-to-image generation. In International Conference on Machine [58] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj  orn Ommer. Highresolution image synthesis with latent diffusion models. In IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2022.\n","\n","[59] Pouria Rouzrokh, Bardia Khosravi, Shahriar Faghani, Mana Moasse , Sanaz Vahdati, and Bradley J. Erickson. Multitask brain tumor inpainting with diffusion models: A methodological report. arXiv preprint arXiv:2210.12113 , 2022. [60] Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily Denton, Seyed Kamyar Seyed Ghasemipour, Burcu Karagol Ayan, S Sara Mahdavi, Rapha Gontijo Lopes, et al. Photorealistic text-to-image diffusion models with deep language understanding.\n","\n","arXiv preprint arXiv:2205.11487 , 2022. [61] Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. Improved techniques for training GANs. Advances in Neural Information Processing Systems , 2016. [62] Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov. Membership inference attacks against machine learning models. In IEEE Symposium on Security and Privacy , 2017. [63] Abhishek Sinha, Kumar Ayush, Jiaming Song, Burak Uzkent, Hongxia Jin, and Stefano Ermon.\n","Document ------------------------------------------------------------\n","## TITLE\n","Extracting Training Data from Diffusion Models\n","[41] Nikhil Kandpal, Eric Wallace, and Colin Raffel. Deduplicating training data mitigates privacy risks in language models. International Conference on Machine Learning , 2022. [42] MinGuk Kang, Joonghyuk Shin, and Jaesik Park. StudioGAN: A Taxonomy and Benchmark of GANs for Image Synthesis. arXiv preprint arXiv:2206.09479 , 2022. [43] Tero Karras, Miika Aittala, Janne Hellsten, Samuli Laine, Jaakko Lehtinen, and Timo Aila. Training generative adversarial networks with limited data.\n","\n","InAdvances in Neural Information Processing Systems, [44] Tero Karras, Samuli Laine, and Timo Aila. A stylebased generator architecture for generative adversarial networks. In IEEE/CVF conference on computer vision and pattern recognition , 2019. [45] Salome Kazeminia, Christoph Baur, Arjan Kuijper, Bram van Ginneken, Nassir Navab, Shadi Albarqouni, and Anirban Mukhopadhyay. GANs for 18medical image analysis. Arti cial Intelligence in [46] Diederik P Kingma and Max Welling. Autoencoding variational bayes.\n","\n","In International Conference on Learning Representations , 2014. [47] Katherine Lee, Daphne Ippolito, Andrew Nystrom, Chiyuan Zhang, Douglas Eck, Chris CallisonBurch, and Nicholas Carlini. Deduplicating training data makes language models better. In Association for Computational Linguistics , 2022. [48] Andreas Lugmayr, Martin Danelljan, Andres Romero, Fisher Yu, Radu Timofte, and Luc Van Gool. RePaint: Inpainting using denoising diffusion probabilistic models.\n"]}],"source":["print(\"==================================Source docs==================================\")\n","for  doc in (relevant_docs):\n","    print(f\"Document ------------------------------------------------------------\")\n","    print(f'{doc}')"]},{"cell_type":"markdown","metadata":{"id":"xEsiqSCesiQy"},"source":["## Evaluation"]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[],"source":["# specify output csv \n","input_file = 'qa_gold-t5-large.csv'\n","output_file = 'flan-t5-large-output.csv'\n","csv_input_dir = f'csv_qa_gold/{input_file}'\n","csv_output_dir = f'csv_qa_gold/{output_file}'"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[],"source":["def initialize_model_answer_column(df):\n","    if 'ModelAnswer' not in df.columns:\n","        df['ModelAnswer'] = None\n","    return df"]},{"cell_type":"code","execution_count":78,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(191, 3)\n","(191, 3)\n"]}],"source":["import glob\n","import os\n","import pandas as pd\n","\n","directory_csv = 'csv_qa_gold'\n","csv_files = ['csv_qa_gold/test_combined.csv']\n","\n","# read in the csv files in the directory and concatenate\n","df_total = pd.DataFrame()\n","for file in csv_files:\n","    df = pd.read_csv(file)\n","    print(df.shape)\n","    df_total = pd.concat([df_total, df], axis=0)\n","print(df_total.shape)\n","df_total = initialize_model_answer_column(df_total)\n","df_total.to_csv(csv_input_dir, index=False) \n","# doing this so the original is untouched"]},{"cell_type":"code","execution_count":79,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Category</th>\n","      <th>Question</th>\n","      <th>Answer</th>\n","      <th>ModelAnswer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>10</th>\n","      <td>webpages</td>\n","      <td>Was the Scottish terrier a familiar figure at CMU before it officially became a mascot?</td>\n","      <td>Yes</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>webpages</td>\n","      <td>Is there an official mascot costume of Scotty?</td>\n","      <td>Yes</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>webpages</td>\n","      <td>Who led the effort to make Carnegie Mellon's mascot the Scottish Terrier?</td>\n","      <td>Susan Bassett and Jennifer Church</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>webpages</td>\n","      <td>Where did Scotty debug as CMU's official mascot?</td>\n","      <td>at a football game</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>webpages</td>\n","      <td>Who did CMU partner with to create the Scotty mascot graphics?</td>\n","      <td>SME Branding</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>webpages</td>\n","      <td>What month and year was the Mascot Identity Task Force formed?</td>\n","      <td>November 2006</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>webpages</td>\n","      <td>When did Scotty debut as CMU's official mascot?</td>\n","      <td>November 2007</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>webpages</td>\n","      <td>What characteristics does the Scottish terrier represent?</td>\n","      <td>determined, thoughtful, strength, power, agility in a small package</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>webpages</td>\n","      <td>Where did the athletic director of CMU graduate from?</td>\n","      <td>Brandeis</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>webpages</td>\n","      <td>When was Carnegie Technical Schools founded?</td>\n","      <td>1900</td>\n","      <td>None</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    Category  \\\n","10  webpages   \n","11  webpages   \n","12  webpages   \n","13  webpages   \n","14  webpages   \n","15  webpages   \n","16  webpages   \n","17  webpages   \n","18  webpages   \n","19  webpages   \n","\n","                                                                                   Question  \\\n","10  Was the Scottish terrier a familiar figure at CMU before it officially became a mascot?   \n","11                                           Is there an official mascot costume of Scotty?   \n","12                Who led the effort to make Carnegie Mellon's mascot the Scottish Terrier?   \n","13                                         Where did Scotty debug as CMU's official mascot?   \n","14                           Who did CMU partner with to create the Scotty mascot graphics?   \n","15                           What month and year was the Mascot Identity Task Force formed?   \n","16                                          When did Scotty debut as CMU's official mascot?   \n","17                                What characteristics does the Scottish terrier represent?   \n","18                                    Where did the athletic director of CMU graduate from?   \n","19                                             When was Carnegie Technical Schools founded?   \n","\n","                                                                 Answer  \\\n","10                                                                  Yes   \n","11                                                                  Yes   \n","12                                    Susan Bassett and Jennifer Church   \n","13                                                   at a football game   \n","14                                                         SME Branding   \n","15                                                        November 2006   \n","16                                                        November 2007   \n","17  determined, thoughtful, strength, power, agility in a small package   \n","18                                                             Brandeis   \n","19                                                                 1900   \n","\n","   ModelAnswer  \n","10        None  \n","11        None  \n","12        None  \n","13        None  \n","14        None  \n","15        None  \n","16        None  \n","17        None  \n","18        None  \n","19        None  "]},"execution_count":79,"metadata":{},"output_type":"execute_result"}],"source":["df_total.iloc[10:20, :] # please check that excel does not fuck up for row 15,16 the November 2006 to Nov-06 or some other format"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"aS3tl8emsiQy"},"outputs":[],"source":["def generate_answer(question):\n","    answer, _ = flanT5_without_threshold(\n","        question, KNOWLEDGE_VECTOR_DATABASE, reranker=RERANKER\n","    )\n","    return answer"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[],"source":["# Define the function to process the CSV and add model answers\n","def generate_answers_and_save(csv_path):\n","    df = pd.read_csv(csv_path)\n","    if 'ModelAnswer' not in df.columns:\n","        df['ModelAnswer'] = ''\n","    for index, row in df.iterrows():\n","        ModelAnswer = generate_answer(row['Question'])\n","        df.at[index, 'ModelAnswer'] = ModelAnswer\n","        df.to_csv(csv_output_dir, index=False)\n","    return df"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["=> Retrieving documents...\n"]},{"name":"stderr","output_type":"stream","text":["/Users/vashisth/anaconda3/envs/llama_hw/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["=> Reranking documents...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  2.78it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=> Generating answer...\n","=> Retrieving documents...\n"]},{"name":"stderr","output_type":"stream","text":["/var/folders/29/2n699yc91qs65qqg0cqgqtlr0000gp/T/ipykernel_34021/3543335436.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'No' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n","  df.at[index, 'ModelAnswer'] = ModelAnswer\n"]},{"name":"stdout","output_type":"stream","text":["=> Reranking documents...\n","Your documents are roughly 236.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  2.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=> Generating answer...\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 236.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  2.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=> Generating answer...\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 290.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=> Generating answer...\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 236.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  2.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=> Generating answer...\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 327.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=> Generating answer...\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 271.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=> Generating answer...\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 271.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=> Generating answer...\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 236.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  2.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=> Generating answer...\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 271.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=> Generating answer...\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 283.0 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=> Generating answer...\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 309.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  1.17it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=> Generating answer...\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 324.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  1.23it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=> Generating answer...\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 296.0 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=> Generating answer...\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 258.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=> Generating answer...\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 283.0 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=> Generating answer...\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 299.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=> Generating answer...\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 312.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=> Generating answer...\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 294.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=> Generating answer...\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 359.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=> Generating answer...\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 320.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=> Generating answer...\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 283.0 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=> Generating answer...\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 313.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=> Generating answer...\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 289.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=> Generating answer...\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 301.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=> Generating answer...\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 313.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=> Generating answer...\n","=> Retrieving documents...\n","=> Reranking documents...\n","Your documents are roughly 307.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n"," Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=> Generating answer...\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_with_model_answers \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_answers_and_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcsv_input_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_with_model_answers\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      3\u001b[0m df_with_model_answers\u001b[38;5;241m.\u001b[39mhead()\n","Cell \u001b[0;32mIn[53], line 7\u001b[0m, in \u001b[0;36mgenerate_answers_and_save\u001b[0;34m(csv_path)\u001b[0m\n\u001b[1;32m      5\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModelAnswer\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m----> 7\u001b[0m     ModelAnswer \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQuestion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     df\u001b[38;5;241m.\u001b[39mat[index, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModelAnswer\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ModelAnswer\n\u001b[1;32m      9\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_csv(csv_output_dir, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","Cell \u001b[0;32mIn[49], line 2\u001b[0m, in \u001b[0;36mgenerate_answer\u001b[0;34m(question)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_answer\u001b[39m(question):\n\u001b[0;32m----> 2\u001b[0m     answer, _ \u001b[38;5;241m=\u001b[39m \u001b[43mflanT5_without_threshold\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKNOWLEDGE_VECTOR_DATABASE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreranker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRERANKER\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m answer\n","Cell \u001b[0;32mIn[19], line 46\u001b[0m, in \u001b[0;36mflanT5_without_threshold\u001b[0;34m(question, knowledge_index, reranker, num_retrieved_docs, num_docs_final)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# context_and_question = \"\"\"\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Answer the user's questions based on the below context. Please keep your answers short and concise. Only provide the answer itself.\"\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# ------------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m \n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Redact an answer\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=> Generating answer...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m generated_sequence, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mget_prediction_and_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext_and_question\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# answer = f\"{question} {generated_sequence}\"\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# removing the special tokens and padding\u001b[39;00m\n\u001b[1;32m     50\u001b[0m answer \u001b[38;5;241m=\u001b[39m generated_sequence\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<pad>\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</s>\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n","Cell \u001b[0;32mIn[18], line 4\u001b[0m, in \u001b[0;36mget_prediction_and_scores\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_prediction_and_scores\u001b[39m(prompt):\n\u001b[1;32m      3\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m tokenizer(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39minput_ids\n\u001b[0;32m----> 4\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m  \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m                             \u001b[38;5;66;03m#   skip_special_tokens=True)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     generated_sequence \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39msequences[\u001b[38;5;241m0\u001b[39m]\n","File \u001b[0;32m~/anaconda3/envs/llama_hw/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/llama_hw/lib/python3.11/site-packages/transformers/generation/utils.py:1544\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massisted_decoding(\n\u001b[1;32m   1527\u001b[0m         input_ids,\n\u001b[1;32m   1528\u001b[0m         candidate_generator\u001b[38;5;241m=\u001b[39mcandidate_generator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1541\u001b[0m     )\n\u001b[1;32m   1542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1543\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1544\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgreedy_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1545\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1549\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1550\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n","File \u001b[0;32m~/anaconda3/envs/llama_hw/lib/python3.11/site-packages/transformers/generation/utils.py:2404\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2401\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2403\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2404\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2405\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2407\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2408\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2409\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2411\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2412\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/llama_hw/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/llama_hw/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/llama_hw/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:1748\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1745\u001b[0m         decoder_attention_mask \u001b[38;5;241m=\u001b[39m decoder_attention_mask\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mfirst_device)\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[0;32m-> 1748\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1749\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1756\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1757\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1759\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1760\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1761\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m decoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/llama_hw/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/llama_hw/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/llama_hw/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:1115\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1100\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1101\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39mforward,\n\u001b[1;32m   1102\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1112\u001b[0m         output_attentions,\n\u001b[1;32m   1113\u001b[0m     )\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1115\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n","File \u001b[0;32m~/anaconda3/envs/llama_hw/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/llama_hw/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/llama_hw/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:725\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    723\u001b[0m     query_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 725\u001b[0m cross_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    738\u001b[0m \u001b[38;5;66;03m# clamp inf values to enable fp16 training\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/llama_hw/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/llama_hw/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/llama_hw/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:636\u001b[0m, in \u001b[0;36mT5LayerCrossAttention.forward\u001b[0;34m(self, hidden_states, key_value_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, query_length, output_attentions)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    625\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    633\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    634\u001b[0m ):\n\u001b[1;32m    635\u001b[0m     normed_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 636\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEncDecAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormed_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_value_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_output[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    648\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m attention_output[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/llama_hw/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/llama_hw/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/llama_hw/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:532\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    527\u001b[0m value_states \u001b[38;5;241m=\u001b[39m project(\n\u001b[1;32m    528\u001b[0m     hidden_states, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv, key_value_states, past_key_value[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    529\u001b[0m )\n\u001b[1;32m    531\u001b[0m \u001b[38;5;66;03m# compute scores\u001b[39;00m\n\u001b[0;32m--> 532\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# equivalent of torch.einsum(\"bnqd,bnkd->bnqk\", query_states, key_states), compatible with onnx op>9\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m position_bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_relative_attention_bias:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["df_with_model_answers = generate_answers_and_save(csv_path=csv_input_dir)\n","print(df_with_model_answers.shape)\n","df_with_model_answers.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3k1mPLZAsiQy"},"outputs":[],"source":["# with additional extraction prompt after generation without prompt\n","type(df['ModelAnswer'][0]),type(df['Answer'][0])\n","df = df.astype(str)  # Convert columns to string type\n","\n","from evaluation_csv import total_score_csv\n","exact_match, f1_score, recall_score = total_score_csv(df['ModelAnswer'], df['Answer'])\n","print(f'Exact match: {exact_match}')\n","print(f'F1 score: {f1_score}')\n","print(f'Recall score: {recall_score}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for category in df['Category'].unique():\n","    print(f'Category: {category}')\n","    df_category = df[df['Category'] == category]\n","    exact_match, f1_score, recall_score = total_score_csv(df_category['ModelAnswer'], df_category['Answer'])\n","    print(f'Exact match: {exact_match}')\n","    print(f'F1 score: {f1_score}')\n","    print(f'Recall score: {recall_score}')\n","    print('\\n')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"widgets":{"application/vnd.jupyter.widget-state+json":{}}},"nbformat":4,"nbformat_minor":0}
