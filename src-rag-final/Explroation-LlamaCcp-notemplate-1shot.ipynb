{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "executionInfo": {
     "elapsed": 13570,
     "status": "ok",
     "timestamp": 1710110042978,
     "user": {
      "displayName": "Vashisth Tiwari",
      "userId": "14058204908965748495"
     },
     "user_tz": 240
    },
    "id": "VbUAaUUtf1mg",
    "outputId": "f8419cd9-3b78-43bf-cc73-772c118d60fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.26.3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install ctransformers[cuda]\n",
    "# !pip3 install numpy==1.26.4\n",
    "import numpy as np\n",
    "np.__version__\n",
    "\n",
    "# restart after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "s96leWz22vbg"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv('.env')\n",
    "# hf_api = os.getenv('HF_API')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 18031,
     "status": "ok",
     "timestamp": 1709884858907,
     "user": {
      "displayName": "Vashisth Tiwari",
      "userId": "14058204908965748495"
     },
     "user_tz": 300
    },
    "id": "s-iSASxn3CUu",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "6c5d8662-e6ed-45db-fcea-54ea512ec45d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.38.0\n",
      "  Downloading transformers-4.38.0-py3-none-any.whl.metadata (131 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.1/131.1 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from transformers==4.38.0) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers==4.38.0)\n",
      "  Downloading huggingface_hub-0.21.4-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from transformers==4.38.0) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from transformers==4.38.0) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from transformers==4.38.0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from transformers==4.38.0) (2023.12.25)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from transformers==4.38.0) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.38.0)\n",
      "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers==4.38.0)\n",
      "  Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from transformers==4.38.0) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.0) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.0) (4.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.38.0) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests->transformers==4.38.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests->transformers==4.38.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests->transformers==4.38.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests->transformers==4.38.0) (2023.11.17)\n",
      "Downloading transformers-4.38.0-py3-none-any.whl (8.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.4/346.4 kB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.21.4 safetensors-0.4.2 tokenizers-0.15.2 transformers-4.38.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.13.1 requires numpy<=1.24.3,>=1.22, but you have numpy 1.26.3 which is incompatible.\n",
      "tensorflow 2.13.1 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mCollecting unstructured\n",
      "  Downloading unstructured-0.12.6-py3-none-any.whl.metadata (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ragatouille\n",
      "  Downloading ragatouille-0.0.7.post10-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting backoff==2.2.1 (from unstructured)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: beautifulsoup4==4.12.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from unstructured) (4.12.3)\n",
      "Collecting certifi==2024.2.2 (from unstructured)\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: chardet==5.2.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from unstructured) (5.2.0)\n",
      "Requirement already satisfied: charset-normalizer==3.3.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from unstructured) (3.3.2)\n",
      "Requirement already satisfied: click==8.1.7 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from unstructured) (8.1.7)\n",
      "Requirement already satisfied: dataclasses-json==0.6.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from unstructured) (0.6.4)\n",
      "Collecting dataclasses-json-speakeasy==0.5.11 (from unstructured)\n",
      "  Downloading dataclasses_json_speakeasy-0.5.11-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting emoji==2.10.1 (from unstructured)\n",
      "  Downloading emoji-2.10.1-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting filetype==1.2.0 (from unstructured)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: idna==3.6 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from unstructured) (3.6)\n",
      "Requirement already satisfied: joblib==1.3.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from unstructured) (1.3.2)\n",
      "Collecting jsonpath-python==1.0.6 (from unstructured)\n",
      "  Downloading jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting langdetect==1.0.9 (from unstructured)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting lxml==5.1.0 (from unstructured)\n",
      "  Downloading lxml-5.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n",
      "Collecting marshmallow==3.20.2 (from unstructured)\n",
      "  Downloading marshmallow-3.20.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: mypy-extensions==1.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from unstructured) (1.0.0)\n",
      "Requirement already satisfied: nltk==3.8.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from unstructured) (3.8.1)\n",
      "Collecting numpy==1.26.4 (from unstructured)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m912.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging==23.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from unstructured) (23.2)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from unstructured) (2.8.2)\n",
      "Collecting python-iso639==2024.2.7 (from unstructured)\n",
      "  Downloading python_iso639-2024.2.7-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting python-magic==0.4.27 (from unstructured)\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting rapidfuzz==3.6.1 (from unstructured)\n",
      "  Downloading rapidfuzz-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: regex==2023.12.25 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from unstructured) (2023.12.25)\n",
      "Requirement already satisfied: requests==2.31.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from unstructured) (2.31.0)\n",
      "Requirement already satisfied: six==1.16.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from unstructured) (1.16.0)\n",
      "Requirement already satisfied: soupsieve==2.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from unstructured) (2.5)\n",
      "Requirement already satisfied: tabulate==0.9.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from unstructured) (0.9.0)\n",
      "Collecting tqdm==4.66.2 (from unstructured)\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions==4.9.0 (from unstructured)\n",
      "  Downloading typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-inspect==0.9.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from unstructured) (0.9.0)\n",
      "Collecting unstructured-client==0.18.0 (from unstructured)\n",
      "  Downloading unstructured_client-0.18.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: urllib3==1.26.18 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from unstructured) (1.26.18)\n",
      "Requirement already satisfied: wrapt==1.16.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from unstructured) (1.16.0)\n",
      "Requirement already satisfied: aiohttp==3.9.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from ragatouille) (3.9.1)\n",
      "Collecting colbert-ai==0.2.19 (from ragatouille)\n",
      "  Downloading colbert-ai-0.2.19.tar.gz (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting faiss-cpu<2.0.0,>=1.7.4 (from ragatouille)\n",
      "  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: langchain<0.2.0,>=0.1.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from ragatouille) (0.1.11)\n",
      "Requirement already satisfied: langchain_core<0.2.0,>=0.1.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from ragatouille) (0.1.30)\n",
      "Collecting llama-index<0.10.0,>=0.9.24 (from ragatouille)\n",
      "  Downloading llama_index-0.9.48-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting onnx<2.0.0,>=1.15.0 (from ragatouille)\n",
      "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Collecting ruff<0.2.0,>=0.1.9 (from ragatouille)\n",
      "  Downloading ruff-0.1.15-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: sentence-transformers<3.0.0,>=2.2.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from ragatouille) (2.5.1)\n",
      "Collecting srsly==2.4.8 (from ragatouille)\n",
      "  Downloading srsly-2.4.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: torch<3.0.0,>=2.0.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from ragatouille) (2.2.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.36.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from ragatouille) (4.38.0)\n",
      "Collecting voyager<3.0.0,>=2.0.2 (from ragatouille)\n",
      "  Downloading voyager-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from aiohttp==3.9.1->ragatouille) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from aiohttp==3.9.1->ragatouille) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from aiohttp==3.9.1->ragatouille) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from aiohttp==3.9.1->ragatouille) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from aiohttp==3.9.1->ragatouille) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from aiohttp==3.9.1->ragatouille) (4.0.3)\n",
      "Requirement already satisfied: bitarray in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from colbert-ai==0.2.19->ragatouille) (2.9.2)\n",
      "Collecting datasets (from colbert-ai==0.2.19->ragatouille)\n",
      "  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: flask in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from colbert-ai==0.2.19->ragatouille) (3.0.1)\n",
      "Collecting git-python (from colbert-ai==0.2.19->ragatouille)\n",
      "  Downloading git_python-1.0.3-py2.py3-none-any.whl.metadata (331 bytes)\n",
      "Collecting python-dotenv (from colbert-ai==0.2.19->ragatouille)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting ninja (from colbert-ai==0.2.19->ragatouille)\n",
      "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from colbert-ai==0.2.19->ragatouille) (1.12.0)\n",
      "Requirement already satisfied: ujson in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from colbert-ai==0.2.19->ragatouille) (5.9.0)\n",
      "Collecting catalogue<2.1.0,>=2.0.3 (from srsly==2.4.8->ragatouille)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (2.0.25)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.25 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (0.0.27)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (0.1.23)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (2.6.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (8.2.3)\n",
      "Requirement already satisfied: anyio<5,>=3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain_core<0.2.0,>=0.1.4->ragatouille) (4.2.0)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index<0.10.0,>=0.9.24->ragatouille)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index<0.10.0,>=0.9.24->ragatouille)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (2023.12.2)\n",
      "Collecting httpx (from llama-index<0.10.0,>=0.9.24->ragatouille)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (3.2.1)\n",
      "Collecting openai>=1.1.0 (from llama-index<0.10.0,>=0.9.24->ragatouille)\n",
      "  Downloading openai-1.13.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (1.5.3)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index<0.10.0,>=0.9.24->ragatouille)\n",
      "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from onnx<2.0.0,>=1.15.0->ragatouille) (4.25.2)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.2.2->ragatouille) (1.4.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.2.2->ragatouille) (0.21.4)\n",
      "Requirement already satisfied: Pillow in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.2.2->ragatouille) (10.2.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch<3.0.0,>=2.0.1->ragatouille) (3.13.1)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch<3.0.0,>=2.0.1->ragatouille) (1.12)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch<3.0.0,>=2.0.1->ragatouille) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch<3.0.0,>=2.0.1->ragatouille) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch<3.0.0,>=2.0.1->ragatouille) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch<3.0.0,>=2.0.1->ragatouille) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch<3.0.0,>=2.0.1->ragatouille) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch<3.0.0,>=2.0.1->ragatouille) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch<3.0.0,>=2.0.1->ragatouille) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch<3.0.0,>=2.0.1->ragatouille) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch<3.0.0,>=2.0.1->ragatouille) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch<3.0.0,>=2.0.1->ragatouille) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch<3.0.0,>=2.0.1->ragatouille) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch<3.0.0,>=2.0.1->ragatouille) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch<3.0.0,>=2.0.1->ragatouille) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<3.0.0,>=2.0.1->ragatouille) (12.4.99)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from transformers<5.0.0,>=4.36.2->ragatouille) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from transformers<5.0.0,>=4.36.2->ragatouille) (0.4.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from anyio<5,>=3->langchain_core<0.2.0,>=0.1.4->ragatouille) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from anyio<5,>=3->langchain_core<0.2.0,>=0.1.4->ragatouille) (1.2.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain<0.2.0,>=0.1.0->ragatouille) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.0->ragatouille) (3.9.15)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.1.0->llama-index<0.10.0,>=0.9.24->ragatouille)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpcore==1.* (from httpx->llama-index<0.10.0,>=0.9.24->ragatouille)\n",
      "  Downloading httpcore-1.0.4-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index<0.10.0,>=0.9.24->ragatouille)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.0->ragatouille) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.0->ragatouille) (2.16.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain<0.2.0,>=0.1.0->ragatouille) (3.0.3)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from datasets->colbert-ai==0.2.19->ragatouille) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from datasets->colbert-ai==0.2.19->ragatouille) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from datasets->colbert-ai==0.2.19->ragatouille) (0.3.8)\n",
      "Collecting xxhash (from datasets->colbert-ai==0.2.19->ragatouille)\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from datasets->colbert-ai==0.2.19->ragatouille) (0.70.16)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from flask->colbert-ai==0.2.19->ragatouille) (3.0.1)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from flask->colbert-ai==0.2.19->ragatouille) (2.1.2)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from flask->colbert-ai==0.2.19->ragatouille) (1.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from jinja2->torch<3.0.0,>=2.0.1->ragatouille) (2.1.4)\n",
      "Collecting gitpython (from git-python->colbert-ai==0.2.19->ragatouille)\n",
      "  Using cached GitPython-3.1.42-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from pandas->llama-index<0.10.0,>=0.9.24->ragatouille) (2023.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from scikit-learn->sentence-transformers<3.0.0,>=2.2.2->ragatouille) (3.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from sympy->torch<3.0.0,>=2.0.1->ragatouille) (1.3.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython->git-python->colbert-ai==0.2.19->ragatouille)\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython->git-python->colbert-ai==0.2.19->ragatouille)\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading unstructured-0.12.6-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Downloading dataclasses_json_speakeasy-0.5.11-py3-none-any.whl (28 kB)\n",
      "Downloading emoji-2.10.1-py2.py3-none-any.whl (421 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.5/421.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
      "Downloading lxml-5.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading python_iso639-2024.2.7-py3-none-any.whl (274 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading rapidfuzz-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Downloading unstructured_client-0.18.0-py3-none-any.whl (21 kB)\n",
      "Downloading ragatouille-0.0.7.post10-py3-none-any.whl (35 kB)\n",
      "Downloading srsly-2.4.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.0/493.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading llama_index-0.9.48-py3-none-any.whl (15.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading ruff-0.1.15-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading voyager-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m992.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading git_python-1.0.3-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
      "Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: langdetect, colbert-ai\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=ae0703143a74ccfbce927ffb0c4038a731c5d2d620353faa520ec41fcc8d824c\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
      "  Building wheel for colbert-ai (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for colbert-ai: filename=colbert_ai-0.2.19-py3-none-any.whl size=114761 sha256=f9e1551c7aa04f98b000d7b69f6c82b07f026ae5a6ab875df9a89cb7d0524f12\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/90/b9/63/d4fc276c73c42ef7fc1065a26cf87e5a1cf56ef6498cbfbe5d\n",
      "Successfully built langdetect colbert-ai\n",
      "Installing collected packages: ninja, filetype, dirtyjson, xxhash, typing-extensions, tqdm, smmap, ruff, rapidfuzz, python-magic, python-iso639, python-dotenv, numpy, marshmallow, lxml, langdetect, jsonpath-python, h11, emoji, distro, deprecated, certifi, catalogue, backoff, voyager, srsly, onnx, httpcore, gitdb, faiss-cpu, tiktoken, httpx, gitpython, dataclasses-json-speakeasy, unstructured-client, openai, git-python, datasets, unstructured, llama-index, colbert-ai, ragatouille\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.10.0\n",
      "    Uninstalling typing_extensions-4.10.0:\n",
      "      Successfully uninstalled typing_extensions-4.10.0\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.1\n",
      "    Uninstalling tqdm-4.66.1:\n",
      "      Successfully uninstalled tqdm-4.66.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.3\n",
      "    Uninstalling numpy-1.26.3:\n",
      "      Successfully uninstalled numpy-1.26.3\n",
      "  Attempting uninstall: marshmallow\n",
      "    Found existing installation: marshmallow 3.21.1\n",
      "    Uninstalling marshmallow-3.21.1:\n",
      "      Successfully uninstalled marshmallow-3.21.1\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2023.11.17\n",
      "    Uninstalling certifi-2023.11.17:\n",
      "      Successfully uninstalled certifi-2023.11.17\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mkl-fft 1.3.8 requires mkl, which is not installed.\n",
      "tensorflow 2.13.1 requires numpy<=1.24.3,>=1.22, but you have numpy 1.26.4 which is incompatible.\n",
      "tensorflow 2.13.1 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed backoff-2.2.1 catalogue-2.0.10 certifi-2024.2.2 colbert-ai-0.2.19 dataclasses-json-speakeasy-0.5.11 datasets-2.18.0 deprecated-1.2.14 dirtyjson-1.0.8 distro-1.9.0 emoji-2.10.1 faiss-cpu-1.8.0 filetype-1.2.0 git-python-1.0.3 gitdb-4.0.11 gitpython-3.1.42 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 jsonpath-python-1.0.6 langdetect-1.0.9 llama-index-0.9.48 lxml-5.1.0 marshmallow-3.20.2 ninja-1.11.1.1 numpy-1.26.4 onnx-1.15.0 openai-1.13.3 python-dotenv-1.0.1 python-iso639-2024.2.7 python-magic-0.4.27 ragatouille-0.0.7.post10 rapidfuzz-3.6.1 ruff-0.1.15 smmap-5.0.1 srsly-2.4.8 tiktoken-0.6.0 tqdm-4.66.2 typing-extensions-4.9.0 unstructured-0.12.6 unstructured-client-0.18.0 voyager-2.0.2 xxhash-3.4.1\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
      "Cuda compilation tools, release 11.8, V11.8.89\n",
      "Build cuda_11.8.r11.8/compiler.31833905_0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.38.0\n",
    "!pip install -q torch accelerate bitsandbytes langchain sentence-transformers faiss-gpu openpyxl\n",
    "!pip install unstructured ragatouille\n",
    "# reranker\n",
    "from ragatouille import RAGPretrainedModel\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 275993,
     "status": "ok",
     "timestamp": 1710110355792,
     "user": {
      "displayName": "Vashisth Tiwari",
      "userId": "14058204908965748495"
     },
     "user_tz": 240
    },
    "id": "-hsCAcjxIP19",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "128ca964-5cf2-4f00-cfa4-2ec234a65bdd",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-cpp-python\n",
      "  Downloading llama_cpp_python-0.2.56.tar.gz (36.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.9/36.9 MB\u001b[0m \u001b[31m178.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting typing-extensions>=4.5.0 (from llama-cpp-python)\n",
      "  Downloading typing_extensions-4.10.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting numpy>=1.20.0 (from llama-cpp-python)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m296.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting diskcache>=5.6.1 (from llama-cpp-python)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting jinja2>=2.11.3 (from llama-cpp-python)\n",
      "  Downloading Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2>=2.11.3->llama-cpp-python)\n",
      "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m237.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 kB\u001b[0m \u001b[31m357.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m349.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Building wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.56-cp310-cp310-manylinux_2_26_x86_64.whl size=23199999 sha256=a13e70f083f1c9fcf5f170e29d7bdb3e3a05a89e7d7bbee66811d4ac1e2c14f9\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-tqvjlzl6/wheels/e5/09/9d/c413053f6258cb2546cc792418c595e276f9efd5db31a80377\n",
      "Successfully built llama-cpp-python\n",
      "Installing collected packages: typing-extensions, numpy, MarkupSafe, diskcache, jinja2, llama-cpp-python\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.9.0\n",
      "    Uninstalling typing_extensions-4.9.0:\n",
      "      Successfully uninstalled typing_extensions-4.9.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 2.1.4\n",
      "    Uninstalling MarkupSafe-2.1.4:\n",
      "      Successfully uninstalled MarkupSafe-2.1.4\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 3.1.3\n",
      "    Uninstalling Jinja2-3.1.3:\n",
      "      Successfully uninstalled Jinja2-3.1.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mkl-fft 1.3.8 requires mkl, which is not installed.\n",
      "tensorflow 2.13.1 requires numpy<=1.24.3,>=1.22, but you have numpy 1.26.4 which is incompatible.\n",
      "tensorflow 2.13.1 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.10.0 which is incompatible.\n",
      "unstructured 0.12.6 requires typing-extensions==4.9.0, but you have typing-extensions 4.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 diskcache-5.6.3 jinja2-3.1.3 llama-cpp-python-0.2.56 numpy-1.26.4 typing-extensions-4.10.0\n"
     ]
    }
   ],
   "source": [
    "# this will take time :c\n",
    "!CUDACXX=/usr/local/cuda-12.1/bin/nvcc CMAKE_ARGS=\"-DLLAMA_CUBLAS=on -DCMAKE_CUDA_ARCHITECTURES=all-major\" FORCE_CMAKE=1 pip install llama-cpp-python --no-cache-dir --force-reinstall --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4ItWW1Es3OX_"
   },
   "outputs": [],
   "source": [
    "# fix colab error: https://stackoverflow.com/questions/56081324/why-are-google-colab-shell-commands-not-working\n",
    "import locale\n",
    "def getpreferredencoding(do_setlocale = True):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = getpreferredencoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CB6DVShA2vbh"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.docstore.document import Document as LangchainDocument\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GrqalAohmDnp"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "m1Dm1uHk2vbh"
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from typing import Optional, List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option(\n",
    "    \"display.max_colwidth\", None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "3ti-G7vMdASy"
   },
   "outputs": [],
   "source": [
    "# pip list --outdated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pO3SVhxSshpo"
   },
   "source": [
    "# Specify the model/versions, etc.\n",
    "## also specify the knowledge base file and the reference answer directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365,
     "referenced_widgets": [
      "800014039af04d66adc94131a8ab568e",
      "f741891d16434e959971b6331ab7a09e",
      "20619dd814a245cb96eed1ffd6d23793",
      "f91289ae253446ed90b7c9260d85ac2c",
      "3088fb3c8cc74d7c97d9cbacc5b20c03",
      "234ab5cd38b14aec8426fcc28dfc4952",
      "b8d486c46bbc4a6abdb3b0af3dbc4c04",
      "be42d78fa32c44f4ba983327b2f2b0ae",
      "d696cc22200743caaaa0d70de5f29eaf",
      "2d7b6a6ffb3849ec9828e24f4e193840",
      "718e83bf80b74bbb9e28a9a2473ab8db",
      "9561e20747684a1a878a637d00c946fa",
      "b5cfff7bf253443682d8051953740ad2",
      "d2b20654e6aa49359b678e198cc55a73",
      "5fca46bd83bd4f95ae25eecf342ff20f",
      "63a47d5282db441a8e5732ab3266af33",
      "8d567a74de4843a4b50292512c7d0ebe",
      "e4710695ec874eada402065fe800edd5",
      "9b8ebc99d0ed4d9fb6f873f06a638318",
      "2750e13775ad4cc5a1ca97abd23a7fa4",
      "fc979bda6f3c486e8108945371fee26e",
      "5de0a6a267a24518ac2857b47c4d2d4e",
      "fc6ba90ca08747e1bace0a55d1eeed55",
      "5e9df76d9eb04c3cacc9caf4edacb913",
      "091d085339a14a0ab5a23a60b24508f6",
      "1191b9f6ca7e491c91a54648d9a95740",
      "b106e671bf2040ff85286339391cacce",
      "25d444efba4c4f8ea2a15c4a197e83fa",
      "fa2721e59a714068a0a5918cd7ec3246",
      "8041af99466c478ab32dcb07ff597d41",
      "ec25bd06a00e4e2cab1b9f62905449ca",
      "d3e5436855af42a5b2f170b44388e4a8",
      "195ac8d683264e9999a419b94e60bdc1",
      "08e5c13a33c442d69db6a4e5cb1aefd8",
      "486f19f393194214820b2e4719793822",
      "82baa3fb82e24827b49b6bda22f72d78",
      "a2c29ede70564d5b879b4084453d753f",
      "bb8b2e9c41ea45dfa6fe7dff8a934fa2",
      "6257ec67ee0043adab5a9e24a4f709a8",
      "df62dad6b54444659f23d7cca3ddaa70",
      "2c938e4d55734c248ffb292415aa5f5b",
      "5582c1c8145b4fe786ba967188680aa7",
      "b5693df9d1cf458e9c7dabfba2331102",
      "4c7a193e4d3349dc8c2ff58c7137e77e",
      "c1225405706548aa86f466345ba78795",
      "f9124d67aef64019a437baa8eef8e54e",
      "7a6d685007704814a51a027b060ba1b0",
      "c87f3b6818934457af1827e01f4924ba",
      "cfab7d69b2634082805f101090dcbd04",
      "9553bb69e7c5479ebbf73787d3fc8b14",
      "0eae622975df4cfaaa2e54cde12fecc2",
      "b599c45a81df44619d92a3ac8ad41b0f",
      "c2cf8f815146436e86373dd6f02e94aa",
      "b02abbcd98d94732961735247946d2d4",
      "666d42ef1a74402fb13ea79db36c1287",
      "c28b40c65c1f450988dfb834ccbf1526",
      "1257cd90321540d8b5530c35b672ac38",
      "365523a881584181973972b7df86c3eb",
      "6023241ffbf740ec871828d6276cccb8",
      "863ed2e3ac1e4670b7850cf4deafc867",
      "890443b9c63d42b597b1fce37ed2612f",
      "e7bc53149d98433785d628cd3783cbdb",
      "3a1808fea5884186924c50c1d44cdb2b",
      "6cb72ab4081a44fd8462b7d58da7236c",
      "d9d79532e89447e1ae295ea296d33dbf",
      "4663ab81441947f7bd1b86a08d82a6b2",
      "b14e572db35545c58c413b5313c230d0",
      "26f3de4a37ed42c783b8cc8496a8830e",
      "25ea5fce0d51425ca66647c86a69054d",
      "1d5d56be1f3e4e06ad05b7a61c073773",
      "0e6e63ccb1164deab11b438e7059d69f",
      "e5ff1078ea2d454ba88d92b978bee13f",
      "97d0ee251daa487db840ba561a36d4a8",
      "572f1df5c7904ccf939d45356997f7a7",
      "abe064fd2d2943cc9658631022e7dfbe",
      "37bbe9f296674040a1e4e6f414645aee",
      "0567916024824a5cb153ee96ae90bcfd"
     ]
    },
    "executionInfo": {
     "elapsed": 6034,
     "status": "ok",
     "timestamp": 1710110390648,
     "user": {
      "displayName": "Vashisth Tiwari",
      "userId": "14058204908965748495"
     },
     "user_tz": 240
    },
    "id": "SscMCDYU2vbh",
    "outputId": "83e0ecb7-0a38-489a-ec55-a9c7d22fc51f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5574da87e1ca4c6f858324ddf462090a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "artifact.metadata:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4f99ede4bd4fc79684db943017b21b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aff7b8895b44e20918de4eda84ab937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa41d326dfd4504a36f8c9f87cf939e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/405 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac8450b56fd43b0ab9040c44d1f8cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe72c4fa70b44ae9bb0fe590f98ee13e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcdb7484c96b442592ba593aa53bbc28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EMBEDDING_MODEL = \"thenlper/gte-base\"\n",
    "RERANKER_MODEL = \"colbert-ir/colbertv2.0\"\n",
    "RERANKER = RAGPretrainedModel.from_pretrained(RERANKER_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337,
     "referenced_widgets": [
      "cb37e6988db144ac9e6b615b71705c3d",
      "58f1227b067740c99856d28d1b3535f0",
      "a68946ee535e4693955f8292b47c5b6c",
      "72f6e2507a5c49338610f22446087687",
      "f7afe5336f9645bbaa3da495dad04c6f",
      "f4c9a624ca3342adbdda81d0c505d540",
      "7b9187f7562945ba813032f73d5fed96",
      "755d31fc51614b78a6798a1f45d66a29",
      "46b7f140d4134097a8f6c7dd41d9acd3",
      "784f6571b15c4ac19ca2e1b1a913f318",
      "42c591eaee9f42f8ad965372898e3bdd",
      "7a550bf2dc964d0caafc8aed54d187a6",
      "5bf549707f604a99a4743166718cd720",
      "bac9a59f6a1244d8a6e37795e0383e30",
      "a113bb38b1f7458cae5e7825d6a65b3c",
      "cda8adeebae9484c9399422c870aa7cf",
      "b524e9e4f75a45aba71a8a2b68557700",
      "fdbe596b18164389a51d860b24f3b15b",
      "e55c826128994d0a8b67885f40574fae",
      "836f49316d114d37846143df795ba15a",
      "1ad12046944a468297e3c982794251ef",
      "c0d3f59319544daa858e76bf490ac735",
      "f8c3f5363e824e338cf4b7ea0f09b92a",
      "6aaf81405fa24b0e93a858d609b85036",
      "4977730998754c6d82831b47a647b428",
      "9dc189ff36034264b081ca782c0bc1ed",
      "91b7390bb1d94bd6be84496ed73052ee",
      "7e04af96adae41a6b05ecc7bfe5a9fd9",
      "b13c2b7166784d0f8d8a1ee231fe3235",
      "761b0c7bec0f4ea98fff4469f3e147e1",
      "2f225874a7174aae9695b521d33eb563",
      "0e167716cc6941e2aaa5e85a476f1b1a",
      "9ce3da5248a34146945e40a660ed455d",
      "6584fa0193f0433ead447e60d2c82607",
      "47d8987c94434ddb89281035f30e9d4f",
      "cf1bd11c82b44b99ac40e8abbec3785f",
      "7e069a6942cb4cb09ef6aa3661844f88",
      "7e0b008fb7294404a73b8341c1230125",
      "45c9710ebd6e45ddaa72f349380c5e16",
      "9defae4a31724cc1b6c0128b76bae404",
      "3332c9a35d2e40ac860233ebfb8c64c7",
      "e0686b63c9374bcda05c70aeffbcda03",
      "f5553c33eefd47eea49e0e3901bf51f5",
      "fc2843b06e0f4b6ca2a7d1d5fcde23d6",
      "7b70f0bd5409433e93719cd05441e473",
      "83665867accd4853b6efe68a06f7f403",
      "66b76f1f830445e98fb9c1acc1683cde",
      "26f97033c9e5479da8dca6f7dc642ece",
      "6da0a949eaf1499094fa4e264e1929ca",
      "0b946716322e43bb9f4213087c6ee1de",
      "c3cb074231f84c169f31afa3baf84fc9",
      "aee8fac5931844c5a88f651e7f854362",
      "e39705238d474d5a99f0a49832b408ed",
      "45d616297f6d42fc89f2b28c6fc10c90",
      "58bdc5e07c694b4f9fc4e6612c1de4c5",
      "0d0fbbe470054b0b879c1a62c411dc0c",
      "6efb365326c24c339085be28cc203fdc",
      "df4976d8d7ec47e4986f5e9c0395c3a9",
      "e249235d4bb14478a802d3fc362fe215",
      "ea2f3d5138cb4d3eb4b5f50122c42634",
      "0bce7925eb1f4323a482bb90467bbc66",
      "392ee34639024892a83a85f6878b60ef",
      "ba96d1c92aeb4a9584f700869c028ace",
      "c8c4de2dd87b409ab14e3bbd4f8ff777",
      "355092a75fa445ddb58c3c0e6c7c87f7",
      "a77de46019434b2182d8ace90729411d",
      "3f54b0320e054ef4ab7cc33ca97ad75c",
      "13c4cd250f4c49169902a77e3b76727c",
      "9100526f824f4e2298b22f43461c6daa",
      "5e7028e3f8f6469086b2b94066dc9526",
      "6901a356aa2c4361953ba9b44065710b",
      "b215c0274af9444c9265aa576d33f6d5",
      "f46f3a7030a34d3894d97214fb03e1c2",
      "34f2229c854f4695b5aba5d5afe772f5",
      "38344f64512b421aa12ac82fcf4b195d",
      "11e9dc55ddd64166a23b389ef4115bc5",
      "090fd1cdc0694112b57d28e833932350",
      "0c73d54adcb74546b98a15ff898640d2",
      "8cd319e80b28462698e8adb196302802",
      "4016322235e5422687997b6c942b8684",
      "90efeff073a541e3ace582146fd5fd45",
      "4da4cc126514421ebb1cd20eff5544f9",
      "255d439785a54b9b8f37be9730c5b9f9",
      "e3ea567b814a4d949a018e39137923fd",
      "ea9b31c529f0482c99ac5ede1b0c2437",
      "2f08477187154be899c3a1378e703260",
      "183c14e615d6471c9fe4b9a56d13f85a",
      "e15406eedc3b4b10b5d8c32d2ba5f1cd",
      "f82609221b714ae58214a6f6745526b3",
      "6f038781e3a5498a9823999548de18fd",
      "8110d80f4fe94d499834b799c85667ad",
      "e7816626014f47fbb744f707990f3c0b",
      "65617f6c0a3f40f1bb7198eadb9757da",
      "1efc8ad79138462e97c1bf5f00d8a210",
      "4e8321573083413d80d545eb711dabcb",
      "ca2e4e27247949fd96c09ca0084eb8d5",
      "ab3716a57cb1461ca4b89d3e2af60aa1",
      "e7096ed061374902935f3363540caa56",
      "3e583707d8f7457bb3a5433440f3a6cb",
      "200a894d245143b59503f70bbe099655",
      "e68e4e022b7946139920753c55012db2",
      "1d9cc219294748d7a4d06a0ef220d034",
      "61055f305b414a9995dd0093c8dd085b",
      "6793b20c68004ef6806c0719d850ee07",
      "45045e6a12e041e1b2b2713ff59ef938",
      "0f57c3f8ee4d42b3b02aba300b4fe271",
      "bfd5578f1cc3406b9b6e49540918dffd",
      "0fab8e8ae3fd4f47b43ee00df8a80deb",
      "f4388ee32ed9434ea5e756c22fb61002",
      "eac3132f4d9349cfa6f1422686ae7bd5"
     ]
    },
    "executionInfo": {
     "elapsed": 5437,
     "status": "ok",
     "timestamp": 1710110400718,
     "user": {
      "displayName": "Vashisth Tiwari",
      "userId": "14058204908965748495"
     },
     "user_tz": 240
    },
    "id": "zliNdIDo2vbh",
    "outputId": "7302e1a2-7bee-4b0e-8fcd-074783531201"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2587b9e250e9489da6f052858e78b00c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b09b88aae344c3e88c9c689d304f9f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/68.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aec823385cee45a0b45fcc77bccfde18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00202830a49141dfbbce9b45e549042a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/618 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "146499f45811435baeef3792a32baa13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/219M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b192e80acde4036b2f87e859bf96c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ec91ff95d9424fb052f694e6d068fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8bea83125f04585b6572dbe5d5a5270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fbf8d0042dd4f89ad63390f6df916df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "595ed78834444330973d28a3dd221287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EMBEDDING_MODEL_NAME = EMBEDDING_MODEL\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=EMBEDDING_MODEL_NAME,\n",
    "    multi_process=True,\n",
    "    model_kwargs={\"device\": \"cuda\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 181,
     "status": "ok",
     "timestamp": 1710111573183,
     "user": {
      "displayName": "Vashisth Tiwari",
      "userId": "14058204908965748495"
     },
     "user_tz": 240
    },
    "id": "JIaPbE2th0I5",
    "outputId": "98ab622e-0a7f-4d29-f1ba-af5c6360d978"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/srg-rag-final\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "0jF7haihucN6"
   },
   "outputs": [],
   "source": [
    "FAISS_FILE = '../faiss_index_total_final'\n",
    "# num_retrieved_docs: int = 5\n",
    "# num_docs_final: int = 3\n",
    "KNOWLEDGE_VECTOR_DATABASE = FAISS.load_local(FAISS_FILE, embedding_model, allow_dangerous_deserialization = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "pHsA8wuz4eE7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9467a54ebe9435591dfaf01ee03fc28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llama-2-7b-chat.Q4_K_M.gguf:   0%|          | 0.00/4.08G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_path = \"TheBloke/Llama-2-7B-Chat-GGUF\"\n",
    "model_basename = \"llama-2-7b-chat.Q4_K_M.gguf\"\n",
    "model_path = hf_hub_download(repo_id=model_path, filename=model_basename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_27tccjshpp"
   },
   "source": [
    "# Reader LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 3662,
     "status": "ok",
     "timestamp": 1710110638040,
     "user": {
      "displayName": "Vashisth Tiwari",
      "userId": "14058204908965748495"
     },
     "user_tz": 240
    },
    "id": "7H5oLKT72vbi",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "68c9a4ec-8d72-46c7-994a-55322496e435",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! repetition_penalty is not default parameter.\n",
      "                repetition_penalty was transferred to model_kwargs.\n",
      "                Please confirm that repetition_penalty is what you intended.\n",
      "  warnings.warn(\n",
      "ggml_init_cublas: GGML_CUDA_FORCE_MMQ:   no\n",
      "ggml_init_cublas: CUDA_USE_TENSOR_CORES: yes\n",
      "ggml_init_cublas: found 1 CUDA devices:\n",
      "  Device 0: Tesla T4, compute capability 7.5, VMM: yes\n",
      "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /home/ec2-user/.cache/huggingface/hub/models--TheBloke--Llama-2-7B-Chat-GGUF/snapshots/191239b3e26b2882fb562ffccdd1cf0f65402adb/llama-2-7b-chat.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
      "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.22 MiB\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =    70.31 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =  3820.94 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2400\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =  1200.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 1200.00 MiB, K (f16):  600.00 MiB, V (f16):  600.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host input buffer size   =     0.22 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =     2.92 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =     0.12 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 2\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n",
      "Using fallback chat format: None\n"
     ]
    }
   ],
   "source": [
    "# https://www.reddit.com/r/LocalLLaMA/comments/1343bgz/what_model_parameters_is_everyone_using/\n",
    "# temperature\t0.7\n",
    "# repetition_penalty=\t1.176\n",
    "# top_k\t= 40\n",
    "# top_p= 0.1\n",
    "\n",
    "# Initialize Large Language Model for answer generation\n",
    "llm_answer_gen = LlamaCpp(\n",
    "streaming = True,\n",
    "model_path = model_path,\n",
    "temperature=.2,\n",
    "n_gpu_layers=-1,\n",
    "top_p=.1,\n",
    "top_k\t= 40,\n",
    "repetition_penalty=\t1.176,\n",
    "verbose=True,\n",
    "n_ctx=2400\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1710113142107,
     "user": {
      "displayName": "Vashisth Tiwari",
      "userId": "14058204908965748495"
     },
     "user_tz": 240
    },
    "id": "l8bKX1rXFQBv",
    "outputId": "9d39a40d-28e7-4025-b401-052cc9b2f1c3"
   },
   "outputs": [],
   "source": [
    "llm_answer_gen.verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCp6KhE0LXh4"
   },
   "source": [
    "# RAG Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "VhwgRYB467Gt"
   },
   "outputs": [],
   "source": [
    "# link: https://python.langchain.com/docs/use_cases/chatbots/retrieval\n",
    "\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# https://stackoverflow.com/questions/76551067/how-to-create-a-langchain-doc-from-an-str\n",
    "\n",
    "def answer_llama_new(\n",
    "    question: str,\n",
    "    knowledge_index: FAISS,\n",
    "    reranker: RAGPretrainedModel,\n",
    "    num_retrieved_docs: int = 5,\n",
    "    num_docs_final: int = 3,\n",
    "    llm: LlamaCpp = llm_answer_gen,\n",
    "    ): #-> Tuple[str, List[LangchainDocument]]\n",
    "\n",
    "    print(\"=> Retrieving documents...\")\n",
    "    relevant_docs_acquired = knowledge_index.similarity_search(query=question, k=num_retrieved_docs)\n",
    "    relevant_doc_id = [doc.metadata['source'] for doc in relevant_docs_acquired]\n",
    "\n",
    "    if reranker:\n",
    "        print(\"=> Reranking documents...\")\n",
    "        relevant_docs = [doc.page_content for doc in relevant_docs_acquired]\n",
    "        relevant_docs = reranker.rerank(question, relevant_docs, k=num_docs_final)\n",
    "\n",
    "        relevant_docs = [LangchainDocument(page_content=doc[\"content\"],\n",
    "                                           metadata={'source': relevant_doc_id[ doc['result_index']] } ) for doc in relevant_docs]\n",
    "\n",
    "        relevant_docs_content = [doc.page_content for doc in relevant_docs]\n",
    "        relevant_doc_id = [doc.metadata for doc in relevant_docs]\n",
    "\n",
    "    else:\n",
    "        relevant_docs_content = [doc.page_content for doc in relevant_docs_acquired]\n",
    "        relevant_docs = relevant_docs_acquired\n",
    "\n",
    "    relevant_docs_content = relevant_docs_content[:num_docs_final]\n",
    "    relevant_docs_indexed = relevant_docs[:num_docs_final]\n",
    "\n",
    "    # Build the final prompt\n",
    "    context = \"\\nExtracted documents:\\n\"\n",
    "    context += \"\".join([f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(relevant_docs_content)])\n",
    "\n",
    "    context_and_question = f\"Please provide concise answers. Extract the most relevant information from the given context while keeping the responses as short as possible. Include multiple correct answers if necessary. If no relevant context, then say 'I dont know'.\\n\\nContext:\\n{context}\\n\\nQuestion:\\n{question}\\n\\nAgain we just want main key points in the answers. For example, if the question is 'What is the biggest planet in the solar system?'; the answer should be 'Jupiter'\\n.Answer:\"\n",
    "    \n",
    "    answer = llm.invoke(context_and_question)\n",
    "    \n",
    "    if answer is not None:\n",
    "        new_answer = answer.split(': ', 1)\n",
    "        if len(new_answer) > 1:\n",
    "            answer = new_answer[1]\n",
    "        else:\n",
    "            answer = new_answer[0]\n",
    "    # print(f\"Question: {question}\")\n",
    "    \n",
    "    forbidden_list = [\"According to the provided context, \", \"Based on the provided context,\", '\\n']\n",
    "    for phrase in forbidden_list:\n",
    "        answer = answer.replace(phrase, \" \")\n",
    "    answer = answer.replace(\"<pad>\", \"\").replace(\"</s>\", \"\").replace(\"\\n\", \"\").strip()\n",
    "    # print(f\"Answer: {answer}\")\n",
    "    \n",
    "    return answer, relevant_docs_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VaFc5mg2vbk"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "qH40Baoa7MNC"
   },
   "outputs": [],
   "source": [
    "# specify output csv \n",
    "input_file = 'qa_gold-llama-1-shot-no_chat_template.csv'\n",
    "output_file = 'llama-1-shot-no_chat_template-output.csv'\n",
    "csv_input_dir = f'csv_qa_gold/{input_file}'\n",
    "csv_output_dir = f'csv_qa_gold/{output_file}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model_answer_column(df):\n",
    "    if 'ModelAnswer' not in df.columns:\n",
    "        df['ModelAnswer'] = None\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(191, 3)\n",
      "(191, 3)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "directory_csv = 'csv_qa_gold'\n",
    "csv_files = ['csv_qa_gold/test_combined.csv']\n",
    "\n",
    "# read in the csv files in the directory and concatenate\n",
    "df_total = pd.DataFrame()\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    print(df.shape)\n",
    "    df_total = pd.concat([df_total, df], axis=0)\n",
    "print(df_total.shape)\n",
    "df_total = initialize_model_answer_column(df_total)\n",
    "df_total.to_csv(csv_input_dir, index=False) \n",
    "# doing this so the original is untouched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_total.iloc[10:20, :] # please check that excel does not fuck up for row 15,16 the November 2006 to Nov-06 or some other format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(question,llm, return_relevant_docs = False):\n",
    "    answer, relevant_docs = answer_llama_new(question, KNOWLEDGE_VECTOR_DATABASE,\n",
    "                            reranker=RERANKER, llm = llm)\n",
    "    if return_relevant_docs:\n",
    "        return answer, relevant_docs\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "97CmQOe4shpp"
   },
   "outputs": [],
   "source": [
    "# Function to run over a list of questions and return the answers\n",
    "# Define the function to process the CSV and add model answers\n",
    "\n",
    "def generate_answers_and_save(csv_path, llm):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if 'ModelAnswer' not in df.columns:\n",
    "        df['ModelAnswer'] = ''\n",
    "    for index, row in df.iterrows():\n",
    "        ModelAnswer = generate_answer(row['Question'],llm=llm)\n",
    "        df.at[index, 'ModelAnswer'] = ModelAnswer\n",
    "        df.to_csv(csv_output_dir, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 43.69it/s]\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       7.17 ms /    12 runs   (    0.60 ms per token,  1672.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10044.01 ms /   979 tokens (   10.26 ms per token,    97.47 tokens per second)\n",
      "llama_print_timings:        eval time =     272.85 ms /    11 runs   (   24.80 ms per token,    40.32 tokens per second)\n",
      "llama_print_timings:       total time =   10603.53 ms /   990 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 236.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 30.24it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      13.81 ms /    23 runs   (    0.60 ms per token,  1665.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9807.40 ms /  1024 tokens (    9.58 ms per token,   104.41 tokens per second)\n",
      "llama_print_timings:        eval time =     576.37 ms /    22 runs   (   26.20 ms per token,    38.17 tokens per second)\n",
      "llama_print_timings:       total time =   10712.94 ms /  1046 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 236.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 30.43it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      13.16 ms /    22 runs   (    0.60 ms per token,  1671.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     544.89 ms /    56 tokens (    9.73 ms per token,   102.77 tokens per second)\n",
      "llama_print_timings:        eval time =     551.73 ms /    21 runs   (   26.27 ms per token,    38.06 tokens per second)\n",
      "llama_print_timings:       total time =    1184.31 ms /    77 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 290.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.68it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      10.28 ms /    17 runs   (    0.60 ms per token,  1653.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5811.24 ms /   589 tokens (    9.87 ms per token,   101.36 tokens per second)\n",
      "llama_print_timings:        eval time =     422.49 ms /    16 runs   (   26.41 ms per token,    37.87 tokens per second)\n",
      "llama_print_timings:       total time =    6437.37 ms /   605 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 236.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 30.32it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      19.93 ms /    33 runs   (    0.60 ms per token,  1655.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4625.19 ms /   471 tokens (    9.82 ms per token,   101.83 tokens per second)\n",
      "llama_print_timings:        eval time =     837.14 ms /    32 runs   (   26.16 ms per token,    38.23 tokens per second)\n",
      "llama_print_timings:       total time =    5692.86 ms /   503 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 327.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 21.56it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      13.19 ms /    22 runs   (    0.60 ms per token,  1667.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17986.78 ms /  1871 tokens (    9.61 ms per token,   104.02 tokens per second)\n",
      "llama_print_timings:        eval time =     573.75 ms /    21 runs   (   27.32 ms per token,    36.60 tokens per second)\n",
      "llama_print_timings:       total time =   19093.97 ms /  1892 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 271.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.98it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      18.63 ms /    31 runs   (    0.60 ms per token,  1664.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14840.51 ms /  1560 tokens (    9.51 ms per token,   105.12 tokens per second)\n",
      "llama_print_timings:        eval time =     819.23 ms /    31 runs   (   26.43 ms per token,    37.84 tokens per second)\n",
      "llama_print_timings:       total time =   16146.31 ms /  1591 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 271.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.87it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      16.74 ms /    28 runs   (    0.60 ms per token,  1672.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     607.11 ms /    61 tokens (    9.95 ms per token,   100.48 tokens per second)\n",
      "llama_print_timings:        eval time =     715.17 ms /    27 runs   (   26.49 ms per token,    37.75 tokens per second)\n",
      "llama_print_timings:       total time =    1433.82 ms /    88 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 236.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 30.52it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      17.41 ms /    29 runs   (    0.60 ms per token,  1665.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13635.05 ms /  1440 tokens (    9.47 ms per token,   105.61 tokens per second)\n",
      "llama_print_timings:        eval time =     759.90 ms /    29 runs   (   26.20 ms per token,    38.16 tokens per second)\n",
      "llama_print_timings:       total time =   14848.02 ms /  1469 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 271.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 23.03it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       4.85 ms /     8 runs   (    0.61 ms per token,  1650.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13559.90 ms /  1432 tokens (    9.47 ms per token,   105.61 tokens per second)\n",
      "llama_print_timings:        eval time =     184.94 ms /     7 runs   (   26.42 ms per token,    37.85 tokens per second)\n",
      "llama_print_timings:       total time =   14123.91 ms /  1439 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 283.0 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 25.35it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       1.22 ms /     2 runs   (    0.61 ms per token,  1636.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11556.80 ms /  1216 tokens (    9.50 ms per token,   105.22 tokens per second)\n",
      "llama_print_timings:        eval time =      27.10 ms /     1 runs   (   27.10 ms per token,    36.90 tokens per second)\n",
      "llama_print_timings:       total time =   11888.47 ms /  1217 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 309.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.19it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       9.06 ms /    15 runs   (    0.60 ms per token,  1655.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12729.90 ms /  1347 tokens (    9.45 ms per token,   105.81 tokens per second)\n",
      "llama_print_timings:        eval time =     363.16 ms /    14 runs   (   25.94 ms per token,    38.55 tokens per second)\n",
      "llama_print_timings:       total time =   13480.22 ms /  1361 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 324.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.16it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      16.77 ms /    28 runs   (    0.60 ms per token,  1669.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12834.80 ms /  1356 tokens (    9.47 ms per token,   105.65 tokens per second)\n",
      "llama_print_timings:        eval time =     701.63 ms /    27 runs   (   25.99 ms per token,    38.48 tokens per second)\n",
      "llama_print_timings:       total time =   13971.59 ms /  1383 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 296.0 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.98it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       5.37 ms /     9 runs   (    0.60 ms per token,  1675.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14765.51 ms /  1550 tokens (    9.53 ms per token,   104.97 tokens per second)\n",
      "llama_print_timings:        eval time =     212.25 ms /     8 runs   (   26.53 ms per token,    37.69 tokens per second)\n",
      "llama_print_timings:       total time =   15399.04 ms /  1558 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 258.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 24.72it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      13.80 ms /    23 runs   (    0.60 ms per token,  1667.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12753.65 ms /  1351 tokens (    9.44 ms per token,   105.93 tokens per second)\n",
      "llama_print_timings:        eval time =     570.35 ms /    22 runs   (   25.92 ms per token,    38.57 tokens per second)\n",
      "llama_print_timings:       total time =   13742.11 ms /  1373 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 283.0 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 25.23it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      10.74 ms /    18 runs   (    0.60 ms per token,  1675.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6134.33 ms /   628 tokens (    9.77 ms per token,   102.37 tokens per second)\n",
      "llama_print_timings:        eval time =     439.57 ms /    17 runs   (   25.86 ms per token,    38.67 tokens per second)\n",
      "llama_print_timings:       total time =    6791.84 ms /   645 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 299.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.15it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      12.61 ms /    21 runs   (    0.60 ms per token,  1666.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3820.73 ms /   396 tokens (    9.65 ms per token,   103.65 tokens per second)\n",
      "llama_print_timings:        eval time =     501.80 ms /    20 runs   (   25.09 ms per token,    39.86 tokens per second)\n",
      "llama_print_timings:       total time =    4492.20 ms /   416 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 312.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.28it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       8.31 ms /    14 runs   (    0.59 ms per token,  1684.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12678.98 ms /  1344 tokens (    9.43 ms per token,   106.00 tokens per second)\n",
      "llama_print_timings:        eval time =     337.11 ms /    13 runs   (   25.93 ms per token,    38.56 tokens per second)\n",
      "llama_print_timings:       total time =   13399.15 ms /  1357 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 294.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.18it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       9.60 ms /    16 runs   (    0.60 ms per token,  1667.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14585.19 ms /  1534 tokens (    9.51 ms per token,   105.18 tokens per second)\n",
      "llama_print_timings:        eval time =     400.44 ms /    15 runs   (   26.70 ms per token,    37.46 tokens per second)\n",
      "llama_print_timings:       total time =   15425.41 ms /  1549 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 359.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 21.26it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      13.23 ms /    22 runs   (    0.60 ms per token,  1662.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18056.32 ms /  1868 tokens (    9.67 ms per token,   103.45 tokens per second)\n",
      "llama_print_timings:        eval time =     571.61 ms /    21 runs   (   27.22 ms per token,    36.74 tokens per second)\n",
      "llama_print_timings:       total time =   19176.84 ms /  1889 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 320.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 21.96it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      48.07 ms /    80 runs   (    0.60 ms per token,  1664.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12586.29 ms /  1267 tokens (    9.93 ms per token,   100.67 tokens per second)\n",
      "llama_print_timings:        eval time =    2163.03 ms /    79 runs   (   27.38 ms per token,    36.52 tokens per second)\n",
      "llama_print_timings:       total time =   15365.78 ms /  1346 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 283.0 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 25.18it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       7.81 ms /    13 runs   (    0.60 ms per token,  1664.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17173.09 ms /  1784 tokens (    9.63 ms per token,   103.88 tokens per second)\n",
      "llama_print_timings:        eval time =     354.55 ms /    13 runs   (   27.27 ms per token,    36.67 tokens per second)\n",
      "llama_print_timings:       total time =   18029.50 ms /  1797 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 313.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.02it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      14.95 ms /    25 runs   (    0.60 ms per token,  1672.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15601.88 ms /  1630 tokens (    9.57 ms per token,   104.47 tokens per second)\n",
      "llama_print_timings:        eval time =     641.03 ms /    24 runs   (   26.71 ms per token,    37.44 tokens per second)\n",
      "llama_print_timings:       total time =   16742.96 ms /  1654 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 289.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 23.06it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      20.96 ms /    35 runs   (    0.60 ms per token,  1670.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16057.01 ms /  1675 tokens (    9.59 ms per token,   104.32 tokens per second)\n",
      "llama_print_timings:        eval time =     911.76 ms /    34 runs   (   26.82 ms per token,    37.29 tokens per second)\n",
      "llama_print_timings:       total time =   17516.41 ms /  1709 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 301.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.09it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       8.99 ms /    15 runs   (    0.60 ms per token,  1669.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15599.46 ms /  1630 tokens (    9.57 ms per token,   104.49 tokens per second)\n",
      "llama_print_timings:        eval time =     376.85 ms /    14 runs   (   26.92 ms per token,    37.15 tokens per second)\n",
      "llama_print_timings:       total time =   16445.15 ms /  1644 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 313.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.16it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       3.59 ms /     6 runs   (    0.60 ms per token,  1673.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17074.41 ms /  1775 tokens (    9.62 ms per token,   103.96 tokens per second)\n",
      "llama_print_timings:        eval time =     138.84 ms /     5 runs   (   27.77 ms per token,    36.01 tokens per second)\n",
      "llama_print_timings:       total time =   17685.21 ms /  1780 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 307.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.02it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      21.55 ms /    36 runs   (    0.60 ms per token,  1670.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14923.97 ms /  1565 tokens (    9.54 ms per token,   104.86 tokens per second)\n",
      "llama_print_timings:        eval time =     924.87 ms /    35 runs   (   26.42 ms per token,    37.84 tokens per second)\n",
      "llama_print_timings:       total time =   16369.95 ms /  1600 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 307.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.11it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       8.44 ms /    14 runs   (    0.60 ms per token,  1659.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14440.81 ms /  1516 tokens (    9.53 ms per token,   104.98 tokens per second)\n",
      "llama_print_timings:        eval time =     343.23 ms /    13 runs   (   26.40 ms per token,    37.88 tokens per second)\n",
      "llama_print_timings:       total time =   15220.08 ms /  1529 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 307.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.11it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      10.78 ms /    18 runs   (    0.60 ms per token,  1669.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15625.57 ms /  1636 tokens (    9.55 ms per token,   104.70 tokens per second)\n",
      "llama_print_timings:        eval time =     455.83 ms /    17 runs   (   26.81 ms per token,    37.29 tokens per second)\n",
      "llama_print_timings:       total time =   16558.04 ms /  1653 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 190.0 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 34.94it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       7.29 ms /    12 runs   (    0.61 ms per token,  1646.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6044.25 ms /   662 tokens (    9.13 ms per token,   109.53 tokens per second)\n",
      "llama_print_timings:        eval time =     264.85 ms /    11 runs   (   24.08 ms per token,    41.53 tokens per second)\n",
      "llama_print_timings:       total time =    6517.17 ms /   673 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 284.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 23.07it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      13.76 ms /    23 runs   (    0.60 ms per token,  1672.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =   19420.29 ms /  2000 tokens (    9.71 ms per token,   102.99 tokens per second)\n",
      "llama_print_timings:        eval time =     612.89 ms /    22 runs   (   27.86 ms per token,    35.90 tokens per second)\n",
      "llama_print_timings:       total time =   20631.15 ms /  2022 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 307.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.09it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      17.96 ms /    30 runs   (    0.60 ms per token,  1670.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14466.83 ms /  1520 tokens (    9.52 ms per token,   105.07 tokens per second)\n",
      "llama_print_timings:        eval time =     762.79 ms /    29 runs   (   26.30 ms per token,    38.02 tokens per second)\n",
      "llama_print_timings:       total time =   15722.43 ms /  1549 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 315.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.07it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      12.73 ms /    21 runs   (    0.61 ms per token,  1649.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15925.83 ms /  1663 tokens (    9.58 ms per token,   104.42 tokens per second)\n",
      "llama_print_timings:        eval time =     539.73 ms /    20 runs   (   26.99 ms per token,    37.06 tokens per second)\n",
      "llama_print_timings:       total time =   16969.69 ms /  1683 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 359.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.44it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    13 runs   (    0.60 ms per token,  1658.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18628.18 ms /  1922 tokens (    9.69 ms per token,   103.18 tokens per second)\n",
      "llama_print_timings:        eval time =     331.54 ms /    12 runs   (   27.63 ms per token,    36.19 tokens per second)\n",
      "llama_print_timings:       total time =   19499.09 ms /  1934 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 359.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 21.26it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      14.39 ms /    24 runs   (    0.60 ms per token,  1667.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18738.99 ms /  1933 tokens (    9.69 ms per token,   103.15 tokens per second)\n",
      "llama_print_timings:        eval time =     632.83 ms /    23 runs   (   27.51 ms per token,    36.34 tokens per second)\n",
      "llama_print_timings:       total time =   19954.73 ms /  1956 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 359.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 21.28it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      49.27 ms /    82 runs   (    0.60 ms per token,  1664.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9766.34 ms /   992 tokens (    9.85 ms per token,   101.57 tokens per second)\n",
      "llama_print_timings:        eval time =    2165.69 ms /    81 runs   (   26.74 ms per token,    37.40 tokens per second)\n",
      "llama_print_timings:       total time =   12483.21 ms /  1073 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 359.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 21.18it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       5.41 ms /     9 runs   (    0.60 ms per token,  1663.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18396.67 ms /  1903 tokens (    9.67 ms per token,   103.44 tokens per second)\n",
      "llama_print_timings:        eval time =     221.21 ms /     8 runs   (   27.65 ms per token,    36.17 tokens per second)\n",
      "llama_print_timings:       total time =   19142.15 ms /  1911 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 320.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 21.91it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      13.53 ms /    22 runs   (    0.62 ms per token,  1625.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10277.71 ms /  1047 tokens (    9.82 ms per token,   101.87 tokens per second)\n",
      "llama_print_timings:        eval time =     562.54 ms /    21 runs   (   26.79 ms per token,    37.33 tokens per second)\n",
      "llama_print_timings:       total time =   11202.84 ms /  1068 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 359.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.44it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      26.32 ms /    44 runs   (    0.60 ms per token,  1671.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17981.05 ms /  1864 tokens (    9.65 ms per token,   103.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1204.84 ms /    44 runs   (   27.38 ms per token,    36.52 tokens per second)\n",
      "llama_print_timings:       total time =   19848.54 ms /  1908 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 323.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.73it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      31.91 ms /    53 runs   (    0.60 ms per token,  1661.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12392.61 ms /  1314 tokens (    9.43 ms per token,   106.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1339.91 ms /    52 runs   (   25.77 ms per token,    38.81 tokens per second)\n",
      "llama_print_timings:       total time =   14271.91 ms /  1366 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 340.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.75it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      18.05 ms /    30 runs   (    0.60 ms per token,  1662.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14376.17 ms /  1514 tokens (    9.50 ms per token,   105.31 tokens per second)\n",
      "llama_print_timings:        eval time =     765.19 ms /    29 runs   (   26.39 ms per token,    37.90 tokens per second)\n",
      "llama_print_timings:       total time =   15647.80 ms /  1543 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 69.77it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      16.78 ms /    28 runs   (    0.60 ms per token,  1668.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1762.39 ms /   199 tokens (    8.86 ms per token,   112.91 tokens per second)\n",
      "llama_print_timings:        eval time =     612.03 ms /    27 runs   (   22.67 ms per token,    44.12 tokens per second)\n",
      "llama_print_timings:       total time =    2519.11 ms /   226 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 335.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.51it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      10.83 ms /    18 runs   (    0.60 ms per token,  1662.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12134.99 ms /  1290 tokens (    9.41 ms per token,   106.30 tokens per second)\n",
      "llama_print_timings:        eval time =     437.11 ms /    17 runs   (   25.71 ms per token,    38.89 tokens per second)\n",
      "llama_print_timings:       total time =   12975.70 ms /  1307 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 290.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 24.27it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      21.76 ms /    36 runs   (    0.60 ms per token,  1654.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10115.75 ms /  1084 tokens (    9.33 ms per token,   107.16 tokens per second)\n",
      "llama_print_timings:        eval time =     876.40 ms /    35 runs   (   25.04 ms per token,    39.94 tokens per second)\n",
      "llama_print_timings:       total time =   11405.70 ms /  1119 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 268.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 25.56it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      43.48 ms /    72 runs   (    0.60 ms per token,  1655.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12814.38 ms /  1358 tokens (    9.44 ms per token,   105.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1845.14 ms /    71 runs   (   25.99 ms per token,    38.48 tokens per second)\n",
      "llama_print_timings:       total time =   15278.59 ms /  1429 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 79.80it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       4.77 ms /     8 runs   (    0.60 ms per token,  1675.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2204.83 ms /   248 tokens (    8.89 ms per token,   112.48 tokens per second)\n",
      "llama_print_timings:        eval time =     160.36 ms /     7 runs   (   22.91 ms per token,    43.65 tokens per second)\n",
      "llama_print_timings:       total time =    2457.30 ms /   255 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 342.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.66it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      13.92 ms /    23 runs   (    0.61 ms per token,  1651.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15807.13 ms /  1656 tokens (    9.55 ms per token,   104.76 tokens per second)\n",
      "llama_print_timings:        eval time =     612.45 ms /    23 runs   (   26.63 ms per token,    37.55 tokens per second)\n",
      "llama_print_timings:       total time =   16944.29 ms /  1679 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 291.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.27it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       3.60 ms /     6 runs   (    0.60 ms per token,  1668.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10698.49 ms /  1144 tokens (    9.35 ms per token,   106.93 tokens per second)\n",
      "llama_print_timings:        eval time =     128.22 ms /     5 runs   (   25.64 ms per token,    39.00 tokens per second)\n",
      "llama_print_timings:       total time =   11151.71 ms /  1149 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 342.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.48it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      10.28 ms /    17 runs   (    0.60 ms per token,  1653.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16155.51 ms /  1688 tokens (    9.57 ms per token,   104.48 tokens per second)\n",
      "llama_print_timings:        eval time =     427.16 ms /    16 runs   (   26.70 ms per token,    37.46 tokens per second)\n",
      "llama_print_timings:       total time =   17096.29 ms /  1704 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 250.0 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 25.10it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      16.36 ms /    27 runs   (    0.61 ms per token,  1649.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12562.71 ms /  1330 tokens (    9.45 ms per token,   105.87 tokens per second)\n",
      "llama_print_timings:        eval time =     671.57 ms /    26 runs   (   25.83 ms per token,    38.72 tokens per second)\n",
      "llama_print_timings:       total time =   13691.31 ms /  1356 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 317.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.92it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      14.93 ms /    25 runs   (    0.60 ms per token,  1674.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     859.69 ms /    90 tokens (    9.55 ms per token,   104.69 tokens per second)\n",
      "llama_print_timings:        eval time =     582.66 ms /    24 runs   (   24.28 ms per token,    41.19 tokens per second)\n",
      "llama_print_timings:       total time =    1551.22 ms /   114 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 250.0 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 24.69it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      15.68 ms /    26 runs   (    0.60 ms per token,  1658.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12569.14 ms /  1333 tokens (    9.43 ms per token,   106.05 tokens per second)\n",
      "llama_print_timings:        eval time =     645.92 ms /    25 runs   (   25.84 ms per token,    38.70 tokens per second)\n",
      "llama_print_timings:       total time =   13664.43 ms /  1358 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 311.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.20it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      41.62 ms /    69 runs   (    0.60 ms per token,  1657.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11789.09 ms /  1256 tokens (    9.39 ms per token,   106.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1742.57 ms /    68 runs   (   25.63 ms per token,    39.02 tokens per second)\n",
      "llama_print_timings:       total time =   14121.80 ms /  1324 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 278.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 23.13it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      19.19 ms /    32 runs   (    0.60 ms per token,  1667.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7267.74 ms /   752 tokens (    9.66 ms per token,   103.47 tokens per second)\n",
      "llama_print_timings:        eval time =     799.94 ms /    31 runs   (   25.80 ms per token,    38.75 tokens per second)\n",
      "llama_print_timings:       total time =    8384.15 ms /   783 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 331.0 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.36it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      11.47 ms /    19 runs   (    0.60 ms per token,  1656.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11164.71 ms /  1191 tokens (    9.37 ms per token,   106.68 tokens per second)\n",
      "llama_print_timings:        eval time =     459.38 ms /    18 runs   (   25.52 ms per token,    39.18 tokens per second)\n",
      "llama_print_timings:       total time =   12013.32 ms /  1209 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 306.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.11it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      15.06 ms /    25 runs   (    0.60 ms per token,  1659.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14223.75 ms /  1498 tokens (    9.50 ms per token,   105.32 tokens per second)\n",
      "llama_print_timings:        eval time =     631.29 ms /    24 runs   (   26.30 ms per token,    38.02 tokens per second)\n",
      "llama_print_timings:       total time =   15352.69 ms /  1522 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 385.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.24it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      20.37 ms /    34 runs   (    0.60 ms per token,  1669.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17784.22 ms /  1843 tokens (    9.65 ms per token,   103.63 tokens per second)\n",
      "llama_print_timings:        eval time =     899.71 ms /    33 runs   (   27.26 ms per token,    36.68 tokens per second)\n",
      "llama_print_timings:       total time =   19305.07 ms /  1876 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 332.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.11it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =     140.31 ms /   233 runs   (    0.60 ms per token,  1660.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16927.93 ms /  1759 tokens (    9.62 ms per token,   103.91 tokens per second)\n",
      "llama_print_timings:        eval time =    6308.24 ms /   232 runs   (   27.19 ms per token,    36.78 tokens per second)\n",
      "llama_print_timings:       total time =   24625.83 ms /  1991 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 273.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.86it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      12.07 ms /    20 runs   (    0.60 ms per token,  1656.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14702.21 ms /  1542 tokens (    9.53 ms per token,   104.88 tokens per second)\n",
      "llama_print_timings:        eval time =     505.39 ms /    19 runs   (   26.60 ms per token,    37.59 tokens per second)\n",
      "llama_print_timings:       total time =   15700.28 ms /  1561 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 344.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 23.07it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      57.23 ms /    95 runs   (    0.60 ms per token,  1660.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15157.64 ms /  1589 tokens (    9.54 ms per token,   104.83 tokens per second)\n",
      "llama_print_timings:        eval time =    2505.04 ms /    94 runs   (   26.65 ms per token,    37.52 tokens per second)\n",
      "llama_print_timings:       total time =   18450.69 ms /  1683 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 341.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.69it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      54.90 ms /    91 runs   (    0.60 ms per token,  1657.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12124.08 ms /  1288 tokens (    9.41 ms per token,   106.23 tokens per second)\n",
      "llama_print_timings:        eval time =    2347.40 ms /    91 runs   (   25.80 ms per token,    38.77 tokens per second)\n",
      "llama_print_timings:       total time =   15154.69 ms /  1379 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 323.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 23.25it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =     124.44 ms /   207 runs   (    0.60 ms per token,  1663.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15130.62 ms /  1584 tokens (    9.55 ms per token,   104.69 tokens per second)\n",
      "llama_print_timings:        eval time =    5534.94 ms /   207 runs   (   26.74 ms per token,    37.40 tokens per second)\n",
      "llama_print_timings:       total time =   21901.06 ms /  1791 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 80.47it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      45.67 ms /    76 runs   (    0.60 ms per token,  1664.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1921.08 ms /   216 tokens (    8.89 ms per token,   112.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1724.12 ms /    76 runs   (   22.69 ms per token,    44.08 tokens per second)\n",
      "llama_print_timings:       total time =    3965.71 ms /   292 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 43.52it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      55.10 ms /    91 runs   (    0.61 ms per token,  1651.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13317.78 ms /  1406 tokens (    9.47 ms per token,   105.57 tokens per second)\n",
      "llama_print_timings:        eval time =    2355.74 ms /    90 runs   (   26.17 ms per token,    38.20 tokens per second)\n",
      "llama_print_timings:       total time =   16401.94 ms /  1496 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 81.00it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      27.48 ms /    46 runs   (    0.60 ms per token,  1673.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2331.34 ms /   262 tokens (    8.90 ms per token,   112.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1020.78 ms /    45 runs   (   22.68 ms per token,    44.08 tokens per second)\n",
      "llama_print_timings:       total time =    3582.94 ms /   307 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 38.71it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       7.19 ms /    12 runs   (    0.60 ms per token,  1669.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7190.49 ms /   784 tokens (    9.17 ms per token,   109.03 tokens per second)\n",
      "llama_print_timings:        eval time =     291.87 ms /    12 runs   (   24.32 ms per token,    41.11 tokens per second)\n",
      "llama_print_timings:       total time =    7738.68 ms /   796 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 79.11it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      14.50 ms /    24 runs   (    0.60 ms per token,  1655.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1414.39 ms /   160 tokens (    8.84 ms per token,   113.12 tokens per second)\n",
      "llama_print_timings:        eval time =     537.96 ms /    24 runs   (   22.41 ms per token,    44.61 tokens per second)\n",
      "llama_print_timings:       total time =    2078.88 ms /   184 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 356.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.81it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      19.88 ms /    33 runs   (    0.60 ms per token,  1659.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18356.24 ms /  1900 tokens (    9.66 ms per token,   103.51 tokens per second)\n",
      "llama_print_timings:        eval time =     886.02 ms /    32 runs   (   27.69 ms per token,    36.12 tokens per second)\n",
      "llama_print_timings:       total time =   19884.61 ms /  1932 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 327.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.06it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      19.42 ms /    32 runs   (    0.61 ms per token,  1647.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16601.62 ms /  1728 tokens (    9.61 ms per token,   104.09 tokens per second)\n",
      "llama_print_timings:        eval time =     860.87 ms /    32 runs   (   26.90 ms per token,    37.17 tokens per second)\n",
      "llama_print_timings:       total time =   18054.94 ms /  1760 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 313.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.72it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      69.33 ms /   114 runs   (    0.61 ms per token,  1644.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15510.48 ms /  1624 tokens (    9.55 ms per token,   104.70 tokens per second)\n",
      "llama_print_timings:        eval time =    3042.23 ms /   114 runs   (   26.69 ms per token,    37.47 tokens per second)\n",
      "llama_print_timings:       total time =   19433.06 ms /  1738 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 266.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 24.48it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      19.35 ms /    32 runs   (    0.60 ms per token,  1653.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =   19501.58 ms /  2003 tokens (    9.74 ms per token,   102.71 tokens per second)\n",
      "llama_print_timings:        eval time =     858.47 ms /    31 runs   (   27.69 ms per token,    36.11 tokens per second)\n",
      "llama_print_timings:       total time =   21036.20 ms /  2034 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 292.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.27it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       8.46 ms /    14 runs   (    0.60 ms per token,  1654.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12491.31 ms /  1322 tokens (    9.45 ms per token,   105.83 tokens per second)\n",
      "llama_print_timings:        eval time =     335.14 ms /    13 runs   (   25.78 ms per token,    38.79 tokens per second)\n",
      "llama_print_timings:       total time =   13241.11 ms /  1335 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 271.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.96it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       5.42 ms /     9 runs   (    0.60 ms per token,  1659.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12823.76 ms /  1355 tokens (    9.46 ms per token,   105.66 tokens per second)\n",
      "llama_print_timings:        eval time =     208.87 ms /     8 runs   (   26.11 ms per token,    38.30 tokens per second)\n",
      "llama_print_timings:       total time =   13435.40 ms /  1363 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 80.26it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      10.84 ms /    18 runs   (    0.60 ms per token,  1659.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1491.99 ms /   168 tokens (    8.88 ms per token,   112.60 tokens per second)\n",
      "llama_print_timings:        eval time =     404.09 ms /    18 runs   (   22.45 ms per token,    44.54 tokens per second)\n",
      "llama_print_timings:       total time =    2003.89 ms /   186 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 345.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.60it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      13.26 ms /    22 runs   (    0.60 ms per token,  1658.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17882.28 ms /  1852 tokens (    9.66 ms per token,   103.57 tokens per second)\n",
      "llama_print_timings:        eval time =     575.55 ms /    21 runs   (   27.41 ms per token,    36.49 tokens per second)\n",
      "llama_print_timings:       total time =   19048.71 ms /  1873 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 333.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.01it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      15.58 ms /    26 runs   (    0.60 ms per token,  1668.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16873.78 ms /  1757 tokens (    9.60 ms per token,   104.13 tokens per second)\n",
      "llama_print_timings:        eval time =     678.01 ms /    25 runs   (   27.12 ms per token,    36.87 tokens per second)\n",
      "llama_print_timings:       total time =   18131.62 ms /  1782 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 82.10it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      22.83 ms /    38 runs   (    0.60 ms per token,  1664.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1508.17 ms /   170 tokens (    8.87 ms per token,   112.72 tokens per second)\n",
      "llama_print_timings:        eval time =     830.55 ms /    37 runs   (   22.45 ms per token,    44.55 tokens per second)\n",
      "llama_print_timings:       total time =    2515.71 ms /   207 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 358.0 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.70it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      18.05 ms /    30 runs   (    0.60 ms per token,  1661.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15186.60 ms /  1592 tokens (    9.54 ms per token,   104.83 tokens per second)\n",
      "llama_print_timings:        eval time =     767.86 ms /    29 runs   (   26.48 ms per token,    37.77 tokens per second)\n",
      "llama_print_timings:       total time =   16501.07 ms /  1621 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 324.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 23.29it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      25.89 ms /    43 runs   (    0.60 ms per token,  1661.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15020.18 ms /  1572 tokens (    9.55 ms per token,   104.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1116.11 ms /    42 runs   (   26.57 ms per token,    37.63 tokens per second)\n",
      "llama_print_timings:       total time =   16724.91 ms /  1614 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 234.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 30.19it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      27.99 ms /    46 runs   (    0.61 ms per token,  1643.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16147.98 ms /  1683 tokens (    9.59 ms per token,   104.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1207.81 ms /    45 runs   (   26.84 ms per token,    37.26 tokens per second)\n",
      "llama_print_timings:       total time =   17991.66 ms /  1728 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 301.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.05it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      34.88 ms /    58 runs   (    0.60 ms per token,  1663.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18632.78 ms /  1918 tokens (    9.71 ms per token,   102.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1568.68 ms /    57 runs   (   27.52 ms per token,    36.34 tokens per second)\n",
      "llama_print_timings:       total time =   20946.48 ms /  1975 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 81.75it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      18.07 ms /    30 runs   (    0.60 ms per token,  1660.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1535.45 ms /   172 tokens (    8.93 ms per token,   112.02 tokens per second)\n",
      "llama_print_timings:        eval time =     651.29 ms /    29 runs   (   22.46 ms per token,    44.53 tokens per second)\n",
      "llama_print_timings:       total time =    2336.90 ms /   201 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 81.14it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       1.20 ms /     2 runs   (    0.60 ms per token,  1673.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1383.44 ms /   156 tokens (    8.87 ms per token,   112.76 tokens per second)\n",
      "llama_print_timings:        eval time =      23.41 ms /     1 runs   (   23.41 ms per token,    42.72 tokens per second)\n",
      "llama_print_timings:       total time =    1454.95 ms /   157 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 80.36it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      19.89 ms /    33 runs   (    0.60 ms per token,  1659.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1652.42 ms /   186 tokens (    8.88 ms per token,   112.56 tokens per second)\n",
      "llama_print_timings:        eval time =     721.73 ms /    32 runs   (   22.55 ms per token,    44.34 tokens per second)\n",
      "llama_print_timings:       total time =    2539.42 ms /   218 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 79.02it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       5.44 ms /     9 runs   (    0.60 ms per token,  1653.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1691.43 ms /   192 tokens (    8.81 ms per token,   113.51 tokens per second)\n",
      "llama_print_timings:        eval time =     207.62 ms /     9 runs   (   23.07 ms per token,    43.35 tokens per second)\n",
      "llama_print_timings:       total time =    1982.04 ms /   201 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 359.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.28it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      17.35 ms /    29 runs   (    0.60 ms per token,  1671.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1403.32 ms /   159 tokens (    8.83 ms per token,   113.30 tokens per second)\n",
      "llama_print_timings:        eval time =     625.25 ms /    28 runs   (   22.33 ms per token,    44.78 tokens per second)\n",
      "llama_print_timings:       total time =    2166.79 ms /   187 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 78.09it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      13.82 ms /    23 runs   (    0.60 ms per token,  1663.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1245.51 ms /   141 tokens (    8.83 ms per token,   113.21 tokens per second)\n",
      "llama_print_timings:        eval time =     490.83 ms /    22 runs   (   22.31 ms per token,    44.82 tokens per second)\n",
      "llama_print_timings:       total time =    1851.67 ms /   163 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 285.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.29it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      16.95 ms /    28 runs   (    0.61 ms per token,  1652.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17195.71 ms /  1791 tokens (    9.60 ms per token,   104.15 tokens per second)\n",
      "llama_print_timings:        eval time =     732.65 ms /    27 runs   (   27.14 ms per token,    36.85 tokens per second)\n",
      "llama_print_timings:       total time =   18526.32 ms /  1818 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 78.67it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      50.56 ms /    84 runs   (    0.60 ms per token,  1661.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2808.27 ms /   314 tokens (    8.94 ms per token,   111.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1901.62 ms /    83 runs   (   22.91 ms per token,    43.65 tokens per second)\n",
      "llama_print_timings:       total time =    5089.25 ms /   397 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 306.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.15it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      12.64 ms /    21 runs   (    0.60 ms per token,  1661.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16057.72 ms /  1679 tokens (    9.56 ms per token,   104.56 tokens per second)\n",
      "llama_print_timings:        eval time =     537.78 ms /    20 runs   (   26.89 ms per token,    37.19 tokens per second)\n",
      "llama_print_timings:       total time =   17136.54 ms /  1699 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 264.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 23.07it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      11.01 ms /    18 runs   (    0.61 ms per token,  1634.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15937.81 ms /  1663 tokens (    9.58 ms per token,   104.34 tokens per second)\n",
      "llama_print_timings:        eval time =     457.39 ms /    17 runs   (   26.91 ms per token,    37.17 tokens per second)\n",
      "llama_print_timings:       total time =   16921.57 ms /  1680 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 312.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.07it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      59.31 ms /    98 runs   (    0.61 ms per token,  1652.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15810.91 ms /  1650 tokens (    9.58 ms per token,   104.36 tokens per second)\n",
      "llama_print_timings:        eval time =    2596.09 ms /    97 runs   (   26.76 ms per token,    37.36 tokens per second)\n",
      "llama_print_timings:       total time =   19247.72 ms /  1747 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 325.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 23.32it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      30.32 ms /    48 runs   (    0.63 ms per token,  1582.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16115.67 ms /  1680 tokens (    9.59 ms per token,   104.25 tokens per second)\n",
      "llama_print_timings:        eval time =    1292.08 ms /    48 runs   (   26.92 ms per token,    37.15 tokens per second)\n",
      "llama_print_timings:       total time =   18068.20 ms /  1728 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 633.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.31it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      45.21 ms /    75 runs   (    0.60 ms per token,  1658.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17299.40 ms /  1796 tokens (    9.63 ms per token,   103.82 tokens per second)\n",
      "llama_print_timings:        eval time =    2008.23 ms /    74 runs   (   27.14 ms per token,    36.85 tokens per second)\n",
      "llama_print_timings:       total time =   20086.58 ms /  1870 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 324.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 23.71it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      10.83 ms /    18 runs   (    0.60 ms per token,  1662.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15503.11 ms /  1621 tokens (    9.56 ms per token,   104.56 tokens per second)\n",
      "llama_print_timings:        eval time =     453.90 ms /    17 runs   (   26.70 ms per token,    37.45 tokens per second)\n",
      "llama_print_timings:       total time =   16470.01 ms /  1638 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 308.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 23.16it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      15.65 ms /    26 runs   (    0.60 ms per token,  1661.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15611.30 ms /  1632 tokens (    9.57 ms per token,   104.54 tokens per second)\n",
      "llama_print_timings:        eval time =     671.65 ms /    25 runs   (   26.87 ms per token,    37.22 tokens per second)\n",
      "llama_print_timings:       total time =   16818.81 ms /  1657 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 306.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 23.92it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      10.76 ms /    18 runs   (    0.60 ms per token,  1672.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10524.76 ms /  1123 tokens (    9.37 ms per token,   106.70 tokens per second)\n",
      "llama_print_timings:        eval time =     430.70 ms /    17 runs   (   25.34 ms per token,    39.47 tokens per second)\n",
      "llama_print_timings:       total time =   11324.89 ms /  1140 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 331.0 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.37it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      16.20 ms /    27 runs   (    0.60 ms per token,  1667.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15646.37 ms /  1634 tokens (    9.58 ms per token,   104.43 tokens per second)\n",
      "llama_print_timings:        eval time =     696.91 ms /    26 runs   (   26.80 ms per token,    37.31 tokens per second)\n",
      "llama_print_timings:       total time =   16884.90 ms /  1660 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 367.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.72it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      41.69 ms /    69 runs   (    0.60 ms per token,  1654.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15258.50 ms /  1597 tokens (    9.55 ms per token,   104.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1812.80 ms /    68 runs   (   26.66 ms per token,    37.51 tokens per second)\n",
      "llama_print_timings:       total time =   17763.25 ms /  1665 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 80.44it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      24.59 ms /    41 runs   (    0.60 ms per token,  1667.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1900.25 ms /   213 tokens (    8.92 ms per token,   112.09 tokens per second)\n",
      "llama_print_timings:        eval time =     907.14 ms /    40 runs   (   22.68 ms per token,    44.09 tokens per second)\n",
      "llama_print_timings:       total time =    3005.28 ms /   253 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 38.58it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      25.92 ms /    43 runs   (    0.60 ms per token,  1658.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8508.94 ms /   919 tokens (    9.26 ms per token,   108.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1035.07 ms /    42 runs   (   24.64 ms per token,    40.58 tokens per second)\n",
      "llama_print_timings:       total time =    9951.36 ms /   961 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 448.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 25.73it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      96.46 ms /   160 runs   (    0.60 ms per token,  1658.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5051.46 ms /   554 tokens (    9.12 ms per token,   109.67 tokens per second)\n",
      "llama_print_timings:        eval time =    3787.66 ms /   159 runs   (   23.82 ms per token,    41.98 tokens per second)\n",
      "llama_print_timings:       total time =    9567.39 ms /   713 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 81.60it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      31.17 ms /    52 runs   (    0.60 ms per token,  1668.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1456.60 ms /   164 tokens (    8.88 ms per token,   112.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1147.20 ms /    51 runs   (   22.49 ms per token,    44.46 tokens per second)\n",
      "llama_print_timings:       total time =    2825.90 ms /   215 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 518.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 27.47it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      13.94 ms /    23 runs   (    0.61 ms per token,  1650.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5220.65 ms /   576 tokens (    9.06 ms per token,   110.33 tokens per second)\n",
      "llama_print_timings:        eval time =     519.26 ms /    22 runs   (   23.60 ms per token,    42.37 tokens per second)\n",
      "llama_print_timings:       total time =    5980.25 ms /   598 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 81.79it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       9.56 ms /    16 runs   (    0.60 ms per token,  1674.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1321.16 ms /   150 tokens (    8.81 ms per token,   113.54 tokens per second)\n",
      "llama_print_timings:        eval time =     336.28 ms /    15 runs   (   22.42 ms per token,    44.61 tokens per second)\n",
      "llama_print_timings:       total time =    1751.60 ms /   165 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 344.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.64it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =     153.92 ms /   256 runs   (    0.60 ms per token,  1663.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18023.63 ms /  1868 tokens (    9.65 ms per token,   103.64 tokens per second)\n",
      "llama_print_timings:        eval time =    7022.27 ms /   255 runs   (   27.54 ms per token,    36.31 tokens per second)\n",
      "llama_print_timings:       total time =   26541.94 ms /  2123 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 342.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.52it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    11 runs   (    0.60 ms per token,  1660.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13982.28 ms /  1472 tokens (    9.50 ms per token,   105.28 tokens per second)\n",
      "llama_print_timings:        eval time =     291.74 ms /    11 runs   (   26.52 ms per token,    37.71 tokens per second)\n",
      "llama_print_timings:       total time =   14707.00 ms /  1483 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 309.0 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.67it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      18.10 ms /    30 runs   (    0.60 ms per token,  1657.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16886.40 ms /  1755 tokens (    9.62 ms per token,   103.93 tokens per second)\n",
      "llama_print_timings:        eval time =     780.34 ms /    29 runs   (   26.91 ms per token,    37.16 tokens per second)\n",
      "llama_print_timings:       total time =   18244.95 ms /  1784 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 509.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.68it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      10.21 ms /    17 runs   (    0.60 ms per token,  1664.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15560.20 ms /  1626 tokens (    9.57 ms per token,   104.50 tokens per second)\n",
      "llama_print_timings:        eval time =     426.91 ms /    16 runs   (   26.68 ms per token,    37.48 tokens per second)\n",
      "llama_print_timings:       total time =   16487.14 ms /  1642 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 38.71it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      10.90 ms /    18 runs   (    0.61 ms per token,  1650.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1164.92 ms /   120 tokens (    9.71 ms per token,   103.01 tokens per second)\n",
      "llama_print_timings:        eval time =     422.51 ms /    17 runs   (   24.85 ms per token,    40.24 tokens per second)\n",
      "llama_print_timings:       total time =    1681.41 ms /   137 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 283.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 23.09it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      13.73 ms /    23 runs   (    0.60 ms per token,  1675.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15955.78 ms /  1668 tokens (    9.57 ms per token,   104.54 tokens per second)\n",
      "llama_print_timings:        eval time =     593.43 ms /    22 runs   (   26.97 ms per token,    37.07 tokens per second)\n",
      "llama_print_timings:       total time =   17070.94 ms /  1690 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 313.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.84it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      20.98 ms /    35 runs   (    0.60 ms per token,  1668.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18431.02 ms /  1904 tokens (    9.68 ms per token,   103.30 tokens per second)\n",
      "llama_print_timings:        eval time =     931.55 ms /    34 runs   (   27.40 ms per token,    36.50 tokens per second)\n",
      "llama_print_timings:       total time =   19995.10 ms /  1938 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 78.70it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      35.76 ms /    60 runs   (    0.60 ms per token,  1678.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2600.50 ms /   290 tokens (    8.97 ms per token,   111.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1342.26 ms /    59 runs   (   22.75 ms per token,    43.96 tokens per second)\n",
      "llama_print_timings:       total time =    4216.48 ms /   349 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 80.48it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       2.98 ms /     5 runs   (    0.60 ms per token,  1678.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2059.11 ms /   232 tokens (    8.88 ms per token,   112.67 tokens per second)\n",
      "llama_print_timings:        eval time =      93.54 ms /     4 runs   (   23.38 ms per token,    42.76 tokens per second)\n",
      "llama_print_timings:       total time =    2227.73 ms /   236 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 78.39it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      65.98 ms /   110 runs   (    0.60 ms per token,  1667.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2628.72 ms /   294 tokens (    8.94 ms per token,   111.84 tokens per second)\n",
      "llama_print_timings:        eval time =    2489.95 ms /   109 runs   (   22.84 ms per token,    43.78 tokens per second)\n",
      "llama_print_timings:       total time =    5571.05 ms /   403 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 83.54it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       9.04 ms /    15 runs   (    0.60 ms per token,  1658.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1987.01 ms /   223 tokens (    8.91 ms per token,   112.23 tokens per second)\n",
      "llama_print_timings:        eval time =     320.73 ms /    14 runs   (   22.91 ms per token,    43.65 tokens per second)\n",
      "llama_print_timings:       total time =    2417.98 ms /   237 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 76.36it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       2.96 ms /     5 runs   (    0.59 ms per token,  1688.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2029.86 ms /   227 tokens (    8.94 ms per token,   111.83 tokens per second)\n",
      "llama_print_timings:        eval time =      93.18 ms /     4 runs   (   23.30 ms per token,    42.93 tokens per second)\n",
      "llama_print_timings:       total time =    2197.40 ms /   231 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 367.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.36it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      21.64 ms /    36 runs   (    0.60 ms per token,  1663.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18345.29 ms /  1899 tokens (    9.66 ms per token,   103.51 tokens per second)\n",
      "llama_print_timings:        eval time =     959.00 ms /    35 runs   (   27.40 ms per token,    36.50 tokens per second)\n",
      "llama_print_timings:       total time =   19931.75 ms /  1934 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 81.81it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      76.27 ms /   127 runs   (    0.60 ms per token,  1665.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3036.06 ms /   338 tokens (    8.98 ms per token,   111.33 tokens per second)\n",
      "llama_print_timings:        eval time =    2896.99 ms /   126 runs   (   22.99 ms per token,    43.49 tokens per second)\n",
      "llama_print_timings:       total time =    6447.13 ms /   464 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 78.55it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      33.12 ms /    55 runs   (    0.60 ms per token,  1660.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3160.22 ms /   352 tokens (    8.98 ms per token,   111.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1240.90 ms /    54 runs   (   22.98 ms per token,    43.52 tokens per second)\n",
      "llama_print_timings:       total time =    4676.07 ms /   406 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 83.06it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      30.52 ms /    51 runs   (    0.60 ms per token,  1671.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2114.58 ms /   237 tokens (    8.92 ms per token,   112.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1129.70 ms /    50 runs   (   22.59 ms per token,    44.26 tokens per second)\n",
      "llama_print_timings:       total time =    3472.31 ms /   287 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 68.96it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      16.93 ms /    28 runs   (    0.60 ms per token,  1654.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1974.66 ms /   221 tokens (    8.94 ms per token,   111.92 tokens per second)\n",
      "llama_print_timings:        eval time =     611.00 ms /    27 runs   (   22.63 ms per token,    44.19 tokens per second)\n",
      "llama_print_timings:       total time =    2737.64 ms /   248 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 80.88it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      92.69 ms /   155 runs   (    0.60 ms per token,  1672.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2707.36 ms /   304 tokens (    8.91 ms per token,   112.29 tokens per second)\n",
      "llama_print_timings:        eval time =    3551.86 ms /   155 runs   (   22.92 ms per token,    43.64 tokens per second)\n",
      "llama_print_timings:       total time =    6867.08 ms /   459 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 214.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 30.37it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       3.62 ms /     6 runs   (    0.60 ms per token,  1658.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12905.00 ms /  1368 tokens (    9.43 ms per token,   106.01 tokens per second)\n",
      "llama_print_timings:        eval time =     157.18 ms /     6 runs   (   26.20 ms per token,    38.17 tokens per second)\n",
      "llama_print_timings:       total time =   13448.51 ms /  1374 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 81.21it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      82.92 ms /   138 runs   (    0.60 ms per token,  1664.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2791.53 ms /   312 tokens (    8.95 ms per token,   111.77 tokens per second)\n",
      "llama_print_timings:        eval time =    3140.42 ms /   137 runs   (   22.92 ms per token,    43.62 tokens per second)\n",
      "llama_print_timings:       total time =    6469.96 ms /   449 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 79.43it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      39.01 ms /    65 runs   (    0.60 ms per token,  1666.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3063.73 ms /   342 tokens (    8.96 ms per token,   111.63 tokens per second)\n",
      "llama_print_timings:        eval time =    1467.28 ms /    64 runs   (   22.93 ms per token,    43.62 tokens per second)\n",
      "llama_print_timings:       total time =    4839.25 ms /   406 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 325.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.82it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      36.05 ms /    60 runs   (    0.60 ms per token,  1664.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =   19025.70 ms /  1963 tokens (    9.69 ms per token,   103.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1636.69 ms /    59 runs   (   27.74 ms per token,    36.05 tokens per second)\n",
      "llama_print_timings:       total time =   21402.88 ms /  2022 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 71.67it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      34.78 ms /    58 runs   (    0.60 ms per token,  1667.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3087.77 ms /   344 tokens (    8.98 ms per token,   111.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1307.65 ms /    57 runs   (   22.94 ms per token,    43.59 tokens per second)\n",
      "llama_print_timings:       total time =    4677.09 ms /   401 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 81.80it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      22.10 ms /    37 runs   (    0.60 ms per token,  1674.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2129.20 ms /   238 tokens (    8.95 ms per token,   111.78 tokens per second)\n",
      "llama_print_timings:        eval time =     815.58 ms /    36 runs   (   22.66 ms per token,    44.14 tokens per second)\n",
      "llama_print_timings:       total time =    3127.57 ms /   274 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 294.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.28it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      32.97 ms /    55 runs   (    0.60 ms per token,  1668.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8176.99 ms /   886 tokens (    9.23 ms per token,   108.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1324.27 ms /    54 runs   (   24.52 ms per token,    40.78 tokens per second)\n",
      "llama_print_timings:       total time =    9920.23 ms /   940 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 84.49it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      39.70 ms /    66 runs   (    0.60 ms per token,  1662.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3054.57 ms /   341 tokens (    8.96 ms per token,   111.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1490.83 ms /    65 runs   (   22.94 ms per token,    43.60 tokens per second)\n",
      "llama_print_timings:       total time =    4854.97 ms /   406 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 296.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.25it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       4.26 ms /     7 runs   (    0.61 ms per token,  1644.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15544.45 ms /  1627 tokens (    9.55 ms per token,   104.67 tokens per second)\n",
      "llama_print_timings:        eval time =     162.06 ms /     6 runs   (   27.01 ms per token,    37.02 tokens per second)\n",
      "llama_print_timings:       total time =   16169.71 ms /  1633 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 70.38it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      23.96 ms /    40 runs   (    0.60 ms per token,  1669.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2177.54 ms /   244 tokens (    8.92 ms per token,   112.05 tokens per second)\n",
      "llama_print_timings:        eval time =     883.29 ms /    39 runs   (   22.65 ms per token,    44.15 tokens per second)\n",
      "llama_print_timings:       total time =    3256.09 ms /   283 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 79.71it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      12.13 ms /    20 runs   (    0.61 ms per token,  1648.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2093.85 ms /   234 tokens (    8.95 ms per token,   111.76 tokens per second)\n",
      "llama_print_timings:        eval time =     429.13 ms /    19 runs   (   22.59 ms per token,    44.28 tokens per second)\n",
      "llama_print_timings:       total time =    2655.96 ms /   253 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 270.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.91it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       1.78 ms /     3 runs   (    0.59 ms per token,  1685.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2197.52 ms /   247 tokens (    8.90 ms per token,   112.40 tokens per second)\n",
      "llama_print_timings:        eval time =      47.97 ms /     2 runs   (   23.98 ms per token,    41.70 tokens per second)\n",
      "llama_print_timings:       total time =    2319.29 ms /   249 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 80.84it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      18.65 ms /    31 runs   (    0.60 ms per token,  1662.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1867.60 ms /   210 tokens (    8.89 ms per token,   112.44 tokens per second)\n",
      "llama_print_timings:        eval time =     676.60 ms /    30 runs   (   22.55 ms per token,    44.34 tokens per second)\n",
      "llama_print_timings:       total time =    2703.68 ms /   240 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 240.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 24.99it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      16.96 ms /    28 runs   (    0.61 ms per token,  1650.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16272.51 ms /  1701 tokens (    9.57 ms per token,   104.53 tokens per second)\n",
      "llama_print_timings:        eval time =     724.68 ms /    27 runs   (   26.84 ms per token,    37.26 tokens per second)\n",
      "llama_print_timings:       total time =   17564.96 ms /  1728 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 82.66it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      33.59 ms /    56 runs   (    0.60 ms per token,  1667.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3337.72 ms /   372 tokens (    8.97 ms per token,   111.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1266.13 ms /    55 runs   (   23.02 ms per token,    43.44 tokens per second)\n",
      "llama_print_timings:       total time =    4884.70 ms /   427 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 286.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.25it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      34.12 ms /    57 runs   (    0.60 ms per token,  1670.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17390.64 ms /  1808 tokens (    9.62 ms per token,   103.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1514.87 ms /    56 runs   (   27.05 ms per token,    36.97 tokens per second)\n",
      "llama_print_timings:       total time =   19585.54 ms /  1864 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 329.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.37it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      79.06 ms /   132 runs   (    0.60 ms per token,  1669.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11869.68 ms /  1259 tokens (    9.43 ms per token,   106.07 tokens per second)\n",
      "llama_print_timings:        eval time =    3360.57 ms /   131 runs   (   25.65 ms per token,    38.98 tokens per second)\n",
      "llama_print_timings:       total time =   16023.46 ms /  1390 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 38.91it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       3.00 ms /     5 runs   (    0.60 ms per token,  1666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2554.83 ms /   286 tokens (    8.93 ms per token,   111.94 tokens per second)\n",
      "llama_print_timings:        eval time =      92.31 ms /     4 runs   (   23.08 ms per token,    43.33 tokens per second)\n",
      "llama_print_timings:       total time =    2737.01 ms /   290 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 78.52it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      26.43 ms /    44 runs   (    0.60 ms per token,  1664.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4807.57 ms /   530 tokens (    9.07 ms per token,   110.24 tokens per second)\n",
      "llama_print_timings:        eval time =    1007.65 ms /    43 runs   (   23.43 ms per token,    42.67 tokens per second)\n",
      "llama_print_timings:       total time =    6098.08 ms /   573 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 253.0 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 24.87it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      31.18 ms /    52 runs   (    0.60 ms per token,  1667.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18316.76 ms /  1895 tokens (    9.67 ms per token,   103.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1398.37 ms /    51 runs   (   27.42 ms per token,    36.47 tokens per second)\n",
      "llama_print_timings:       total time =   20401.13 ms /  1946 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 82.63it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      11.41 ms /    19 runs   (    0.60 ms per token,  1664.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2184.49 ms /   245 tokens (    8.92 ms per token,   112.15 tokens per second)\n",
      "llama_print_timings:        eval time =     409.05 ms /    18 runs   (   22.72 ms per token,    44.00 tokens per second)\n",
      "llama_print_timings:       total time =    2719.73 ms /   263 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 192.40000000000003 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 35.32it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       3.56 ms /     6 runs   (    0.59 ms per token,  1685.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2263.52 ms /   254 tokens (    8.91 ms per token,   112.21 tokens per second)\n",
      "llama_print_timings:        eval time =     114.86 ms /     5 runs   (   22.97 ms per token,    43.53 tokens per second)\n",
      "llama_print_timings:       total time =    2463.76 ms /   259 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 79.12it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      10.18 ms /    17 runs   (    0.60 ms per token,  1670.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2490.47 ms /   280 tokens (    8.89 ms per token,   112.43 tokens per second)\n",
      "llama_print_timings:        eval time =     387.46 ms /    17 runs   (   22.79 ms per token,    43.88 tokens per second)\n",
      "llama_print_timings:       total time =    3015.91 ms /   297 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 250.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 25.11it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      60.09 ms /   100 runs   (    0.60 ms per token,  1664.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15673.16 ms /  1642 tokens (    9.55 ms per token,   104.77 tokens per second)\n",
      "llama_print_timings:        eval time =    2648.66 ms /    99 runs   (   26.75 ms per token,    37.38 tokens per second)\n",
      "llama_print_timings:       total time =   19117.23 ms /  1741 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 277.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 23.15it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       4.20 ms /     7 runs   (    0.60 ms per token,  1666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12026.16 ms /  1279 tokens (    9.40 ms per token,   106.35 tokens per second)\n",
      "llama_print_timings:        eval time =     155.74 ms /     6 runs   (   25.96 ms per token,    38.53 tokens per second)\n",
      "llama_print_timings:       total time =   12548.12 ms /  1285 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 219.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 30.44it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      28.70 ms /    48 runs   (    0.60 ms per token,  1672.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12474.26 ms /  1323 tokens (    9.43 ms per token,   106.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1209.31 ms /    47 runs   (   25.73 ms per token,    38.87 tokens per second)\n",
      "llama_print_timings:       total time =   14204.15 ms /  1370 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 304.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.36it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    11 runs   (    0.60 ms per token,  1678.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8112.53 ms /   880 tokens (    9.22 ms per token,   108.47 tokens per second)\n",
      "llama_print_timings:        eval time =     245.91 ms /    10 runs   (   24.59 ms per token,    40.67 tokens per second)\n",
      "llama_print_timings:       total time =    8626.22 ms /   890 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 215.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 30.49it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       9.56 ms /    16 runs   (    0.60 ms per token,  1673.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2122.83 ms /   238 tokens (    8.92 ms per token,   112.11 tokens per second)\n",
      "llama_print_timings:        eval time =     339.41 ms /    15 runs   (   22.63 ms per token,    44.19 tokens per second)\n",
      "llama_print_timings:       total time =    2575.23 ms /   253 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 75.57it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      57.55 ms /    96 runs   (    0.60 ms per token,  1668.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2418.39 ms /   272 tokens (    8.89 ms per token,   112.47 tokens per second)\n",
      "llama_print_timings:        eval time =    2163.35 ms /    95 runs   (   22.77 ms per token,    43.91 tokens per second)\n",
      "llama_print_timings:       total time =    4984.78 ms /   367 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 70.13it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      81.68 ms /   137 runs   (    0.60 ms per token,  1677.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2607.62 ms /   291 tokens (    8.96 ms per token,   111.60 tokens per second)\n",
      "llama_print_timings:        eval time =    3104.84 ms /   136 runs   (   22.83 ms per token,    43.80 tokens per second)\n",
      "llama_print_timings:       total time =    6239.91 ms /   427 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 81.84it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      34.12 ms /    57 runs   (    0.60 ms per token,  1670.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2062.39 ms /   232 tokens (    8.89 ms per token,   112.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1285.92 ms /    57 runs   (   22.56 ms per token,    44.33 tokens per second)\n",
      "llama_print_timings:       total time =    3592.97 ms /   289 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 80.64it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      48.73 ms /    81 runs   (    0.60 ms per token,  1662.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3171.83 ms /   354 tokens (    8.96 ms per token,   111.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1833.33 ms /    80 runs   (   22.92 ms per token,    43.64 tokens per second)\n",
      "llama_print_timings:       total time =    5363.71 ms /   434 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 83.16it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      33.97 ms /    57 runs   (    0.60 ms per token,  1677.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2989.21 ms /   335 tokens (    8.92 ms per token,   112.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1281.03 ms /    56 runs   (   22.88 ms per token,    43.71 tokens per second)\n",
      "llama_print_timings:       total time =    4538.77 ms /   391 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 308.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.05it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      20.64 ms /    34 runs   (    0.61 ms per token,  1647.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17540.97 ms /  1826 tokens (    9.61 ms per token,   104.10 tokens per second)\n",
      "llama_print_timings:        eval time =     898.73 ms /    33 runs   (   27.23 ms per token,    36.72 tokens per second)\n",
      "llama_print_timings:       total time =   19075.91 ms /  1859 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 79.74it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      67.38 ms /   112 runs   (    0.60 ms per token,  1662.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3125.67 ms /   349 tokens (    8.96 ms per token,   111.66 tokens per second)\n",
      "llama_print_timings:        eval time =    2554.55 ms /   111 runs   (   23.01 ms per token,    43.45 tokens per second)\n",
      "llama_print_timings:       total time =    6165.04 ms /   460 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 80.96it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      42.39 ms /    71 runs   (    0.60 ms per token,  1674.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3565.76 ms /   398 tokens (    8.96 ms per token,   111.62 tokens per second)\n",
      "llama_print_timings:        eval time =    1616.74 ms /    70 runs   (   23.10 ms per token,    43.30 tokens per second)\n",
      "llama_print_timings:       total time =    5516.04 ms /   468 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 275.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 23.06it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      30.28 ms /    50 runs   (    0.61 ms per token,  1651.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16288.40 ms /  1703 tokens (    9.56 ms per token,   104.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1312.41 ms /    49 runs   (   26.78 ms per token,    37.34 tokens per second)\n",
      "llama_print_timings:       total time =   18254.68 ms /  1752 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 208.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 35.50it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      20.56 ms /    34 runs   (    0.60 ms per token,  1653.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16696.19 ms /  1739 tokens (    9.60 ms per token,   104.16 tokens per second)\n",
      "llama_print_timings:        eval time =     889.72 ms /    33 runs   (   26.96 ms per token,    37.09 tokens per second)\n",
      "llama_print_timings:       total time =   18184.15 ms /  1772 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 321.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.77it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       2.41 ms /     4 runs   (    0.60 ms per token,  1663.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6928.69 ms /   756 tokens (    9.16 ms per token,   109.11 tokens per second)\n",
      "llama_print_timings:        eval time =      75.60 ms /     3 runs   (   25.20 ms per token,    39.68 tokens per second)\n",
      "llama_print_timings:       total time =    7216.54 ms /   759 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 76.80it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      57.97 ms /    97 runs   (    0.60 ms per token,  1673.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3134.19 ms /   349 tokens (    8.98 ms per token,   111.35 tokens per second)\n",
      "llama_print_timings:        eval time =    2205.05 ms /    96 runs   (   22.97 ms per token,    43.54 tokens per second)\n",
      "llama_print_timings:       total time =    5752.05 ms /   445 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 80.97it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      43.25 ms /    72 runs   (    0.60 ms per token,  1664.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3510.07 ms /   391 tokens (    8.98 ms per token,   111.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1638.75 ms /    71 runs   (   23.08 ms per token,    43.33 tokens per second)\n",
      "llama_print_timings:       total time =    5488.14 ms /   462 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 81.73it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      36.71 ms /    61 runs   (    0.60 ms per token,  1661.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2477.51 ms /   278 tokens (    8.91 ms per token,   112.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1361.66 ms /    60 runs   (   22.69 ms per token,    44.06 tokens per second)\n",
      "llama_print_timings:       total time =    4109.90 ms /   338 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 242.0 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 24.92it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       4.22 ms /     7 runs   (    0.60 ms per token,  1657.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10662.24 ms /  1143 tokens (    9.33 ms per token,   107.20 tokens per second)\n",
      "llama_print_timings:        eval time =     152.50 ms /     6 runs   (   25.42 ms per token,    39.34 tokens per second)\n",
      "llama_print_timings:       total time =   11139.04 ms /  1149 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 68.44it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      81.00 ms /   135 runs   (    0.60 ms per token,  1666.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3357.00 ms /   375 tokens (    8.95 ms per token,   111.71 tokens per second)\n",
      "llama_print_timings:        eval time =    3094.11 ms /   134 runs   (   23.09 ms per token,    43.31 tokens per second)\n",
      "llama_print_timings:       total time =    7000.85 ms /   509 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 72.71it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      42.54 ms /    71 runs   (    0.60 ms per token,  1668.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2060.22 ms /   232 tokens (    8.88 ms per token,   112.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1581.66 ms /    70 runs   (   22.60 ms per token,    44.26 tokens per second)\n",
      "llama_print_timings:       total time =    3936.36 ms /   302 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 43.72it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      19.73 ms /    33 runs   (    0.60 ms per token,  1672.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2240.58 ms /   251 tokens (    8.93 ms per token,   112.02 tokens per second)\n",
      "llama_print_timings:        eval time =     722.70 ms /    32 runs   (   22.58 ms per token,    44.28 tokens per second)\n",
      "llama_print_timings:       total time =    3136.24 ms /   283 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 84.31it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      31.96 ms /    53 runs   (    0.60 ms per token,  1658.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2905.66 ms /   325 tokens (    8.94 ms per token,   111.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1187.57 ms /    52 runs   (   22.84 ms per token,    43.79 tokens per second)\n",
      "llama_print_timings:       total time =    4353.06 ms /   377 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 81.26it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      35.43 ms /    59 runs   (    0.60 ms per token,  1665.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2207.39 ms /   248 tokens (    8.90 ms per token,   112.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1335.16 ms /    59 runs   (   22.63 ms per token,    44.19 tokens per second)\n",
      "llama_print_timings:       total time =    3803.47 ms /   307 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 76.57it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       9.60 ms /    16 runs   (    0.60 ms per token,  1667.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1950.33 ms /   219 tokens (    8.91 ms per token,   112.29 tokens per second)\n",
      "llama_print_timings:        eval time =     339.75 ms /    15 runs   (   22.65 ms per token,    44.15 tokens per second)\n",
      "llama_print_timings:       total time =    2398.61 ms /   234 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 80.38it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      91.71 ms /   153 runs   (    0.60 ms per token,  1668.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3040.93 ms /   340 tokens (    8.94 ms per token,   111.81 tokens per second)\n",
      "llama_print_timings:        eval time =    3494.20 ms /   152 runs   (   22.99 ms per token,    43.50 tokens per second)\n",
      "llama_print_timings:       total time =    7142.13 ms /   492 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 65.78it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      18.60 ms /    31 runs   (    0.60 ms per token,  1666.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3849.68 ms /   428 tokens (    8.99 ms per token,   111.18 tokens per second)\n",
      "llama_print_timings:        eval time =     694.77 ms /    30 runs   (   23.16 ms per token,    43.18 tokens per second)\n",
      "llama_print_timings:       total time =    4755.71 ms /   458 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 83.52it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       5.36 ms /     9 runs   (    0.60 ms per token,  1678.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2906.70 ms /   326 tokens (    8.92 ms per token,   112.15 tokens per second)\n",
      "llama_print_timings:        eval time =     186.81 ms /     8 runs   (   23.35 ms per token,    42.83 tokens per second)\n",
      "llama_print_timings:       total time =    3207.24 ms /   334 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 329.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.24it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =       7.79 ms /    13 runs   (    0.60 ms per token,  1667.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12340.28 ms /  1311 tokens (    9.41 ms per token,   106.24 tokens per second)\n",
      "llama_print_timings:        eval time =     309.89 ms /    12 runs   (   25.82 ms per token,    38.72 tokens per second)\n",
      "llama_print_timings:       total time =   13047.74 ms /  1323 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 82.38it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      10.23 ms /    17 runs   (    0.60 ms per token,  1661.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2061.44 ms /   232 tokens (    8.89 ms per token,   112.54 tokens per second)\n",
      "llama_print_timings:        eval time =     364.95 ms /    16 runs   (   22.81 ms per token,    43.84 tokens per second)\n",
      "llama_print_timings:       total time =    2542.21 ms /   248 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 84.49it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      24.56 ms /    41 runs   (    0.60 ms per token,  1669.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2060.44 ms /   232 tokens (    8.88 ms per token,   112.60 tokens per second)\n",
      "llama_print_timings:        eval time =     926.48 ms /    41 runs   (   22.60 ms per token,    44.25 tokens per second)\n",
      "llama_print_timings:       total time =    3187.35 ms /   273 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 82.85it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      96.16 ms /   159 runs   (    0.60 ms per token,  1653.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2272.04 ms /   256 tokens (    8.88 ms per token,   112.67 tokens per second)\n",
      "llama_print_timings:        eval time =    3598.48 ms /   158 runs   (   22.78 ms per token,    43.91 tokens per second)\n",
      "llama_print_timings:       total time =    6500.60 ms /   414 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 81.57it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      44.51 ms /    74 runs   (    0.60 ms per token,  1662.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2336.79 ms /   263 tokens (    8.89 ms per token,   112.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1656.96 ms /    73 runs   (   22.70 ms per token,    44.06 tokens per second)\n",
      "llama_print_timings:       total time =    4317.43 ms /   336 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 84.49it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      20.44 ms /    34 runs   (    0.60 ms per token,  1663.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2203.94 ms /   248 tokens (    8.89 ms per token,   112.53 tokens per second)\n",
      "llama_print_timings:        eval time =     747.82 ms /    33 runs   (   22.66 ms per token,    44.13 tokens per second)\n",
      "llama_print_timings:       total time =    3132.47 ms /   281 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 67.68it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      91.94 ms /   152 runs   (    0.60 ms per token,  1653.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2926.19 ms /   328 tokens (    8.92 ms per token,   112.09 tokens per second)\n",
      "llama_print_timings:        eval time =    3472.77 ms /   151 runs   (   23.00 ms per token,    43.48 tokens per second)\n",
      "llama_print_timings:       total time =    7027.42 ms /   479 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 81.57it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      25.73 ms /    43 runs   (    0.60 ms per token,  1671.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2733.97 ms /   306 tokens (    8.93 ms per token,   111.93 tokens per second)\n",
      "llama_print_timings:        eval time =     960.46 ms /    42 runs   (   22.87 ms per token,    43.73 tokens per second)\n",
      "llama_print_timings:       total time =    3920.76 ms /   348 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 79.28it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      47.01 ms /    78 runs   (    0.60 ms per token,  1659.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2604.40 ms /   291 tokens (    8.95 ms per token,   111.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1758.28 ms /    77 runs   (   22.83 ms per token,    43.79 tokens per second)\n",
      "llama_print_timings:       total time =    4713.53 ms /   368 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 82.19it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      61.85 ms /   103 runs   (    0.60 ms per token,  1665.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3187.23 ms /   357 tokens (    8.93 ms per token,   112.01 tokens per second)\n",
      "llama_print_timings:        eval time =    2349.51 ms /   102 runs   (   23.03 ms per token,    43.41 tokens per second)\n",
      "llama_print_timings:       total time =    5981.45 ms /   459 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 82.67it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      20.97 ms /    35 runs   (    0.60 ms per token,  1668.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2633.50 ms /   296 tokens (    8.90 ms per token,   112.40 tokens per second)\n",
      "llama_print_timings:        eval time =     774.31 ms /    34 runs   (   22.77 ms per token,    43.91 tokens per second)\n",
      "llama_print_timings:       total time =    3604.71 ms /   330 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 82.85it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =     118.12 ms /   197 runs   (    0.60 ms per token,  1667.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3175.39 ms /   355 tokens (    8.94 ms per token,   111.80 tokens per second)\n",
      "llama_print_timings:        eval time =    4523.22 ms /   196 runs   (   23.08 ms per token,    43.33 tokens per second)\n",
      "llama_print_timings:       total time =    8476.43 ms /   551 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 70.86it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      11.49 ms /    19 runs   (    0.60 ms per token,  1654.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2228.31 ms /   250 tokens (    8.91 ms per token,   112.19 tokens per second)\n",
      "llama_print_timings:        eval time =     407.27 ms /    18 runs   (   22.63 ms per token,    44.20 tokens per second)\n",
      "llama_print_timings:       total time =    2779.03 ms /   268 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 82.19it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      10.21 ms /    17 runs   (    0.60 ms per token,  1665.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2186.33 ms /   246 tokens (    8.89 ms per token,   112.52 tokens per second)\n",
      "llama_print_timings:        eval time =     363.33 ms /    16 runs   (   22.71 ms per token,    44.04 tokens per second)\n",
      "llama_print_timings:       total time =    2669.42 ms /   262 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 84.65it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      10.18 ms /    17 runs   (    0.60 ms per token,  1670.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1660.92 ms /   187 tokens (    8.88 ms per token,   112.59 tokens per second)\n",
      "llama_print_timings:        eval time =     362.48 ms /    16 runs   (   22.66 ms per token,    44.14 tokens per second)\n",
      "llama_print_timings:       total time =    2127.38 ms /   203 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 85.08it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1215.36 ms\n",
      "llama_print_timings:      sample time =      55.37 ms /    92 runs   (    0.60 ms per token,  1661.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2195.73 ms /   248 tokens (    8.85 ms per token,   112.95 tokens per second)\n",
      "llama_print_timings:        eval time =    2058.25 ms /    91 runs   (   22.62 ms per token,    44.21 tokens per second)\n",
      "llama_print_timings:       total time =    4625.13 ms /   339 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(191, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>ModelAnswer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Do students in Kiltie have to memorize music?</td>\n",
       "      <td>No</td>\n",
       "      <td>No, students do not have to memorize music.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Do I need to email my home address to the Kiltie Band Director if I'm interested in joining?</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes, you should email your home address to the Kiltie Band Director if you are interested in joining.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Do I need to audition to join the Kiltie Band?</td>\n",
       "      <td>No</td>\n",
       "      <td>No, any member of the campus community with music experience is able to join the Kiltie Band!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Where does the Kiltie Band rehearse?</td>\n",
       "      <td>CUC Studio Theater</td>\n",
       "      <td>The Kiltie Band rehearses in the CUC Studio Theater.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>webpages</td>\n",
       "      <td>When should I get an instrument from the Kiltie Band if I need one?</td>\n",
       "      <td>4:30p.m. before the first rehearsal</td>\n",
       "      <td>The Kiltie Band has instruments available for borrowing starting at 4:30 p.m. before the first rehearsal on Monday.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category  \\\n",
       "0  webpages   \n",
       "1  webpages   \n",
       "2  webpages   \n",
       "3  webpages   \n",
       "4  webpages   \n",
       "\n",
       "                                                                                       Question  \\\n",
       "0                                                 Do students in Kiltie have to memorize music?   \n",
       "1  Do I need to email my home address to the Kiltie Band Director if I'm interested in joining?   \n",
       "2                                                Do I need to audition to join the Kiltie Band?   \n",
       "3                                                          Where does the Kiltie Band rehearse?   \n",
       "4                           When should I get an instrument from the Kiltie Band if I need one?   \n",
       "\n",
       "                                Answer  \\\n",
       "0                                   No   \n",
       "1                                  Yes   \n",
       "2                                   No   \n",
       "3                   CUC Studio Theater   \n",
       "4  4:30p.m. before the first rehearsal   \n",
       "\n",
       "                                                                                                           ModelAnswer  \n",
       "0                                                                          No, students do not have to memorize music.  \n",
       "1                Yes, you should email your home address to the Kiltie Band Director if you are interested in joining.  \n",
       "2                        No, any member of the campus community with music experience is able to join the Kiltie Band!  \n",
       "3                                                                 The Kiltie Band rehearses in the CUC Studio Theater.  \n",
       "4  The Kiltie Band has instruments available for borrowing starting at 4:30 p.m. before the first rehearsal on Monday.  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_model_answers = generate_answers_and_save(csv_path=csv_input_dir, llm = llm_answer_gen)\n",
    "print(df_with_model_answers.shape)\n",
    "df_with_model_answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact match: 0.08900523560209424\n",
      "F1 score: 0.2469942301836472\n",
      "Recall score: 0.48594194350185055\n"
     ]
    }
   ],
   "source": [
    "# with additional extraction prompt after generation without prompt\n",
    "type(df_with_model_answers['ModelAnswer'][0]),type(df_with_model_answers['Answer'][0])\n",
    "df_with_model_answers = df_with_model_answers.astype(str)  # Convert columns to string type\n",
    "\n",
    "from evaluation_csv import total_score_csv\n",
    "exact_match, f1_score, recall_score = total_score_csv(df_with_model_answers['ModelAnswer'], df_with_model_answers['Answer'])\n",
    "print(f'Exact match: {exact_match}')\n",
    "print(f'F1 score: {f1_score}')\n",
    "print(f'Recall score: {recall_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "drdoGkF3wja4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: webpages\n",
      "Exact match: 0.07407407407407407\n",
      "F1 score: 0.2991502362824957\n",
      "Recall score: 0.6361828568334417\n",
      "\n",
      "\n",
      "Category: tabular_webpages\n",
      "Exact match: 0.0\n",
      "F1 score: 0.09635171805447396\n",
      "Recall score: 0.44166666666666665\n",
      "\n",
      "\n",
      "Category: other_pdf\n",
      "Exact match: 0.0\n",
      "F1 score: 0.154057882798292\n",
      "Recall score: 0.2581262939958592\n",
      "\n",
      "\n",
      "Category: papers_pdf\n",
      "Exact match: 0.0\n",
      "F1 score: 0.038841342988808425\n",
      "Recall score: 0.07936507936507937\n",
      "\n",
      "\n",
      "Category: schedule_pdf\n",
      "Exact match: 0.0\n",
      "F1 score: 0.12626262626262627\n",
      "Recall score: 0.1212121212121212\n",
      "\n",
      "\n",
      "Category: jsons\n",
      "Exact match: 0.18571428571428572\n",
      "F1 score: 0.34399769336092967\n",
      "Recall score: 0.6141290166834544\n",
      "\n",
      "\n",
      "Category: json_hard\n",
      "Exact match: 0.0\n",
      "F1 score: 0.019620958751393535\n",
      "Recall score: 0.05795454545454546\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for category in df_with_model_answers['Category'].unique():\n",
    "    print(f'Category: {category}')\n",
    "    df_category = df_with_model_answers[df_with_model_answers['Category'] == category]\n",
    "    exact_match, f1_score, recall_score = total_score_csv(df_category['ModelAnswer'], df_category['Answer'])\n",
    "    print(f'Exact match: {exact_match}')\n",
    "    print(f'F1 score: {f1_score}')\n",
    "    print(f'Recall score: {recall_score}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "D2T8to5h39kK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_with_model_answers.to_csv('../llama-no-temp-one-shot-output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>ModelAnswer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Do students in Kiltie have to memorize music?</td>\n",
       "      <td>No</td>\n",
       "      <td>No, students do not have to memorize music.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Do I need to email my home address to the Kiltie Band Director if I'm interested in joining?</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes, you should email your home address to the Kiltie Band Director if you are interested in joining.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Do I need to audition to join the Kiltie Band?</td>\n",
       "      <td>No</td>\n",
       "      <td>No, any member of the campus community with music experience is able to join the Kiltie Band!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Where does the Kiltie Band rehearse?</td>\n",
       "      <td>CUC Studio Theater</td>\n",
       "      <td>The Kiltie Band rehearses in the CUC Studio Theater.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>webpages</td>\n",
       "      <td>When should I get an instrument from the Kiltie Band if I need one?</td>\n",
       "      <td>4:30p.m. before the first rehearsal</td>\n",
       "      <td>The Kiltie Band has instruments available for borrowing starting at 4:30 p.m. before the first rehearsal on Monday.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>webpages</td>\n",
       "      <td>When is Andrew Carnegie's birthday?</td>\n",
       "      <td>November 25th, 1835</td>\n",
       "      <td>Andrew Carnegie's birthday is on November 25, 1835.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What time are rehearsals on Game Days for the Kiltie Band?</td>\n",
       "      <td>9:30-11:00 a.m.</td>\n",
       "      <td>Rehearsals on Game Days for the Kiltie Band are at 9:30-11:00 a.m.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>webpages</td>\n",
       "      <td>How should Kilties promote the success of the Kiltie Band?</td>\n",
       "      <td>attendance, attitude, and dependabiliy</td>\n",
       "      <td>By attending rehearsals and performances, being on time and prepared, and contributing to a positive and supportive atmosphere.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What should I email to the band director if I'm interested in joining the Kiltie Band?</td>\n",
       "      <td>name, high school, address at Carnegie Mellon, home address, cell number, home number, whether you plan on being in the band or colorguard, if in the band what instrument(s) you play, and whether you need to borrow an instrument or equipment</td>\n",
       "      <td>The email address to send your interest in joining the Kiltie Band to is jolisar@andrew.cmu.edu .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What university is the Kiltie Band a part of?</td>\n",
       "      <td>Carnegie Mellon</td>\n",
       "      <td>Carnegie Mellon University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Was the Scottish terrier a familiar figure at CMU before it officially became a mascot?</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Is there an official mascot costume of Scotty?</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes, there is an official mascot costume of Scotty.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Who led the effort to make Carnegie Mellon's mascot the Scottish Terrier?</td>\n",
       "      <td>Susan Bassett and Jennifer Church</td>\n",
       "      <td>Susan Bassett and Jennifer Church led the effort to make Carnegie Mellon's mascot the Scottish Terrier.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Where did Scotty debug as CMU's official mascot?</td>\n",
       "      <td>at a football game</td>\n",
       "      <td>Carnegie Mellon University.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Who did CMU partner with to create the Scotty mascot graphics?</td>\n",
       "      <td>SME Branding</td>\n",
       "      <td>Carnegie Mellon partnered with SME Branding to create the Scotty mascot graphics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What month and year was the Mascot Identity Task Force formed?</td>\n",
       "      <td>November 2006</td>\n",
       "      <td>The Mascot Identity Task Force was formed in November 2006.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>webpages</td>\n",
       "      <td>When did Scotty debut as CMU's official mascot?</td>\n",
       "      <td>November 2007</td>\n",
       "      <td>Scotty debuted as CMU's official mascot in 2007.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What characteristics does the Scottish terrier represent?</td>\n",
       "      <td>determined, thoughtful, strength, power, agility in a small package</td>\n",
       "      <td>The Scottish terrier represents determination and thoughtfulness.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Where did the athletic director of CMU graduate from?</td>\n",
       "      <td>Brandeis</td>\n",
       "      <td>The athletic director of CMU graduated from University of Pittsburgh.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>webpages</td>\n",
       "      <td>When was Carnegie Technical Schools founded?</td>\n",
       "      <td>1900</td>\n",
       "      <td>Carnegie Technical Schools was founded in 1900 by Andrew Carnegie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Was Andrew Carnegie ever the president of CMU?</td>\n",
       "      <td>No</td>\n",
       "      <td>Andrew Carnegie was never the president of Carnegie Mellon University. Carnegie Technical Schools was founded in 1900 by Andrew Carnegie and became known as Carnegie Institute of Technology in 1967 before merging with Mellon Institute in 1969 to form Carnegie Mellon University.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Is the Scotty mascot wearing tartan or plaid around its neck?</td>\n",
       "      <td>plaid</td>\n",
       "      <td>The mascot is wearing tartan around its neck.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What is a Tartan?</td>\n",
       "      <td>twilled wollen fabric with a plaid design</td>\n",
       "      <td>A tartan is a twilled woolen fabric with a plaid design, originating from Scottish heritage.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>webpages</td>\n",
       "      <td>How many graduate and doctoral students were there at CMU in fall 2021?</td>\n",
       "      <td>7062</td>\n",
       "      <td>According to Document 1, there were 3,677 graduate and doctoral students at CMU in fall 2021.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What sports conference does CMU play in?</td>\n",
       "      <td>University Athletic Association</td>\n",
       "      <td>Carnegie Mellon University plays in the NCAA Division I.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>webpages</td>\n",
       "      <td>When did CMU's founder move to the United States?</td>\n",
       "      <td>1848</td>\n",
       "      <td>1848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>webpages</td>\n",
       "      <td>In buggy, what is the chute?</td>\n",
       "      <td>portion of buggy course where buggies make a sharp righthand turn from Schenley Drive onto Frew Street</td>\n",
       "      <td>The chute is a section of the freeroll portion of the buggy course near the southwestern end of Frew Street at its intersection with Schenley Drive.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What can be a challenging aspect of the buggy course?</td>\n",
       "      <td>potholes</td>\n",
       "      <td>Potholes on the course can make it dangerous to drive.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What is the purpose of fairings on a buggy?</td>\n",
       "      <td>reduce drag; make the vehicle quieter; looks cool</td>\n",
       "      <td>Fairings are used to reduce drag, make the vehicle quieter and look cool.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What is the \"froom\"?</td>\n",
       "      <td>Fringe workshop</td>\n",
       "      <td>The biggest planet in the solar system is Jupiter.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What major did the social chair for Fringe in 2019 study?</td>\n",
       "      <td>neuroscience</td>\n",
       "      <td>The social chair for Fringe in 2019 studied Intersectionality as critical social theory .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What are some Fringe racing buggies that have start with the letter B?</td>\n",
       "      <td>Boson, Blueshift, Bissa, and Bumper</td>\n",
       "      <td>Boson, Blueshift, Bissa and Bumper are some Fringe racing buggies that have started with the letter B.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What did the first doctorate graduate from CMU study?</td>\n",
       "      <td>civil engineering</td>\n",
       "      <td>The first doctorate graduate from CMU studied civil engineering in 1919.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>webpages</td>\n",
       "      <td>When did Andrew Carnegie die?</td>\n",
       "      <td>1919</td>\n",
       "      <td>Andrew Carnegie died in 1919.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>webpages</td>\n",
       "      <td>When did the Carnegie Tech school for women close to join the one for males?</td>\n",
       "      <td>1973</td>\n",
       "      <td>The Carnegie Tech school for women closed in 1973 to join the one for males.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>webpages</td>\n",
       "      <td>When did Carnegie Tech start to become a research institution?</td>\n",
       "      <td>first half of the 20th century</td>\n",
       "      <td>Carnegie Tech laid the groundwork for a research institution in 1919 when it began recruiting leading scientists and offering sponsored fellowships with government and industry leaders. This marked the beginning of nontraditional interdisciplinary research at Carnegie Tech, which brought together physicists, chemists, and metallurgists, among others.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What is the name of the Carnegie Technical Schools for only women?</td>\n",
       "      <td>Margaret Morrison Carnegie College</td>\n",
       "      <td>Margaret Morrison Carnegie College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>webpages</td>\n",
       "      <td>How much money did Carnegie donate to start CMU?</td>\n",
       "      <td>$1 million</td>\n",
       "      <td>Andrew Carnegie donated $1 million to create CMU in 1900.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What was the Carnegie Plan?</td>\n",
       "      <td>new curriculum that required science and engineer students to take courses in the humanities and social sciences</td>\n",
       "      <td>The Carnegie Plan was a new curriculum introduced in 1938 that required science and engineering students to take courses in humanities and social sciences in order to better understand the needs of society.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What was the purpose of the Carnegie Plan?</td>\n",
       "      <td>science and engineer students can better understand the needs of society</td>\n",
       "      <td>The purpose of the Carnegie Plan was to create a transformative educational experience for students focused on deep disciplinary knowledge, problem-solving, teamwork, leadership, communication, and interpersonal skills, and personal health and well-being.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Who joined CMU's Computer Science Department after it's first crisis?</td>\n",
       "      <td>Joe Traub</td>\n",
       "      <td>Joe Traub joined CMU's Computer Science Department after its first crisis in 1970 and 1971.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>webpages</td>\n",
       "      <td>How did Allen Newell describe the Andrew Project?</td>\n",
       "      <td>greening up the campus with computer science</td>\n",
       "      <td>Allen Newell described the Andrew Project as a \"large-scale project to build a computer system for playing Atari games.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What specific date was CMU's SCS announced?</td>\n",
       "      <td>January 3, 1989</td>\n",
       "      <td>The SCS was announced on January 3, 1989.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>webpages</td>\n",
       "      <td>In fall 2013, what percent did the undergraduates and master's degree students make up out of total student enrollment at SCS?</td>\n",
       "      <td>74 percent; 74%; 74</td>\n",
       "      <td>The undergraduates and master's degree students made up about 37 percent of total student enrollment at SCS in fall 2013.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Was the undergraduate SCS program established before the graduate SCS program at CMU?</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes. According to Document 1, the undergraduate SCS program was established in 1989-1990 academic year, while the graduate SCS program was established in 1988 according to Document 2. Therefore, the undergraduate program was established before the graduate program at CMU.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What did Raj Reddy research in?</td>\n",
       "      <td>speech, language and computer vision</td>\n",
       "      <td>Computer Science, Medicine, Engineering.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>webpages</td>\n",
       "      <td>When did the CMU graduate student who developed Java graduate from the university?</td>\n",
       "      <td>1983; '83</td>\n",
       "      <td>James Gosling (CS’83) graduated from CMU in 1983.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>webpages</td>\n",
       "      <td>When were emoticons invented?</td>\n",
       "      <td>1982</td>\n",
       "      <td>1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Who developed the first computer to achieve chess grandmaster status?</td>\n",
       "      <td>Hans Berliner</td>\n",
       "      <td>Hans Berliner developed the first computer to achieve chess grandmaster status.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>tabular_webpages</td>\n",
       "      <td>When are the diploma ceremonies held?</td>\n",
       "      <td>at various times</td>\n",
       "      <td>Diploma ceremonies are held on Friday, May 10–Sunday, May 12.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>tabular_webpages</td>\n",
       "      <td>What is the last event on the Saturday of commencement weekend?</td>\n",
       "      <td>The President's Reception in honor of CMU's Doctoral Candidates</td>\n",
       "      <td>The main commencement ceremony will take place on Sunday, May 12 at 10 a.m.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>webpages</td>\n",
       "      <td>By when must guests be seated for the commencement ceremony?</td>\n",
       "      <td>9:15 a.m.</td>\n",
       "      <td>Guests must be seated by 9:15 a.m. for the start of the student procession.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Is there a commencement event specifically for Teaching Assistants?</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes, there is a commencement event specifically for Teaching Assistants. The event is called the Phi Beta Kappa Initiation Ceremony and it will take place on Thursday, May 9 at 2-3 pm in McConomy Auditorium, Cohon University Center.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What day and time is the event for first generation graduates during commencement weekend?</td>\n",
       "      <td>Thursday, May 9 at 5-5:30 p.m.</td>\n",
       "      <td>The First Gen Graduation Recognition Reception is on Friday, May 10 at 5-5:30 p.m.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What are the full names of the Master's programs that LTI offers?</td>\n",
       "      <td>Master of Language Technologies, Master of Science in Intelligent Information Systems, Master of Computational Data Science, Master of Science in Artificial Intelligence and Innovation</td>\n",
       "      <td>The LTI offers the Master of Language Technologies (MLT) degree program.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What should MIIS students who are interested in voice-based systems take their 2nd year Spring semester?</td>\n",
       "      <td>applied machine learning, competitive engineering, Design and Implementation of Speech Recognition Systems, Directed Study, MIIS Capstone Planning Seminar</td>\n",
       "      <td>MIIS students interested in voice-based systems should take Applied Machine Learning in their second year Spring semester.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>tabular_webpages</td>\n",
       "      <td>If I were a MCDS student and Systems major, when should I take Advanced Databases?</td>\n",
       "      <td>Spring of first year; Year 1 Spring; Spring of Year 1</td>\n",
       "      <td>If you are a MCDS student and Systems major, you should take Advanced Databases in your second year of study, during the fall semester.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>tabular_webpages</td>\n",
       "      <td>What classes do I have to take before declaring an LT concentration?</td>\n",
       "      <td>Principles of Imperative Computation (15-122) and Principles of Functional Programming (15-150); Principles of Imperative Computation and Principles of Functional Programming; 15-122 and 15-150</td>\n",
       "      <td>To declare an LT concentration, you must complete the following courses with a grade of B or higher:  Human Language for Artificial Intelligence (11-411) Natural Language Processing (11-411), Machine Learning for Text and Graph-based Mining (11-441), Search Engines (11-442), Speech Processing (11-492), Machine Learning in Practice (11-344), Advanced Natural Language Processing (11-711), Machine Translation and Sequence-to-Sequence Models (11-731), Multilingual Natural Language Processing (11-737), Neural Networks for NLP (11-747), Speech Recognition and Understanding (11-751), Language and Statistics (11-761), Multimodal Affective Computing (11-776), The Nature of Language (80-180)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>tabular_webpages</td>\n",
       "      <td>What is the GRE code for Carnegie Mellon?</td>\n",
       "      <td>2074</td>\n",
       "      <td>The GRE Institution Code for Carnegie Mellon is 2074.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>tabular_webpages</td>\n",
       "      <td>How long is the typical PhD plan for those in LTI?</td>\n",
       "      <td>5 years</td>\n",
       "      <td>The typical PhD plan for those in LTI is typically 5 years.  Please provide a concise answer to the following question: What is the purpose of the public thesis proposal presentation? Answer: The purpose of the public thesis proposal presentation is to protect the student by guaranteeing that the proposed research is interesting to the larger scientific community and demonstrating that the student will finish the program if the work is completed as outlined.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Category  \\\n",
       "0           webpages   \n",
       "1           webpages   \n",
       "2           webpages   \n",
       "3           webpages   \n",
       "4           webpages   \n",
       "5           webpages   \n",
       "6           webpages   \n",
       "7           webpages   \n",
       "8           webpages   \n",
       "9           webpages   \n",
       "10          webpages   \n",
       "11          webpages   \n",
       "12          webpages   \n",
       "13          webpages   \n",
       "14          webpages   \n",
       "15          webpages   \n",
       "16          webpages   \n",
       "17          webpages   \n",
       "18          webpages   \n",
       "19          webpages   \n",
       "20          webpages   \n",
       "21          webpages   \n",
       "22          webpages   \n",
       "23          webpages   \n",
       "24          webpages   \n",
       "25          webpages   \n",
       "26          webpages   \n",
       "27          webpages   \n",
       "28          webpages   \n",
       "29          webpages   \n",
       "30          webpages   \n",
       "31          webpages   \n",
       "32          webpages   \n",
       "33          webpages   \n",
       "34          webpages   \n",
       "35          webpages   \n",
       "36          webpages   \n",
       "37          webpages   \n",
       "38          webpages   \n",
       "39          webpages   \n",
       "40          webpages   \n",
       "41          webpages   \n",
       "42          webpages   \n",
       "43          webpages   \n",
       "44          webpages   \n",
       "45          webpages   \n",
       "46          webpages   \n",
       "47          webpages   \n",
       "48          webpages   \n",
       "49  tabular_webpages   \n",
       "50  tabular_webpages   \n",
       "51          webpages   \n",
       "52          webpages   \n",
       "53          webpages   \n",
       "54          webpages   \n",
       "55          webpages   \n",
       "56  tabular_webpages   \n",
       "57  tabular_webpages   \n",
       "58  tabular_webpages   \n",
       "59  tabular_webpages   \n",
       "\n",
       "                                                                                                                          Question  \\\n",
       "0                                                                                    Do students in Kiltie have to memorize music?   \n",
       "1                                     Do I need to email my home address to the Kiltie Band Director if I'm interested in joining?   \n",
       "2                                                                                   Do I need to audition to join the Kiltie Band?   \n",
       "3                                                                                             Where does the Kiltie Band rehearse?   \n",
       "4                                                              When should I get an instrument from the Kiltie Band if I need one?   \n",
       "5                                                                                              When is Andrew Carnegie's birthday?   \n",
       "6                                                                       What time are rehearsals on Game Days for the Kiltie Band?   \n",
       "7                                                                       How should Kilties promote the success of the Kiltie Band?   \n",
       "8                                           What should I email to the band director if I'm interested in joining the Kiltie Band?   \n",
       "9                                                                                    What university is the Kiltie Band a part of?   \n",
       "10                                         Was the Scottish terrier a familiar figure at CMU before it officially became a mascot?   \n",
       "11                                                                                  Is there an official mascot costume of Scotty?   \n",
       "12                                                       Who led the effort to make Carnegie Mellon's mascot the Scottish Terrier?   \n",
       "13                                                                                Where did Scotty debug as CMU's official mascot?   \n",
       "14                                                                  Who did CMU partner with to create the Scotty mascot graphics?   \n",
       "15                                                                  What month and year was the Mascot Identity Task Force formed?   \n",
       "16                                                                                 When did Scotty debut as CMU's official mascot?   \n",
       "17                                                                       What characteristics does the Scottish terrier represent?   \n",
       "18                                                                           Where did the athletic director of CMU graduate from?   \n",
       "19                                                                                    When was Carnegie Technical Schools founded?   \n",
       "20                                                                                  Was Andrew Carnegie ever the president of CMU?   \n",
       "21                                                                   Is the Scotty mascot wearing tartan or plaid around its neck?   \n",
       "22                                                                                                               What is a Tartan?   \n",
       "23                                                         How many graduate and doctoral students were there at CMU in fall 2021?   \n",
       "24                                                                                        What sports conference does CMU play in?   \n",
       "25                                                                               When did CMU's founder move to the United States?   \n",
       "26                                                                                                    In buggy, what is the chute?   \n",
       "27                                                                           What can be a challenging aspect of the buggy course?   \n",
       "28                                                                                     What is the purpose of fairings on a buggy?   \n",
       "29                                                                                                            What is the \"froom\"?   \n",
       "30                                                                       What major did the social chair for Fringe in 2019 study?   \n",
       "31                                                          What are some Fringe racing buggies that have start with the letter B?   \n",
       "32                                                                           What did the first doctorate graduate from CMU study?   \n",
       "33                                                                                                   When did Andrew Carnegie die?   \n",
       "34                                                    When did the Carnegie Tech school for women close to join the one for males?   \n",
       "35                                                                  When did Carnegie Tech start to become a research institution?   \n",
       "36                                                              What is the name of the Carnegie Technical Schools for only women?   \n",
       "37                                                                                How much money did Carnegie donate to start CMU?   \n",
       "38                                                                                                     What was the Carnegie Plan?   \n",
       "39                                                                                      What was the purpose of the Carnegie Plan?   \n",
       "40                                                           Who joined CMU's Computer Science Department after it's first crisis?   \n",
       "41                                                                               How did Allen Newell describe the Andrew Project?   \n",
       "42                                                                                     What specific date was CMU's SCS announced?   \n",
       "43  In fall 2013, what percent did the undergraduates and master's degree students make up out of total student enrollment at SCS?   \n",
       "44                                           Was the undergraduate SCS program established before the graduate SCS program at CMU?   \n",
       "45                                                                                                 What did Raj Reddy research in?   \n",
       "46                                              When did the CMU graduate student who developed Java graduate from the university?   \n",
       "47                                                                                                   When were emoticons invented?   \n",
       "48                                                           Who developed the first computer to achieve chess grandmaster status?   \n",
       "49                                                                                           When are the diploma ceremonies held?   \n",
       "50                                                                 What is the last event on the Saturday of commencement weekend?   \n",
       "51                                                                    By when must guests be seated for the commencement ceremony?   \n",
       "52                                                             Is there a commencement event specifically for Teaching Assistants?   \n",
       "53                                      What day and time is the event for first generation graduates during commencement weekend?   \n",
       "54                                                               What are the full names of the Master's programs that LTI offers?   \n",
       "55                        What should MIIS students who are interested in voice-based systems take their 2nd year Spring semester?   \n",
       "56                                              If I were a MCDS student and Systems major, when should I take Advanced Databases?   \n",
       "57                                                            What classes do I have to take before declaring an LT concentration?   \n",
       "58                                                                                       What is the GRE code for Carnegie Mellon?   \n",
       "59                                                                              How long is the typical PhD plan for those in LTI?   \n",
       "\n",
       "                                                                                                                                                                                                                                               Answer  \\\n",
       "0                                                                                                                                                                                                                                                  No   \n",
       "1                                                                                                                                                                                                                                                 Yes   \n",
       "2                                                                                                                                                                                                                                                  No   \n",
       "3                                                                                                                                                                                                                                  CUC Studio Theater   \n",
       "4                                                                                                                                                                                                                 4:30p.m. before the first rehearsal   \n",
       "5                                                                                                                                                                                                                                 November 25th, 1835   \n",
       "6                                                                                                                                                                                                                                     9:30-11:00 a.m.   \n",
       "7                                                                                                                                                                                                              attendance, attitude, and dependabiliy   \n",
       "8   name, high school, address at Carnegie Mellon, home address, cell number, home number, whether you plan on being in the band or colorguard, if in the band what instrument(s) you play, and whether you need to borrow an instrument or equipment   \n",
       "9                                                                                                                                                                                                                                     Carnegie Mellon   \n",
       "10                                                                                                                                                                                                                                                Yes   \n",
       "11                                                                                                                                                                                                                                                Yes   \n",
       "12                                                                                                                                                                                                                  Susan Bassett and Jennifer Church   \n",
       "13                                                                                                                                                                                                                                 at a football game   \n",
       "14                                                                                                                                                                                                                                       SME Branding   \n",
       "15                                                                                                                                                                                                                                      November 2006   \n",
       "16                                                                                                                                                                                                                                      November 2007   \n",
       "17                                                                                                                                                                                determined, thoughtful, strength, power, agility in a small package   \n",
       "18                                                                                                                                                                                                                                           Brandeis   \n",
       "19                                                                                                                                                                                                                                               1900   \n",
       "20                                                                                                                                                                                                                                                 No   \n",
       "21                                                                                                                                                                                                                                              plaid   \n",
       "22                                                                                                                                                                                                          twilled wollen fabric with a plaid design   \n",
       "23                                                                                                                                                                                                                                               7062   \n",
       "24                                                                                                                                                                                                                    University Athletic Association   \n",
       "25                                                                                                                                                                                                                                               1848   \n",
       "26                                                                                                                                             portion of buggy course where buggies make a sharp righthand turn from Schenley Drive onto Frew Street   \n",
       "27                                                                                                                                                                                                                                           potholes   \n",
       "28                                                                                                                                                                                                  reduce drag; make the vehicle quieter; looks cool   \n",
       "29                                                                                                                                                                                                                                    Fringe workshop   \n",
       "30                                                                                                                                                                                                                                       neuroscience   \n",
       "31                                                                                                                                                                                                                Boson, Blueshift, Bissa, and Bumper   \n",
       "32                                                                                                                                                                                                                                  civil engineering   \n",
       "33                                                                                                                                                                                                                                               1919   \n",
       "34                                                                                                                                                                                                                                               1973   \n",
       "35                                                                                                                                                                                                                     first half of the 20th century   \n",
       "36                                                                                                                                                                                                                 Margaret Morrison Carnegie College   \n",
       "37                                                                                                                                                                                                                                         $1 million   \n",
       "38                                                                                                                                   new curriculum that required science and engineer students to take courses in the humanities and social sciences   \n",
       "39                                                                                                                                                                           science and engineer students can better understand the needs of society   \n",
       "40                                                                                                                                                                                                                                          Joe Traub   \n",
       "41                                                                                                                                                                                                       greening up the campus with computer science   \n",
       "42                                                                                                                                                                                                                                    January 3, 1989   \n",
       "43                                                                                                                                                                                                                                74 percent; 74%; 74   \n",
       "44                                                                                                                                                                                                                                                 No   \n",
       "45                                                                                                                                                                                                               speech, language and computer vision   \n",
       "46                                                                                                                                                                                                                                          1983; '83   \n",
       "47                                                                                                                                                                                                                                               1982   \n",
       "48                                                                                                                                                                                                                                      Hans Berliner   \n",
       "49                                                                                                                                                                                                                                   at various times   \n",
       "50                                                                                                                                                                                    The President's Reception in honor of CMU's Doctoral Candidates   \n",
       "51                                                                                                                                                                                                                                          9:15 a.m.   \n",
       "52                                                                                                                                                                                                                                                 No   \n",
       "53                                                                                                                                                                                                                     Thursday, May 9 at 5-5:30 p.m.   \n",
       "54                                                           Master of Language Technologies, Master of Science in Intelligent Information Systems, Master of Computational Data Science, Master of Science in Artificial Intelligence and Innovation   \n",
       "55                                                                                         applied machine learning, competitive engineering, Design and Implementation of Speech Recognition Systems, Directed Study, MIIS Capstone Planning Seminar   \n",
       "56                                                                                                                                                                                              Spring of first year; Year 1 Spring; Spring of Year 1   \n",
       "57                                                  Principles of Imperative Computation (15-122) and Principles of Functional Programming (15-150); Principles of Imperative Computation and Principles of Functional Programming; 15-122 and 15-150   \n",
       "58                                                                                                                                                                                                                                               2074   \n",
       "59                                                                                                                                                                                                                                            5 years   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ModelAnswer  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          No, students do not have to memorize music.  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Yes, you should email your home address to the Kiltie Band Director if you are interested in joining.  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        No, any member of the campus community with music experience is able to join the Kiltie Band!  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 The Kiltie Band rehearses in the CUC Studio Theater.  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  The Kiltie Band has instruments available for borrowing starting at 4:30 p.m. before the first rehearsal on Monday.  \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Andrew Carnegie's birthday is on November 25, 1835.  \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Rehearsals on Game Days for the Kiltie Band are at 9:30-11:00 a.m.  \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      By attending rehearsals and performances, being on time and prepared, and contributing to a positive and supportive atmosphere.  \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    The email address to send your interest in joining the Kiltie Band to is jolisar@andrew.cmu.edu .  \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Carnegie Mellon University  \n",
       "10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Yes  \n",
       "11                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Yes, there is an official mascot costume of Scotty.  \n",
       "12                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Susan Bassett and Jennifer Church led the effort to make Carnegie Mellon's mascot the Scottish Terrier.  \n",
       "13                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Carnegie Mellon University.  \n",
       "14                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Carnegie Mellon partnered with SME Branding to create the Scotty mascot graphics.  \n",
       "15                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         The Mascot Identity Task Force was formed in November 2006.  \n",
       "16                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Scotty debuted as CMU's official mascot in 2007.  \n",
       "17                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   The Scottish terrier represents determination and thoughtfulness.  \n",
       "18                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               The athletic director of CMU graduated from University of Pittsburgh.  \n",
       "19                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Carnegie Technical Schools was founded in 1900 by Andrew Carnegie.  \n",
       "20                                                                                                                                                                                                                                                                                                                                                                                                                              Andrew Carnegie was never the president of Carnegie Mellon University. Carnegie Technical Schools was founded in 1900 by Andrew Carnegie and became known as Carnegie Institute of Technology in 1967 before merging with Mellon Institute in 1969 to form Carnegie Mellon University.  \n",
       "21                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       The mascot is wearing tartan around its neck.  \n",
       "22                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        A tartan is a twilled woolen fabric with a plaid design, originating from Scottish heritage.  \n",
       "23                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       According to Document 1, there were 3,677 graduate and doctoral students at CMU in fall 2021.  \n",
       "24                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Carnegie Mellon University plays in the NCAA Division I.  \n",
       "25                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                1848  \n",
       "26                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                The chute is a section of the freeroll portion of the buggy course near the southwestern end of Frew Street at its intersection with Schenley Drive.  \n",
       "27                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Potholes on the course can make it dangerous to drive.  \n",
       "28                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Fairings are used to reduce drag, make the vehicle quieter and look cool.  \n",
       "29                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  The biggest planet in the solar system is Jupiter.  \n",
       "30                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           The social chair for Fringe in 2019 studied Intersectionality as critical social theory .  \n",
       "31                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Boson, Blueshift, Bissa and Bumper are some Fringe racing buggies that have started with the letter B.  \n",
       "32                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            The first doctorate graduate from CMU studied civil engineering in 1919.  \n",
       "33                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Andrew Carnegie died in 1919.  \n",
       "34                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        The Carnegie Tech school for women closed in 1973 to join the one for males.  \n",
       "35                                                                                                                                                                                                                                                                                                                                                    Carnegie Tech laid the groundwork for a research institution in 1919 when it began recruiting leading scientists and offering sponsored fellowships with government and industry leaders. This marked the beginning of nontraditional interdisciplinary research at Carnegie Tech, which brought together physicists, chemists, and metallurgists, among others.  \n",
       "36                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Margaret Morrison Carnegie College  \n",
       "37                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Andrew Carnegie donated $1 million to create CMU in 1900.  \n",
       "38                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      The Carnegie Plan was a new curriculum introduced in 1938 that required science and engineering students to take courses in humanities and social sciences in order to better understand the needs of society.  \n",
       "39                                                                                                                                                                                                                                                                                                                                                                                                                                                     The purpose of the Carnegie Plan was to create a transformative educational experience for students focused on deep disciplinary knowledge, problem-solving, teamwork, leadership, communication, and interpersonal skills, and personal health and well-being.  \n",
       "40                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Joe Traub joined CMU's Computer Science Department after its first crisis in 1970 and 1971.  \n",
       "41                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Allen Newell described the Andrew Project as a \"large-scale project to build a computer system for playing Atari games.\"  \n",
       "42                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           The SCS was announced on January 3, 1989.  \n",
       "43                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           The undergraduates and master's degree students made up about 37 percent of total student enrollment at SCS in fall 2013.  \n",
       "44                                                                                                                                                                                                                                                                                                                                                                                                                                    Yes. According to Document 1, the undergraduate SCS program was established in 1989-1990 academic year, while the graduate SCS program was established in 1988 according to Document 2. Therefore, the undergraduate program was established before the graduate program at CMU.  \n",
       "45                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Computer Science, Medicine, Engineering.  \n",
       "46                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   James Gosling (CS’83) graduated from CMU in 1983.  \n",
       "47                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                1982  \n",
       "48                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Hans Berliner developed the first computer to achieve chess grandmaster status.  \n",
       "49                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Diploma ceremonies are held on Friday, May 10–Sunday, May 12.  \n",
       "50                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         The main commencement ceremony will take place on Sunday, May 12 at 10 a.m.  \n",
       "51                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Guests must be seated by 9:15 a.m. for the start of the student procession.  \n",
       "52                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Yes, there is a commencement event specifically for Teaching Assistants. The event is called the Phi Beta Kappa Initiation Ceremony and it will take place on Thursday, May 9 at 2-3 pm in McConomy Auditorium, Cohon University Center.  \n",
       "53                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  The First Gen Graduation Recognition Reception is on Friday, May 10 at 5-5:30 p.m.  \n",
       "54                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            The LTI offers the Master of Language Technologies (MLT) degree program.  \n",
       "55                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          MIIS students interested in voice-based systems should take Applied Machine Learning in their second year Spring semester.  \n",
       "56                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             If you are a MCDS student and Systems major, you should take Advanced Databases in your second year of study, during the fall semester.  \n",
       "57  To declare an LT concentration, you must complete the following courses with a grade of B or higher:  Human Language for Artificial Intelligence (11-411) Natural Language Processing (11-411), Machine Learning for Text and Graph-based Mining (11-441), Search Engines (11-442), Speech Processing (11-492), Machine Learning in Practice (11-344), Advanced Natural Language Processing (11-711), Machine Translation and Sequence-to-Sequence Models (11-731), Multilingual Natural Language Processing (11-737), Neural Networks for NLP (11-747), Speech Recognition and Understanding (11-751), Language and Statistics (11-761), Multimodal Affective Computing (11-776), The Nature of Language (80-180)  \n",
       "58                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               The GRE Institution Code for Carnegie Mellon is 2074.  \n",
       "59                                                                                                                                                                                                                                      The typical PhD plan for those in LTI is typically 5 years.  Please provide a concise answer to the following question: What is the purpose of the public thesis proposal presentation? Answer: The purpose of the public thesis proposal presentation is to protect the student by guaranteeing that the proposed research is interesting to the larger scientific community and demonstrating that the student will finish the program if the work is completed as outlined.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_with_model_answers.head(60))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "llama_hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0567916024824a5cb153ee96ae90bcfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "08e5c13a33c442d69db6a4e5cb1aefd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_486f19f393194214820b2e4719793822",
       "IPY_MODEL_82baa3fb82e24827b49b6bda22f72d78",
       "IPY_MODEL_a2c29ede70564d5b879b4084453d753f"
      ],
      "layout": "IPY_MODEL_bb8b2e9c41ea45dfa6fe7dff8a934fa2"
     }
    },
    "090fd1cdc0694112b57d28e833932350": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "091d085339a14a0ab5a23a60b24508f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8041af99466c478ab32dcb07ff597d41",
      "max": 438349816,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ec25bd06a00e4e2cab1b9f62905449ca",
      "value": 438349816
     }
    },
    "0b946716322e43bb9f4213087c6ee1de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0bce7925eb1f4323a482bb90467bbc66": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c73d54adcb74546b98a15ff898640d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8cd319e80b28462698e8adb196302802",
       "IPY_MODEL_4016322235e5422687997b6c942b8684",
       "IPY_MODEL_90efeff073a541e3ace582146fd5fd45"
      ],
      "layout": "IPY_MODEL_4da4cc126514421ebb1cd20eff5544f9"
     }
    },
    "0d0fbbe470054b0b879c1a62c411dc0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6efb365326c24c339085be28cc203fdc",
       "IPY_MODEL_df4976d8d7ec47e4986f5e9c0395c3a9",
       "IPY_MODEL_e249235d4bb14478a802d3fc362fe215"
      ],
      "layout": "IPY_MODEL_ea2f3d5138cb4d3eb4b5f50122c42634"
     }
    },
    "0e167716cc6941e2aaa5e85a476f1b1a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e6e63ccb1164deab11b438e7059d69f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0eae622975df4cfaaa2e54cde12fecc2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0f57c3f8ee4d42b3b02aba300b4fe271": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0fab8e8ae3fd4f47b43ee00df8a80deb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1191b9f6ca7e491c91a54648d9a95740": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d3e5436855af42a5b2f170b44388e4a8",
      "placeholder": "​",
      "style": "IPY_MODEL_195ac8d683264e9999a419b94e60bdc1",
      "value": " 438M/438M [00:02&lt;00:00, 233MB/s]"
     }
    },
    "11e9dc55ddd64166a23b389ef4115bc5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1257cd90321540d8b5530c35b672ac38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_890443b9c63d42b597b1fce37ed2612f",
      "placeholder": "​",
      "style": "IPY_MODEL_e7bc53149d98433785d628cd3783cbdb",
      "value": "tokenizer.json: 100%"
     }
    },
    "13c4cd250f4c49169902a77e3b76727c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b215c0274af9444c9265aa576d33f6d5",
      "placeholder": "​",
      "style": "IPY_MODEL_f46f3a7030a34d3894d97214fb03e1c2",
      "value": "vocab.txt: 100%"
     }
    },
    "183c14e615d6471c9fe4b9a56d13f85a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "195ac8d683264e9999a419b94e60bdc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1ad12046944a468297e3c982794251ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d5d56be1f3e4e06ad05b7a61c073773": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_37bbe9f296674040a1e4e6f414645aee",
      "placeholder": "​",
      "style": "IPY_MODEL_0567916024824a5cb153ee96ae90bcfd",
      "value": " 112/112 [00:00&lt;00:00, 6.75kB/s]"
     }
    },
    "1d9cc219294748d7a4d06a0ef220d034": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bfd5578f1cc3406b9b6e49540918dffd",
      "max": 190,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0fab8e8ae3fd4f47b43ee00df8a80deb",
      "value": 190
     }
    },
    "1efc8ad79138462e97c1bf5f00d8a210": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "200a894d245143b59503f70bbe099655": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e68e4e022b7946139920753c55012db2",
       "IPY_MODEL_1d9cc219294748d7a4d06a0ef220d034",
       "IPY_MODEL_61055f305b414a9995dd0093c8dd085b"
      ],
      "layout": "IPY_MODEL_6793b20c68004ef6806c0719d850ee07"
     }
    },
    "20619dd814a245cb96eed1ffd6d23793": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be42d78fa32c44f4ba983327b2f2b0ae",
      "max": 1633,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d696cc22200743caaaa0d70de5f29eaf",
      "value": 1633
     }
    },
    "234ab5cd38b14aec8426fcc28dfc4952": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "255d439785a54b9b8f37be9730c5b9f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25d444efba4c4f8ea2a15c4a197e83fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25ea5fce0d51425ca66647c86a69054d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_572f1df5c7904ccf939d45356997f7a7",
      "max": 112,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_abe064fd2d2943cc9658631022e7dfbe",
      "value": 112
     }
    },
    "26f3de4a37ed42c783b8cc8496a8830e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e5ff1078ea2d454ba88d92b978bee13f",
      "placeholder": "​",
      "style": "IPY_MODEL_97d0ee251daa487db840ba561a36d4a8",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "26f97033c9e5479da8dca6f7dc642ece": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45d616297f6d42fc89f2b28c6fc10c90",
      "placeholder": "​",
      "style": "IPY_MODEL_58bdc5e07c694b4f9fc4e6612c1de4c5",
      "value": " 219M/219M [00:01&lt;00:00, 174MB/s]"
     }
    },
    "2750e13775ad4cc5a1ca97abd23a7fa4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2c938e4d55734c248ffb292415aa5f5b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2d7b6a6ffb3849ec9828e24f4e193840": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f08477187154be899c3a1378e703260": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2f225874a7174aae9695b521d33eb563": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3088fb3c8cc74d7c97d9cbacc5b20c03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3332c9a35d2e40ac860233ebfb8c64c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34f2229c854f4695b5aba5d5afe772f5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "355092a75fa445ddb58c3c0e6c7c87f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "365523a881584181973972b7df86c3eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a1808fea5884186924c50c1d44cdb2b",
      "max": 466081,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6cb72ab4081a44fd8462b7d58da7236c",
      "value": 466081
     }
    },
    "37bbe9f296674040a1e4e6f414645aee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38344f64512b421aa12ac82fcf4b195d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "392ee34639024892a83a85f6878b60ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3a1808fea5884186924c50c1d44cdb2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e583707d8f7457bb3a5433440f3a6cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f54b0320e054ef4ab7cc33ca97ad75c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_13c4cd250f4c49169902a77e3b76727c",
       "IPY_MODEL_9100526f824f4e2298b22f43461c6daa",
       "IPY_MODEL_5e7028e3f8f6469086b2b94066dc9526"
      ],
      "layout": "IPY_MODEL_6901a356aa2c4361953ba9b44065710b"
     }
    },
    "4016322235e5422687997b6c942b8684": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea9b31c529f0482c99ac5ede1b0c2437",
      "max": 711661,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2f08477187154be899c3a1378e703260",
      "value": 711661
     }
    },
    "42c591eaee9f42f8ad965372898e3bdd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "45045e6a12e041e1b2b2713ff59ef938": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45c9710ebd6e45ddaa72f349380c5e16": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45d616297f6d42fc89f2b28c6fc10c90": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4663ab81441947f7bd1b86a08d82a6b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "46b7f140d4134097a8f6c7dd41d9acd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "47d8987c94434ddb89281035f30e9d4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45c9710ebd6e45ddaa72f349380c5e16",
      "placeholder": "​",
      "style": "IPY_MODEL_9defae4a31724cc1b6c0128b76bae404",
      "value": "config.json: 100%"
     }
    },
    "486f19f393194214820b2e4719793822": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6257ec67ee0043adab5a9e24a4f709a8",
      "placeholder": "​",
      "style": "IPY_MODEL_df62dad6b54444659f23d7cca3ddaa70",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "4977730998754c6d82831b47a647b428": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_761b0c7bec0f4ea98fff4469f3e147e1",
      "max": 57,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2f225874a7174aae9695b521d33eb563",
      "value": 57
     }
    },
    "4c7a193e4d3349dc8c2ff58c7137e77e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4da4cc126514421ebb1cd20eff5544f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e8321573083413d80d545eb711dabcb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5582c1c8145b4fe786ba967188680aa7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "572f1df5c7904ccf939d45356997f7a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58bdc5e07c694b4f9fc4e6612c1de4c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "58f1227b067740c99856d28d1b3535f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4c9a624ca3342adbdda81d0c505d540",
      "placeholder": "​",
      "style": "IPY_MODEL_7b9187f7562945ba813032f73d5fed96",
      "value": "modules.json: 100%"
     }
    },
    "5bf549707f604a99a4743166718cd720": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b524e9e4f75a45aba71a8a2b68557700",
      "placeholder": "​",
      "style": "IPY_MODEL_fdbe596b18164389a51d860b24f3b15b",
      "value": "README.md: 100%"
     }
    },
    "5de0a6a267a24518ac2857b47c4d2d4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e7028e3f8f6469086b2b94066dc9526": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_11e9dc55ddd64166a23b389ef4115bc5",
      "placeholder": "​",
      "style": "IPY_MODEL_090fd1cdc0694112b57d28e833932350",
      "value": " 232k/232k [00:00&lt;00:00, 1.78MB/s]"
     }
    },
    "5e9df76d9eb04c3cacc9caf4edacb913": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_25d444efba4c4f8ea2a15c4a197e83fa",
      "placeholder": "​",
      "style": "IPY_MODEL_fa2721e59a714068a0a5918cd7ec3246",
      "value": "model.safetensors: 100%"
     }
    },
    "5fca46bd83bd4f95ae25eecf342ff20f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc979bda6f3c486e8108945371fee26e",
      "placeholder": "​",
      "style": "IPY_MODEL_5de0a6a267a24518ac2857b47c4d2d4e",
      "value": " 743/743 [00:00&lt;00:00, 31.0kB/s]"
     }
    },
    "6023241ffbf740ec871828d6276cccb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d9d79532e89447e1ae295ea296d33dbf",
      "placeholder": "​",
      "style": "IPY_MODEL_4663ab81441947f7bd1b86a08d82a6b2",
      "value": " 466k/466k [00:00&lt;00:00, 2.32MB/s]"
     }
    },
    "61055f305b414a9995dd0093c8dd085b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4388ee32ed9434ea5e756c22fb61002",
      "placeholder": "​",
      "style": "IPY_MODEL_eac3132f4d9349cfa6f1422686ae7bd5",
      "value": " 190/190 [00:00&lt;00:00, 11.7kB/s]"
     }
    },
    "6257ec67ee0043adab5a9e24a4f709a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "63a47d5282db441a8e5732ab3266af33": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65617f6c0a3f40f1bb7198eadb9757da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6584fa0193f0433ead447e60d2c82607": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_47d8987c94434ddb89281035f30e9d4f",
       "IPY_MODEL_cf1bd11c82b44b99ac40e8abbec3785f",
       "IPY_MODEL_7e069a6942cb4cb09ef6aa3661844f88"
      ],
      "layout": "IPY_MODEL_7e0b008fb7294404a73b8341c1230125"
     }
    },
    "666d42ef1a74402fb13ea79db36c1287": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "66b76f1f830445e98fb9c1acc1683cde": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aee8fac5931844c5a88f651e7f854362",
      "max": 218990904,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e39705238d474d5a99f0a49832b408ed",
      "value": 218990904
     }
    },
    "6793b20c68004ef6806c0719d850ee07": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6901a356aa2c4361953ba9b44065710b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6aaf81405fa24b0e93a858d609b85036": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e04af96adae41a6b05ecc7bfe5a9fd9",
      "placeholder": "​",
      "style": "IPY_MODEL_b13c2b7166784d0f8d8a1ee231fe3235",
      "value": "sentence_bert_config.json: 100%"
     }
    },
    "6cb72ab4081a44fd8462b7d58da7236c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6da0a949eaf1499094fa4e264e1929ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6efb365326c24c339085be28cc203fdc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0bce7925eb1f4323a482bb90467bbc66",
      "placeholder": "​",
      "style": "IPY_MODEL_392ee34639024892a83a85f6878b60ef",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "6f038781e3a5498a9823999548de18fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1efc8ad79138462e97c1bf5f00d8a210",
      "placeholder": "​",
      "style": "IPY_MODEL_4e8321573083413d80d545eb711dabcb",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "718e83bf80b74bbb9e28a9a2473ab8db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "72f6e2507a5c49338610f22446087687": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_784f6571b15c4ac19ca2e1b1a913f318",
      "placeholder": "​",
      "style": "IPY_MODEL_42c591eaee9f42f8ad965372898e3bdd",
      "value": " 385/385 [00:00&lt;00:00, 26.4kB/s]"
     }
    },
    "755d31fc51614b78a6798a1f45d66a29": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "761b0c7bec0f4ea98fff4469f3e147e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "784f6571b15c4ac19ca2e1b1a913f318": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a550bf2dc964d0caafc8aed54d187a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5bf549707f604a99a4743166718cd720",
       "IPY_MODEL_bac9a59f6a1244d8a6e37795e0383e30",
       "IPY_MODEL_a113bb38b1f7458cae5e7825d6a65b3c"
      ],
      "layout": "IPY_MODEL_cda8adeebae9484c9399422c870aa7cf"
     }
    },
    "7a6d685007704814a51a027b060ba1b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b599c45a81df44619d92a3ac8ad41b0f",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c2cf8f815146436e86373dd6f02e94aa",
      "value": 231508
     }
    },
    "7b70f0bd5409433e93719cd05441e473": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_83665867accd4853b6efe68a06f7f403",
       "IPY_MODEL_66b76f1f830445e98fb9c1acc1683cde",
       "IPY_MODEL_26f97033c9e5479da8dca6f7dc642ece"
      ],
      "layout": "IPY_MODEL_6da0a949eaf1499094fa4e264e1929ca"
     }
    },
    "7b9187f7562945ba813032f73d5fed96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7e04af96adae41a6b05ecc7bfe5a9fd9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e069a6942cb4cb09ef6aa3661844f88": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f5553c33eefd47eea49e0e3901bf51f5",
      "placeholder": "​",
      "style": "IPY_MODEL_fc2843b06e0f4b6ca2a7d1d5fcde23d6",
      "value": " 618/618 [00:00&lt;00:00, 56.6kB/s]"
     }
    },
    "7e0b008fb7294404a73b8341c1230125": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "800014039af04d66adc94131a8ab568e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f741891d16434e959971b6331ab7a09e",
       "IPY_MODEL_20619dd814a245cb96eed1ffd6d23793",
       "IPY_MODEL_f91289ae253446ed90b7c9260d85ac2c"
      ],
      "layout": "IPY_MODEL_3088fb3c8cc74d7c97d9cbacc5b20c03"
     }
    },
    "8041af99466c478ab32dcb07ff597d41": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8110d80f4fe94d499834b799c85667ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca2e4e27247949fd96c09ca0084eb8d5",
      "max": 125,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ab3716a57cb1461ca4b89d3e2af60aa1",
      "value": 125
     }
    },
    "82baa3fb82e24827b49b6bda22f72d78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c938e4d55734c248ffb292415aa5f5b",
      "max": 405,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5582c1c8145b4fe786ba967188680aa7",
      "value": 405
     }
    },
    "83665867accd4853b6efe68a06f7f403": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b946716322e43bb9f4213087c6ee1de",
      "placeholder": "​",
      "style": "IPY_MODEL_c3cb074231f84c169f31afa3baf84fc9",
      "value": "model.safetensors: 100%"
     }
    },
    "836f49316d114d37846143df795ba15a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "863ed2e3ac1e4670b7850cf4deafc867": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "890443b9c63d42b597b1fce37ed2612f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cd319e80b28462698e8adb196302802": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_255d439785a54b9b8f37be9730c5b9f9",
      "placeholder": "​",
      "style": "IPY_MODEL_e3ea567b814a4d949a018e39137923fd",
      "value": "tokenizer.json: 100%"
     }
    },
    "8d567a74de4843a4b50292512c7d0ebe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90efeff073a541e3ace582146fd5fd45": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_183c14e615d6471c9fe4b9a56d13f85a",
      "placeholder": "​",
      "style": "IPY_MODEL_e15406eedc3b4b10b5d8c32d2ba5f1cd",
      "value": " 712k/712k [00:00&lt;00:00, 3.68MB/s]"
     }
    },
    "9100526f824f4e2298b22f43461c6daa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_34f2229c854f4695b5aba5d5afe772f5",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_38344f64512b421aa12ac82fcf4b195d",
      "value": 231508
     }
    },
    "91b7390bb1d94bd6be84496ed73052ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9553bb69e7c5479ebbf73787d3fc8b14": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9561e20747684a1a878a637d00c946fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b5cfff7bf253443682d8051953740ad2",
       "IPY_MODEL_d2b20654e6aa49359b678e198cc55a73",
       "IPY_MODEL_5fca46bd83bd4f95ae25eecf342ff20f"
      ],
      "layout": "IPY_MODEL_63a47d5282db441a8e5732ab3266af33"
     }
    },
    "97d0ee251daa487db840ba561a36d4a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b8ebc99d0ed4d9fb6f873f06a638318": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ce3da5248a34146945e40a660ed455d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9dc189ff36034264b081ca782c0bc1ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0e167716cc6941e2aaa5e85a476f1b1a",
      "placeholder": "​",
      "style": "IPY_MODEL_9ce3da5248a34146945e40a660ed455d",
      "value": " 57.0/57.0 [00:00&lt;00:00, 4.50kB/s]"
     }
    },
    "9defae4a31724cc1b6c0128b76bae404": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a113bb38b1f7458cae5e7825d6a65b3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ad12046944a468297e3c982794251ef",
      "placeholder": "​",
      "style": "IPY_MODEL_c0d3f59319544daa858e76bf490ac735",
      "value": " 68.1k/68.1k [00:00&lt;00:00, 4.12MB/s]"
     }
    },
    "a2c29ede70564d5b879b4084453d753f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b5693df9d1cf458e9c7dabfba2331102",
      "placeholder": "​",
      "style": "IPY_MODEL_4c7a193e4d3349dc8c2ff58c7137e77e",
      "value": " 405/405 [00:00&lt;00:00, 24.3kB/s]"
     }
    },
    "a68946ee535e4693955f8292b47c5b6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_755d31fc51614b78a6798a1f45d66a29",
      "max": 385,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_46b7f140d4134097a8f6c7dd41d9acd3",
      "value": 385
     }
    },
    "a77de46019434b2182d8ace90729411d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ab3716a57cb1461ca4b89d3e2af60aa1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "abe064fd2d2943cc9658631022e7dfbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "aee8fac5931844c5a88f651e7f854362": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b02abbcd98d94732961735247946d2d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b106e671bf2040ff85286339391cacce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b13c2b7166784d0f8d8a1ee231fe3235": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b14e572db35545c58c413b5313c230d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_26f3de4a37ed42c783b8cc8496a8830e",
       "IPY_MODEL_25ea5fce0d51425ca66647c86a69054d",
       "IPY_MODEL_1d5d56be1f3e4e06ad05b7a61c073773"
      ],
      "layout": "IPY_MODEL_0e6e63ccb1164deab11b438e7059d69f"
     }
    },
    "b215c0274af9444c9265aa576d33f6d5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b524e9e4f75a45aba71a8a2b68557700": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b5693df9d1cf458e9c7dabfba2331102": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b599c45a81df44619d92a3ac8ad41b0f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b5cfff7bf253443682d8051953740ad2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8d567a74de4843a4b50292512c7d0ebe",
      "placeholder": "​",
      "style": "IPY_MODEL_e4710695ec874eada402065fe800edd5",
      "value": "config.json: 100%"
     }
    },
    "b8d486c46bbc4a6abdb3b0af3dbc4c04": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ba96d1c92aeb4a9584f700869c028ace": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bac9a59f6a1244d8a6e37795e0383e30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e55c826128994d0a8b67885f40574fae",
      "max": 68075,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_836f49316d114d37846143df795ba15a",
      "value": 68075
     }
    },
    "bb8b2e9c41ea45dfa6fe7dff8a934fa2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be42d78fa32c44f4ba983327b2f2b0ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bfd5578f1cc3406b9b6e49540918dffd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0d3f59319544daa858e76bf490ac735": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c1225405706548aa86f466345ba78795": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f9124d67aef64019a437baa8eef8e54e",
       "IPY_MODEL_7a6d685007704814a51a027b060ba1b0",
       "IPY_MODEL_c87f3b6818934457af1827e01f4924ba"
      ],
      "layout": "IPY_MODEL_cfab7d69b2634082805f101090dcbd04"
     }
    },
    "c28b40c65c1f450988dfb834ccbf1526": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1257cd90321540d8b5530c35b672ac38",
       "IPY_MODEL_365523a881584181973972b7df86c3eb",
       "IPY_MODEL_6023241ffbf740ec871828d6276cccb8"
      ],
      "layout": "IPY_MODEL_863ed2e3ac1e4670b7850cf4deafc867"
     }
    },
    "c2cf8f815146436e86373dd6f02e94aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c3cb074231f84c169f31afa3baf84fc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c87f3b6818934457af1827e01f4924ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b02abbcd98d94732961735247946d2d4",
      "placeholder": "​",
      "style": "IPY_MODEL_666d42ef1a74402fb13ea79db36c1287",
      "value": " 232k/232k [00:00&lt;00:00, 3.33MB/s]"
     }
    },
    "c8c4de2dd87b409ab14e3bbd4f8ff777": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ca2e4e27247949fd96c09ca0084eb8d5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb37e6988db144ac9e6b615b71705c3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_58f1227b067740c99856d28d1b3535f0",
       "IPY_MODEL_a68946ee535e4693955f8292b47c5b6c",
       "IPY_MODEL_72f6e2507a5c49338610f22446087687"
      ],
      "layout": "IPY_MODEL_f7afe5336f9645bbaa3da495dad04c6f"
     }
    },
    "cda8adeebae9484c9399422c870aa7cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf1bd11c82b44b99ac40e8abbec3785f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3332c9a35d2e40ac860233ebfb8c64c7",
      "max": 618,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e0686b63c9374bcda05c70aeffbcda03",
      "value": 618
     }
    },
    "cfab7d69b2634082805f101090dcbd04": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2b20654e6aa49359b678e198cc55a73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b8ebc99d0ed4d9fb6f873f06a638318",
      "max": 743,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2750e13775ad4cc5a1ca97abd23a7fa4",
      "value": 743
     }
    },
    "d3e5436855af42a5b2f170b44388e4a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d696cc22200743caaaa0d70de5f29eaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d9d79532e89447e1ae295ea296d33dbf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df4976d8d7ec47e4986f5e9c0395c3a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ba96d1c92aeb4a9584f700869c028ace",
      "max": 314,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c8c4de2dd87b409ab14e3bbd4f8ff777",
      "value": 314
     }
    },
    "df62dad6b54444659f23d7cca3ddaa70": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e0686b63c9374bcda05c70aeffbcda03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e15406eedc3b4b10b5d8c32d2ba5f1cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e249235d4bb14478a802d3fc362fe215": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_355092a75fa445ddb58c3c0e6c7c87f7",
      "placeholder": "​",
      "style": "IPY_MODEL_a77de46019434b2182d8ace90729411d",
      "value": " 314/314 [00:00&lt;00:00, 15.5kB/s]"
     }
    },
    "e39705238d474d5a99f0a49832b408ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e3ea567b814a4d949a018e39137923fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e4710695ec874eada402065fe800edd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e55c826128994d0a8b67885f40574fae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5ff1078ea2d454ba88d92b978bee13f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e68e4e022b7946139920753c55012db2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45045e6a12e041e1b2b2713ff59ef938",
      "placeholder": "​",
      "style": "IPY_MODEL_0f57c3f8ee4d42b3b02aba300b4fe271",
      "value": "1_Pooling/config.json: 100%"
     }
    },
    "e7096ed061374902935f3363540caa56": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7816626014f47fbb744f707990f3c0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e7096ed061374902935f3363540caa56",
      "placeholder": "​",
      "style": "IPY_MODEL_3e583707d8f7457bb3a5433440f3a6cb",
      "value": " 125/125 [00:00&lt;00:00, 7.81kB/s]"
     }
    },
    "e7bc53149d98433785d628cd3783cbdb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ea2f3d5138cb4d3eb4b5f50122c42634": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea9b31c529f0482c99ac5ede1b0c2437": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eac3132f4d9349cfa6f1422686ae7bd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec25bd06a00e4e2cab1b9f62905449ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f4388ee32ed9434ea5e756c22fb61002": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f46f3a7030a34d3894d97214fb03e1c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f4c9a624ca3342adbdda81d0c505d540": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5553c33eefd47eea49e0e3901bf51f5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f741891d16434e959971b6331ab7a09e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_234ab5cd38b14aec8426fcc28dfc4952",
      "placeholder": "​",
      "style": "IPY_MODEL_b8d486c46bbc4a6abdb3b0af3dbc4c04",
      "value": "artifact.metadata: 100%"
     }
    },
    "f7afe5336f9645bbaa3da495dad04c6f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f82609221b714ae58214a6f6745526b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6f038781e3a5498a9823999548de18fd",
       "IPY_MODEL_8110d80f4fe94d499834b799c85667ad",
       "IPY_MODEL_e7816626014f47fbb744f707990f3c0b"
      ],
      "layout": "IPY_MODEL_65617f6c0a3f40f1bb7198eadb9757da"
     }
    },
    "f8c3f5363e824e338cf4b7ea0f09b92a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6aaf81405fa24b0e93a858d609b85036",
       "IPY_MODEL_4977730998754c6d82831b47a647b428",
       "IPY_MODEL_9dc189ff36034264b081ca782c0bc1ed"
      ],
      "layout": "IPY_MODEL_91b7390bb1d94bd6be84496ed73052ee"
     }
    },
    "f9124d67aef64019a437baa8eef8e54e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9553bb69e7c5479ebbf73787d3fc8b14",
      "placeholder": "​",
      "style": "IPY_MODEL_0eae622975df4cfaaa2e54cde12fecc2",
      "value": "vocab.txt: 100%"
     }
    },
    "f91289ae253446ed90b7c9260d85ac2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d7b6a6ffb3849ec9828e24f4e193840",
      "placeholder": "​",
      "style": "IPY_MODEL_718e83bf80b74bbb9e28a9a2473ab8db",
      "value": " 1.63k/1.63k [00:00&lt;00:00, 59.6kB/s]"
     }
    },
    "fa2721e59a714068a0a5918cd7ec3246": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fc2843b06e0f4b6ca2a7d1d5fcde23d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fc6ba90ca08747e1bace0a55d1eeed55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5e9df76d9eb04c3cacc9caf4edacb913",
       "IPY_MODEL_091d085339a14a0ab5a23a60b24508f6",
       "IPY_MODEL_1191b9f6ca7e491c91a54648d9a95740"
      ],
      "layout": "IPY_MODEL_b106e671bf2040ff85286339391cacce"
     }
    },
    "fc979bda6f3c486e8108945371fee26e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fdbe596b18164389a51d860b24f3b15b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
