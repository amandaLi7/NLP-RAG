{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.26.3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install ctransformers[cuda]\n",
    "# !pip3 install numpy==1.26.4\n",
    "import numpy as np\n",
    "np.__version__\n",
    "\n",
    "# restart after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "s96leWz22vbg",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv('.env')\n",
    "# hf_api = os.getenv('HF_API')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 18031,
     "status": "ok",
     "timestamp": 1709884858907,
     "user": {
      "displayName": "Vashisth Tiwari",
      "userId": "14058204908965748495"
     },
     "user_tz": 300
    },
    "id": "s-iSASxn3CUu",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "6c5d8662-e6ed-45db-fcea-54ea512ec45d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.38.0\n",
      "  Downloading transformers-4.38.0-py3-none-any.whl.metadata (131 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.1/131.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.38.0) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.38.0) (0.21.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.38.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.38.0) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.38.0) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.38.0)\n",
      "  Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.38.0) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.38.0)\n",
      "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers==4.38.0)\n",
      "  Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.38.0) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.0) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.0) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.38.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.38.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.38.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.38.0) (2023.11.17)\n",
      "Downloading transformers-4.38.0-py3-none-any.whl (8.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, regex, tokenizers, transformers\n",
      "Successfully installed regex-2023.12.25 safetensors-0.4.2 tokenizers-0.15.2 transformers-4.38.0\n",
      "Collecting unstructured\n",
      "  Downloading unstructured-0.12.6-py3-none-any.whl.metadata (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting ragatouille\n",
      "  Downloading ragatouille-0.0.7.post10-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting backoff==2.2.1 (from unstructured)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: beautifulsoup4==4.12.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from unstructured) (4.12.3)\n",
      "Collecting certifi==2024.2.2 (from unstructured)\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting chardet==5.2.0 (from unstructured)\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: charset-normalizer==3.3.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from unstructured) (3.3.2)\n",
      "Requirement already satisfied: click==8.1.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from unstructured) (8.1.7)\n",
      "Requirement already satisfied: dataclasses-json==0.6.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from unstructured) (0.6.4)\n",
      "Collecting dataclasses-json-speakeasy==0.5.11 (from unstructured)\n",
      "  Downloading dataclasses_json_speakeasy-0.5.11-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting emoji==2.10.1 (from unstructured)\n",
      "  Downloading emoji-2.10.1-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting filetype==1.2.0 (from unstructured)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: idna==3.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from unstructured) (3.6)\n",
      "Requirement already satisfied: joblib==1.3.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from unstructured) (1.3.2)\n",
      "Collecting jsonpath-python==1.0.6 (from unstructured)\n",
      "  Downloading jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting langdetect==1.0.9 (from unstructured)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting lxml==5.1.0 (from unstructured)\n",
      "  Downloading lxml-5.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n",
      "Collecting marshmallow==3.20.2 (from unstructured)\n",
      "  Downloading marshmallow-3.20.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: mypy-extensions==1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from unstructured) (1.0.0)\n",
      "Collecting nltk==3.8.1 (from unstructured)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: numpy==1.26.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from unstructured) (1.26.4)\n",
      "Requirement already satisfied: packaging==23.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from unstructured) (23.2)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from unstructured) (2.8.2)\n",
      "Collecting python-iso639==2024.2.7 (from unstructured)\n",
      "  Downloading python_iso639-2024.2.7-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting python-magic==0.4.27 (from unstructured)\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting rapidfuzz==3.6.1 (from unstructured)\n",
      "  Downloading rapidfuzz-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: regex==2023.12.25 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from unstructured) (2023.12.25)\n",
      "Requirement already satisfied: requests==2.31.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from unstructured) (2.31.0)\n",
      "Requirement already satisfied: six==1.16.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from unstructured) (1.16.0)\n",
      "Requirement already satisfied: soupsieve==2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from unstructured) (2.5)\n",
      "Requirement already satisfied: tabulate==0.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from unstructured) (0.9.0)\n",
      "Collecting tqdm==4.66.2 (from unstructured)\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions==4.9.0 (from unstructured)\n",
      "  Downloading typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-inspect==0.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from unstructured) (0.9.0)\n",
      "Collecting unstructured-client==0.18.0 (from unstructured)\n",
      "  Downloading unstructured_client-0.18.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: urllib3==1.26.18 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from unstructured) (1.26.18)\n",
      "Collecting wrapt==1.16.0 (from unstructured)\n",
      "  Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting aiohttp==3.9.1 (from ragatouille)\n",
      "  Downloading aiohttp-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting colbert-ai==0.2.19 (from ragatouille)\n",
      "  Downloading colbert-ai-0.2.19.tar.gz (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting faiss-cpu<2.0.0,>=1.7.4 (from ragatouille)\n",
      "  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: langchain<0.2.0,>=0.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ragatouille) (0.1.11)\n",
      "Requirement already satisfied: langchain_core<0.2.0,>=0.1.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ragatouille) (0.1.30)\n",
      "Collecting llama-index<0.10.0,>=0.9.24 (from ragatouille)\n",
      "  Downloading llama_index-0.9.48-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting onnx<2.0.0,>=1.15.0 (from ragatouille)\n",
      "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Collecting ruff<0.2.0,>=0.1.9 (from ragatouille)\n",
      "  Downloading ruff-0.1.15-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: sentence-transformers<3.0.0,>=2.2.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ragatouille) (2.5.1)\n",
      "Collecting srsly==2.4.8 (from ragatouille)\n",
      "  Downloading srsly-2.4.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: torch<3.0.0,>=2.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ragatouille) (2.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.36.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ragatouille) (4.38.0)\n",
      "Collecting voyager<3.0.0,>=2.0.2 (from ragatouille)\n",
      "  Downloading voyager-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp==3.9.1->ragatouille) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp==3.9.1->ragatouille) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp==3.9.1->ragatouille) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp==3.9.1->ragatouille) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp==3.9.1->ragatouille) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp==3.9.1->ragatouille) (4.0.3)\n",
      "Collecting bitarray (from colbert-ai==0.2.19->ragatouille)\n",
      "  Downloading bitarray-2.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
      "Collecting datasets (from colbert-ai==0.2.19->ragatouille)\n",
      "  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: flask in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from colbert-ai==0.2.19->ragatouille) (3.0.1)\n",
      "Collecting git-python (from colbert-ai==0.2.19->ragatouille)\n",
      "  Downloading git_python-1.0.3-py2.py3-none-any.whl.metadata (331 bytes)\n",
      "Collecting python-dotenv (from colbert-ai==0.2.19->ragatouille)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting ninja (from colbert-ai==0.2.19->ragatouille)\n",
      "  Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from colbert-ai==0.2.19->ragatouille) (1.12.0)\n",
      "Requirement already satisfied: ujson in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from colbert-ai==0.2.19->ragatouille) (5.9.0)\n",
      "Collecting catalogue<2.1.0,>=2.0.3 (from srsly==2.4.8->ragatouille)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (2.0.28)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.25 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (0.0.27)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (0.1.23)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (2.6.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (8.2.3)\n",
      "Requirement already satisfied: anyio<5,>=3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain_core<0.2.0,>=0.1.4->ragatouille) (4.2.0)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index<0.10.0,>=0.9.24->ragatouille)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index<0.10.0,>=0.9.24->ragatouille)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (2023.12.2)\n",
      "Collecting httpx (from llama-index<0.10.0,>=0.9.24->ragatouille)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (3.2.1)\n",
      "Collecting openai>=1.1.0 (from llama-index<0.10.0,>=0.9.24->ragatouille)\n",
      "  Downloading openai-1.13.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from llama-index<0.10.0,>=0.9.24->ragatouille) (1.5.3)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index<0.10.0,>=0.9.24->ragatouille)\n",
      "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from onnx<2.0.0,>=1.15.0->ragatouille) (4.25.2)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.2.2->ragatouille) (1.4.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.2.2->ragatouille) (0.21.4)\n",
      "Requirement already satisfied: Pillow in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.2.2->ragatouille) (10.2.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<3.0.0,>=2.0.1->ragatouille) (3.13.1)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<3.0.0,>=2.0.1->ragatouille) (1.12)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<3.0.0,>=2.0.1->ragatouille) (3.1.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers<5.0.0,>=4.36.2->ragatouille) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers<5.0.0,>=4.36.2->ragatouille) (0.4.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<5,>=3->langchain_core<0.2.0,>=0.1.4->ragatouille) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<5,>=3->langchain_core<0.2.0,>=0.1.4->ragatouille) (1.2.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain<0.2.0,>=0.1.0->ragatouille) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.0->ragatouille) (3.9.15)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.1.0->llama-index<0.10.0,>=0.9.24->ragatouille)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpcore==1.* (from httpx->llama-index<0.10.0,>=0.9.24->ragatouille)\n",
      "  Downloading httpcore-1.0.4-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index<0.10.0,>=0.9.24->ragatouille)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.0->ragatouille) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.0->ragatouille) (2.16.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain<0.2.0,>=0.1.0->ragatouille) (3.0.3)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->colbert-ai==0.2.19->ragatouille) (15.0.0)\n",
      "Collecting pyarrow-hotfix (from datasets->colbert-ai==0.2.19->ragatouille)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->colbert-ai==0.2.19->ragatouille) (0.3.8)\n",
      "Collecting xxhash (from datasets->colbert-ai==0.2.19->ragatouille)\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->colbert-ai==0.2.19->ragatouille) (0.70.16)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from flask->colbert-ai==0.2.19->ragatouille) (3.0.1)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from flask->colbert-ai==0.2.19->ragatouille) (2.1.2)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from flask->colbert-ai==0.2.19->ragatouille) (1.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch<3.0.0,>=2.0.1->ragatouille) (2.1.5)\n",
      "Collecting gitpython (from git-python->colbert-ai==0.2.19->ragatouille)\n",
      "  Using cached GitPython-3.1.42-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->llama-index<0.10.0,>=0.9.24->ragatouille) (2023.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn->sentence-transformers<3.0.0,>=2.2.2->ragatouille) (3.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch<3.0.0,>=2.0.1->ragatouille) (1.3.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython->git-python->colbert-ai==0.2.19->ragatouille)\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython->git-python->colbert-ai==0.2.19->ragatouille)\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading unstructured-0.12.6-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json_speakeasy-0.5.11-py3-none-any.whl (28 kB)\n",
      "Downloading emoji-2.10.1-py2.py3-none-any.whl (421 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.5/421.5 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
      "Downloading lxml-5.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_iso639-2024.2.7-py3-none-any.whl (274 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading rapidfuzz-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Downloading unstructured_client-0.18.0-py3-none-any.whl (21 kB)\n",
      "Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ragatouille-0.0.7.post10-py3-none-any.whl (35 kB)\n",
      "Downloading aiohttp-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading srsly-2.4.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.0/493.0 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading llama_index-0.9.48-py3-none-any.whl (15.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ruff-0.1.15-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading voyager-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading bitarray-2.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.3/288.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading git_python-1.0.3-py2.py3-none-any.whl (1.9 kB)\n",
      "Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
      "Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m524.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: langdetect, colbert-ai\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=9f7336d4bc66e413bbb684c9fa7ef82291cbd53d6b045535a2df76d592b429d7\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
      "  Building wheel for colbert-ai (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for colbert-ai: filename=colbert_ai-0.2.19-py3-none-any.whl size=114761 sha256=f1dd2012ba027fcebddb2d0eb504eb3ae8047193d7d1a186659b5c61b51a80e2\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/90/b9/63/d4fc276c73c42ef7fc1065a26cf87e5a1cf56ef6498cbfbe5d\n",
      "Successfully built langdetect colbert-ai\n",
      "Installing collected packages: ninja, filetype, dirtyjson, bitarray, xxhash, wrapt, voyager, typing-extensions, tqdm, smmap, ruff, rapidfuzz, python-magic, python-iso639, python-dotenv, pyarrow-hotfix, onnx, marshmallow, lxml, langdetect, jsonpath-python, h11, faiss-cpu, emoji, distro, chardet, certifi, catalogue, backoff, srsly, nltk, httpcore, gitdb, deprecated, aiohttp, tiktoken, httpx, gitpython, dataclasses-json-speakeasy, unstructured-client, openai, git-python, datasets, unstructured, llama-index, colbert-ai, ragatouille\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.10.0\n",
      "    Uninstalling typing_extensions-4.10.0:\n",
      "      Successfully uninstalled typing_extensions-4.10.0\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.1\n",
      "    Uninstalling tqdm-4.66.1:\n",
      "      Successfully uninstalled tqdm-4.66.1\n",
      "  Attempting uninstall: onnx\n",
      "    Found existing installation: onnx 1.13.1\n",
      "    Uninstalling onnx-1.13.1:\n",
      "      Successfully uninstalled onnx-1.13.1\n",
      "  Attempting uninstall: marshmallow\n",
      "    Found existing installation: marshmallow 3.21.1\n",
      "    Uninstalling marshmallow-3.21.1:\n",
      "      Successfully uninstalled marshmallow-3.21.1\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2023.11.17\n",
      "    Uninstalling certifi-2023.11.17:\n",
      "      Successfully uninstalled certifi-2023.11.17\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.9.3\n",
      "    Uninstalling aiohttp-3.9.3:\n",
      "      Successfully uninstalled aiohttp-3.9.3\n",
      "Successfully installed aiohttp-3.9.1 backoff-2.2.1 bitarray-2.9.2 catalogue-2.0.10 certifi-2024.2.2 chardet-5.2.0 colbert-ai-0.2.19 dataclasses-json-speakeasy-0.5.11 datasets-2.18.0 deprecated-1.2.14 dirtyjson-1.0.8 distro-1.9.0 emoji-2.10.1 faiss-cpu-1.8.0 filetype-1.2.0 git-python-1.0.3 gitdb-4.0.11 gitpython-3.1.42 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 jsonpath-python-1.0.6 langdetect-1.0.9 llama-index-0.9.48 lxml-5.1.0 marshmallow-3.20.2 ninja-1.11.1.1 nltk-3.8.1 onnx-1.15.0 openai-1.13.3 pyarrow-hotfix-0.6 python-dotenv-1.0.1 python-iso639-2024.2.7 python-magic-0.4.27 ragatouille-0.0.7.post10 rapidfuzz-3.6.1 ruff-0.1.15 smmap-5.0.1 srsly-2.4.8 tiktoken-0.6.0 tqdm-4.66.2 typing-extensions-4.9.0 unstructured-0.12.6 unstructured-client-0.18.0 voyager-2.0.2 wrapt-1.16.0 xxhash-3.4.1\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Mon_Apr__3_17:16:06_PDT_2023\n",
      "Cuda compilation tools, release 12.1, V12.1.105\n",
      "Build cuda_12.1.r12.1/compiler.32688072_0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.38.0\n",
    "!pip install -q torch accelerate bitsandbytes langchain sentence-transformers faiss-gpu openpyxl\n",
    "!pip install unstructured ragatouille\n",
    "# # reranker\n",
    "from ragatouille import RAGPretrainedModel\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 275993,
     "status": "ok",
     "timestamp": 1710110355792,
     "user": {
      "displayName": "Vashisth Tiwari",
      "userId": "14058204908965748495"
     },
     "user_tz": 240
    },
    "id": "-hsCAcjxIP19",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "128ca964-5cf2-4f00-cfa4-2ec234a65bdd",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-cpp-python\n",
      "  Downloading llama_cpp_python-0.2.56.tar.gz (36.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.9/36.9 MB\u001b[0m \u001b[31m199.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting typing-extensions>=4.5.0 (from llama-cpp-python)\n",
      "  Downloading typing_extensions-4.10.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting numpy>=1.20.0 (from llama-cpp-python)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m319.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting diskcache>=5.6.1 (from llama-cpp-python)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting jinja2>=2.11.3 (from llama-cpp-python)\n",
      "  Downloading Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2>=2.11.3->llama-cpp-python)\n",
      "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m281.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 kB\u001b[0m \u001b[31m366.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m198.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Building wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.56-cp310-cp310-manylinux_2_26_x86_64.whl size=22629768 sha256=96959f4538094622cad8cdb23481bd0810132457e58ebc5c6b226bb13a0d209d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-qp1bt_xg/wheels/e5/09/9d/c413053f6258cb2546cc792418c595e276f9efd5db31a80377\n",
      "Successfully built llama-cpp-python\n",
      "Installing collected packages: typing-extensions, numpy, MarkupSafe, diskcache, jinja2, llama-cpp-python\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.9.0\n",
      "    Uninstalling typing_extensions-4.9.0:\n",
      "      Successfully uninstalled typing_extensions-4.9.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.3\n",
      "    Uninstalling numpy-1.26.3:\n",
      "      Successfully uninstalled numpy-1.26.3\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 2.1.4\n",
      "    Uninstalling MarkupSafe-2.1.4:\n",
      "      Successfully uninstalled MarkupSafe-2.1.4\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 3.1.3\n",
      "    Uninstalling Jinja2-3.1.3:\n",
      "      Successfully uninstalled Jinja2-3.1.3\n",
      "Successfully installed MarkupSafe-2.1.5 diskcache-5.6.3 jinja2-3.1.3 llama-cpp-python-0.2.56 numpy-1.26.4 typing-extensions-4.10.0\n"
     ]
    }
   ],
   "source": [
    "# this will take time :c\n",
    "!CUDACXX=/usr/local/cuda-12.1/bin/nvcc CMAKE_ARGS=\"-DLLAMA_CUBLAS=on -DCMAKE_CUDA_ARCHITECTURES=all-major\" FORCE_CMAKE=1 pip install llama-cpp-python --no-cache-dir --force-reinstall --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4ItWW1Es3OX_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fix colab error: https://stackoverflow.com/questions/56081324/why-are-google-colab-shell-commands-not-working\n",
    "import locale\n",
    "def getpreferredencoding(do_setlocale = True):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = getpreferredencoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "id": "CB6DVShA2vbh",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.1.11-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.28-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Downloading dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.25 (from langchain)\n",
      "  Downloading langchain_community-0.0.27-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting langchain-core<0.2,>=0.1.29 (from langchain)\n",
      "  Downloading langchain_core-0.1.30-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.23-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (2.6.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading marshmallow-3.21.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.29->langchain) (4.2.0)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2,>=0.1.29->langchain)\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.29->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.29->langchain) (1.2.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain-0.1.11-py3-none-any.whl (807 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.5/807.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_community-0.0.27-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m111.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.1.30-py3-none-any.whl (256 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.9/256.9 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Downloading langsmith-0.1.23-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.6/66.6 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.28-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.0/616.0 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: packaging, orjson, mypy-extensions, multidict, jsonpatch, greenlet, frozenlist, async-timeout, yarl, typing-inspect, SQLAlchemy, marshmallow, aiosignal, langsmith, dataclasses-json, aiohttp, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.3\n",
      "    Uninstalling packaging-21.3:\n",
      "      Successfully uninstalled packaging-21.3\n",
      "Successfully installed SQLAlchemy-2.0.28 aiohttp-3.9.3 aiosignal-1.3.1 async-timeout-4.0.3 dataclasses-json-0.6.4 frozenlist-1.4.1 greenlet-3.0.3 jsonpatch-1.33 langchain-0.1.11 langchain-community-0.0.27 langchain-core-0.1.30 langchain-text-splitters-0.0.1 langsmith-0.1.23 marshmallow-3.21.1 multidict-6.0.5 mypy-extensions-1.0.0 orjson-3.9.15 packaging-23.2 typing-inspect-0.9.0 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.docstore.document import Document as LangchainDocument\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "id": "GrqalAohmDnp",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-0.21.4-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub) (2023.12.2)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub) (4.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface_hub) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface_hub) (2023.11.17)\n",
      "Downloading huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.4/346.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: huggingface_hub\n",
      "Successfully installed huggingface_hub-0.21.4\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install huggingface_hub\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hf_hub_download\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub\n",
    "from huggingface_hub import hf_hub_download\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "m1Dm1uHk2vbh",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from typing import Optional, List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option(\n",
    "    \"display.max_colwidth\", None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ti-G7vMdASy"
   },
   "outputs": [],
   "source": [
    "# pip list --outdated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pO3SVhxSshpo"
   },
   "source": [
    "# Specify the model/versions, etc.\n",
    "## also specify the knowledge base file and the reference answer directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365,
     "referenced_widgets": [
      "800014039af04d66adc94131a8ab568e",
      "f741891d16434e959971b6331ab7a09e",
      "20619dd814a245cb96eed1ffd6d23793",
      "f91289ae253446ed90b7c9260d85ac2c",
      "3088fb3c8cc74d7c97d9cbacc5b20c03",
      "234ab5cd38b14aec8426fcc28dfc4952",
      "b8d486c46bbc4a6abdb3b0af3dbc4c04",
      "be42d78fa32c44f4ba983327b2f2b0ae",
      "d696cc22200743caaaa0d70de5f29eaf",
      "2d7b6a6ffb3849ec9828e24f4e193840",
      "718e83bf80b74bbb9e28a9a2473ab8db",
      "9561e20747684a1a878a637d00c946fa",
      "b5cfff7bf253443682d8051953740ad2",
      "d2b20654e6aa49359b678e198cc55a73",
      "5fca46bd83bd4f95ae25eecf342ff20f",
      "63a47d5282db441a8e5732ab3266af33",
      "8d567a74de4843a4b50292512c7d0ebe",
      "e4710695ec874eada402065fe800edd5",
      "9b8ebc99d0ed4d9fb6f873f06a638318",
      "2750e13775ad4cc5a1ca97abd23a7fa4",
      "fc979bda6f3c486e8108945371fee26e",
      "5de0a6a267a24518ac2857b47c4d2d4e",
      "fc6ba90ca08747e1bace0a55d1eeed55",
      "5e9df76d9eb04c3cacc9caf4edacb913",
      "091d085339a14a0ab5a23a60b24508f6",
      "1191b9f6ca7e491c91a54648d9a95740",
      "b106e671bf2040ff85286339391cacce",
      "25d444efba4c4f8ea2a15c4a197e83fa",
      "fa2721e59a714068a0a5918cd7ec3246",
      "8041af99466c478ab32dcb07ff597d41",
      "ec25bd06a00e4e2cab1b9f62905449ca",
      "d3e5436855af42a5b2f170b44388e4a8",
      "195ac8d683264e9999a419b94e60bdc1",
      "08e5c13a33c442d69db6a4e5cb1aefd8",
      "486f19f393194214820b2e4719793822",
      "82baa3fb82e24827b49b6bda22f72d78",
      "a2c29ede70564d5b879b4084453d753f",
      "bb8b2e9c41ea45dfa6fe7dff8a934fa2",
      "6257ec67ee0043adab5a9e24a4f709a8",
      "df62dad6b54444659f23d7cca3ddaa70",
      "2c938e4d55734c248ffb292415aa5f5b",
      "5582c1c8145b4fe786ba967188680aa7",
      "b5693df9d1cf458e9c7dabfba2331102",
      "4c7a193e4d3349dc8c2ff58c7137e77e",
      "c1225405706548aa86f466345ba78795",
      "f9124d67aef64019a437baa8eef8e54e",
      "7a6d685007704814a51a027b060ba1b0",
      "c87f3b6818934457af1827e01f4924ba",
      "cfab7d69b2634082805f101090dcbd04",
      "9553bb69e7c5479ebbf73787d3fc8b14",
      "0eae622975df4cfaaa2e54cde12fecc2",
      "b599c45a81df44619d92a3ac8ad41b0f",
      "c2cf8f815146436e86373dd6f02e94aa",
      "b02abbcd98d94732961735247946d2d4",
      "666d42ef1a74402fb13ea79db36c1287",
      "c28b40c65c1f450988dfb834ccbf1526",
      "1257cd90321540d8b5530c35b672ac38",
      "365523a881584181973972b7df86c3eb",
      "6023241ffbf740ec871828d6276cccb8",
      "863ed2e3ac1e4670b7850cf4deafc867",
      "890443b9c63d42b597b1fce37ed2612f",
      "e7bc53149d98433785d628cd3783cbdb",
      "3a1808fea5884186924c50c1d44cdb2b",
      "6cb72ab4081a44fd8462b7d58da7236c",
      "d9d79532e89447e1ae295ea296d33dbf",
      "4663ab81441947f7bd1b86a08d82a6b2",
      "b14e572db35545c58c413b5313c230d0",
      "26f3de4a37ed42c783b8cc8496a8830e",
      "25ea5fce0d51425ca66647c86a69054d",
      "1d5d56be1f3e4e06ad05b7a61c073773",
      "0e6e63ccb1164deab11b438e7059d69f",
      "e5ff1078ea2d454ba88d92b978bee13f",
      "97d0ee251daa487db840ba561a36d4a8",
      "572f1df5c7904ccf939d45356997f7a7",
      "abe064fd2d2943cc9658631022e7dfbe",
      "37bbe9f296674040a1e4e6f414645aee",
      "0567916024824a5cb153ee96ae90bcfd"
     ]
    },
    "executionInfo": {
     "elapsed": 6034,
     "status": "ok",
     "timestamp": 1710110390648,
     "user": {
      "displayName": "Vashisth Tiwari",
      "userId": "14058204908965748495"
     },
     "user_tz": 240
    },
    "id": "SscMCDYU2vbh",
    "outputId": "83e0ecb7-0a38-489a-ec55-a9c7d22fc51f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50eb11e35d14454680451a779ec45dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "artifact.metadata:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7881257a572b414cb916f8caaf91e17f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57404125662a4b278ec182b93a6212a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f880fcb210c04ec6b0a4fd83cc92b618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/405 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03391ba33ffa4e9cbd81aa894b1d5143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2143a29b53934b51871a521d4793ae96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "055e945ba9014a9780f2773cfcb6e755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EMBEDDING_MODEL = \"thenlper/gte-base\"\n",
    "RERANKER_MODEL = \"colbert-ir/colbertv2.0\"\n",
    "RERANKER = RAGPretrainedModel.from_pretrained(RERANKER_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337,
     "referenced_widgets": [
      "cb37e6988db144ac9e6b615b71705c3d",
      "58f1227b067740c99856d28d1b3535f0",
      "a68946ee535e4693955f8292b47c5b6c",
      "72f6e2507a5c49338610f22446087687",
      "f7afe5336f9645bbaa3da495dad04c6f",
      "f4c9a624ca3342adbdda81d0c505d540",
      "7b9187f7562945ba813032f73d5fed96",
      "755d31fc51614b78a6798a1f45d66a29",
      "46b7f140d4134097a8f6c7dd41d9acd3",
      "784f6571b15c4ac19ca2e1b1a913f318",
      "42c591eaee9f42f8ad965372898e3bdd",
      "7a550bf2dc964d0caafc8aed54d187a6",
      "5bf549707f604a99a4743166718cd720",
      "bac9a59f6a1244d8a6e37795e0383e30",
      "a113bb38b1f7458cae5e7825d6a65b3c",
      "cda8adeebae9484c9399422c870aa7cf",
      "b524e9e4f75a45aba71a8a2b68557700",
      "fdbe596b18164389a51d860b24f3b15b",
      "e55c826128994d0a8b67885f40574fae",
      "836f49316d114d37846143df795ba15a",
      "1ad12046944a468297e3c982794251ef",
      "c0d3f59319544daa858e76bf490ac735",
      "f8c3f5363e824e338cf4b7ea0f09b92a",
      "6aaf81405fa24b0e93a858d609b85036",
      "4977730998754c6d82831b47a647b428",
      "9dc189ff36034264b081ca782c0bc1ed",
      "91b7390bb1d94bd6be84496ed73052ee",
      "7e04af96adae41a6b05ecc7bfe5a9fd9",
      "b13c2b7166784d0f8d8a1ee231fe3235",
      "761b0c7bec0f4ea98fff4469f3e147e1",
      "2f225874a7174aae9695b521d33eb563",
      "0e167716cc6941e2aaa5e85a476f1b1a",
      "9ce3da5248a34146945e40a660ed455d",
      "6584fa0193f0433ead447e60d2c82607",
      "47d8987c94434ddb89281035f30e9d4f",
      "cf1bd11c82b44b99ac40e8abbec3785f",
      "7e069a6942cb4cb09ef6aa3661844f88",
      "7e0b008fb7294404a73b8341c1230125",
      "45c9710ebd6e45ddaa72f349380c5e16",
      "9defae4a31724cc1b6c0128b76bae404",
      "3332c9a35d2e40ac860233ebfb8c64c7",
      "e0686b63c9374bcda05c70aeffbcda03",
      "f5553c33eefd47eea49e0e3901bf51f5",
      "fc2843b06e0f4b6ca2a7d1d5fcde23d6",
      "7b70f0bd5409433e93719cd05441e473",
      "83665867accd4853b6efe68a06f7f403",
      "66b76f1f830445e98fb9c1acc1683cde",
      "26f97033c9e5479da8dca6f7dc642ece",
      "6da0a949eaf1499094fa4e264e1929ca",
      "0b946716322e43bb9f4213087c6ee1de",
      "c3cb074231f84c169f31afa3baf84fc9",
      "aee8fac5931844c5a88f651e7f854362",
      "e39705238d474d5a99f0a49832b408ed",
      "45d616297f6d42fc89f2b28c6fc10c90",
      "58bdc5e07c694b4f9fc4e6612c1de4c5",
      "0d0fbbe470054b0b879c1a62c411dc0c",
      "6efb365326c24c339085be28cc203fdc",
      "df4976d8d7ec47e4986f5e9c0395c3a9",
      "e249235d4bb14478a802d3fc362fe215",
      "ea2f3d5138cb4d3eb4b5f50122c42634",
      "0bce7925eb1f4323a482bb90467bbc66",
      "392ee34639024892a83a85f6878b60ef",
      "ba96d1c92aeb4a9584f700869c028ace",
      "c8c4de2dd87b409ab14e3bbd4f8ff777",
      "355092a75fa445ddb58c3c0e6c7c87f7",
      "a77de46019434b2182d8ace90729411d",
      "3f54b0320e054ef4ab7cc33ca97ad75c",
      "13c4cd250f4c49169902a77e3b76727c",
      "9100526f824f4e2298b22f43461c6daa",
      "5e7028e3f8f6469086b2b94066dc9526",
      "6901a356aa2c4361953ba9b44065710b",
      "b215c0274af9444c9265aa576d33f6d5",
      "f46f3a7030a34d3894d97214fb03e1c2",
      "34f2229c854f4695b5aba5d5afe772f5",
      "38344f64512b421aa12ac82fcf4b195d",
      "11e9dc55ddd64166a23b389ef4115bc5",
      "090fd1cdc0694112b57d28e833932350",
      "0c73d54adcb74546b98a15ff898640d2",
      "8cd319e80b28462698e8adb196302802",
      "4016322235e5422687997b6c942b8684",
      "90efeff073a541e3ace582146fd5fd45",
      "4da4cc126514421ebb1cd20eff5544f9",
      "255d439785a54b9b8f37be9730c5b9f9",
      "e3ea567b814a4d949a018e39137923fd",
      "ea9b31c529f0482c99ac5ede1b0c2437",
      "2f08477187154be899c3a1378e703260",
      "183c14e615d6471c9fe4b9a56d13f85a",
      "e15406eedc3b4b10b5d8c32d2ba5f1cd",
      "f82609221b714ae58214a6f6745526b3",
      "6f038781e3a5498a9823999548de18fd",
      "8110d80f4fe94d499834b799c85667ad",
      "e7816626014f47fbb744f707990f3c0b",
      "65617f6c0a3f40f1bb7198eadb9757da",
      "1efc8ad79138462e97c1bf5f00d8a210",
      "4e8321573083413d80d545eb711dabcb",
      "ca2e4e27247949fd96c09ca0084eb8d5",
      "ab3716a57cb1461ca4b89d3e2af60aa1",
      "e7096ed061374902935f3363540caa56",
      "3e583707d8f7457bb3a5433440f3a6cb",
      "200a894d245143b59503f70bbe099655",
      "e68e4e022b7946139920753c55012db2",
      "1d9cc219294748d7a4d06a0ef220d034",
      "61055f305b414a9995dd0093c8dd085b",
      "6793b20c68004ef6806c0719d850ee07",
      "45045e6a12e041e1b2b2713ff59ef938",
      "0f57c3f8ee4d42b3b02aba300b4fe271",
      "bfd5578f1cc3406b9b6e49540918dffd",
      "0fab8e8ae3fd4f47b43ee00df8a80deb",
      "f4388ee32ed9434ea5e756c22fb61002",
      "eac3132f4d9349cfa6f1422686ae7bd5"
     ]
    },
    "executionInfo": {
     "elapsed": 5437,
     "status": "ok",
     "timestamp": 1710110400718,
     "user": {
      "displayName": "Vashisth Tiwari",
      "userId": "14058204908965748495"
     },
     "user_tz": 240
    },
    "id": "zliNdIDo2vbh",
    "outputId": "7302e1a2-7bee-4b0e-8fcd-074783531201",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17a375e612244e0bb6ebf595bb8a26ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9c623d88d24ae98b76152afed984db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/68.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "635e916f8d384a938e5843806ec2303a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599cb88405274ba3adff9fceadc76e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/618 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6510de05a7c54816b2011258f3051c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/219M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b8ebc0c45004432a82925b2f2245c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a409d18bf5a144b0b05d54048219556a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ebb24c7896480e9e4c40e91b4653b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3bdc30ba6ca42399cf423e3428cb2ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088945c97b2a4779991136d807af17a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EMBEDDING_MODEL_NAME = EMBEDDING_MODEL\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=EMBEDDING_MODEL_NAME,\n",
    "    multi_process=True,\n",
    "    model_kwargs={\"device\": \"cuda\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 181,
     "status": "ok",
     "timestamp": 1710111573183,
     "user": {
      "displayName": "Vashisth Tiwari",
      "userId": "14058204908965748495"
     },
     "user_tz": 240
    },
    "id": "JIaPbE2th0I5",
    "outputId": "98ab622e-0a7f-4d29-f1ba-af5c6360d978",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/src-rag-final\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "0jF7haihucN6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "FAISS_FILE = '../faiss_index_total_final'\n",
    "# num_retrieved_docs: int = 10\n",
    "# num_docs_final: int = 3\n",
    "KNOWLEDGE_VECTOR_DATABASE = FAISS.load_local(FAISS_FILE, embedding_model, allow_dangerous_deserialization = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "pHsA8wuz4eE7",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8189cc02cb474cfc88a96b51bf2fdc58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llama-2-7b-chat.Q4_K_M.gguf:   0%|          | 0.00/4.08G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_path = \"TheBloke/Llama-2-7B-Chat-GGUF\"\n",
    "model_basename = \"llama-2-7b-chat.Q4_K_M.gguf\"\n",
    "model_path = hf_hub_download(repo_id=model_path, filename=model_basename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_27tccjshpp"
   },
   "source": [
    "# Reader LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3662,
     "status": "ok",
     "timestamp": 1710110638040,
     "user": {
      "displayName": "Vashisth Tiwari",
      "userId": "14058204908965748495"
     },
     "user_tz": 240
    },
    "id": "7H5oLKT72vbi",
    "outputId": "68c9a4ec-8d72-46c7-994a-55322496e435",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! repetition_penalty is not default parameter.\n",
      "                repetition_penalty was transferred to model_kwargs.\n",
      "                Please confirm that repetition_penalty is what you intended.\n",
      "  warnings.warn(\n",
      "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /home/ec2-user/.cache/huggingface/hub/models--TheBloke--Llama-2-7B-Chat-GGUF/snapshots/191239b3e26b2882fb562ffccdd1cf0f65402adb/llama-2-7b-chat.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
      "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.22 MiB\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =    70.31 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =  3820.94 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2400\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =  1200.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 1200.00 MiB, K (f16):  600.00 MiB, V (f16):  600.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host input buffer size   =     0.22 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =     2.92 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =     0.12 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 2\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n",
      "Using fallback chat format: None\n"
     ]
    }
   ],
   "source": [
    "# https://www.reddit.com/r/LocalLLaMA/comments/1343bgz/what_model_parameters_is_everyone_using/\n",
    "# temperature\t0.7\n",
    "# repetition_penalty=\t1.176\n",
    "# top_k\t= 40\n",
    "# top_p= 0.1\n",
    "\n",
    "# Initialize Large Language Model for answer generation\n",
    "llm_answer_gen = LlamaCpp(\n",
    "streaming = True,\n",
    "model_path = model_path,\n",
    "temperature=.2,\n",
    "n_gpu_layers=-1,\n",
    "top_p=.1,\n",
    "top_k\t= 40,\n",
    "repetition_penalty=\t1.176,\n",
    "verbose=True,\n",
    "n_ctx=2400\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1710113142107,
     "user": {
      "displayName": "Vashisth Tiwari",
      "userId": "14058204908965748495"
     },
     "user_tz": 240
    },
    "id": "l8bKX1rXFQBv",
    "outputId": "9d39a40d-28e7-4025-b401-052cc9b2f1c3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_answer_gen.verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCp6KhE0LXh4"
   },
   "source": [
    "# RAG Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "VhwgRYB467Gt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# link: https://python.langchain.com/docs/use_cases/chatbots/retrieval\n",
    "\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def answer_llama_new(\n",
    "    question: str,\n",
    "    knowledge_index: FAISS,\n",
    "    reranker: RAGPretrainedModel,\n",
    "    num_retrieved_docs: int = 10,\n",
    "    num_docs_final: int = 3,\n",
    "    llm: LlamaCpp = llm_answer_gen,\n",
    "    ): #-> Tuple[str, List[LangchainDocument]]\n",
    "\n",
    "    # https://stackoverflow.com/questions/76551067/how-to-create-a-langchain-doc-from-an-str\n",
    "\n",
    "    print(\"=> Retrieving documents...\")\n",
    "    relevant_docs_acquired = knowledge_index.similarity_search(query=question, k=num_retrieved_docs)\n",
    "    relevant_doc_id = [doc.metadata['source'] for doc in relevant_docs_acquired]\n",
    "\n",
    "    if reranker:\n",
    "        print(\"=> Reranking documents...\")\n",
    "        relevant_docs = [doc.page_content for doc in relevant_docs_acquired]\n",
    "        relevant_docs = reranker.rerank(question, relevant_docs, k=num_docs_final)\n",
    "\n",
    "        relevant_docs = [LangchainDocument(page_content=doc[\"content\"],\n",
    "                                           metadata={'source': relevant_doc_id[ doc['result_index']] } ) for doc in relevant_docs]\n",
    "\n",
    "        relevant_docs_content = [doc.page_content for doc in relevant_docs]\n",
    "        relevant_doc_id = [doc.metadata for doc in relevant_docs]\n",
    "\n",
    "    else:\n",
    "        relevant_docs_content = [doc.page_content for doc in relevant_docs_acquired]\n",
    "        relevant_docs = relevant_docs_acquired\n",
    "\n",
    "    relevant_docs_content = relevant_docs_content[:num_docs_final]\n",
    "    relevant_docs_indexed = relevant_docs[:num_docs_final]\n",
    "\n",
    "    # Build the final prompt\n",
    "    context = \"\\nExtracted documents:\\n\"\n",
    "    context += \"\".join([f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(relevant_docs_content)])\n",
    "\n",
    "    context_and_question = f\"Please provide concise answers while extracting only the necessary keywords from the context need to answer the question. Keep responses as short as possible and avoid verbosity. Include multiple correct answers if necessary. If no relevant context, then say 'I dont know'. \\n\\nContext:\\n{context}\\n\\nQuestion:\\n{question}\\n\\nAnswer:\"\n",
    "    \n",
    "    answer = llm.invoke(context_and_question)\n",
    "    \n",
    "    if answer is not None:\n",
    "        new_answer = answer.split(': ', 1)\n",
    "        if len(new_answer) > 1:\n",
    "            answer = new_answer[1]\n",
    "        else:\n",
    "            answer = new_answer[0]\n",
    "    # print(f\"Question: {question}\")\n",
    "    \n",
    "    forbidden_list = [\"According to the provided context,\", \"Based on the provided context,\", '\\n']\n",
    "    for phrase in forbidden_list:\n",
    "        answer = answer.replace(phrase, \" \")\n",
    "    answer = answer.replace(\"<pad>\", \"\").replace(\"</s>\", \"\").replace(\"\\n\", \"\").strip()\n",
    "    # print(f\"Answer: {answer}\")\n",
    "    return answer, relevant_docs_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VaFc5mg2vbk"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "qH40Baoa7MNC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# specify output csv \n",
    "input_file = 'qa_gold-llama-no_chat_template.csv'\n",
    "output_file = 'llama-no_chat_template-output.csv'\n",
    "csv_input_dir = f'csv_qa_gold/{input_file}'\n",
    "csv_output_dir = f'csv_qa_gold/{output_file}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initialize_model_answer_column(df):\n",
    "    if 'ModelAnswer' not in df.columns:\n",
    "        df['ModelAnswer'] = None\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(191, 3)\n",
      "(191, 3)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "directory_csv = 'csv_qa_gold'\n",
    "csv_files = ['csv_qa_gold/test_combined.csv']\n",
    "\n",
    "# read in the csv files in the directory and concatenate\n",
    "df_total = pd.DataFrame()\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    print(df.shape)\n",
    "    df_total = pd.concat([df_total, df], axis=0)\n",
    "print(df_total.shape)\n",
    "df_total = initialize_model_answer_column(df_total)\n",
    "df_total.to_csv(csv_input_dir, index=False) \n",
    "# doing this so the original is untouched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>ModelAnswer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Was the Scottish terrier a familiar figure at CMU before it officially became a mascot?</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Is there an official mascot costume of Scotty?</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Who led the effort to make Carnegie Mellon's mascot the Scottish Terrier?</td>\n",
       "      <td>Susan Bassett and Jennifer Church</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Where did Scotty debug as CMU's official mascot?</td>\n",
       "      <td>at a football game</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Who did CMU partner with to create the Scotty mascot graphics?</td>\n",
       "      <td>SME Branding</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What month and year was the Mascot Identity Task Force formed?</td>\n",
       "      <td>November 2006</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>webpages</td>\n",
       "      <td>When did Scotty debut as CMU's official mascot?</td>\n",
       "      <td>November 2007</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What characteristics does the Scottish terrier represent?</td>\n",
       "      <td>determined, thoughtful, strength, power, agility in a small package</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Where did the athletic director of CMU graduate from?</td>\n",
       "      <td>Brandeis</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>webpages</td>\n",
       "      <td>When was Carnegie Technical Schools founded?</td>\n",
       "      <td>1900</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Category  \\\n",
       "10  webpages   \n",
       "11  webpages   \n",
       "12  webpages   \n",
       "13  webpages   \n",
       "14  webpages   \n",
       "15  webpages   \n",
       "16  webpages   \n",
       "17  webpages   \n",
       "18  webpages   \n",
       "19  webpages   \n",
       "\n",
       "                                                                                   Question  \\\n",
       "10  Was the Scottish terrier a familiar figure at CMU before it officially became a mascot?   \n",
       "11                                           Is there an official mascot costume of Scotty?   \n",
       "12                Who led the effort to make Carnegie Mellon's mascot the Scottish Terrier?   \n",
       "13                                         Where did Scotty debug as CMU's official mascot?   \n",
       "14                           Who did CMU partner with to create the Scotty mascot graphics?   \n",
       "15                           What month and year was the Mascot Identity Task Force formed?   \n",
       "16                                          When did Scotty debut as CMU's official mascot?   \n",
       "17                                What characteristics does the Scottish terrier represent?   \n",
       "18                                    Where did the athletic director of CMU graduate from?   \n",
       "19                                             When was Carnegie Technical Schools founded?   \n",
       "\n",
       "                                                                 Answer  \\\n",
       "10                                                                  Yes   \n",
       "11                                                                  Yes   \n",
       "12                                    Susan Bassett and Jennifer Church   \n",
       "13                                                   at a football game   \n",
       "14                                                         SME Branding   \n",
       "15                                                        November 2006   \n",
       "16                                                        November 2007   \n",
       "17  determined, thoughtful, strength, power, agility in a small package   \n",
       "18                                                             Brandeis   \n",
       "19                                                                 1900   \n",
       "\n",
       "   ModelAnswer  \n",
       "10        None  \n",
       "11        None  \n",
       "12        None  \n",
       "13        None  \n",
       "14        None  \n",
       "15        None  \n",
       "16        None  \n",
       "17        None  \n",
       "18        None  \n",
       "19        None  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total.iloc[10:20, :]  # please check that excel does not fuck up for row 15,16 the November 2006 to Nov-06 or some other format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_answer(question,llm, return_relevant_docs = False):\n",
    "    answer, relevant_docs = answer_llama_new(question, KNOWLEDGE_VECTOR_DATABASE,\n",
    "                            reranker=RERANKER, llm = llm)\n",
    "    if return_relevant_docs:\n",
    "        return answer, relevant_docs\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "97CmQOe4shpp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to run over a list of questions and return the answers\n",
    "# Define the function to process the CSV and add model answers\n",
    "\n",
    "def generate_answers_and_save(csv_path, llm):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if 'ModelAnswer' not in df.columns:\n",
    "        df['ModelAnswer'] = ''\n",
    "    for index, row in df.iterrows():\n",
    "        ModelAnswer = generate_answer(row['Question'],llm=llm)\n",
    "        df.at[index, 'ModelAnswer'] = ModelAnswer\n",
    "        df.to_csv(csv_output_dir, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 213.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n",
      "Your documents are roughly 213.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.65it/s]\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      14.89 ms /    23 runs   (    0.65 ms per token,  1544.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14109.95 ms /  1463 tokens (    9.64 ms per token,   103.69 tokens per second)\n",
      "llama_print_timings:        eval time =     568.80 ms /    22 runs   (   25.85 ms per token,    38.68 tokens per second)\n",
      "llama_print_timings:       total time =   15186.17 ms /  1485 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 213.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.08it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      12.98 ms /    20 runs   (    0.65 ms per token,  1540.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.24 ms /    26 tokens (   10.05 ms per token,    99.52 tokens per second)\n",
      "llama_print_timings:        eval time =     493.13 ms /    19 runs   (   25.95 ms per token,    38.53 tokens per second)\n",
      "llama_print_timings:       total time =     833.88 ms /    45 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 213.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.16it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      14.29 ms /    22 runs   (    0.65 ms per token,  1539.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     135.05 ms /    14 tokens (    9.65 ms per token,   103.66 tokens per second)\n",
      "llama_print_timings:        eval time =     542.48 ms /    21 runs   (   25.83 ms per token,    38.71 tokens per second)\n",
      "llama_print_timings:       total time =     764.29 ms /    35 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 283.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.83it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      11.05 ms /    17 runs   (    0.65 ms per token,  1539.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5346.04 ms /   547 tokens (    9.77 ms per token,   102.32 tokens per second)\n",
      "llama_print_timings:        eval time =     417.18 ms /    16 runs   (   26.07 ms per token,    38.35 tokens per second)\n",
      "llama_print_timings:       total time =    5978.08 ms /   563 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 213.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.35it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =       9.10 ms /    14 runs   (    0.65 ms per token,  1538.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4201.47 ms /   429 tokens (    9.79 ms per token,   102.11 tokens per second)\n",
      "llama_print_timings:        eval time =     338.42 ms /    13 runs   (   26.03 ms per token,    38.41 tokens per second)\n",
      "llama_print_timings:       total time =    4708.34 ms /   442 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 350.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.10it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      20.82 ms /    32 runs   (    0.65 ms per token,  1536.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17405.48 ms /  1829 tokens (    9.52 ms per token,   105.08 tokens per second)\n",
      "llama_print_timings:        eval time =     834.58 ms /    31 runs   (   26.92 ms per token,    37.14 tokens per second)\n",
      "llama_print_timings:       total time =   18874.50 ms /  1860 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 283.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.60it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      18.89 ms /    29 runs   (    0.65 ms per token,  1535.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14906.72 ms /  1580 tokens (    9.43 ms per token,   105.99 tokens per second)\n",
      "llama_print_timings:        eval time =     740.80 ms /    28 runs   (   26.46 ms per token,    37.80 tokens per second)\n",
      "llama_print_timings:       total time =   16197.02 ms /  1608 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 283.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.54it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      22.07 ms /    34 runs   (    0.65 ms per token,  1540.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5383.58 ms /   550 tokens (    9.79 ms per token,   102.16 tokens per second)\n",
      "llama_print_timings:        eval time =     867.31 ms /    33 runs   (   26.28 ms per token,    38.05 tokens per second)\n",
      "llama_print_timings:       total time =    6529.96 ms /   583 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 213.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.30it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      71.64 ms /   110 runs   (    0.65 ms per token,  1535.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13084.89 ms /  1399 tokens (    9.35 ms per token,   106.92 tokens per second)\n",
      "llama_print_timings:        eval time =    2839.02 ms /   109 runs   (   26.05 ms per token,    38.39 tokens per second)\n",
      "llama_print_timings:       total time =   16730.92 ms /  1508 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 283.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.60it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      11.58 ms /    18 runs   (    0.64 ms per token,  1554.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13025.12 ms /  1390 tokens (    9.37 ms per token,   106.72 tokens per second)\n",
      "llama_print_timings:        eval time =     440.94 ms /    17 runs   (   25.94 ms per token,    38.55 tokens per second)\n",
      "llama_print_timings:       total time =   13929.36 ms /  1407 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 298.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.30it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      18.84 ms /    29 runs   (    0.65 ms per token,  1539.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11041.64 ms /  1174 tokens (    9.41 ms per token,   106.32 tokens per second)\n",
      "llama_print_timings:        eval time =     718.05 ms /    28 runs   (   25.64 ms per token,    38.99 tokens per second)\n",
      "llama_print_timings:       total time =   12201.52 ms /  1202 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 290.7 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.41it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =       1.98 ms /     3 runs   (    0.66 ms per token,  1512.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12165.09 ms /  1304 tokens (    9.33 ms per token,   107.19 tokens per second)\n",
      "llama_print_timings:        eval time =      78.88 ms /     3 runs   (   26.29 ms per token,    38.03 tokens per second)\n",
      "llama_print_timings:       total time =   12628.27 ms /  1307 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 350.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.77it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    12 runs   (    0.65 ms per token,  1542.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12308.35 ms /  1314 tokens (    9.37 ms per token,   106.76 tokens per second)\n",
      "llama_print_timings:        eval time =     282.53 ms /    11 runs   (   25.68 ms per token,    38.93 tokens per second)\n",
      "llama_print_timings:       total time =   13009.74 ms /  1325 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 304.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.49it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      20.33 ms /    31 runs   (    0.66 ms per token,  1524.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12239.11 ms /  1308 tokens (    9.36 ms per token,   106.87 tokens per second)\n",
      "llama_print_timings:        eval time =     770.01 ms /    30 runs   (   25.67 ms per token,    38.96 tokens per second)\n",
      "llama_print_timings:       total time =   13497.01 ms /  1338 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 296.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.43it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =       3.91 ms /     6 runs   (    0.65 ms per token,  1535.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12250.40 ms /  1309 tokens (    9.36 ms per token,   106.85 tokens per second)\n",
      "llama_print_timings:        eval time =     130.42 ms /     5 runs   (   26.08 ms per token,    38.34 tokens per second)\n",
      "llama_print_timings:       total time =   12780.64 ms /  1314 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 294.79999999999995 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.48it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      11.74 ms /    18 runs   (    0.65 ms per token,  1533.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5663.64 ms /   586 tokens (    9.66 ms per token,   103.47 tokens per second)\n",
      "llama_print_timings:        eval time =     435.90 ms /    17 runs   (   25.64 ms per token,    39.00 tokens per second)\n",
      "llama_print_timings:       total time =    6335.69 ms /   603 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 296.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.51it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      13.76 ms /    21 runs   (    0.66 ms per token,  1525.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7186.51 ms /   750 tokens (    9.58 ms per token,   104.36 tokens per second)\n",
      "llama_print_timings:        eval time =     512.43 ms /    20 runs   (   25.62 ms per token,    39.03 tokens per second)\n",
      "llama_print_timings:       total time =    7990.11 ms /   770 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 291.3 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.49it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      24.02 ms /    37 runs   (    0.65 ms per token,  1540.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12159.06 ms /  1302 tokens (    9.34 ms per token,   107.08 tokens per second)\n",
      "llama_print_timings:        eval time =     921.74 ms /    36 runs   (   25.60 ms per token,    39.06 tokens per second)\n",
      "llama_print_timings:       total time =   13587.03 ms /  1338 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 302.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.32it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      53.71 ms /    82 runs   (    0.65 ms per token,  1526.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15506.61 ms /  1636 tokens (    9.48 ms per token,   105.50 tokens per second)\n",
      "llama_print_timings:        eval time =    2165.26 ms /    81 runs   (   26.73 ms per token,    37.41 tokens per second)\n",
      "llama_print_timings:       total time =   18465.41 ms /  1717 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 350.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.91it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =     166.39 ms /   255 runs   (    0.65 ms per token,  1532.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17468.64 ms /  1826 tokens (    9.57 ms per token,   104.53 tokens per second)\n",
      "llama_print_timings:        eval time =    6942.39 ms /   254 runs   (   27.33 ms per token,    36.59 tokens per second)\n",
      "llama_print_timings:       total time =   25978.75 ms /  2080 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 314.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.50it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      29.29 ms /    45 runs   (    0.65 ms per token,  1536.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7338.56 ms /   760 tokens (    9.66 ms per token,   103.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1137.84 ms /    44 runs   (   25.86 ms per token,    38.67 tokens per second)\n",
      "llama_print_timings:       total time =    8867.68 ms /   804 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 282.5 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.53it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =       3.28 ms /     5 runs   (    0.66 ms per token,  1525.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16614.32 ms /  1743 tokens (    9.53 ms per token,   104.91 tokens per second)\n",
      "llama_print_timings:        eval time =     108.98 ms /     4 runs   (   27.24 ms per token,    36.70 tokens per second)\n",
      "llama_print_timings:       total time =   17254.11 ms /  1747 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 300.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.39it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      45.96 ms /    71 runs   (    0.65 ms per token,  1544.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15013.95 ms /  1588 tokens (    9.45 ms per token,   105.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1858.94 ms /    70 runs   (   26.56 ms per token,    37.66 tokens per second)\n",
      "llama_print_timings:       total time =   17603.39 ms /  1658 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 342.3 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.92it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      21.80 ms /    32 runs   (    0.68 ms per token,  1468.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15940.77 ms /  1678 tokens (    9.50 ms per token,   105.26 tokens per second)\n",
      "llama_print_timings:        eval time =     831.81 ms /    31 runs   (   26.83 ms per token,    37.27 tokens per second)\n",
      "llama_print_timings:       total time =   17407.19 ms /  1709 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 330.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.03it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      12.43 ms /    19 runs   (    0.65 ms per token,  1528.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15304.96 ms /  1615 tokens (    9.48 ms per token,   105.52 tokens per second)\n",
      "llama_print_timings:        eval time =     480.16 ms /    18 runs   (   26.68 ms per token,    37.49 tokens per second)\n",
      "llama_print_timings:       total time =   16342.41 ms /  1633 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 350.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.84it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      11.06 ms /    17 runs   (    0.65 ms per token,  1536.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14813.89 ms /  1566 tokens (    9.46 ms per token,   105.71 tokens per second)\n",
      "llama_print_timings:        eval time =     427.24 ms /    16 runs   (   26.70 ms per token,    37.45 tokens per second)\n",
      "llama_print_timings:       total time =   15771.74 ms /  1582 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 291.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.59it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      42.55 ms /    65 runs   (    0.65 ms per token,  1527.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14387.45 ms /  1523 tokens (    9.45 ms per token,   105.86 tokens per second)\n",
      "llama_print_timings:        eval time =    1689.39 ms /    64 runs   (   26.40 ms per token,    37.88 tokens per second)\n",
      "llama_print_timings:       total time =   16787.69 ms /  1587 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 291.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.47it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      11.83 ms /    15 runs   (    0.79 ms per token,  1267.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14393.50 ms /  1526 tokens (    9.43 ms per token,   106.02 tokens per second)\n",
      "llama_print_timings:        eval time =     371.75 ms /    14 runs   (   26.55 ms per token,    37.66 tokens per second)\n",
      "llama_print_timings:       total time =   15302.46 ms /  1540 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 291.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.48it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      28.08 ms /    43 runs   (    0.65 ms per token,  1531.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15079.25 ms /  1594 tokens (    9.46 ms per token,   105.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1113.00 ms /    42 runs   (   26.50 ms per token,    37.74 tokens per second)\n",
      "llama_print_timings:       total time =   16843.28 ms /  1636 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 25.62it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      14.40 ms /    22 runs   (    0.65 ms per token,  1527.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5768.68 ms /   637 tokens (    9.06 ms per token,   110.42 tokens per second)\n",
      "llama_print_timings:        eval time =     502.81 ms /    21 runs   (   23.94 ms per token,    41.76 tokens per second)\n",
      "llama_print_timings:       total time =    6549.91 ms /   658 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 300.0 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.39it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      17.17 ms /    26 runs   (    0.66 ms per token,  1514.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18621.03 ms /  1938 tokens (    9.61 ms per token,   104.08 tokens per second)\n",
      "llama_print_timings:        eval time =     688.99 ms /    25 runs   (   27.56 ms per token,    36.29 tokens per second)\n",
      "llama_print_timings:       total time =   20018.27 ms /  1963 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 291.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.54it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =       9.08 ms /    14 runs   (    0.65 ms per token,  1542.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13922.15 ms /  1478 tokens (    9.42 ms per token,   106.16 tokens per second)\n",
      "llama_print_timings:        eval time =     339.51 ms /    13 runs   (   26.12 ms per token,    38.29 tokens per second)\n",
      "llama_print_timings:       total time =   14764.60 ms /  1491 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 361.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.80it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =       2.59 ms /     4 runs   (    0.65 ms per token,  1544.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13677.38 ms /  1456 tokens (    9.39 ms per token,   106.45 tokens per second)\n",
      "llama_print_timings:        eval time =     105.68 ms /     4 runs   (   26.42 ms per token,    37.85 tokens per second)\n",
      "llama_print_timings:       total time =   14241.50 ms /  1460 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 350.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.86it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =       8.50 ms /    13 runs   (    0.65 ms per token,  1529.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18023.81 ms /  1880 tokens (    9.59 ms per token,   104.31 tokens per second)\n",
      "llama_print_timings:        eval time =     329.89 ms /    12 runs   (   27.49 ms per token,    36.38 tokens per second)\n",
      "llama_print_timings:       total time =   18985.48 ms /  1892 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 350.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.78it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      47.77 ms /    73 runs   (    0.65 ms per token,  1528.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15073.95 ms /  1592 tokens (    9.47 ms per token,   105.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1902.30 ms /    72 runs   (   26.42 ms per token,    37.85 tokens per second)\n",
      "llama_print_timings:       total time =   17745.61 ms /  1664 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 350.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.88it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      46.21 ms /    71 runs   (    0.65 ms per token,  1536.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9268.74 ms /   950 tokens (    9.76 ms per token,   102.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1856.92 ms /    70 runs   (   26.53 ms per token,    37.70 tokens per second)\n",
      "llama_print_timings:       total time =   11683.34 ms /  1020 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 381.29999999999995 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.84it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    10 runs   (    0.65 ms per token,  1529.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17527.96 ms /  1832 tokens (    9.57 ms per token,   104.52 tokens per second)\n",
      "llama_print_timings:        eval time =     245.58 ms /     9 runs   (   27.29 ms per token,    36.65 tokens per second)\n",
      "llama_print_timings:       total time =   18355.13 ms /  1841 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 350.0 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.71it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =     168.06 ms /   256 runs   (    0.66 ms per token,  1523.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9767.27 ms /  1005 tokens (    9.72 ms per token,   102.89 tokens per second)\n",
      "llama_print_timings:        eval time =    6829.65 ms /   255 runs   (   26.78 ms per token,    37.34 tokens per second)\n",
      "llama_print_timings:       total time =   17999.95 ms /  1260 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 350.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.43it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      32.90 ms /    50 runs   (    0.66 ms per token,  1519.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17291.70 ms /  1808 tokens (    9.56 ms per token,   104.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1329.15 ms /    49 runs   (   27.13 ms per token,    36.87 tokens per second)\n",
      "llama_print_timings:       total time =   19404.50 ms /  1857 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 350.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.48it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      33.55 ms /    51 runs   (    0.66 ms per token,  1519.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11536.13 ms /  1174 tokens (    9.83 ms per token,   101.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1358.71 ms /    50 runs   (   27.17 ms per token,    36.80 tokens per second)\n",
      "llama_print_timings:       total time =   13480.01 ms /  1224 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 325.9 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.90it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      19.06 ms /    29 runs   (    0.66 ms per token,  1521.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13872.67 ms /  1472 tokens (    9.42 ms per token,   106.11 tokens per second)\n",
      "llama_print_timings:        eval time =     731.73 ms /    28 runs   (   26.13 ms per token,    38.27 tokens per second)\n",
      "llama_print_timings:       total time =   15189.68 ms /  1500 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 63.06it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =       4.57 ms /     7 runs   (    0.65 ms per token,  1531.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1049.03 ms /   120 tokens (    8.74 ms per token,   114.39 tokens per second)\n",
      "llama_print_timings:        eval time =     135.06 ms /     6 runs   (   22.51 ms per token,    44.42 tokens per second)\n",
      "llama_print_timings:       total time =    1246.14 ms /   126 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 307.7 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.30it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      13.16 ms /    20 runs   (    0.66 ms per token,  1519.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13656.32 ms /  1453 tokens (    9.40 ms per token,   106.40 tokens per second)\n",
      "llama_print_timings:        eval time =     501.56 ms /    19 runs   (   26.40 ms per token,    37.88 tokens per second)\n",
      "llama_print_timings:       total time =   14698.23 ms /  1472 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 295.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.13it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      49.49 ms /    75 runs   (    0.66 ms per token,  1515.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14388.25 ms /  1527 tokens (    9.42 ms per token,   106.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1946.00 ms /    74 runs   (   26.30 ms per token,    38.03 tokens per second)\n",
      "llama_print_timings:       total time =   17119.68 ms /  1601 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 289.59999999999997 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.26it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      30.88 ms /    47 runs   (    0.66 ms per token,  1522.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12320.49 ms /  1316 tokens (    9.36 ms per token,   106.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1185.79 ms /    46 runs   (   25.78 ms per token,    38.79 tokens per second)\n",
      "llama_print_timings:       total time =   14105.91 ms /  1362 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 58.98it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      11.14 ms /    17 runs   (    0.66 ms per token,  1525.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2032.69 ms /   230 tokens (    8.84 ms per token,   113.15 tokens per second)\n",
      "llama_print_timings:        eval time =     362.74 ms /    16 runs   (   22.67 ms per token,    44.11 tokens per second)\n",
      "llama_print_timings:       total time =    2526.54 ms /   246 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 318.7 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.02it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      15.03 ms /    23 runs   (    0.65 ms per token,  1530.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15279.73 ms /  1615 tokens (    9.46 ms per token,   105.70 tokens per second)\n",
      "llama_print_timings:        eval time =     584.97 ms /    22 runs   (   26.59 ms per token,    37.61 tokens per second)\n",
      "llama_print_timings:       total time =   16462.75 ms /  1637 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 285.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.37it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =       3.93 ms /     6 runs   (    0.65 ms per token,  1528.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10216.92 ms /  1102 tokens (    9.27 ms per token,   107.86 tokens per second)\n",
      "llama_print_timings:        eval time =     127.10 ms /     5 runs   (   25.42 ms per token,    39.34 tokens per second)\n",
      "llama_print_timings:       total time =   10714.60 ms /  1107 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 318.7 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.08it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      20.35 ms /    31 runs   (    0.66 ms per token,  1523.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14720.14 ms /  1558 tokens (    9.45 ms per token,   105.84 tokens per second)\n",
      "llama_print_timings:        eval time =     789.72 ms /    30 runs   (   26.32 ms per token,    37.99 tokens per second)\n",
      "llama_print_timings:       total time =   16128.33 ms /  1588 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 288.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.46it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      36.82 ms /    56 runs   (    0.66 ms per token,  1521.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12045.12 ms /  1288 tokens (    9.35 ms per token,   106.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1415.10 ms /    55 runs   (   25.73 ms per token,    38.87 tokens per second)\n",
      "llama_print_timings:       total time =   14098.61 ms /  1343 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 339.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.25it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =       9.79 ms /    15 runs   (    0.65 ms per token,  1531.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     440.49 ms /    48 tokens (    9.18 ms per token,   108.97 tokens per second)\n",
      "llama_print_timings:        eval time =     338.39 ms /    14 runs   (   24.17 ms per token,    41.37 tokens per second)\n",
      "llama_print_timings:       total time =     852.51 ms /    62 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 288.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.68it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      17.08 ms /    26 runs   (    0.66 ms per token,  1522.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12064.05 ms /  1291 tokens (    9.34 ms per token,   107.01 tokens per second)\n",
      "llama_print_timings:        eval time =     641.44 ms /    25 runs   (   25.66 ms per token,    38.97 tokens per second)\n",
      "llama_print_timings:       total time =   13223.51 ms /  1316 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 308.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.69it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      35.92 ms /    55 runs   (    0.65 ms per token,  1531.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11086.94 ms /  1192 tokens (    9.30 ms per token,   107.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1398.39 ms /    55 runs   (   25.43 ms per token,    39.33 tokens per second)\n",
      "llama_print_timings:       total time =   13085.37 ms /  1247 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 291.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.46it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      28.17 ms /    43 runs   (    0.66 ms per token,  1526.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6828.40 ms /   710 tokens (    9.62 ms per token,   103.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1077.52 ms /    42 runs   (   25.66 ms per token,    38.98 tokens per second)\n",
      "llama_print_timings:       total time =    8307.03 ms /   752 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 336.5 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.54it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      28.00 ms /    43 runs   (    0.65 ms per token,  1535.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15122.83 ms /  1600 tokens (    9.45 ms per token,   105.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1115.15 ms /    42 runs   (   26.55 ms per token,    37.66 tokens per second)\n",
      "llama_print_timings:       total time =   16906.21 ms /  1642 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 318.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.57it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      26.93 ms /    41 runs   (    0.66 ms per token,  1522.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13684.43 ms /  1456 tokens (    9.40 ms per token,   106.40 tokens per second)\n",
      "llama_print_timings:        eval time =    1052.17 ms /    40 runs   (   26.30 ms per token,    38.02 tokens per second)\n",
      "llama_print_timings:       total time =   15359.69 ms /  1496 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 376.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.05it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      17.16 ms /    26 runs   (    0.66 ms per token,  1515.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16913.75 ms /  1773 tokens (    9.54 ms per token,   104.83 tokens per second)\n",
      "llama_print_timings:        eval time =     677.23 ms /    25 runs   (   27.09 ms per token,    36.91 tokens per second)\n",
      "llama_print_timings:       total time =   18261.49 ms /  1798 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 332.1 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.75it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =     123.82 ms /   188 runs   (    0.66 ms per token,  1518.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16355.91 ms /  1717 tokens (    9.53 ms per token,   104.98 tokens per second)\n",
      "llama_print_timings:        eval time =    5044.86 ms /   187 runs   (   26.98 ms per token,    37.07 tokens per second)\n",
      "llama_print_timings:       total time =   22745.53 ms /  1904 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 485.3 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.47it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      12.46 ms /    19 runs   (    0.66 ms per token,  1524.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14147.18 ms /  1500 tokens (    9.43 ms per token,   106.03 tokens per second)\n",
      "llama_print_timings:        eval time =     472.30 ms /    18 runs   (   26.24 ms per token,    38.11 tokens per second)\n",
      "llama_print_timings:       total time =   15172.48 ms /  1518 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 356.7 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.00it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =     167.62 ms /   256 runs   (    0.65 ms per token,  1527.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14641.34 ms /  1547 tokens (    9.46 ms per token,   105.66 tokens per second)\n",
      "llama_print_timings:        eval time =    6787.95 ms /   255 runs   (   26.62 ms per token,    37.57 tokens per second)\n",
      "llama_print_timings:       total time =   23004.31 ms /  1802 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 313.59999999999997 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.59it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      44.79 ms /    68 runs   (    0.66 ms per token,  1518.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11663.73 ms /  1247 tokens (    9.35 ms per token,   106.91 tokens per second)\n",
      "llama_print_timings:        eval time =    1714.80 ms /    67 runs   (   25.59 ms per token,    39.07 tokens per second)\n",
      "llama_print_timings:       total time =   14057.23 ms /  1314 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 328.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.81it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      47.99 ms /    73 runs   (    0.66 ms per token,  1521.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14584.44 ms /  1543 tokens (    9.45 ms per token,   105.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1889.94 ms /    72 runs   (   26.25 ms per token,    38.10 tokens per second)\n",
      "llama_print_timings:       total time =   17272.29 ms /  1615 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 58.60it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      18.96 ms /    29 runs   (    0.65 ms per token,  1529.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1909.13 ms /   216 tokens (    8.84 ms per token,   113.14 tokens per second)\n",
      "llama_print_timings:        eval time =     633.19 ms /    28 runs   (   22.61 ms per token,    44.22 tokens per second)\n",
      "llama_print_timings:       total time =    2718.87 ms /   244 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 25.45it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      31.53 ms /    48 runs   (    0.66 ms per token,  1522.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8255.25 ms /   900 tokens (    9.17 ms per token,   109.02 tokens per second)\n",
      "llama_print_timings:        eval time =    1155.39 ms /    47 runs   (   24.58 ms per token,    40.68 tokens per second)\n",
      "llama_print_timings:       total time =    9899.78 ms /   947 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 56.01it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      41.33 ms /    63 runs   (    0.66 ms per token,  1524.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1951.70 ms /   220 tokens (    8.87 ms per token,   112.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1400.35 ms /    62 runs   (   22.59 ms per token,    44.27 tokens per second)\n",
      "llama_print_timings:       total time =    3665.71 ms /   282 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 304.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.45it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      91.58 ms /   140 runs   (    0.65 ms per token,  1528.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17846.31 ms /  1864 tokens (    9.57 ms per token,   104.45 tokens per second)\n",
      "llama_print_timings:        eval time =    3803.12 ms /   139 runs   (   27.36 ms per token,    36.55 tokens per second)\n",
      "llama_print_timings:       total time =   22812.40 ms /  2003 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 64.14it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      11.92 ms /    18 runs   (    0.66 ms per token,  1509.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1268.26 ms /   144 tokens (    8.81 ms per token,   113.54 tokens per second)\n",
      "llama_print_timings:        eval time =     401.73 ms /    18 runs   (   22.32 ms per token,    44.81 tokens per second)\n",
      "llama_print_timings:       total time =    1785.55 ms /   162 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 352.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.29it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      29.49 ms /    45 runs   (    0.66 ms per token,  1525.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17786.89 ms /  1858 tokens (    9.57 ms per token,   104.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1196.08 ms /    44 runs   (   27.18 ms per token,    36.79 tokens per second)\n",
      "llama_print_timings:       total time =   19763.06 ms /  1902 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 340.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.76it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      21.51 ms /    33 runs   (    0.65 ms per token,  1534.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16038.63 ms /  1687 tokens (    9.51 ms per token,   105.18 tokens per second)\n",
      "llama_print_timings:        eval time =     857.03 ms /    32 runs   (   26.78 ms per token,    37.34 tokens per second)\n",
      "llama_print_timings:       total time =   17572.49 ms /  1719 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 301.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      60.72 ms /    92 runs   (    0.66 ms per token,  1515.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14988.91 ms /  1583 tokens (    9.47 ms per token,   105.61 tokens per second)\n",
      "llama_print_timings:        eval time =    2409.08 ms /    91 runs   (   26.47 ms per token,    37.77 tokens per second)\n",
      "llama_print_timings:       total time =   18286.12 ms /  1674 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 273.9 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.43it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      18.33 ms /    28 runs   (    0.65 ms per token,  1527.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =   19096.25 ms /  1980 tokens (    9.64 ms per token,   103.69 tokens per second)\n",
      "llama_print_timings:        eval time =     751.80 ms /    27 runs   (   27.84 ms per token,    35.91 tokens per second)\n",
      "llama_print_timings:       total time =   20598.44 ms /  2007 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 298.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.36it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =       9.82 ms /    15 runs   (    0.65 ms per token,  1527.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11978.10 ms /  1280 tokens (    9.36 ms per token,   106.86 tokens per second)\n",
      "llama_print_timings:        eval time =     359.52 ms /    14 runs   (   25.68 ms per token,    38.94 tokens per second)\n",
      "llama_print_timings:       total time =   12807.60 ms /  1294 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 319.6999999999999 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.36it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =       8.59 ms /    13 runs   (    0.66 ms per token,  1513.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12360.87 ms /  1318 tokens (    9.38 ms per token,   106.63 tokens per second)\n",
      "llama_print_timings:        eval time =     308.72 ms /    12 runs   (   25.73 ms per token,    38.87 tokens per second)\n",
      "llama_print_timings:       total time =   13150.75 ms /  1330 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 69.22it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      17.95 ms /    27 runs   (    0.66 ms per token,  1504.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1226.20 ms /   138 tokens (    8.89 ms per token,   112.54 tokens per second)\n",
      "llama_print_timings:        eval time =     580.66 ms /    26 runs   (   22.33 ms per token,    44.78 tokens per second)\n",
      "llama_print_timings:       total time =    1957.37 ms /   164 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 325.9 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.90it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =       2.66 ms /     4 runs   (    0.66 ms per token,  1504.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12726.16 ms /  1359 tokens (    9.36 ms per token,   106.79 tokens per second)\n",
      "llama_print_timings:        eval time =      79.36 ms /     3 runs   (   26.45 ms per token,    37.80 tokens per second)\n",
      "llama_print_timings:       total time =   13255.56 ms /  1362 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 314.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.52it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      19.11 ms /    29 runs   (    0.66 ms per token,  1517.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17511.67 ms /  1832 tokens (    9.56 ms per token,   104.62 tokens per second)\n",
      "llama_print_timings:        eval time =     790.66 ms /    29 runs   (   27.26 ms per token,    36.68 tokens per second)\n",
      "llama_print_timings:       total time =   19019.75 ms /  1861 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 74.87it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      13.20 ms /    20 runs   (    0.66 ms per token,  1514.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1129.25 ms /   128 tokens (    8.82 ms per token,   113.35 tokens per second)\n",
      "llama_print_timings:        eval time =     424.13 ms /    19 runs   (   22.32 ms per token,    44.80 tokens per second)\n",
      "llama_print_timings:       total time =    1668.80 ms /   147 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 340.5 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.07it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      50.59 ms /    77 runs   (    0.66 ms per token,  1522.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14644.03 ms /  1550 tokens (    9.45 ms per token,   105.85 tokens per second)\n",
      "llama_print_timings:        eval time =    2000.07 ms /    76 runs   (   26.32 ms per token,    38.00 tokens per second)\n",
      "llama_print_timings:       total time =   17462.02 ms /  1626 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 332.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.87it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      62.58 ms /    95 runs   (    0.66 ms per token,  1518.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14481.04 ms /  1534 tokens (    9.44 ms per token,   105.93 tokens per second)\n",
      "llama_print_timings:        eval time =    2468.39 ms /    94 runs   (   26.26 ms per token,    38.08 tokens per second)\n",
      "llama_print_timings:       total time =   17832.74 ms /  1628 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 244.6 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.13it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      34.51 ms /    52 runs   (    0.66 ms per token,  1506.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6817.91 ms /   748 tokens (    9.11 ms per token,   109.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1231.95 ms /    51 runs   (   24.16 ms per token,    41.40 tokens per second)\n",
      "llama_print_timings:       total time =    8503.83 ms /   799 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 297.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.34it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      36.11 ms /    55 runs   (    0.66 ms per token,  1523.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9292.98 ms /  1007 tokens (    9.23 ms per token,   108.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1342.63 ms /    54 runs   (   24.86 ms per token,    40.22 tokens per second)\n",
      "llama_print_timings:       total time =   11174.43 ms /  1061 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 69.15it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      72.41 ms /   110 runs   (    0.66 ms per token,  1519.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1168.60 ms /   133 tokens (    8.79 ms per token,   113.81 tokens per second)\n",
      "llama_print_timings:        eval time =    2438.04 ms /   109 runs   (   22.37 ms per token,    44.71 tokens per second)\n",
      "llama_print_timings:       total time =    4069.30 ms /   242 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 77.46it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =       4.58 ms /     7 runs   (    0.65 ms per token,  1528.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1009.36 ms /   114 tokens (    8.85 ms per token,   112.94 tokens per second)\n",
      "llama_print_timings:        eval time =     134.66 ms /     6 runs   (   22.44 ms per token,    44.56 tokens per second)\n",
      "llama_print_timings:       total time =    1207.20 ms /   120 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 69.13it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =       4.63 ms /     7 runs   (    0.66 ms per token,  1511.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1255.47 ms /   144 tokens (    8.72 ms per token,   114.70 tokens per second)\n",
      "llama_print_timings:        eval time =     134.86 ms /     6 runs   (   22.48 ms per token,    44.49 tokens per second)\n",
      "llama_print_timings:       total time =    1460.12 ms /   150 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 67.09it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =       4.53 ms /     7 runs   (    0.65 ms per token,  1544.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1302.05 ms /   149 tokens (    8.74 ms per token,   114.43 tokens per second)\n",
      "llama_print_timings:        eval time =     137.76 ms /     6 runs   (   22.96 ms per token,    43.55 tokens per second)\n",
      "llama_print_timings:       total time =    1511.85 ms /   155 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 341.59999999999997 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.81it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =       4.58 ms /     7 runs   (    0.65 ms per token,  1527.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1077.23 ms /   122 tokens (    8.83 ms per token,   113.25 tokens per second)\n",
      "llama_print_timings:        eval time =     135.40 ms /     6 runs   (   22.57 ms per token,    44.31 tokens per second)\n",
      "llama_print_timings:       total time =    1278.43 ms /   128 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 67.47it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =       5.27 ms /     8 runs   (    0.66 ms per token,  1518.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     947.66 ms /   108 tokens (    8.77 ms per token,   113.96 tokens per second)\n",
      "llama_print_timings:        eval time =     156.50 ms /     7 runs   (   22.36 ms per token,    44.73 tokens per second)\n",
      "llama_print_timings:       total time =    1168.42 ms /   115 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 285.1 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.33it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =       3.26 ms /     5 runs   (    0.65 ms per token,  1534.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15630.49 ms /  1653 tokens (    9.46 ms per token,   105.75 tokens per second)\n",
      "llama_print_timings:        eval time =     109.13 ms /     4 runs   (   27.28 ms per token,    36.65 tokens per second)\n",
      "llama_print_timings:       total time =   16295.96 ms /  1657 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 60.26it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      11.16 ms /    17 runs   (    0.66 ms per token,  1523.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2402.68 ms /   272 tokens (    8.83 ms per token,   113.21 tokens per second)\n",
      "llama_print_timings:        eval time =     363.46 ms /    16 runs   (   22.72 ms per token,    44.02 tokens per second)\n",
      "llama_print_timings:       total time =    2914.26 ms /   288 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 315.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.03it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      28.77 ms /    44 runs   (    0.65 ms per token,  1529.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9093.80 ms /   990 tokens (    9.19 ms per token,   108.87 tokens per second)\n",
      "llama_print_timings:        eval time =    1066.22 ms /    43 runs   (   24.80 ms per token,    40.33 tokens per second)\n",
      "llama_print_timings:       total time =   10650.60 ms /  1033 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 321.9 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.89it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      63.78 ms /    96 runs   (    0.66 ms per token,  1505.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15346.66 ms /  1622 tokens (    9.46 ms per token,   105.69 tokens per second)\n",
      "llama_print_timings:        eval time =    2534.85 ms /    95 runs   (   26.68 ms per token,    37.48 tokens per second)\n",
      "llama_print_timings:       total time =   18813.85 ms /  1717 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 256.29999999999995 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.15it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      43.02 ms /    65 runs   (    0.66 ms per token,  1511.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15320.65 ms /  1615 tokens (    9.49 ms per token,   105.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1707.29 ms /    64 runs   (   26.68 ms per token,    37.49 tokens per second)\n",
      "llama_print_timings:       total time =   17831.63 ms /  1679 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 320.9 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.70it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      65.89 ms /   100 runs   (    0.66 ms per token,  1517.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15557.25 ms /  1639 tokens (    9.49 ms per token,   105.35 tokens per second)\n",
      "llama_print_timings:        eval time =    2645.67 ms /    99 runs   (   26.72 ms per token,    37.42 tokens per second)\n",
      "llama_print_timings:       total time =   19158.44 ms /  1738 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 649.5 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.46it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      47.55 ms /    72 runs   (    0.66 ms per token,  1514.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15743.99 ms /  1656 tokens (    9.51 ms per token,   105.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1902.08 ms /    71 runs   (   26.79 ms per token,    37.33 tokens per second)\n",
      "llama_print_timings:       total time =   18490.75 ms /  1727 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 336.5 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.39it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      11.14 ms /    17 runs   (    0.66 ms per token,  1526.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15900.10 ms /  1671 tokens (    9.52 ms per token,   105.09 tokens per second)\n",
      "llama_print_timings:        eval time =     430.51 ms /    16 runs   (   26.91 ms per token,    37.17 tokens per second)\n",
      "llama_print_timings:       total time =   16941.79 ms /  1687 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 320.09999999999997 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.99it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      15.83 ms /    24 runs   (    0.66 ms per token,  1515.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13899.63 ms /  1474 tokens (    9.43 ms per token,   106.05 tokens per second)\n",
      "llama_print_timings:        eval time =     601.36 ms /    23 runs   (   26.15 ms per token,    38.25 tokens per second)\n",
      "llama_print_timings:       total time =   15081.94 ms /  1497 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 328.5 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.94it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =       1.97 ms /     3 runs   (    0.66 ms per token,  1521.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6662.83 ms /   731 tokens (    9.11 ms per token,   109.71 tokens per second)\n",
      "llama_print_timings:        eval time =      50.90 ms /     2 runs   (   25.45 ms per token,    39.29 tokens per second)\n",
      "llama_print_timings:       total time =    6962.02 ms /   733 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 335.9 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.37it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      20.90 ms /    32 runs   (    0.65 ms per token,  1530.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5501.92 ms /   576 tokens (    9.55 ms per token,   104.69 tokens per second)\n",
      "llama_print_timings:        eval time =     784.42 ms /    31 runs   (   25.30 ms per token,    39.52 tokens per second)\n",
      "llama_print_timings:       total time =    6595.04 ms /   607 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 374.1 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.24it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      27.61 ms /    42 runs   (    0.66 ms per token,  1521.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15899.41 ms /  1672 tokens (    9.51 ms per token,   105.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1127.93 ms /    42 runs   (   26.86 ms per token,    37.24 tokens per second)\n",
      "llama_print_timings:       total time =   17749.94 ms /  1714 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 66.84it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =       4.58 ms /     7 runs   (    0.65 ms per token,  1530.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1527.80 ms /   174 tokens (    8.78 ms per token,   113.89 tokens per second)\n",
      "llama_print_timings:        eval time =     135.74 ms /     6 runs   (   22.62 ms per token,    44.20 tokens per second)\n",
      "llama_print_timings:       total time =    1744.00 ms /   180 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 232.0 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.21it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      44.25 ms /    67 runs   (    0.66 ms per token,  1514.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9257.49 ms /  1006 tokens (    9.20 ms per token,   108.67 tokens per second)\n",
      "llama_print_timings:        eval time =    1638.50 ms /    66 runs   (   24.83 ms per token,    40.28 tokens per second)\n",
      "llama_print_timings:       total time =   11496.24 ms /  1072 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 223.09999999999985 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.08it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      48.66 ms /    74 runs   (    0.66 ms per token,  1520.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1099.62 ms /   125 tokens (    8.80 ms per token,   113.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1622.62 ms /    73 runs   (   22.23 ms per token,    44.99 tokens per second)\n",
      "llama_print_timings:       total time =    3042.27 ms /   198 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 80.42it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      28.44 ms /    43 runs   (    0.66 ms per token,  1512.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1075.96 ms /   122 tokens (    8.82 ms per token,   113.39 tokens per second)\n",
      "llama_print_timings:        eval time =     933.19 ms /    42 runs   (   22.22 ms per token,    45.01 tokens per second)\n",
      "llama_print_timings:       total time =    2216.37 ms /   164 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 584.9 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.53it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      11.23 ms /    17 runs   (    0.66 ms per token,  1514.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10439.15 ms /  1127 tokens (    9.26 ms per token,   107.96 tokens per second)\n",
      "llama_print_timings:        eval time =     403.11 ms /    16 runs   (   25.19 ms per token,    39.69 tokens per second)\n",
      "llama_print_timings:       total time =   11278.64 ms /  1143 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 25.45it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      17.07 ms /    26 runs   (    0.66 ms per token,  1522.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5543.36 ms /   615 tokens (    9.01 ms per token,   110.94 tokens per second)\n",
      "llama_print_timings:        eval time =     592.88 ms /    25 runs   (   23.72 ms per token,    42.17 tokens per second)\n",
      "llama_print_timings:       total time =    6441.08 ms /   640 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 352.7 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.24it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =       9.25 ms /    14 runs   (    0.66 ms per token,  1514.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17446.06 ms /  1826 tokens (    9.55 ms per token,   104.67 tokens per second)\n",
      "llama_print_timings:        eval time =     353.16 ms /    13 runs   (   27.17 ms per token,    36.81 tokens per second)\n",
      "llama_print_timings:       total time =   18460.65 ms /  1839 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 325.9 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.99it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =       9.20 ms /    14 runs   (    0.66 ms per token,  1521.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15784.21 ms /  1662 tokens (    9.50 ms per token,   105.30 tokens per second)\n",
      "llama_print_timings:        eval time =     349.85 ms /    13 runs   (   26.91 ms per token,    37.16 tokens per second)\n",
      "llama_print_timings:       total time =   16732.94 ms /  1675 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 316.09999999999997 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.03it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      19.84 ms /    30 runs   (    0.66 ms per token,  1511.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16294.08 ms /  1712 tokens (    9.52 ms per token,   105.07 tokens per second)\n",
      "llama_print_timings:        eval time =     779.75 ms /    29 runs   (   26.89 ms per token,    37.19 tokens per second)\n",
      "llama_print_timings:       total time =   17758.68 ms /  1741 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 566.6999999999999 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.76it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =     127.16 ms /   193 runs   (    0.66 ms per token,  1517.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15005.16 ms /  1584 tokens (    9.47 ms per token,   105.56 tokens per second)\n",
      "llama_print_timings:        eval time =    5116.98 ms /   192 runs   (   26.65 ms per token,    37.52 tokens per second)\n",
      "llama_print_timings:       total time =   21482.71 ms /  1776 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 297.59999999999985 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.36it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      13.91 ms /    21 runs   (    0.66 ms per token,  1510.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4795.56 ms /   490 tokens (    9.79 ms per token,   102.18 tokens per second)\n",
      "llama_print_timings:        eval time =     515.22 ms /    20 runs   (   25.76 ms per token,    38.82 tokens per second)\n",
      "llama_print_timings:       total time =    5560.79 ms /   510 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 300.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.48it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      13.23 ms /    20 runs   (    0.66 ms per token,  1511.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15922.17 ms /  1674 tokens (    9.51 ms per token,   105.14 tokens per second)\n",
      "llama_print_timings:        eval time =     509.41 ms /    19 runs   (   26.81 ms per token,    37.30 tokens per second)\n",
      "llama_print_timings:       total time =   17065.09 ms /  1693 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 319.59999999999997 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.99it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /     4 runs   (    0.66 ms per token,  1520.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12502.62 ms /  1334 tokens (    9.37 ms per token,   106.70 tokens per second)\n",
      "llama_print_timings:        eval time =      78.03 ms /     3 runs   (   26.01 ms per token,    38.45 tokens per second)\n",
      "llama_print_timings:       total time =   13029.01 ms /  1337 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 67.26it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      17.70 ms /    27 runs   (    0.66 ms per token,  1525.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2186.30 ms /   246 tokens (    8.89 ms per token,   112.52 tokens per second)\n",
      "llama_print_timings:        eval time =     589.84 ms /    26 runs   (   22.69 ms per token,    44.08 tokens per second)\n",
      "llama_print_timings:       total time =    2955.30 ms /   272 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 62.90it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      22.30 ms /    34 runs   (    0.66 ms per token,  1524.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1675.24 ms /   191 tokens (    8.77 ms per token,   114.01 tokens per second)\n",
      "llama_print_timings:        eval time =     742.56 ms /    33 runs   (   22.50 ms per token,    44.44 tokens per second)\n",
      "llama_print_timings:       total time =    2609.87 ms /   224 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 59.23it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =     100.74 ms /   153 runs   (    0.66 ms per token,  1518.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2229.82 ms /   252 tokens (    8.85 ms per token,   113.01 tokens per second)\n",
      "llama_print_timings:        eval time =    3458.66 ms /   152 runs   (   22.75 ms per token,    43.95 tokens per second)\n",
      "llama_print_timings:       total time =    6377.39 ms /   404 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 76.27it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      20.16 ms /    30 runs   (    0.67 ms per token,  1487.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1501.23 ms /   170 tokens (    8.83 ms per token,   113.24 tokens per second)\n",
      "llama_print_timings:        eval time =     647.97 ms /    29 runs   (   22.34 ms per token,    44.75 tokens per second)\n",
      "llama_print_timings:       total time =    2322.82 ms /   199 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 61.40it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      10.58 ms /    16 runs   (    0.66 ms per token,  1511.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1613.13 ms /   184 tokens (    8.77 ms per token,   114.06 tokens per second)\n",
      "llama_print_timings:        eval time =     361.45 ms /    16 runs   (   22.59 ms per token,    44.27 tokens per second)\n",
      "llama_print_timings:       total time =    2096.80 ms /   200 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 374.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.82it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      23.80 ms /    36 runs   (    0.66 ms per token,  1512.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17749.65 ms /  1856 tokens (    9.56 ms per token,   104.57 tokens per second)\n",
      "llama_print_timings:        eval time =     981.87 ms /    36 runs   (   27.27 ms per token,    36.66 tokens per second)\n",
      "llama_print_timings:       total time =   19493.56 ms /  1892 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 48.92it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =     161.04 ms /   245 runs   (    0.66 ms per token,  1521.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3317.73 ms /   372 tokens (    8.92 ms per token,   112.12 tokens per second)\n",
      "llama_print_timings:        eval time =    5668.00 ms /   244 runs   (   23.23 ms per token,    43.05 tokens per second)\n",
      "llama_print_timings:       total time =   10131.15 ms /   616 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 25.54it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =     141.66 ms /   215 runs   (    0.66 ms per token,  1517.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3257.07 ms /   366 tokens (    8.90 ms per token,   112.37 tokens per second)\n",
      "llama_print_timings:        eval time =    4966.15 ms /   214 runs   (   23.21 ms per token,    43.09 tokens per second)\n",
      "llama_print_timings:       total time =    9224.40 ms /   580 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 67.17it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      41.87 ms /    63 runs   (    0.66 ms per token,  1504.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1721.06 ms /   195 tokens (    8.83 ms per token,   113.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1397.08 ms /    62 runs   (   22.53 ms per token,    44.38 tokens per second)\n",
      "llama_print_timings:       total time =    3433.20 ms /   257 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 63.98it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =       8.54 ms /    13 runs   (    0.66 ms per token,  1522.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1882.75 ms /   214 tokens (    8.80 ms per token,   113.66 tokens per second)\n",
      "llama_print_timings:        eval time =     272.71 ms /    12 runs   (   22.73 ms per token,    44.00 tokens per second)\n",
      "llama_print_timings:       total time =    2273.93 ms /   226 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 56.30it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =     100.47 ms /   153 runs   (    0.66 ms per token,  1522.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2324.53 ms /   263 tokens (    8.84 ms per token,   113.14 tokens per second)\n",
      "llama_print_timings:        eval time =    3462.22 ms /   152 runs   (   22.78 ms per token,    43.90 tokens per second)\n",
      "llama_print_timings:       total time =    6485.75 ms /   415 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 212.0 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.86it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      21.08 ms /    32 runs   (    0.66 ms per token,  1517.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7493.84 ms /   822 tokens (    9.12 ms per token,   109.69 tokens per second)\n",
      "llama_print_timings:        eval time =     752.58 ms /    31 runs   (   24.28 ms per token,    41.19 tokens per second)\n",
      "llama_print_timings:       total time =    8633.92 ms /   853 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 75.31it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      41.52 ms /    63 runs   (    0.66 ms per token,  1517.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2442.60 ms /   275 tokens (    8.88 ms per token,   112.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1406.78 ms /    62 runs   (   22.69 ms per token,    44.07 tokens per second)\n",
      "llama_print_timings:       total time =    4182.96 ms /   337 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 54.02it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      41.38 ms /    63 runs   (    0.66 ms per token,  1522.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2762.47 ms /   312 tokens (    8.85 ms per token,   112.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1437.96 ms /    63 runs   (   22.82 ms per token,    43.81 tokens per second)\n",
      "llama_print_timings:       total time =    4545.74 ms /   375 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 306.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.39it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      13.84 ms /    21 runs   (    0.66 ms per token,  1517.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2677.99 ms /   302 tokens (    8.87 ms per token,   112.77 tokens per second)\n",
      "llama_print_timings:        eval time =     458.31 ms /    20 runs   (   22.92 ms per token,    43.64 tokens per second)\n",
      "llama_print_timings:       total time =    3316.63 ms /   322 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 68.76it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      32.38 ms /    49 runs   (    0.66 ms per token,  1513.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2540.58 ms /   288 tokens (    8.82 ms per token,   113.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1114.85 ms /    49 runs   (   22.75 ms per token,    43.95 tokens per second)\n",
      "llama_print_timings:       total time =    3947.26 ms /   337 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 77.07it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      22.84 ms /    34 runs   (    0.67 ms per token,  1488.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1727.73 ms /   196 tokens (    8.81 ms per token,   113.44 tokens per second)\n",
      "llama_print_timings:        eval time =     743.23 ms /    33 runs   (   22.52 ms per token,    44.40 tokens per second)\n",
      "llama_print_timings:       total time =    2663.81 ms /   229 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 313.8 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.05it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      23.01 ms /    35 runs   (    0.66 ms per token,  1521.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2354.73 ms /   266 tokens (    8.85 ms per token,   112.96 tokens per second)\n",
      "llama_print_timings:        eval time =     769.16 ms /    34 runs   (   22.62 ms per token,    44.20 tokens per second)\n",
      "llama_print_timings:       total time =    3344.75 ms /   300 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 59.55it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =     105.34 ms /   160 runs   (    0.66 ms per token,  1518.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2757.82 ms /   312 tokens (    8.84 ms per token,   113.13 tokens per second)\n",
      "llama_print_timings:        eval time =    3665.24 ms /   160 runs   (   22.91 ms per token,    43.65 tokens per second)\n",
      "llama_print_timings:       total time =    7167.23 ms /   472 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 297.5 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.47it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      18.41 ms /    28 runs   (    0.66 ms per token,  1520.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15912.63 ms /  1679 tokens (    9.48 ms per token,   105.51 tokens per second)\n",
      "llama_print_timings:        eval time =     722.52 ms /    27 runs   (   26.76 ms per token,    37.37 tokens per second)\n",
      "llama_print_timings:       total time =   17298.07 ms /  1706 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 60.87it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      17.85 ms /    27 runs   (    0.66 ms per token,  1512.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1788.58 ms /   202 tokens (    8.85 ms per token,   112.94 tokens per second)\n",
      "llama_print_timings:        eval time =     586.30 ms /    26 runs   (   22.55 ms per token,    44.35 tokens per second)\n",
      "llama_print_timings:       total time =    2546.24 ms /   228 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 78.58it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      52.05 ms /    79 runs   (    0.66 ms per token,  1517.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1785.23 ms /   202 tokens (    8.84 ms per token,   113.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1755.09 ms /    78 runs   (   22.50 ms per token,    44.44 tokens per second)\n",
      "llama_print_timings:       total time =    3911.69 ms /   280 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 283.7 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.44it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =       9.17 ms /    14 runs   (    0.65 ms per token,  1527.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1811.45 ms /   205 tokens (    8.84 ms per token,   113.17 tokens per second)\n",
      "llama_print_timings:        eval time =     295.27 ms /    13 runs   (   22.71 ms per token,    44.03 tokens per second)\n",
      "llama_print_timings:       total time =    2223.20 ms /   218 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 61.72it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =     120.16 ms /   183 runs   (    0.66 ms per token,  1522.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1800.79 ms /   205 tokens (    8.78 ms per token,   113.84 tokens per second)\n",
      "llama_print_timings:        eval time =    4122.62 ms /   182 runs   (   22.65 ms per token,    44.15 tokens per second)\n",
      "llama_print_timings:       total time =    6714.40 ms /   387 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 263.9 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.51it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      18.58 ms /    28 runs   (    0.66 ms per token,  1506.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14531.68 ms /  1541 tokens (    9.43 ms per token,   106.04 tokens per second)\n",
      "llama_print_timings:        eval time =     706.57 ms /    27 runs   (   26.17 ms per token,    38.21 tokens per second)\n",
      "llama_print_timings:       total time =   15868.48 ms /  1568 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 59.46it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      62.08 ms /    94 runs   (    0.66 ms per token,  1514.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2665.64 ms /   300 tokens (    8.89 ms per token,   112.54 tokens per second)\n",
      "llama_print_timings:        eval time =    2120.17 ms /    93 runs   (   22.80 ms per token,    43.86 tokens per second)\n",
      "llama_print_timings:       total time =    5258.19 ms /   393 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 306.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.33it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      37.58 ms /    57 runs   (    0.66 ms per token,  1516.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16652.96 ms /  1746 tokens (    9.54 ms per token,   104.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1511.45 ms /    56 runs   (   26.99 ms per token,    37.05 tokens per second)\n",
      "llama_print_timings:       total time =   18981.01 ms /  1802 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 359.1 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.80it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      60.97 ms /    92 runs   (    0.66 ms per token,  1509.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11897.42 ms /  1272 tokens (    9.35 ms per token,   106.91 tokens per second)\n",
      "llama_print_timings:        eval time =    2374.44 ms /    92 runs   (   25.81 ms per token,    38.75 tokens per second)\n",
      "llama_print_timings:       total time =   15088.20 ms /  1364 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 241.79999999999998 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.14it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      28.30 ms /    43 runs   (    0.66 ms per token,  1519.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2224.92 ms /   250 tokens (    8.90 ms per token,   112.36 tokens per second)\n",
      "llama_print_timings:        eval time =     950.23 ms /    42 runs   (   22.62 ms per token,    44.20 tokens per second)\n",
      "llama_print_timings:       total time =    3420.14 ms /   292 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 48.71it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =     163.54 ms /   248 runs   (    0.66 ms per token,  1516.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4376.22 ms /   488 tokens (    8.97 ms per token,   111.51 tokens per second)\n",
      "llama_print_timings:        eval time =    5827.02 ms /   247 runs   (   23.59 ms per token,    42.39 tokens per second)\n",
      "llama_print_timings:       total time =   11393.15 ms /   735 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 277.79999999999995 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.43it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      43.05 ms /    63 runs   (    0.68 ms per token,  1463.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6441.23 ms /   708 tokens (    9.10 ms per token,   109.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1491.93 ms /    62 runs   (   24.06 ms per token,    41.56 tokens per second)\n",
      "llama_print_timings:       total time =    8429.40 ms /   770 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 70.90it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      20.34 ms /    31 runs   (    0.66 ms per token,  1524.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1765.21 ms /   200 tokens (    8.83 ms per token,   113.30 tokens per second)\n",
      "llama_print_timings:        eval time =     700.36 ms /    31 runs   (   22.59 ms per token,    44.26 tokens per second)\n",
      "llama_print_timings:       total time =    2647.41 ms /   231 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 309.29999999999995 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.03it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      33.64 ms /    51 runs   (    0.66 ms per token,  1516.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1878.17 ms /   212 tokens (    8.86 ms per token,   112.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1128.21 ms /    50 runs   (   22.56 ms per token,    44.32 tokens per second)\n",
      "llama_print_timings:       total time =    3270.72 ms /   262 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 61.32it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      56.36 ms /    86 runs   (    0.66 ms per token,  1525.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2107.01 ms /   239 tokens (    8.82 ms per token,   113.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1921.95 ms /    85 runs   (   22.61 ms per token,    44.23 tokens per second)\n",
      "llama_print_timings:       total time =    4438.78 ms /   324 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 294.9 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.28it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      65.07 ms /    99 runs   (    0.66 ms per token,  1521.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15131.38 ms /  1600 tokens (    9.46 ms per token,   105.74 tokens per second)\n",
      "llama_print_timings:        eval time =    2637.23 ms /    99 runs   (   26.64 ms per token,    37.54 tokens per second)\n",
      "llama_print_timings:       total time =   18706.77 ms /  1699 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 299.7 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.30it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =     167.86 ms /   256 runs   (    0.66 ms per token,  1525.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6457.09 ms /   711 tokens (    9.08 ms per token,   110.11 tokens per second)\n",
      "llama_print_timings:        eval time =    6178.02 ms /   255 runs   (   24.23 ms per token,    41.28 tokens per second)\n",
      "llama_print_timings:       total time =   13915.46 ms /   966 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.70it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      10.57 ms /    16 runs   (    0.66 ms per token,  1514.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2587.27 ms /   291 tokens (    8.89 ms per token,   112.47 tokens per second)\n",
      "llama_print_timings:        eval time =     341.95 ms /    15 runs   (   22.80 ms per token,    43.87 tokens per second)\n",
      "llama_print_timings:       total time =    3085.52 ms /   306 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 294.0 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.23it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =       7.22 ms /    11 runs   (    0.66 ms per token,  1523.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5454.06 ms /   603 tokens (    9.04 ms per token,   110.56 tokens per second)\n",
      "llama_print_timings:        eval time =     239.14 ms /    10 runs   (   23.91 ms per token,    41.82 tokens per second)\n",
      "llama_print_timings:       total time =    5931.77 ms /   613 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.71it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      41.50 ms /    63 runs   (    0.66 ms per token,  1518.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1732.32 ms /   196 tokens (    8.84 ms per token,   113.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1397.35 ms /    62 runs   (   22.54 ms per token,    44.37 tokens per second)\n",
      "llama_print_timings:       total time =    3435.47 ms /   258 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 57.70it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      50.67 ms /    77 runs   (    0.66 ms per token,  1519.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2032.73 ms /   230 tokens (    8.84 ms per token,   113.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1717.87 ms /    76 runs   (   22.60 ms per token,    44.24 tokens per second)\n",
      "llama_print_timings:       total time =    4129.61 ms /   306 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 77.24it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      53.90 ms /    82 runs   (    0.66 ms per token,  1521.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2193.16 ms /   248 tokens (    8.84 ms per token,   113.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1853.80 ms /    82 runs   (   22.61 ms per token,    44.23 tokens per second)\n",
      "llama_print_timings:       total time =    4445.13 ms /   330 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 25.52it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      29.55 ms /    45 runs   (    0.66 ms per token,  1522.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1680.13 ms /   191 tokens (    8.80 ms per token,   113.68 tokens per second)\n",
      "llama_print_timings:        eval time =     989.04 ms /    44 runs   (   22.48 ms per token,    44.49 tokens per second)\n",
      "llama_print_timings:       total time =    2897.00 ms /   235 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 51.63it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      27.27 ms /    41 runs   (    0.67 ms per token,  1503.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2763.65 ms /   312 tokens (    8.86 ms per token,   112.89 tokens per second)\n",
      "llama_print_timings:        eval time =     913.18 ms /    40 runs   (   22.83 ms per token,    43.80 tokens per second)\n",
      "llama_print_timings:       total time =    3936.79 ms /   352 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 59.71it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      24.34 ms /    37 runs   (    0.66 ms per token,  1519.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2587.03 ms /   292 tokens (    8.86 ms per token,   112.87 tokens per second)\n",
      "llama_print_timings:        eval time =     817.95 ms /    36 runs   (   22.72 ms per token,    44.01 tokens per second)\n",
      "llama_print_timings:       total time =    3643.21 ms /   328 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 322.4 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.03it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      27.56 ms /    42 runs   (    0.66 ms per token,  1524.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11253.99 ms /  1210 tokens (    9.30 ms per token,   107.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1046.03 ms /    41 runs   (   25.51 ms per token,    39.20 tokens per second)\n",
      "llama_print_timings:       total time =   12866.79 ms /  1251 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 50.58it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      80.89 ms /   123 runs   (    0.66 ms per token,  1520.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3332.56 ms /   374 tokens (    8.91 ms per token,   112.23 tokens per second)\n",
      "llama_print_timings:        eval time =    2816.58 ms /   122 runs   (   23.09 ms per token,    43.31 tokens per second)\n",
      "llama_print_timings:       total time =    6758.54 ms /   496 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 55.78it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      48.14 ms /    73 runs   (    0.66 ms per token,  1516.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2904.74 ms /   327 tokens (    8.88 ms per token,   112.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1645.05 ms /    72 runs   (   22.85 ms per token,    43.77 tokens per second)\n",
      "llama_print_timings:       total time =    4938.96 ms /   399 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 278.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      32.91 ms /    50 runs   (    0.66 ms per token,  1519.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14987.34 ms /  1584 tokens (    9.46 ms per token,   105.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1323.27 ms /    50 runs   (   26.47 ms per token,    37.79 tokens per second)\n",
      "llama_print_timings:       total time =   17042.55 ms /  1634 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 208.1 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.72it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      20.36 ms /    31 runs   (    0.66 ms per token,  1522.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16106.53 ms /  1692 tokens (    9.52 ms per token,   105.05 tokens per second)\n",
      "llama_print_timings:        eval time =     808.23 ms /    30 runs   (   26.94 ms per token,    37.12 tokens per second)\n",
      "llama_print_timings:       total time =   17594.46 ms /  1722 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 310.2 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.68it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =     168.52 ms /   256 runs   (    0.66 ms per token,  1519.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6513.53 ms /   714 tokens (    9.12 ms per token,   109.62 tokens per second)\n",
      "llama_print_timings:        eval time =    6187.25 ms /   255 runs   (   24.26 ms per token,    41.21 tokens per second)\n",
      "llama_print_timings:       total time =   14000.38 ms /   969 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 25.71it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =     168.13 ms /   256 runs   (    0.66 ms per token,  1522.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6222.48 ms /   683 tokens (    9.11 ms per token,   109.76 tokens per second)\n",
      "llama_print_timings:        eval time =    6166.49 ms /   255 runs   (   24.18 ms per token,    41.35 tokens per second)\n",
      "llama_print_timings:       total time =   13689.77 ms /   938 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 49.63it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =     168.45 ms /   256 runs   (    0.66 ms per token,  1519.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3897.35 ms /   434 tokens (    8.98 ms per token,   111.36 tokens per second)\n",
      "llama_print_timings:        eval time =    5991.16 ms /   255 runs   (   23.49 ms per token,    42.56 tokens per second)\n",
      "llama_print_timings:       total time =   11081.17 ms /   689 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 47.93it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      33.44 ms /    51 runs   (    0.66 ms per token,  1525.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2105.41 ms /   236 tokens (    8.92 ms per token,   112.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1133.37 ms /    50 runs   (   22.67 ms per token,    44.12 tokens per second)\n",
      "llama_print_timings:       total time =    3517.80 ms /   286 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 229.5 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.85it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      57.82 ms /    88 runs   (    0.66 ms per token,  1521.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5327.98 ms /   588 tokens (    9.06 ms per token,   110.36 tokens per second)\n",
      "llama_print_timings:        eval time =    2061.76 ms /    87 runs   (   23.70 ms per token,    42.20 tokens per second)\n",
      "llama_print_timings:       total time =    7939.55 ms /   675 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 60.04it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =     112.48 ms /   171 runs   (    0.66 ms per token,  1520.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2973.64 ms /   333 tokens (    8.93 ms per token,   111.98 tokens per second)\n",
      "llama_print_timings:        eval time =    3920.34 ms /   170 runs   (   23.06 ms per token,    43.36 tokens per second)\n",
      "llama_print_timings:       total time =    7684.93 ms /   503 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 58.48it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      40.95 ms /    62 runs   (    0.66 ms per token,  1514.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1671.70 ms /   190 tokens (    8.80 ms per token,   113.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1376.85 ms /    61 runs   (   22.57 ms per token,    44.30 tokens per second)\n",
      "llama_print_timings:       total time =    3351.86 ms /   251 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.49it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      63.77 ms /    97 runs   (    0.66 ms per token,  1521.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1897.82 ms /   215 tokens (    8.83 ms per token,   113.29 tokens per second)\n",
      "llama_print_timings:        eval time =    2171.71 ms /    96 runs   (   22.62 ms per token,    44.20 tokens per second)\n",
      "llama_print_timings:       total time =    4525.73 ms /   311 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 69.08it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =       4.65 ms /     7 runs   (    0.66 ms per token,  1505.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2661.18 ms /   298 tokens (    8.93 ms per token,   111.98 tokens per second)\n",
      "llama_print_timings:        eval time =     138.37 ms /     6 runs   (   23.06 ms per token,    43.36 tokens per second)\n",
      "llama_print_timings:       total time =    2924.01 ms /   304 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 70.64it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      41.46 ms /    63 runs   (    0.66 ms per token,  1519.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1824.77 ms /   207 tokens (    8.82 ms per token,   113.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1398.56 ms /    62 runs   (   22.56 ms per token,    44.33 tokens per second)\n",
      "llama_print_timings:       total time =    3539.21 ms /   269 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 61.12it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      34.22 ms /    52 runs   (    0.66 ms per token,  1519.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1546.79 ms /   176 tokens (    8.79 ms per token,   113.78 tokens per second)\n",
      "llama_print_timings:        eval time =    1169.85 ms /    52 runs   (   22.50 ms per token,    44.45 tokens per second)\n",
      "llama_print_timings:       total time =    2976.23 ms /   228 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 56.06it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =     140.66 ms /   214 runs   (    0.66 ms per token,  1521.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2647.80 ms /   298 tokens (    8.89 ms per token,   112.55 tokens per second)\n",
      "llama_print_timings:        eval time =    4891.01 ms /   213 runs   (   22.96 ms per token,    43.55 tokens per second)\n",
      "llama_print_timings:       total time =    8494.43 ms /   511 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 42.31it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      24.90 ms /    38 runs   (    0.66 ms per token,  1526.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3444.00 ms /   386 tokens (    8.92 ms per token,   112.08 tokens per second)\n",
      "llama_print_timings:        eval time =     852.61 ms /    37 runs   (   23.04 ms per token,    43.40 tokens per second)\n",
      "llama_print_timings:       total time =    4571.90 ms /   423 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 59.89it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      61.70 ms /    94 runs   (    0.66 ms per token,  1523.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2523.87 ms /   284 tokens (    8.89 ms per token,   112.53 tokens per second)\n",
      "llama_print_timings:        eval time =    2121.88 ms /    93 runs   (   22.82 ms per token,    43.83 tokens per second)\n",
      "llama_print_timings:       total time =    5107.87 ms /   377 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n",
      "Your documents are roughly 359.1 tokens long at the 90th percentile! This is quite long and might slow down reranking!\n",
      " Provide fewer documents, build smaller chunks or run on GPU if it takes too long for your needs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.84it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    12 runs   (    0.65 ms per token,  1526.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11465.06 ms /  1228 tokens (    9.34 ms per token,   107.11 tokens per second)\n",
      "llama_print_timings:        eval time =     285.41 ms /    11 runs   (   25.95 ms per token,    38.54 tokens per second)\n",
      "llama_print_timings:       total time =   12206.19 ms /  1239 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 69.79it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =       7.89 ms /    12 runs   (    0.66 ms per token,  1521.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1587.04 ms /   179 tokens (    8.87 ms per token,   112.79 tokens per second)\n",
      "llama_print_timings:        eval time =     247.82 ms /    11 runs   (   22.53 ms per token,    44.39 tokens per second)\n",
      "llama_print_timings:       total time =    1939.13 ms /   190 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 62.38it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      56.95 ms /    87 runs   (    0.65 ms per token,  1527.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2263.38 ms /   256 tokens (    8.84 ms per token,   113.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1973.44 ms /    87 runs   (   22.68 ms per token,    44.09 tokens per second)\n",
      "llama_print_timings:       total time =    4648.88 ms /   343 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 68.05it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      46.60 ms /    71 runs   (    0.66 ms per token,  1523.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2035.62 ms /   230 tokens (    8.85 ms per token,   112.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1585.48 ms /    70 runs   (   22.65 ms per token,    44.15 tokens per second)\n",
      "llama_print_timings:       total time =    3965.39 ms /   300 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 56.12it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      98.65 ms /   150 runs   (    0.66 ms per token,  1520.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2628.68 ms /   296 tokens (    8.88 ms per token,   112.60 tokens per second)\n",
      "llama_print_timings:        eval time =    3411.72 ms /   149 runs   (   22.90 ms per token,    43.67 tokens per second)\n",
      "llama_print_timings:       total time =    6734.57 ms /   445 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 67.57it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      28.24 ms /    43 runs   (    0.66 ms per token,  1522.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1764.64 ms /   200 tokens (    8.82 ms per token,   113.34 tokens per second)\n",
      "llama_print_timings:        eval time =     970.20 ms /    43 runs   (   22.56 ms per token,    44.32 tokens per second)\n",
      "llama_print_timings:       total time =    2961.11 ms /   243 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 45.60it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      19.19 ms /    29 runs   (    0.66 ms per token,  1511.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2482.72 ms /   280 tokens (    8.87 ms per token,   112.78 tokens per second)\n",
      "llama_print_timings:        eval time =     635.83 ms /    28 runs   (   22.71 ms per token,    44.04 tokens per second)\n",
      "llama_print_timings:       total time =    3316.59 ms /   308 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 58.16it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      61.59 ms /    94 runs   (    0.66 ms per token,  1526.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2480.34 ms /   280 tokens (    8.86 ms per token,   112.89 tokens per second)\n",
      "llama_print_timings:        eval time =    2117.84 ms /    93 runs   (   22.77 ms per token,    43.91 tokens per second)\n",
      "llama_print_timings:       total time =    5048.75 ms /   373 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 57.42it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      37.91 ms /    58 runs   (    0.65 ms per token,  1529.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1683.48 ms /   191 tokens (    8.81 ms per token,   113.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1283.77 ms /    57 runs   (   22.52 ms per token,    44.40 tokens per second)\n",
      "llama_print_timings:       total time =    3237.11 ms /   248 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 25.64it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      30.31 ms /    46 runs   (    0.66 ms per token,  1517.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6088.28 ms /   672 tokens (    9.06 ms per token,   110.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1078.00 ms /    45 runs   (   23.96 ms per token,    41.74 tokens per second)\n",
      "llama_print_timings:       total time =    7566.76 ms /   717 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 57.25it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =     168.75 ms /   256 runs   (    0.66 ms per token,  1517.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2252.40 ms /   254 tokens (    8.87 ms per token,   112.77 tokens per second)\n",
      "llama_print_timings:        eval time =    5842.22 ms /   255 runs   (   22.91 ms per token,    43.65 tokens per second)\n",
      "llama_print_timings:       total time =    9192.74 ms /   509 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 25.68it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      27.80 ms /    42 runs   (    0.66 ms per token,  1510.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6053.75 ms /   667 tokens (    9.08 ms per token,   110.18 tokens per second)\n",
      "llama_print_timings:        eval time =     980.11 ms /    41 runs   (   23.91 ms per token,    41.83 tokens per second)\n",
      "llama_print_timings:       total time =    7421.28 ms /   708 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 81.94it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      48.78 ms /    74 runs   (    0.66 ms per token,  1516.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1860.42 ms /   210 tokens (    8.86 ms per token,   112.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1649.39 ms /    73 runs   (   22.59 ms per token,    44.26 tokens per second)\n",
      "llama_print_timings:       total time =    3871.70 ms /   283 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 66.34it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      28.39 ms /    43 runs   (    0.66 ms per token,  1514.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1804.85 ms /   204 tokens (    8.85 ms per token,   113.03 tokens per second)\n",
      "llama_print_timings:        eval time =     949.93 ms /    42 runs   (   22.62 ms per token,    44.21 tokens per second)\n",
      "llama_print_timings:       total time =    2988.29 ms /   246 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 81.43it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      34.29 ms /    52 runs   (    0.66 ms per token,  1516.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1739.30 ms /   196 tokens (    8.87 ms per token,   112.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1150.93 ms /    51 runs   (   22.57 ms per token,    44.31 tokens per second)\n",
      "llama_print_timings:       total time =    3150.32 ms /   247 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 70.07it/s]\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     652.09 ms\n",
      "llama_print_timings:      sample time =      38.42 ms /    58 runs   (    0.66 ms per token,  1509.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1819.17 ms /   206 tokens (    8.83 ms per token,   113.24 tokens per second)\n",
      "llama_print_timings:        eval time =    1285.26 ms /    57 runs   (   22.55 ms per token,    44.35 tokens per second)\n",
      "llama_print_timings:       total time =    3393.44 ms /   263 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(191, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>ModelAnswer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Do students in Kiltie have to memorize music?</td>\n",
       "      <td>No</td>\n",
       "      <td>No, the music is changed for every show. You should invest in a good and trusty lyre.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Do I need to email my home address to the Kiltie Band Director if I'm interested in joining?</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No, you do not need to email your home address to the Kiltie Band Director.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Do I need to audition to join the Kiltie Band?</td>\n",
       "      <td>No</td>\n",
       "      <td>No, any member of the campus community with music experience is able to join the Kiltie Band!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Where does the Kiltie Band rehearse?</td>\n",
       "      <td>CUC Studio Theater</td>\n",
       "      <td>The Kiltie Band rehearses at the CUC Studio Theater.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>webpages</td>\n",
       "      <td>When should I get an instrument from the Kiltie Band if I need one?</td>\n",
       "      <td>4:30p.m. before the first rehearsal</td>\n",
       "      <td>You should invest in a good and trusty lyre.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category  \\\n",
       "0  webpages   \n",
       "1  webpages   \n",
       "2  webpages   \n",
       "3  webpages   \n",
       "4  webpages   \n",
       "\n",
       "                                                                                       Question  \\\n",
       "0                                                 Do students in Kiltie have to memorize music?   \n",
       "1  Do I need to email my home address to the Kiltie Band Director if I'm interested in joining?   \n",
       "2                                                Do I need to audition to join the Kiltie Band?   \n",
       "3                                                          Where does the Kiltie Band rehearse?   \n",
       "4                           When should I get an instrument from the Kiltie Band if I need one?   \n",
       "\n",
       "                                Answer  \\\n",
       "0                                   No   \n",
       "1                                  Yes   \n",
       "2                                   No   \n",
       "3                   CUC Studio Theater   \n",
       "4  4:30p.m. before the first rehearsal   \n",
       "\n",
       "                                                                                     ModelAnswer  \n",
       "0          No, the music is changed for every show. You should invest in a good and trusty lyre.  \n",
       "1                    No, you do not need to email your home address to the Kiltie Band Director.  \n",
       "2  No, any member of the campus community with music experience is able to join the Kiltie Band!  \n",
       "3                                           The Kiltie Band rehearses at the CUC Studio Theater.  \n",
       "4                                                   You should invest in a good and trusty lyre.  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_model_answers = generate_answers_and_save(csv_path=csv_input_dir, llm = llm_answer_gen)\n",
    "print(df_with_model_answers.shape)\n",
    "df_with_model_answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact match: 0.04712041884816754\n",
      "F1 score: 0.19903977874921847\n",
      "Recall score: 0.45991834195224224\n"
     ]
    }
   ],
   "source": [
    "# with additional extraction prompt after generation without prompt\n",
    "type(df_with_model_answers['ModelAnswer'][0]),type(df_with_model_answers['Answer'][0])\n",
    "df_with_model_answers = df_with_model_answers.astype(str)  # Convert columns to string type\n",
    "from evaluation_csv import total_score_csv\n",
    "exact_match, f1_score, recall_score = total_score_csv(df_with_model_answers['ModelAnswer'], df_with_model_answers['Answer'])\n",
    "print(f'Exact match: {exact_match}')\n",
    "print(f'F1 score: {f1_score}')\n",
    "print(f'Recall score: {recall_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "drdoGkF3wja4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: webpages\n",
      "Exact match: 0.09259259259259259\n",
      "F1 score: 0.31618458605389715\n",
      "Recall score: 0.6935956790123456\n",
      "\n",
      "\n",
      "Category: tabular_webpages\n",
      "Exact match: 0.0\n",
      "F1 score: 0.14436440295815298\n",
      "Recall score: 0.46610576923076924\n",
      "\n",
      "\n",
      "Category: other_pdf\n",
      "Exact match: 0.0\n",
      "F1 score: 0.13257874211960932\n",
      "Recall score: 0.2637853692201518\n",
      "\n",
      "\n",
      "Category: papers_pdf\n",
      "Exact match: 0.0\n",
      "F1 score: 0.0574977817213842\n",
      "Recall score: 0.22222222222222224\n",
      "\n",
      "\n",
      "Category: schedule_pdf\n",
      "Exact match: 0.0\n",
      "F1 score: 0.015810276679841896\n",
      "Recall score: 0.045454545454545456\n",
      "\n",
      "\n",
      "Category: jsons\n",
      "Exact match: 0.05714285714285714\n",
      "F1 score: 0.2100834755820694\n",
      "Recall score: 0.49030412753234165\n",
      "\n",
      "\n",
      "Category: json_hard\n",
      "Exact match: 0.0\n",
      "F1 score: 0.030124777183600716\n",
      "Recall score: 0.048863636363636366\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for category in df['Category'].unique():\n",
    "    print(f'Category: {category}')\n",
    "    df_category = df_with_model_answers[df_with_model_answers['Category'] == category]\n",
    "    exact_match, f1_score, recall_score = total_score_csv(df_category['ModelAnswer'], df_category['Answer'])\n",
    "    print(f'Exact match: {exact_match}')\n",
    "    print(f'F1 score: {f1_score}')\n",
    "    print(f'Recall score: {recall_score}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_with_model_answers.to_csv('../llama-no-temp-output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>ModelAnswer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Do students in Kiltie have to memorize music?</td>\n",
       "      <td>No</td>\n",
       "      <td>No, the music is changed for every show. You should invest in a good and trusty lyre.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Do I need to email my home address to the Kiltie Band Director if I'm interested in joining?</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No, you do not need to email your home address to the Kiltie Band Director.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Do I need to audition to join the Kiltie Band?</td>\n",
       "      <td>No</td>\n",
       "      <td>No, any member of the campus community with music experience is able to join the Kiltie Band!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Where does the Kiltie Band rehearse?</td>\n",
       "      <td>CUC Studio Theater</td>\n",
       "      <td>The Kiltie Band rehearses at the CUC Studio Theater.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>webpages</td>\n",
       "      <td>When should I get an instrument from the Kiltie Band if I need one?</td>\n",
       "      <td>4:30p.m. before the first rehearsal</td>\n",
       "      <td>You should invest in a good and trusty lyre.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>webpages</td>\n",
       "      <td>When is Andrew Carnegie's birthday?</td>\n",
       "      <td>November 25th, 1835</td>\n",
       "      <td>Andrew Carnegie was born in Dunfermline, Scotland in 1835. His birthday is on November 25th.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What time are rehearsals on Game Days for the Kiltie Band?</td>\n",
       "      <td>9:30-11:00 a.m.</td>\n",
       "      <td>Rehearsals for the Kiltie Band on Game Days are at 9:30-11 a.m.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>webpages</td>\n",
       "      <td>How should Kilties promote the success of the Kiltie Band?</td>\n",
       "      <td>attendance, attitude, and dependabiliy</td>\n",
       "      <td>Kilties should promote the success of the Kiltie Band by attending rehearsals consistently, having a positive attitude, and being dependable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What should I email to the band director if I'm interested in joining the Kiltie Band?</td>\n",
       "      <td>name, high school, address at Carnegie Mellon, home address, cell number, home number, whether you plan on being in the band or colorguard, if in the band what instrument(s) you play, and whether you need to borrow an instrument or equipment</td>\n",
       "      <td>If you are interested in joining the Kiltie Band, please email the following information to the band director, Jeremy Olisar: Name High School Address at Carnegie Mellon (if known) Home address Cell number Home number Whether you plan on being in the band or colorguard If in the band what instrument(s) you play Whether you need to borrow an instrument or equipment To see and hear the band in action, visit our YouTube channel .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What university is the Kiltie Band a part of?</td>\n",
       "      <td>Carnegie Mellon</td>\n",
       "      <td>The Kiltie Band is a part of Carnegie Mellon University.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Was the Scottish terrier a familiar figure at CMU before it officially became a mascot?</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes. For years students have suited up in an unofficial Scottish terrier costume to excite fans at athletic events.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Is there an official mascot costume of Scotty?</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Who led the effort to make Carnegie Mellon's mascot the Scottish Terrier?</td>\n",
       "      <td>Susan Bassett and Jennifer Church</td>\n",
       "      <td>Susan Bassett and Jennifer Church led the effort.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Where did Scotty debug as CMU's official mascot?</td>\n",
       "      <td>at a football game</td>\n",
       "      <td>Scotty debuted as CMU's official mascot at the Nov. 10, 2007 home football game.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Who did CMU partner with to create the Scotty mascot graphics?</td>\n",
       "      <td>SME Branding</td>\n",
       "      <td>SME Branding.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What month and year was the Mascot Identity Task Force formed?</td>\n",
       "      <td>November 2006</td>\n",
       "      <td>The Mascot Identity Task Force was formed in November 2006.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>webpages</td>\n",
       "      <td>When did Scotty debut as CMU's official mascot?</td>\n",
       "      <td>November 2007</td>\n",
       "      <td>Scotty debuted as CMU's official mascot in 2007.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What characteristics does the Scottish terrier represent?</td>\n",
       "      <td>determined, thoughtful, strength, power, agility in a small package</td>\n",
       "      <td>Determined, thoughtful, strong, powerful, agile in a small package.  Please provide a detailed answer or list of answers based on the given text.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Where did the athletic director of CMU graduate from?</td>\n",
       "      <td>Brandeis</td>\n",
       "      <td>The athletic director of CMU graduated from CMU.  Explanation: The athletic director of CMU is mentioned in Document 7, which states that the athletic director is located in the Skibo Gymnasium. Since Skibo Gymnasium is a part of CMU, it means that the athletic director graduated from CMU.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>webpages</td>\n",
       "      <td>When was Carnegie Technical Schools founded?</td>\n",
       "      <td>1900</td>\n",
       "      <td>What is a Tartan?  Answer: A tartan is a twilled woolen fabric with a plaid design, often misrepresented as a fierce warrior from either the Asian tundra or Scottish highlands. It is of Scottish origin and consists of stripes of various colors and widths against a solid ground, denoting a particular family lineage.Document 3::: Carnegie Technical Schools was founded in 1900 by Andrew Carnegie. Twelve years later it became known as the Carnegie Institute of Technology. In 1967, the school merged with Mellon Institute and became what is known today as Carnegie Mellon University.  Question: What is the difference between tartan and plaid?  Answer: Tartan is a twilled woolen fabric with a plaid design, while plaid is a pattern of stripes in a fabric, often horizontal and vertical. The term tartan specifically refers to a particular type of plaid with a specific pattern of stripes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Was Andrew Carnegie ever the president of CMU?</td>\n",
       "      <td>No</td>\n",
       "      <td>No. Andrew Carnegie was never the president of CMU. He was a philanthropist who founded the Carnegie Technical Schools, which later became Carnegie Mellon University.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Is the Scotty mascot wearing tartan or plaid around its neck?</td>\n",
       "      <td>plaid</td>\n",
       "      <td>Tartan.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What is a Tartan?</td>\n",
       "      <td>twilled wollen fabric with a plaid design</td>\n",
       "      <td>A Tartan is a twilled woolen fabric with a plaid design, often misrepresented as a fierce warrior from either the Asian tundra or Scottish highlands. It is of Scottish origin and consists of stripes of various colors and widths against a solid ground, denoting a particular family lineage.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>webpages</td>\n",
       "      <td>How many graduate and doctoral students were there at CMU in fall 2021?</td>\n",
       "      <td>7062</td>\n",
       "      <td>According to Document 0, there were 2,479 graduate students at CMU in fall 2021.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What sports conference does CMU play in?</td>\n",
       "      <td>University Athletic Association</td>\n",
       "      <td>Carnegie Mellon University plays in the University Athletic Association (UAA).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>webpages</td>\n",
       "      <td>When did CMU's founder move to the United States?</td>\n",
       "      <td>1848</td>\n",
       "      <td>Andrew Carnegie moved to the United States in 1880.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>webpages</td>\n",
       "      <td>In buggy, what is the chute?</td>\n",
       "      <td>portion of buggy course where buggies make a sharp righthand turn from Schenley Drive onto Frew Street</td>\n",
       "      <td>In buggy, the chute refers to a section of the freeroll portion of the buggy course near the southwestern end of Frew Street at its intersection with Schenley Drive. It is where buggies make a sharp right-hand turn from Schenley Drive onto Frew Street.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What can be a challenging aspect of the buggy course?</td>\n",
       "      <td>potholes</td>\n",
       "      <td>Potholes can make or break a fast run on the course.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What is the purpose of fairings on a buggy?</td>\n",
       "      <td>reduce drag; make the vehicle quieter; looks cool</td>\n",
       "      <td>Fairings are used to reduce drag, make the vehicle quieter, and look cool. They are a key feature for the Fringe team, which has a reputation of being the quietest on the course.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What is the \"froom\"?</td>\n",
       "      <td>Fringe workshop</td>\n",
       "      <td>Froom is not a valid term in this context.  Please provide your answer for each question.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What major did the social chair for Fringe in 2019 study?</td>\n",
       "      <td>neuroscience</td>\n",
       "      <td>The major studied by the social chair for Fringe in 2019 is not explicitly mentioned in the provided text.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What are some Fringe racing buggies that have start with the letter B?</td>\n",
       "      <td>Boson, Blueshift, Bissa, and Bumper</td>\n",
       "      <td>Boson, Bumper, Bane, Bissa.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What did the first doctorate graduate from CMU study?</td>\n",
       "      <td>civil engineering</td>\n",
       "      <td>Civil Engineering.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>webpages</td>\n",
       "      <td>When did Andrew Carnegie die?</td>\n",
       "      <td>1919</td>\n",
       "      <td>Andrew Carnegie died in 1919.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>webpages</td>\n",
       "      <td>When did the Carnegie Tech school for women close to join the one for males?</td>\n",
       "      <td>1973</td>\n",
       "      <td>Document 1 states that in 1973, Margaret Morrison closed and women joined their male peers in classrooms and dorms at Carnegie Tech. This means that the school for women, Margaret Morrison Carnegie College, closed in 1973, allowing women to join the one for males.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>webpages</td>\n",
       "      <td>When did Carnegie Tech start to become a research institution?</td>\n",
       "      <td>first half of the 20th century</td>\n",
       "      <td>According to Document 1, Carnegie Tech laid the groundwork for a research institution in 1919 by recruiting leading scientists, offering sponsored fellowships with government and industry leaders, and pioneering nontraditional interdisciplinary research.  Therefore, the answer is 1919.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What is the name of the Carnegie Technical Schools for only women?</td>\n",
       "      <td>Margaret Morrison Carnegie College</td>\n",
       "      <td>Margaret Morrison Carnegie College.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>webpages</td>\n",
       "      <td>How much money did Carnegie donate to start CMU?</td>\n",
       "      <td>$1 million</td>\n",
       "      <td>What was the first degree offered at CMU? Answer: Bachelor's degree in engineering or fine arts  Question: What was the first U.S. degree offered at CMU? Answer: Drama degree in 1914  Question: What was the name of the school established by Carnegie in 1900? Answer: Carnegie Technical Schools  Question: What is the name of the school today? Answer: Carnegie Mellon University  Question: What is the ranking of CMU in MANAGEMENT INFORMATION SYSTEMS in 2022? Answer: #1  Question: What is the ranking of CMU in ARTIFICIAL INTELLIGENCE in 2022? Answer: #1  Question: What is the ranking of CMU in SOFTWARE ENGINEERING in 2022? Answer: #1  Question: What is the ranking of CMU in U.S. News &amp; World Report in 2023? Answer: #</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What was the Carnegie Plan?</td>\n",
       "      <td>new curriculum that required science and engineer students to take courses in the humanities and social sciences</td>\n",
       "      <td>The Carnegie Plan was a new curriculum introduced by Carnegie Tech in 1938 that required science and engineering students to take courses in humanities and social sciences in order to better understand the needs of society.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What was the purpose of the Carnegie Plan?</td>\n",
       "      <td>science and engineer students can better understand the needs of society</td>\n",
       "      <td>The Carnegie Plan was a new curriculum introduced by Carnegie Tech in 1938 that required science and engineering students to take courses in humanities and social sciences in order to better understand the needs of society.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Who joined CMU's Computer Science Department after it's first crisis?</td>\n",
       "      <td>Joe Traub</td>\n",
       "      <td>Joe Traub joined CMU's Computer Science Department after its first crisis in 1970-1971.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>webpages</td>\n",
       "      <td>How did Allen Newell describe the Andrew Project?</td>\n",
       "      <td>greening up the campus with computer science</td>\n",
       "      <td>I don't know.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What specific date was CMU's SCS announced?</td>\n",
       "      <td>January 3, 1989</td>\n",
       "      <td>The School of Computer Science was announced on January 3, 1989.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>webpages</td>\n",
       "      <td>In fall 2013, what percent did the undergraduates and master's degree students make up out of total student enrollment at SCS?</td>\n",
       "      <td>74 percent; 74%; 74</td>\n",
       "      <td>According to Document 0, undergraduates made up about 37 percent of student enrollment at SCS in fall 2013, along with more than 600 master’s degree students, which together constituted more than half of total student enrollment (600+37% = 434).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Was the undergraduate SCS program established before the graduate SCS program at CMU?</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes. According to Document 1, the undergraduate SCS program was created during the 1989-90 academic year, while the graduate SCS program was established in 1988.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What did Raj Reddy research in?</td>\n",
       "      <td>speech, language and computer vision</td>\n",
       "      <td>Computer Science, Medicine, Engineering  Please provide your answer for each question.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>webpages</td>\n",
       "      <td>When did the CMU graduate student who developed Java graduate from the university?</td>\n",
       "      <td>1983; '83</td>\n",
       "      <td>James Gosling (CS’83) graduated from CMU in 1983.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>webpages</td>\n",
       "      <td>When were emoticons invented?</td>\n",
       "      <td>1982</td>\n",
       "      <td>1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Who developed the first computer to achieve chess grandmaster status?</td>\n",
       "      <td>Hans Berliner</td>\n",
       "      <td>Hans Berliner (CS’74) developed Hitech, which was the first computer to achieve grandmaster status in computer chess.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>tabular_webpages</td>\n",
       "      <td>When are the diploma ceremonies held?</td>\n",
       "      <td>at various times</td>\n",
       "      <td>The diploma ceremonies are held over the course of the weekend (Friday, May 10–Sunday, May 12). Exact times for each ceremony are not provided in the given text but will be provided soon.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>tabular_webpages</td>\n",
       "      <td>What is the last event on the Saturday of commencement weekend?</td>\n",
       "      <td>The President's Reception in honor of CMU's Doctoral Candidates</td>\n",
       "      <td>Diploma Ceremonies on Saturday, May 11.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>webpages</td>\n",
       "      <td>By when must guests be seated for the commencement ceremony?</td>\n",
       "      <td>9:15 a.m.</td>\n",
       "      <td>Guests must be seated by 9:15 a.m. for the start of the student procession.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>webpages</td>\n",
       "      <td>Is there a commencement event specifically for Teaching Assistants?</td>\n",
       "      <td>No</td>\n",
       "      <td>No, there is no commencement event specifically for Teaching Assistants. The main commencement ceremony is for all graduating students, and diploma ceremonies are organized by each college/school/department for their graduating students.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What day and time is the event for first generation graduates during commencement weekend?</td>\n",
       "      <td>Thursday, May 9 at 5-5:30 p.m.</td>\n",
       "      <td>The event for first generation graduates during commencement weekend is on Friday, May 10th from 5-5:30 p.m. at Alumni Concert Hall.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What are the full names of the Master's programs that LTI offers?</td>\n",
       "      <td>Master of Language Technologies, Master of Science in Intelligent Information Systems, Master of Computational Data Science, Master of Science in Artificial Intelligence and Innovation</td>\n",
       "      <td>Master of Language Technologies (MLT) and Ph.D. in Language and Information Technologies (Ph.D.).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>webpages</td>\n",
       "      <td>What should MIIS students who are interested in voice-based systems take their 2nd year Spring semester?</td>\n",
       "      <td>applied machine learning, competitive engineering, Design and Implementation of Speech Recognition Systems, Directed Study, MIIS Capstone Planning Seminar</td>\n",
       "      <td>Option 1 - Applied Machine Learning - Competitive Engineering - Design and Implementation of Speech Recognition Systems - Directed Study - MIIS Capstone Planning Seminar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>tabular_webpages</td>\n",
       "      <td>If I were a MCDS student and Systems major, when should I take Advanced Databases?</td>\n",
       "      <td>Spring of first year; Year 1 Spring; Spring of Year 1</td>\n",
       "      <td>According to Document 1, you should take Advanced Databases in the fall semester of your second year of study.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>tabular_webpages</td>\n",
       "      <td>What classes do I have to take before declaring an LT concentration?</td>\n",
       "      <td>Principles of Imperative Computation (15-122) and Principles of Functional Programming (15-150); Principles of Imperative Computation and Principles of Functional Programming; 15-122 and 15-150</td>\n",
       "      <td>Before declaring an LT concentration, you must take the following classes:  Principles of Imperative Computation (15-122) Principles of Functional Programming (15-150) We also strongly encourage candidates to take Differential and Integral Calculus (21-120) and Integration and Approximation (21-122) Matrices and Linear Transformations (21-241) or Matrix Theory (21-242) Probability and Computing (15-259) or Probability (21-325) or Probability Theory for Computer Scientists (36-218) or Introduction to Probability Theory (36-225) These classes are required before declaring an LT concentration.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>tabular_webpages</td>\n",
       "      <td>What is the GRE code for Carnegie Mellon?</td>\n",
       "      <td>2074</td>\n",
       "      <td>The GRE code for Carnegie Mellon is 2074.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>tabular_webpages</td>\n",
       "      <td>How long is the typical PhD plan for those in LTI?</td>\n",
       "      <td>5 years</td>\n",
       "      <td>Can students use courses taken as a Master's degree student towards their PhD requirements?  Answer: Yes, LTI PhD students can use courses taken as a Master's degree student towards their PhD requirements with approval from the academic program.  Question: What is the public thesis proposal defense?  Answer: The public thesis proposal defense is a public presentation and defense of the dissertation results, which protects the student by guaranteeing that the proposed research is interesting to the larger scientific community and demonstrating that the student will finish the program if the work is completed as outlined.  Question: What is the research speaking requirement?  Answer: The research speaking requirement is a yearly oral presentation at the LTI, which consists of a 20-minute talk plus time for discussion, and is advertised to the LTI mailing lists at least one week before the presentation. At least two LTI faculty members will attend the presentation, including the research advisor, and provide written feedback to both the student and the Program Director of graduate programs.  Question: Can students consult with other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Category  \\\n",
       "0           webpages   \n",
       "1           webpages   \n",
       "2           webpages   \n",
       "3           webpages   \n",
       "4           webpages   \n",
       "5           webpages   \n",
       "6           webpages   \n",
       "7           webpages   \n",
       "8           webpages   \n",
       "9           webpages   \n",
       "10          webpages   \n",
       "11          webpages   \n",
       "12          webpages   \n",
       "13          webpages   \n",
       "14          webpages   \n",
       "15          webpages   \n",
       "16          webpages   \n",
       "17          webpages   \n",
       "18          webpages   \n",
       "19          webpages   \n",
       "20          webpages   \n",
       "21          webpages   \n",
       "22          webpages   \n",
       "23          webpages   \n",
       "24          webpages   \n",
       "25          webpages   \n",
       "26          webpages   \n",
       "27          webpages   \n",
       "28          webpages   \n",
       "29          webpages   \n",
       "30          webpages   \n",
       "31          webpages   \n",
       "32          webpages   \n",
       "33          webpages   \n",
       "34          webpages   \n",
       "35          webpages   \n",
       "36          webpages   \n",
       "37          webpages   \n",
       "38          webpages   \n",
       "39          webpages   \n",
       "40          webpages   \n",
       "41          webpages   \n",
       "42          webpages   \n",
       "43          webpages   \n",
       "44          webpages   \n",
       "45          webpages   \n",
       "46          webpages   \n",
       "47          webpages   \n",
       "48          webpages   \n",
       "49  tabular_webpages   \n",
       "50  tabular_webpages   \n",
       "51          webpages   \n",
       "52          webpages   \n",
       "53          webpages   \n",
       "54          webpages   \n",
       "55          webpages   \n",
       "56  tabular_webpages   \n",
       "57  tabular_webpages   \n",
       "58  tabular_webpages   \n",
       "59  tabular_webpages   \n",
       "\n",
       "                                                                                                                          Question  \\\n",
       "0                                                                                    Do students in Kiltie have to memorize music?   \n",
       "1                                     Do I need to email my home address to the Kiltie Band Director if I'm interested in joining?   \n",
       "2                                                                                   Do I need to audition to join the Kiltie Band?   \n",
       "3                                                                                             Where does the Kiltie Band rehearse?   \n",
       "4                                                              When should I get an instrument from the Kiltie Band if I need one?   \n",
       "5                                                                                              When is Andrew Carnegie's birthday?   \n",
       "6                                                                       What time are rehearsals on Game Days for the Kiltie Band?   \n",
       "7                                                                       How should Kilties promote the success of the Kiltie Band?   \n",
       "8                                           What should I email to the band director if I'm interested in joining the Kiltie Band?   \n",
       "9                                                                                    What university is the Kiltie Band a part of?   \n",
       "10                                         Was the Scottish terrier a familiar figure at CMU before it officially became a mascot?   \n",
       "11                                                                                  Is there an official mascot costume of Scotty?   \n",
       "12                                                       Who led the effort to make Carnegie Mellon's mascot the Scottish Terrier?   \n",
       "13                                                                                Where did Scotty debug as CMU's official mascot?   \n",
       "14                                                                  Who did CMU partner with to create the Scotty mascot graphics?   \n",
       "15                                                                  What month and year was the Mascot Identity Task Force formed?   \n",
       "16                                                                                 When did Scotty debut as CMU's official mascot?   \n",
       "17                                                                       What characteristics does the Scottish terrier represent?   \n",
       "18                                                                           Where did the athletic director of CMU graduate from?   \n",
       "19                                                                                    When was Carnegie Technical Schools founded?   \n",
       "20                                                                                  Was Andrew Carnegie ever the president of CMU?   \n",
       "21                                                                   Is the Scotty mascot wearing tartan or plaid around its neck?   \n",
       "22                                                                                                               What is a Tartan?   \n",
       "23                                                         How many graduate and doctoral students were there at CMU in fall 2021?   \n",
       "24                                                                                        What sports conference does CMU play in?   \n",
       "25                                                                               When did CMU's founder move to the United States?   \n",
       "26                                                                                                    In buggy, what is the chute?   \n",
       "27                                                                           What can be a challenging aspect of the buggy course?   \n",
       "28                                                                                     What is the purpose of fairings on a buggy?   \n",
       "29                                                                                                            What is the \"froom\"?   \n",
       "30                                                                       What major did the social chair for Fringe in 2019 study?   \n",
       "31                                                          What are some Fringe racing buggies that have start with the letter B?   \n",
       "32                                                                           What did the first doctorate graduate from CMU study?   \n",
       "33                                                                                                   When did Andrew Carnegie die?   \n",
       "34                                                    When did the Carnegie Tech school for women close to join the one for males?   \n",
       "35                                                                  When did Carnegie Tech start to become a research institution?   \n",
       "36                                                              What is the name of the Carnegie Technical Schools for only women?   \n",
       "37                                                                                How much money did Carnegie donate to start CMU?   \n",
       "38                                                                                                     What was the Carnegie Plan?   \n",
       "39                                                                                      What was the purpose of the Carnegie Plan?   \n",
       "40                                                           Who joined CMU's Computer Science Department after it's first crisis?   \n",
       "41                                                                               How did Allen Newell describe the Andrew Project?   \n",
       "42                                                                                     What specific date was CMU's SCS announced?   \n",
       "43  In fall 2013, what percent did the undergraduates and master's degree students make up out of total student enrollment at SCS?   \n",
       "44                                           Was the undergraduate SCS program established before the graduate SCS program at CMU?   \n",
       "45                                                                                                 What did Raj Reddy research in?   \n",
       "46                                              When did the CMU graduate student who developed Java graduate from the university?   \n",
       "47                                                                                                   When were emoticons invented?   \n",
       "48                                                           Who developed the first computer to achieve chess grandmaster status?   \n",
       "49                                                                                           When are the diploma ceremonies held?   \n",
       "50                                                                 What is the last event on the Saturday of commencement weekend?   \n",
       "51                                                                    By when must guests be seated for the commencement ceremony?   \n",
       "52                                                             Is there a commencement event specifically for Teaching Assistants?   \n",
       "53                                      What day and time is the event for first generation graduates during commencement weekend?   \n",
       "54                                                               What are the full names of the Master's programs that LTI offers?   \n",
       "55                        What should MIIS students who are interested in voice-based systems take their 2nd year Spring semester?   \n",
       "56                                              If I were a MCDS student and Systems major, when should I take Advanced Databases?   \n",
       "57                                                            What classes do I have to take before declaring an LT concentration?   \n",
       "58                                                                                       What is the GRE code for Carnegie Mellon?   \n",
       "59                                                                              How long is the typical PhD plan for those in LTI?   \n",
       "\n",
       "                                                                                                                                                                                                                                               Answer  \\\n",
       "0                                                                                                                                                                                                                                                  No   \n",
       "1                                                                                                                                                                                                                                                 Yes   \n",
       "2                                                                                                                                                                                                                                                  No   \n",
       "3                                                                                                                                                                                                                                  CUC Studio Theater   \n",
       "4                                                                                                                                                                                                                 4:30p.m. before the first rehearsal   \n",
       "5                                                                                                                                                                                                                                 November 25th, 1835   \n",
       "6                                                                                                                                                                                                                                     9:30-11:00 a.m.   \n",
       "7                                                                                                                                                                                                              attendance, attitude, and dependabiliy   \n",
       "8   name, high school, address at Carnegie Mellon, home address, cell number, home number, whether you plan on being in the band or colorguard, if in the band what instrument(s) you play, and whether you need to borrow an instrument or equipment   \n",
       "9                                                                                                                                                                                                                                     Carnegie Mellon   \n",
       "10                                                                                                                                                                                                                                                Yes   \n",
       "11                                                                                                                                                                                                                                                Yes   \n",
       "12                                                                                                                                                                                                                  Susan Bassett and Jennifer Church   \n",
       "13                                                                                                                                                                                                                                 at a football game   \n",
       "14                                                                                                                                                                                                                                       SME Branding   \n",
       "15                                                                                                                                                                                                                                      November 2006   \n",
       "16                                                                                                                                                                                                                                      November 2007   \n",
       "17                                                                                                                                                                                determined, thoughtful, strength, power, agility in a small package   \n",
       "18                                                                                                                                                                                                                                           Brandeis   \n",
       "19                                                                                                                                                                                                                                               1900   \n",
       "20                                                                                                                                                                                                                                                 No   \n",
       "21                                                                                                                                                                                                                                              plaid   \n",
       "22                                                                                                                                                                                                          twilled wollen fabric with a plaid design   \n",
       "23                                                                                                                                                                                                                                               7062   \n",
       "24                                                                                                                                                                                                                    University Athletic Association   \n",
       "25                                                                                                                                                                                                                                               1848   \n",
       "26                                                                                                                                             portion of buggy course where buggies make a sharp righthand turn from Schenley Drive onto Frew Street   \n",
       "27                                                                                                                                                                                                                                           potholes   \n",
       "28                                                                                                                                                                                                  reduce drag; make the vehicle quieter; looks cool   \n",
       "29                                                                                                                                                                                                                                    Fringe workshop   \n",
       "30                                                                                                                                                                                                                                       neuroscience   \n",
       "31                                                                                                                                                                                                                Boson, Blueshift, Bissa, and Bumper   \n",
       "32                                                                                                                                                                                                                                  civil engineering   \n",
       "33                                                                                                                                                                                                                                               1919   \n",
       "34                                                                                                                                                                                                                                               1973   \n",
       "35                                                                                                                                                                                                                     first half of the 20th century   \n",
       "36                                                                                                                                                                                                                 Margaret Morrison Carnegie College   \n",
       "37                                                                                                                                                                                                                                         $1 million   \n",
       "38                                                                                                                                   new curriculum that required science and engineer students to take courses in the humanities and social sciences   \n",
       "39                                                                                                                                                                           science and engineer students can better understand the needs of society   \n",
       "40                                                                                                                                                                                                                                          Joe Traub   \n",
       "41                                                                                                                                                                                                       greening up the campus with computer science   \n",
       "42                                                                                                                                                                                                                                    January 3, 1989   \n",
       "43                                                                                                                                                                                                                                74 percent; 74%; 74   \n",
       "44                                                                                                                                                                                                                                                 No   \n",
       "45                                                                                                                                                                                                               speech, language and computer vision   \n",
       "46                                                                                                                                                                                                                                          1983; '83   \n",
       "47                                                                                                                                                                                                                                               1982   \n",
       "48                                                                                                                                                                                                                                      Hans Berliner   \n",
       "49                                                                                                                                                                                                                                   at various times   \n",
       "50                                                                                                                                                                                    The President's Reception in honor of CMU's Doctoral Candidates   \n",
       "51                                                                                                                                                                                                                                          9:15 a.m.   \n",
       "52                                                                                                                                                                                                                                                 No   \n",
       "53                                                                                                                                                                                                                     Thursday, May 9 at 5-5:30 p.m.   \n",
       "54                                                           Master of Language Technologies, Master of Science in Intelligent Information Systems, Master of Computational Data Science, Master of Science in Artificial Intelligence and Innovation   \n",
       "55                                                                                         applied machine learning, competitive engineering, Design and Implementation of Speech Recognition Systems, Directed Study, MIIS Capstone Planning Seminar   \n",
       "56                                                                                                                                                                                              Spring of first year; Year 1 Spring; Spring of Year 1   \n",
       "57                                                  Principles of Imperative Computation (15-122) and Principles of Functional Programming (15-150); Principles of Imperative Computation and Principles of Functional Programming; 15-122 and 15-150   \n",
       "58                                                                                                                                                                                                                                               2074   \n",
       "59                                                                                                                                                                                                                                            5 years   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ModelAnswer  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         No, the music is changed for every show. You should invest in a good and trusty lyre.  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   No, you do not need to email your home address to the Kiltie Band Director.  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 No, any member of the campus community with music experience is able to join the Kiltie Band!  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          The Kiltie Band rehearses at the CUC Studio Theater.  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  You should invest in a good and trusty lyre.  \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Andrew Carnegie was born in Dunfermline, Scotland in 1835. His birthday is on November 25th.  \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Rehearsals for the Kiltie Band on Game Days are at 9:30-11 a.m.  \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Kilties should promote the success of the Kiltie Band by attending rehearsals consistently, having a positive attitude, and being dependable.  \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                If you are interested in joining the Kiltie Band, please email the following information to the band director, Jeremy Olisar: Name High School Address at Carnegie Mellon (if known) Home address Cell number Home number Whether you plan on being in the band or colorguard If in the band what instrument(s) you play Whether you need to borrow an instrument or equipment To see and hear the band in action, visit our YouTube channel .  \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      The Kiltie Band is a part of Carnegie Mellon University.  \n",
       "10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Yes. For years students have suited up in an unofficial Scottish terrier costume to excite fans at athletic events.  \n",
       "11                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Yes.  \n",
       "12                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Susan Bassett and Jennifer Church led the effort.  \n",
       "13                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Scotty debuted as CMU's official mascot at the Nov. 10, 2007 home football game.  \n",
       "14                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                SME Branding.  \n",
       "15                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  The Mascot Identity Task Force was formed in November 2006.  \n",
       "16                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Scotty debuted as CMU's official mascot in 2007.  \n",
       "17                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Determined, thoughtful, strong, powerful, agile in a small package.  Please provide a detailed answer or list of answers based on the given text.  \n",
       "18                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           The athletic director of CMU graduated from CMU.  Explanation: The athletic director of CMU is mentioned in Document 7, which states that the athletic director is located in the Skibo Gymnasium. Since Skibo Gymnasium is a part of CMU, it means that the athletic director graduated from CMU.  \n",
       "19                                                                                                                                                                                                                                                                    What is a Tartan?  Answer: A tartan is a twilled woolen fabric with a plaid design, often misrepresented as a fierce warrior from either the Asian tundra or Scottish highlands. It is of Scottish origin and consists of stripes of various colors and widths against a solid ground, denoting a particular family lineage.Document 3::: Carnegie Technical Schools was founded in 1900 by Andrew Carnegie. Twelve years later it became known as the Carnegie Institute of Technology. In 1967, the school merged with Mellon Institute and became what is known today as Carnegie Mellon University.  Question: What is the difference between tartan and plaid?  Answer: Tartan is a twilled woolen fabric with a plaid design, while plaid is a pattern of stripes in a fabric, often horizontal and vertical. The term tartan specifically refers to a particular type of plaid with a specific pattern of stripes.  \n",
       "20                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       No. Andrew Carnegie was never the president of CMU. He was a philanthropist who founded the Carnegie Technical Schools, which later became Carnegie Mellon University.  \n",
       "21                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Tartan.  \n",
       "22                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            A Tartan is a twilled woolen fabric with a plaid design, often misrepresented as a fierce warrior from either the Asian tundra or Scottish highlands. It is of Scottish origin and consists of stripes of various colors and widths against a solid ground, denoting a particular family lineage.  \n",
       "23                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             According to Document 0, there were 2,479 graduate students at CMU in fall 2021.  \n",
       "24                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Carnegie Mellon University plays in the University Athletic Association (UAA).  \n",
       "25                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Andrew Carnegie moved to the United States in 1880.  \n",
       "26                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 In buggy, the chute refers to a section of the freeroll portion of the buggy course near the southwestern end of Frew Street at its intersection with Schenley Drive. It is where buggies make a sharp right-hand turn from Schenley Drive onto Frew Street.  \n",
       "27                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Potholes can make or break a fast run on the course.  \n",
       "28                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Fairings are used to reduce drag, make the vehicle quieter, and look cool. They are a key feature for the Fringe team, which has a reputation of being the quietest on the course.  \n",
       "29                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Froom is not a valid term in this context.  Please provide your answer for each question.  \n",
       "30                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   The major studied by the social chair for Fringe in 2019 is not explicitly mentioned in the provided text.  \n",
       "31                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Boson, Bumper, Bane, Bissa.  \n",
       "32                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Civil Engineering.  \n",
       "33                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Andrew Carnegie died in 1919.  \n",
       "34                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Document 1 states that in 1973, Margaret Morrison closed and women joined their male peers in classrooms and dorms at Carnegie Tech. This means that the school for women, Margaret Morrison Carnegie College, closed in 1973, allowing women to join the one for males.  \n",
       "35                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               According to Document 1, Carnegie Tech laid the groundwork for a research institution in 1919 by recruiting leading scientists, offering sponsored fellowships with government and industry leaders, and pioneering nontraditional interdisciplinary research.  Therefore, the answer is 1919.  \n",
       "36                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Margaret Morrison Carnegie College.  \n",
       "37                                                                                                                                                                                                                                                                                                                                                                                                                                            What was the first degree offered at CMU? Answer: Bachelor's degree in engineering or fine arts  Question: What was the first U.S. degree offered at CMU? Answer: Drama degree in 1914  Question: What was the name of the school established by Carnegie in 1900? Answer: Carnegie Technical Schools  Question: What is the name of the school today? Answer: Carnegie Mellon University  Question: What is the ranking of CMU in MANAGEMENT INFORMATION SYSTEMS in 2022? Answer: #1  Question: What is the ranking of CMU in ARTIFICIAL INTELLIGENCE in 2022? Answer: #1  Question: What is the ranking of CMU in SOFTWARE ENGINEERING in 2022? Answer: #1  Question: What is the ranking of CMU in U.S. News & World Report in 2023? Answer: #  \n",
       "38                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              The Carnegie Plan was a new curriculum introduced by Carnegie Tech in 1938 that required science and engineering students to take courses in humanities and social sciences in order to better understand the needs of society.  \n",
       "39                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              The Carnegie Plan was a new curriculum introduced by Carnegie Tech in 1938 that required science and engineering students to take courses in humanities and social sciences in order to better understand the needs of society.  \n",
       "40                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Joe Traub joined CMU's Computer Science Department after its first crisis in 1970-1971.  \n",
       "41                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                I don't know.  \n",
       "42                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             The School of Computer Science was announced on January 3, 1989.  \n",
       "43                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        According to Document 0, undergraduates made up about 37 percent of student enrollment at SCS in fall 2013, along with more than 600 master’s degree students, which together constituted more than half of total student enrollment (600+37% = 434).  \n",
       "44                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Yes. According to Document 1, the undergraduate SCS program was created during the 1989-90 academic year, while the graduate SCS program was established in 1988.  \n",
       "45                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Computer Science, Medicine, Engineering  Please provide your answer for each question.  \n",
       "46                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            James Gosling (CS’83) graduated from CMU in 1983.  \n",
       "47                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         1982  \n",
       "48                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Hans Berliner (CS’74) developed Hitech, which was the first computer to achieve grandmaster status in computer chess.  \n",
       "49                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  The diploma ceremonies are held over the course of the weekend (Friday, May 10–Sunday, May 12). Exact times for each ceremony are not provided in the given text but will be provided soon.  \n",
       "50                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Diploma Ceremonies on Saturday, May 11.  \n",
       "51                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Guests must be seated by 9:15 a.m. for the start of the student procession.  \n",
       "52                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                No, there is no commencement event specifically for Teaching Assistants. The main commencement ceremony is for all graduating students, and diploma ceremonies are organized by each college/school/department for their graduating students.  \n",
       "53                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         The event for first generation graduates during commencement weekend is on Friday, May 10th from 5-5:30 p.m. at Alumni Concert Hall.  \n",
       "54                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Master of Language Technologies (MLT) and Ph.D. in Language and Information Technologies (Ph.D.).  \n",
       "55                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Option 1 - Applied Machine Learning - Competitive Engineering - Design and Implementation of Speech Recognition Systems - Directed Study - MIIS Capstone Planning Seminar.  \n",
       "56                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               According to Document 1, you should take Advanced Databases in the fall semester of your second year of study.  \n",
       "57                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Before declaring an LT concentration, you must take the following classes:  Principles of Imperative Computation (15-122) Principles of Functional Programming (15-150) We also strongly encourage candidates to take Differential and Integral Calculus (21-120) and Integration and Approximation (21-122) Matrices and Linear Transformations (21-241) or Matrix Theory (21-242) Probability and Computing (15-259) or Probability (21-325) or Probability Theory for Computer Scientists (36-218) or Introduction to Probability Theory (36-225) These classes are required before declaring an LT concentration.  \n",
       "58                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    The GRE code for Carnegie Mellon is 2074.  \n",
       "59  Can students use courses taken as a Master's degree student towards their PhD requirements?  Answer: Yes, LTI PhD students can use courses taken as a Master's degree student towards their PhD requirements with approval from the academic program.  Question: What is the public thesis proposal defense?  Answer: The public thesis proposal defense is a public presentation and defense of the dissertation results, which protects the student by guaranteeing that the proposed research is interesting to the larger scientific community and demonstrating that the student will finish the program if the work is completed as outlined.  Question: What is the research speaking requirement?  Answer: The research speaking requirement is a yearly oral presentation at the LTI, which consists of a 20-minute talk plus time for discussion, and is advertised to the LTI mailing lists at least one week before the presentation. At least two LTI faculty members will attend the presentation, including the research advisor, and provide written feedback to both the student and the Program Director of graduate programs.  Question: Can students consult with other  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_with_model_answers.head(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0567916024824a5cb153ee96ae90bcfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "08e5c13a33c442d69db6a4e5cb1aefd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_486f19f393194214820b2e4719793822",
       "IPY_MODEL_82baa3fb82e24827b49b6bda22f72d78",
       "IPY_MODEL_a2c29ede70564d5b879b4084453d753f"
      ],
      "layout": "IPY_MODEL_bb8b2e9c41ea45dfa6fe7dff8a934fa2"
     }
    },
    "090fd1cdc0694112b57d28e833932350": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "091d085339a14a0ab5a23a60b24508f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8041af99466c478ab32dcb07ff597d41",
      "max": 438349816,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ec25bd06a00e4e2cab1b9f62905449ca",
      "value": 438349816
     }
    },
    "0b946716322e43bb9f4213087c6ee1de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0bce7925eb1f4323a482bb90467bbc66": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c73d54adcb74546b98a15ff898640d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8cd319e80b28462698e8adb196302802",
       "IPY_MODEL_4016322235e5422687997b6c942b8684",
       "IPY_MODEL_90efeff073a541e3ace582146fd5fd45"
      ],
      "layout": "IPY_MODEL_4da4cc126514421ebb1cd20eff5544f9"
     }
    },
    "0d0fbbe470054b0b879c1a62c411dc0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6efb365326c24c339085be28cc203fdc",
       "IPY_MODEL_df4976d8d7ec47e4986f5e9c0395c3a9",
       "IPY_MODEL_e249235d4bb14478a802d3fc362fe215"
      ],
      "layout": "IPY_MODEL_ea2f3d5138cb4d3eb4b5f50122c42634"
     }
    },
    "0e167716cc6941e2aaa5e85a476f1b1a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e6e63ccb1164deab11b438e7059d69f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0eae622975df4cfaaa2e54cde12fecc2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0f57c3f8ee4d42b3b02aba300b4fe271": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0fab8e8ae3fd4f47b43ee00df8a80deb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1191b9f6ca7e491c91a54648d9a95740": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d3e5436855af42a5b2f170b44388e4a8",
      "placeholder": "​",
      "style": "IPY_MODEL_195ac8d683264e9999a419b94e60bdc1",
      "value": " 438M/438M [00:02&lt;00:00, 233MB/s]"
     }
    },
    "11e9dc55ddd64166a23b389ef4115bc5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1257cd90321540d8b5530c35b672ac38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_890443b9c63d42b597b1fce37ed2612f",
      "placeholder": "​",
      "style": "IPY_MODEL_e7bc53149d98433785d628cd3783cbdb",
      "value": "tokenizer.json: 100%"
     }
    },
    "13c4cd250f4c49169902a77e3b76727c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b215c0274af9444c9265aa576d33f6d5",
      "placeholder": "​",
      "style": "IPY_MODEL_f46f3a7030a34d3894d97214fb03e1c2",
      "value": "vocab.txt: 100%"
     }
    },
    "183c14e615d6471c9fe4b9a56d13f85a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "195ac8d683264e9999a419b94e60bdc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1ad12046944a468297e3c982794251ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d5d56be1f3e4e06ad05b7a61c073773": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_37bbe9f296674040a1e4e6f414645aee",
      "placeholder": "​",
      "style": "IPY_MODEL_0567916024824a5cb153ee96ae90bcfd",
      "value": " 112/112 [00:00&lt;00:00, 6.75kB/s]"
     }
    },
    "1d9cc219294748d7a4d06a0ef220d034": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bfd5578f1cc3406b9b6e49540918dffd",
      "max": 190,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0fab8e8ae3fd4f47b43ee00df8a80deb",
      "value": 190
     }
    },
    "1efc8ad79138462e97c1bf5f00d8a210": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "200a894d245143b59503f70bbe099655": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e68e4e022b7946139920753c55012db2",
       "IPY_MODEL_1d9cc219294748d7a4d06a0ef220d034",
       "IPY_MODEL_61055f305b414a9995dd0093c8dd085b"
      ],
      "layout": "IPY_MODEL_6793b20c68004ef6806c0719d850ee07"
     }
    },
    "20619dd814a245cb96eed1ffd6d23793": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be42d78fa32c44f4ba983327b2f2b0ae",
      "max": 1633,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d696cc22200743caaaa0d70de5f29eaf",
      "value": 1633
     }
    },
    "234ab5cd38b14aec8426fcc28dfc4952": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "255d439785a54b9b8f37be9730c5b9f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25d444efba4c4f8ea2a15c4a197e83fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25ea5fce0d51425ca66647c86a69054d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_572f1df5c7904ccf939d45356997f7a7",
      "max": 112,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_abe064fd2d2943cc9658631022e7dfbe",
      "value": 112
     }
    },
    "26f3de4a37ed42c783b8cc8496a8830e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e5ff1078ea2d454ba88d92b978bee13f",
      "placeholder": "​",
      "style": "IPY_MODEL_97d0ee251daa487db840ba561a36d4a8",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "26f97033c9e5479da8dca6f7dc642ece": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45d616297f6d42fc89f2b28c6fc10c90",
      "placeholder": "​",
      "style": "IPY_MODEL_58bdc5e07c694b4f9fc4e6612c1de4c5",
      "value": " 219M/219M [00:01&lt;00:00, 174MB/s]"
     }
    },
    "2750e13775ad4cc5a1ca97abd23a7fa4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2c938e4d55734c248ffb292415aa5f5b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2d7b6a6ffb3849ec9828e24f4e193840": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f08477187154be899c3a1378e703260": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2f225874a7174aae9695b521d33eb563": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3088fb3c8cc74d7c97d9cbacc5b20c03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3332c9a35d2e40ac860233ebfb8c64c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34f2229c854f4695b5aba5d5afe772f5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "355092a75fa445ddb58c3c0e6c7c87f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "365523a881584181973972b7df86c3eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a1808fea5884186924c50c1d44cdb2b",
      "max": 466081,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6cb72ab4081a44fd8462b7d58da7236c",
      "value": 466081
     }
    },
    "37bbe9f296674040a1e4e6f414645aee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38344f64512b421aa12ac82fcf4b195d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "392ee34639024892a83a85f6878b60ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3a1808fea5884186924c50c1d44cdb2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e583707d8f7457bb3a5433440f3a6cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f54b0320e054ef4ab7cc33ca97ad75c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_13c4cd250f4c49169902a77e3b76727c",
       "IPY_MODEL_9100526f824f4e2298b22f43461c6daa",
       "IPY_MODEL_5e7028e3f8f6469086b2b94066dc9526"
      ],
      "layout": "IPY_MODEL_6901a356aa2c4361953ba9b44065710b"
     }
    },
    "4016322235e5422687997b6c942b8684": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea9b31c529f0482c99ac5ede1b0c2437",
      "max": 711661,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2f08477187154be899c3a1378e703260",
      "value": 711661
     }
    },
    "42c591eaee9f42f8ad965372898e3bdd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "45045e6a12e041e1b2b2713ff59ef938": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45c9710ebd6e45ddaa72f349380c5e16": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45d616297f6d42fc89f2b28c6fc10c90": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4663ab81441947f7bd1b86a08d82a6b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "46b7f140d4134097a8f6c7dd41d9acd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "47d8987c94434ddb89281035f30e9d4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45c9710ebd6e45ddaa72f349380c5e16",
      "placeholder": "​",
      "style": "IPY_MODEL_9defae4a31724cc1b6c0128b76bae404",
      "value": "config.json: 100%"
     }
    },
    "486f19f393194214820b2e4719793822": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6257ec67ee0043adab5a9e24a4f709a8",
      "placeholder": "​",
      "style": "IPY_MODEL_df62dad6b54444659f23d7cca3ddaa70",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "4977730998754c6d82831b47a647b428": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_761b0c7bec0f4ea98fff4469f3e147e1",
      "max": 57,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2f225874a7174aae9695b521d33eb563",
      "value": 57
     }
    },
    "4c7a193e4d3349dc8c2ff58c7137e77e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4da4cc126514421ebb1cd20eff5544f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e8321573083413d80d545eb711dabcb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5582c1c8145b4fe786ba967188680aa7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "572f1df5c7904ccf939d45356997f7a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58bdc5e07c694b4f9fc4e6612c1de4c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "58f1227b067740c99856d28d1b3535f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4c9a624ca3342adbdda81d0c505d540",
      "placeholder": "​",
      "style": "IPY_MODEL_7b9187f7562945ba813032f73d5fed96",
      "value": "modules.json: 100%"
     }
    },
    "5bf549707f604a99a4743166718cd720": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b524e9e4f75a45aba71a8a2b68557700",
      "placeholder": "​",
      "style": "IPY_MODEL_fdbe596b18164389a51d860b24f3b15b",
      "value": "README.md: 100%"
     }
    },
    "5de0a6a267a24518ac2857b47c4d2d4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e7028e3f8f6469086b2b94066dc9526": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_11e9dc55ddd64166a23b389ef4115bc5",
      "placeholder": "​",
      "style": "IPY_MODEL_090fd1cdc0694112b57d28e833932350",
      "value": " 232k/232k [00:00&lt;00:00, 1.78MB/s]"
     }
    },
    "5e9df76d9eb04c3cacc9caf4edacb913": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_25d444efba4c4f8ea2a15c4a197e83fa",
      "placeholder": "​",
      "style": "IPY_MODEL_fa2721e59a714068a0a5918cd7ec3246",
      "value": "model.safetensors: 100%"
     }
    },
    "5fca46bd83bd4f95ae25eecf342ff20f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc979bda6f3c486e8108945371fee26e",
      "placeholder": "​",
      "style": "IPY_MODEL_5de0a6a267a24518ac2857b47c4d2d4e",
      "value": " 743/743 [00:00&lt;00:00, 31.0kB/s]"
     }
    },
    "6023241ffbf740ec871828d6276cccb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d9d79532e89447e1ae295ea296d33dbf",
      "placeholder": "​",
      "style": "IPY_MODEL_4663ab81441947f7bd1b86a08d82a6b2",
      "value": " 466k/466k [00:00&lt;00:00, 2.32MB/s]"
     }
    },
    "61055f305b414a9995dd0093c8dd085b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4388ee32ed9434ea5e756c22fb61002",
      "placeholder": "​",
      "style": "IPY_MODEL_eac3132f4d9349cfa6f1422686ae7bd5",
      "value": " 190/190 [00:00&lt;00:00, 11.7kB/s]"
     }
    },
    "6257ec67ee0043adab5a9e24a4f709a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "63a47d5282db441a8e5732ab3266af33": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65617f6c0a3f40f1bb7198eadb9757da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6584fa0193f0433ead447e60d2c82607": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_47d8987c94434ddb89281035f30e9d4f",
       "IPY_MODEL_cf1bd11c82b44b99ac40e8abbec3785f",
       "IPY_MODEL_7e069a6942cb4cb09ef6aa3661844f88"
      ],
      "layout": "IPY_MODEL_7e0b008fb7294404a73b8341c1230125"
     }
    },
    "666d42ef1a74402fb13ea79db36c1287": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "66b76f1f830445e98fb9c1acc1683cde": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aee8fac5931844c5a88f651e7f854362",
      "max": 218990904,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e39705238d474d5a99f0a49832b408ed",
      "value": 218990904
     }
    },
    "6793b20c68004ef6806c0719d850ee07": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6901a356aa2c4361953ba9b44065710b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6aaf81405fa24b0e93a858d609b85036": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e04af96adae41a6b05ecc7bfe5a9fd9",
      "placeholder": "​",
      "style": "IPY_MODEL_b13c2b7166784d0f8d8a1ee231fe3235",
      "value": "sentence_bert_config.json: 100%"
     }
    },
    "6cb72ab4081a44fd8462b7d58da7236c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6da0a949eaf1499094fa4e264e1929ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6efb365326c24c339085be28cc203fdc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0bce7925eb1f4323a482bb90467bbc66",
      "placeholder": "​",
      "style": "IPY_MODEL_392ee34639024892a83a85f6878b60ef",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "6f038781e3a5498a9823999548de18fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1efc8ad79138462e97c1bf5f00d8a210",
      "placeholder": "​",
      "style": "IPY_MODEL_4e8321573083413d80d545eb711dabcb",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "718e83bf80b74bbb9e28a9a2473ab8db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "72f6e2507a5c49338610f22446087687": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_784f6571b15c4ac19ca2e1b1a913f318",
      "placeholder": "​",
      "style": "IPY_MODEL_42c591eaee9f42f8ad965372898e3bdd",
      "value": " 385/385 [00:00&lt;00:00, 26.4kB/s]"
     }
    },
    "755d31fc51614b78a6798a1f45d66a29": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "761b0c7bec0f4ea98fff4469f3e147e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "784f6571b15c4ac19ca2e1b1a913f318": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a550bf2dc964d0caafc8aed54d187a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5bf549707f604a99a4743166718cd720",
       "IPY_MODEL_bac9a59f6a1244d8a6e37795e0383e30",
       "IPY_MODEL_a113bb38b1f7458cae5e7825d6a65b3c"
      ],
      "layout": "IPY_MODEL_cda8adeebae9484c9399422c870aa7cf"
     }
    },
    "7a6d685007704814a51a027b060ba1b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b599c45a81df44619d92a3ac8ad41b0f",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c2cf8f815146436e86373dd6f02e94aa",
      "value": 231508
     }
    },
    "7b70f0bd5409433e93719cd05441e473": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_83665867accd4853b6efe68a06f7f403",
       "IPY_MODEL_66b76f1f830445e98fb9c1acc1683cde",
       "IPY_MODEL_26f97033c9e5479da8dca6f7dc642ece"
      ],
      "layout": "IPY_MODEL_6da0a949eaf1499094fa4e264e1929ca"
     }
    },
    "7b9187f7562945ba813032f73d5fed96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7e04af96adae41a6b05ecc7bfe5a9fd9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e069a6942cb4cb09ef6aa3661844f88": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f5553c33eefd47eea49e0e3901bf51f5",
      "placeholder": "​",
      "style": "IPY_MODEL_fc2843b06e0f4b6ca2a7d1d5fcde23d6",
      "value": " 618/618 [00:00&lt;00:00, 56.6kB/s]"
     }
    },
    "7e0b008fb7294404a73b8341c1230125": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "800014039af04d66adc94131a8ab568e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f741891d16434e959971b6331ab7a09e",
       "IPY_MODEL_20619dd814a245cb96eed1ffd6d23793",
       "IPY_MODEL_f91289ae253446ed90b7c9260d85ac2c"
      ],
      "layout": "IPY_MODEL_3088fb3c8cc74d7c97d9cbacc5b20c03"
     }
    },
    "8041af99466c478ab32dcb07ff597d41": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8110d80f4fe94d499834b799c85667ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca2e4e27247949fd96c09ca0084eb8d5",
      "max": 125,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ab3716a57cb1461ca4b89d3e2af60aa1",
      "value": 125
     }
    },
    "82baa3fb82e24827b49b6bda22f72d78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c938e4d55734c248ffb292415aa5f5b",
      "max": 405,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5582c1c8145b4fe786ba967188680aa7",
      "value": 405
     }
    },
    "83665867accd4853b6efe68a06f7f403": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b946716322e43bb9f4213087c6ee1de",
      "placeholder": "​",
      "style": "IPY_MODEL_c3cb074231f84c169f31afa3baf84fc9",
      "value": "model.safetensors: 100%"
     }
    },
    "836f49316d114d37846143df795ba15a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "863ed2e3ac1e4670b7850cf4deafc867": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "890443b9c63d42b597b1fce37ed2612f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cd319e80b28462698e8adb196302802": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_255d439785a54b9b8f37be9730c5b9f9",
      "placeholder": "​",
      "style": "IPY_MODEL_e3ea567b814a4d949a018e39137923fd",
      "value": "tokenizer.json: 100%"
     }
    },
    "8d567a74de4843a4b50292512c7d0ebe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90efeff073a541e3ace582146fd5fd45": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_183c14e615d6471c9fe4b9a56d13f85a",
      "placeholder": "​",
      "style": "IPY_MODEL_e15406eedc3b4b10b5d8c32d2ba5f1cd",
      "value": " 712k/712k [00:00&lt;00:00, 3.68MB/s]"
     }
    },
    "9100526f824f4e2298b22f43461c6daa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_34f2229c854f4695b5aba5d5afe772f5",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_38344f64512b421aa12ac82fcf4b195d",
      "value": 231508
     }
    },
    "91b7390bb1d94bd6be84496ed73052ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9553bb69e7c5479ebbf73787d3fc8b14": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9561e20747684a1a878a637d00c946fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b5cfff7bf253443682d8051953740ad2",
       "IPY_MODEL_d2b20654e6aa49359b678e198cc55a73",
       "IPY_MODEL_5fca46bd83bd4f95ae25eecf342ff20f"
      ],
      "layout": "IPY_MODEL_63a47d5282db441a8e5732ab3266af33"
     }
    },
    "97d0ee251daa487db840ba561a36d4a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b8ebc99d0ed4d9fb6f873f06a638318": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ce3da5248a34146945e40a660ed455d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9dc189ff36034264b081ca782c0bc1ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0e167716cc6941e2aaa5e85a476f1b1a",
      "placeholder": "​",
      "style": "IPY_MODEL_9ce3da5248a34146945e40a660ed455d",
      "value": " 57.0/57.0 [00:00&lt;00:00, 4.50kB/s]"
     }
    },
    "9defae4a31724cc1b6c0128b76bae404": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a113bb38b1f7458cae5e7825d6a65b3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ad12046944a468297e3c982794251ef",
      "placeholder": "​",
      "style": "IPY_MODEL_c0d3f59319544daa858e76bf490ac735",
      "value": " 68.1k/68.1k [00:00&lt;00:00, 4.12MB/s]"
     }
    },
    "a2c29ede70564d5b879b4084453d753f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b5693df9d1cf458e9c7dabfba2331102",
      "placeholder": "​",
      "style": "IPY_MODEL_4c7a193e4d3349dc8c2ff58c7137e77e",
      "value": " 405/405 [00:00&lt;00:00, 24.3kB/s]"
     }
    },
    "a68946ee535e4693955f8292b47c5b6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_755d31fc51614b78a6798a1f45d66a29",
      "max": 385,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_46b7f140d4134097a8f6c7dd41d9acd3",
      "value": 385
     }
    },
    "a77de46019434b2182d8ace90729411d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ab3716a57cb1461ca4b89d3e2af60aa1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "abe064fd2d2943cc9658631022e7dfbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "aee8fac5931844c5a88f651e7f854362": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b02abbcd98d94732961735247946d2d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b106e671bf2040ff85286339391cacce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b13c2b7166784d0f8d8a1ee231fe3235": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b14e572db35545c58c413b5313c230d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_26f3de4a37ed42c783b8cc8496a8830e",
       "IPY_MODEL_25ea5fce0d51425ca66647c86a69054d",
       "IPY_MODEL_1d5d56be1f3e4e06ad05b7a61c073773"
      ],
      "layout": "IPY_MODEL_0e6e63ccb1164deab11b438e7059d69f"
     }
    },
    "b215c0274af9444c9265aa576d33f6d5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b524e9e4f75a45aba71a8a2b68557700": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b5693df9d1cf458e9c7dabfba2331102": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b599c45a81df44619d92a3ac8ad41b0f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b5cfff7bf253443682d8051953740ad2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8d567a74de4843a4b50292512c7d0ebe",
      "placeholder": "​",
      "style": "IPY_MODEL_e4710695ec874eada402065fe800edd5",
      "value": "config.json: 100%"
     }
    },
    "b8d486c46bbc4a6abdb3b0af3dbc4c04": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ba96d1c92aeb4a9584f700869c028ace": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bac9a59f6a1244d8a6e37795e0383e30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e55c826128994d0a8b67885f40574fae",
      "max": 68075,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_836f49316d114d37846143df795ba15a",
      "value": 68075
     }
    },
    "bb8b2e9c41ea45dfa6fe7dff8a934fa2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be42d78fa32c44f4ba983327b2f2b0ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bfd5578f1cc3406b9b6e49540918dffd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0d3f59319544daa858e76bf490ac735": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c1225405706548aa86f466345ba78795": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f9124d67aef64019a437baa8eef8e54e",
       "IPY_MODEL_7a6d685007704814a51a027b060ba1b0",
       "IPY_MODEL_c87f3b6818934457af1827e01f4924ba"
      ],
      "layout": "IPY_MODEL_cfab7d69b2634082805f101090dcbd04"
     }
    },
    "c28b40c65c1f450988dfb834ccbf1526": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1257cd90321540d8b5530c35b672ac38",
       "IPY_MODEL_365523a881584181973972b7df86c3eb",
       "IPY_MODEL_6023241ffbf740ec871828d6276cccb8"
      ],
      "layout": "IPY_MODEL_863ed2e3ac1e4670b7850cf4deafc867"
     }
    },
    "c2cf8f815146436e86373dd6f02e94aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c3cb074231f84c169f31afa3baf84fc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c87f3b6818934457af1827e01f4924ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b02abbcd98d94732961735247946d2d4",
      "placeholder": "​",
      "style": "IPY_MODEL_666d42ef1a74402fb13ea79db36c1287",
      "value": " 232k/232k [00:00&lt;00:00, 3.33MB/s]"
     }
    },
    "c8c4de2dd87b409ab14e3bbd4f8ff777": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ca2e4e27247949fd96c09ca0084eb8d5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb37e6988db144ac9e6b615b71705c3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_58f1227b067740c99856d28d1b3535f0",
       "IPY_MODEL_a68946ee535e4693955f8292b47c5b6c",
       "IPY_MODEL_72f6e2507a5c49338610f22446087687"
      ],
      "layout": "IPY_MODEL_f7afe5336f9645bbaa3da495dad04c6f"
     }
    },
    "cda8adeebae9484c9399422c870aa7cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf1bd11c82b44b99ac40e8abbec3785f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3332c9a35d2e40ac860233ebfb8c64c7",
      "max": 618,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e0686b63c9374bcda05c70aeffbcda03",
      "value": 618
     }
    },
    "cfab7d69b2634082805f101090dcbd04": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2b20654e6aa49359b678e198cc55a73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b8ebc99d0ed4d9fb6f873f06a638318",
      "max": 743,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2750e13775ad4cc5a1ca97abd23a7fa4",
      "value": 743
     }
    },
    "d3e5436855af42a5b2f170b44388e4a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d696cc22200743caaaa0d70de5f29eaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d9d79532e89447e1ae295ea296d33dbf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df4976d8d7ec47e4986f5e9c0395c3a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ba96d1c92aeb4a9584f700869c028ace",
      "max": 314,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c8c4de2dd87b409ab14e3bbd4f8ff777",
      "value": 314
     }
    },
    "df62dad6b54444659f23d7cca3ddaa70": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e0686b63c9374bcda05c70aeffbcda03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e15406eedc3b4b10b5d8c32d2ba5f1cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e249235d4bb14478a802d3fc362fe215": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_355092a75fa445ddb58c3c0e6c7c87f7",
      "placeholder": "​",
      "style": "IPY_MODEL_a77de46019434b2182d8ace90729411d",
      "value": " 314/314 [00:00&lt;00:00, 15.5kB/s]"
     }
    },
    "e39705238d474d5a99f0a49832b408ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e3ea567b814a4d949a018e39137923fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e4710695ec874eada402065fe800edd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e55c826128994d0a8b67885f40574fae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5ff1078ea2d454ba88d92b978bee13f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e68e4e022b7946139920753c55012db2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45045e6a12e041e1b2b2713ff59ef938",
      "placeholder": "​",
      "style": "IPY_MODEL_0f57c3f8ee4d42b3b02aba300b4fe271",
      "value": "1_Pooling/config.json: 100%"
     }
    },
    "e7096ed061374902935f3363540caa56": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7816626014f47fbb744f707990f3c0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e7096ed061374902935f3363540caa56",
      "placeholder": "​",
      "style": "IPY_MODEL_3e583707d8f7457bb3a5433440f3a6cb",
      "value": " 125/125 [00:00&lt;00:00, 7.81kB/s]"
     }
    },
    "e7bc53149d98433785d628cd3783cbdb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ea2f3d5138cb4d3eb4b5f50122c42634": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea9b31c529f0482c99ac5ede1b0c2437": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eac3132f4d9349cfa6f1422686ae7bd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec25bd06a00e4e2cab1b9f62905449ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f4388ee32ed9434ea5e756c22fb61002": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f46f3a7030a34d3894d97214fb03e1c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f4c9a624ca3342adbdda81d0c505d540": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5553c33eefd47eea49e0e3901bf51f5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f741891d16434e959971b6331ab7a09e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_234ab5cd38b14aec8426fcc28dfc4952",
      "placeholder": "​",
      "style": "IPY_MODEL_b8d486c46bbc4a6abdb3b0af3dbc4c04",
      "value": "artifact.metadata: 100%"
     }
    },
    "f7afe5336f9645bbaa3da495dad04c6f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f82609221b714ae58214a6f6745526b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6f038781e3a5498a9823999548de18fd",
       "IPY_MODEL_8110d80f4fe94d499834b799c85667ad",
       "IPY_MODEL_e7816626014f47fbb744f707990f3c0b"
      ],
      "layout": "IPY_MODEL_65617f6c0a3f40f1bb7198eadb9757da"
     }
    },
    "f8c3f5363e824e338cf4b7ea0f09b92a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6aaf81405fa24b0e93a858d609b85036",
       "IPY_MODEL_4977730998754c6d82831b47a647b428",
       "IPY_MODEL_9dc189ff36034264b081ca782c0bc1ed"
      ],
      "layout": "IPY_MODEL_91b7390bb1d94bd6be84496ed73052ee"
     }
    },
    "f9124d67aef64019a437baa8eef8e54e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9553bb69e7c5479ebbf73787d3fc8b14",
      "placeholder": "​",
      "style": "IPY_MODEL_0eae622975df4cfaaa2e54cde12fecc2",
      "value": "vocab.txt: 100%"
     }
    },
    "f91289ae253446ed90b7c9260d85ac2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d7b6a6ffb3849ec9828e24f4e193840",
      "placeholder": "​",
      "style": "IPY_MODEL_718e83bf80b74bbb9e28a9a2473ab8db",
      "value": " 1.63k/1.63k [00:00&lt;00:00, 59.6kB/s]"
     }
    },
    "fa2721e59a714068a0a5918cd7ec3246": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fc2843b06e0f4b6ca2a7d1d5fcde23d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fc6ba90ca08747e1bace0a55d1eeed55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5e9df76d9eb04c3cacc9caf4edacb913",
       "IPY_MODEL_091d085339a14a0ab5a23a60b24508f6",
       "IPY_MODEL_1191b9f6ca7e491c91a54648d9a95740"
      ],
      "layout": "IPY_MODEL_b106e671bf2040ff85286339391cacce"
     }
    },
    "fc979bda6f3c486e8108945371fee26e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fdbe596b18164389a51d860b24f3b15b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
