{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.read_csv('../data/paper_logs/combined_json_data.csv')\n",
    "# display(info.head(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['profName', 'authorId', 'authorName', 'authorUrl', 'authorHIndex',\n",
      "       'authorAffiliations', 'authorPaperCount', 'authorCitationCount',\n",
      "       'paperId', 'externalIds', 'url', 'title', 'abstract', 'venue', 'year',\n",
      "       'referenceCount', 'citationCount', 'influentialCitationCount',\n",
      "       'isOpenAccess', 'openAccessPdf', 'fieldsOfStudy', 'journal', 'authors',\n",
      "       'tldr'],\n",
      "      dtype='object')\n",
      "Index(['paperId', 'title', 'profName'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(info.columns)\n",
    "\n",
    "cols_to_keep = ['paperId', 'title', 'profName']\n",
    "\n",
    "info = info[cols_to_keep]\n",
    "\n",
    "print(info.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperId</th>\n",
       "      <th>title</th>\n",
       "      <th>profName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2107b867cb8f8afa30a9a940288d7c8b657f8aa5</td>\n",
       "      <td>Zero-Shot and Few-Shot Stance Detection on Var...</td>\n",
       "      <td>Alexander Hauptmann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>376f494126d1ea4f571ea0263c43ac2b6331800a</td>\n",
       "      <td>SPAE: Semantic Pyramid AutoEncoder for Multimo...</td>\n",
       "      <td>Alexander Hauptmann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>405e3910e06c9efe7e660b8697bcb4bab4e92f48</td>\n",
       "      <td>STMT: A Spatial-Temporal Mesh Transformer for ...</td>\n",
       "      <td>Alexander Hauptmann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8ccda6de0223bcd897d5dc0efc8f33222a899d0d</td>\n",
       "      <td>DocumentNet: Bridging the Data Gap in Document...</td>\n",
       "      <td>Alexander Hauptmann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10127fa44054eb985ede206113b96aac3a96fd80</td>\n",
       "      <td>The Inside Story: Towards Better Understanding...</td>\n",
       "      <td>Alon Lavie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5579d38636b898c6a67ad67a16a80dd83be0f8d4</td>\n",
       "      <td>Towards Multilingual Automatic Dialogue Evalua...</td>\n",
       "      <td>Alon Lavie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5c920b2326282d93ad2ac3d1cb8f746bd7ab6f50</td>\n",
       "      <td>Results of WMT23 Metrics Shared Task: Metrics ...</td>\n",
       "      <td>Alon Lavie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9364720b2ab9ac67bc08e2b0b49aadded3d4e2e5</td>\n",
       "      <td>Appropriateness is all you need!</td>\n",
       "      <td>Alon Lavie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9e8f125ef479af7e95ee5b8949b24e750c7df367</td>\n",
       "      <td>Towards Multilingual Automatic Open-Domain Dia...</td>\n",
       "      <td>Alon Lavie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bcefc74b20649fd41ea05d87a3fa512d2559fc8d</td>\n",
       "      <td>Simple LLM Prompting is State-of-the-Art for R...</td>\n",
       "      <td>Alon Lavie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>161bf3f0705ef8e088f53b383363338daac9af44</td>\n",
       "      <td>Latent Positional Information is in the Self-A...</td>\n",
       "      <td>Alexander Rudnicky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>465ec2212d865e875e64638b3dd1ecaac21c5ddd</td>\n",
       "      <td>Transformer Working Memory Enables Regular Lan...</td>\n",
       "      <td>Alexander Rudnicky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100eb82862a66e264686d015934c97c54bdadb4f</td>\n",
       "      <td>SYNTACC : Synthesizing Multi-Accent Speech By ...</td>\n",
       "      <td>Alexander Waibel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>610d9958390ab83515d0d81e19f8e5264faf8e9b</td>\n",
       "      <td>KIT’s Multilingual Speech Translation System f...</td>\n",
       "      <td>Alexander Waibel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7e13fcb7b7bae202fb9087e87abaa71a4b19a3e3</td>\n",
       "      <td>Convoifilter: A case study of doing cocktail p...</td>\n",
       "      <td>Alexander Waibel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>d24d60719e90e69749a75c160cb760d1d9fca44a</td>\n",
       "      <td>Incremental Blockwise Beam Search for Simultan...</td>\n",
       "      <td>Alexander Waibel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>f524f119afc13cc07ca15998c10b9509e9e9b0b5</td>\n",
       "      <td>End-to-End Evaluation for Low-Latency Simultan...</td>\n",
       "      <td>Alexander Waibel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>f7e995c3cae465963ecaa8c9b4ce8b9b4323a71b</td>\n",
       "      <td>FINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN</td>\n",
       "      <td>Alexander Waibel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>aab2ed83bc3739a20e90ae1d97dcf45f3bc8e508</td>\n",
       "      <td>AdapITN: A Fast, Reliable, and Dynamic Adaptiv...</td>\n",
       "      <td>Alexander Waibel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>f3e237e794bc4cd8df7f3e31d0caa2f7ee8cd06b</td>\n",
       "      <td>Train Global, Tailor Local: Minimalist Multili...</td>\n",
       "      <td>Alexander Waibel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>f547c7ec86cbc0989e87f0e23f7e0b2cfc5259c3</td>\n",
       "      <td>Towards Efficient Simultaneous Speech Translat...</td>\n",
       "      <td>Alexander Waibel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>72cce47fd053bf916314d89a8174726c58c05e02</td>\n",
       "      <td>Towards Open-Domain Twitter User Profile Infer...</td>\n",
       "      <td>Alexander Hauptmann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>06a8f2e3c4266196b008851f1ec7ef9f340809da</td>\n",
       "      <td>Advancing Regular Language Reasoning in Linear...</td>\n",
       "      <td>Alexander Rudnicky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2670612b5e11297cd9b98f4d7ff796725f77fe35</td>\n",
       "      <td>Structured Dialogue Discourse Parsing</td>\n",
       "      <td>Alexander Rudnicky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4b8d3ede673ddeab9dfb5184da6b748d7a526754</td>\n",
       "      <td>A Vector Quantized Approach for Text to Speech...</td>\n",
       "      <td>Alexander Rudnicky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9799c17fd287bb9e8d231fe032c6dbf9c0c9d675</td>\n",
       "      <td>Overview of Robust and Multilingual Automatic ...</td>\n",
       "      <td>Alexander Rudnicky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>f743324682d5d50db9b114fa60b908f09c10c9a0</td>\n",
       "      <td>Learning to Ask Questions for Zero-shot Dialog...</td>\n",
       "      <td>Alexander Rudnicky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>02a626bd8538ecb675bd2bcd8f5985274e965d00</td>\n",
       "      <td>Assessment and Therapy Goal Planning Using Fre...</td>\n",
       "      <td>Brian MacWhinney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0773228ecc4c1f2d729c0ae5764c77c1c9bb9573</td>\n",
       "      <td>Automation of Language Sample Analysis</td>\n",
       "      <td>Brian MacWhinney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>283dbaa4da4beafa5e5719095bcc88e63d17815e</td>\n",
       "      <td>The role of novelty stimuli in second language...</td>\n",
       "      <td>Brian MacWhinney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3859f18277f0c5876a53411b07f80d65254c52e5</td>\n",
       "      <td>Using diagnostic feedback to enhance the devel...</td>\n",
       "      <td>Brian MacWhinney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4d35540aaf993c8fa7e1fa5fc6a990f1eb830263</td>\n",
       "      <td>A New Benchmark of Aphasia Speech Recognition ...</td>\n",
       "      <td>Brian MacWhinney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>52b48ab5d7d87642395818bea1ff804ff6dd0bd3</td>\n",
       "      <td>Collaborative Commentary for Understanding Com...</td>\n",
       "      <td>Brian MacWhinney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>cf152ac1b3c9daea5b48f858acc13193a83df185</td>\n",
       "      <td>Establishing the DementiaBank Delaware Corpus:...</td>\n",
       "      <td>Brian MacWhinney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>d898963243ad4b177b799f197a7732395e165cf6</td>\n",
       "      <td>Evaluating Picture Description Speech for Deme...</td>\n",
       "      <td>Brian MacWhinney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>f1ebdd8c99aa33284e3604c28b72efa9dc46047c</td>\n",
       "      <td>Multilingual Alzheimer’s Dementia Recognition ...</td>\n",
       "      <td>Brian MacWhinney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>f7254ae607056ba5522c10dbcf21b394967b6d42</td>\n",
       "      <td>DementiaBank: Theoretical Rationale, Protocol,...</td>\n",
       "      <td>Brian MacWhinney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>078f86c6a691806cc71bbef1e734f75690db0ffc</td>\n",
       "      <td>FREDOM: Fairness Domain Adaptation Approach to...</td>\n",
       "      <td>Bhiksha Raj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0a8d38686b18f28aae1222529e6b9e8a60cab1c2</td>\n",
       "      <td>UTOPIA: Unconstrained Tracking Objects without...</td>\n",
       "      <td>Bhiksha Raj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>100da279ee981960884a12dfc5a0697c24ed315a</td>\n",
       "      <td>SoftMatch: Addressing the Quantity-Quality Tra...</td>\n",
       "      <td>Bhiksha Raj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>11c50900f50036fb3247be7c83849a8774a4ba60</td>\n",
       "      <td>Fixed Inter-Neuron Covariability Induces Adver...</td>\n",
       "      <td>Bhiksha Raj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>22c9eb4868c5cabb26d132e0a160b9a093579f08</td>\n",
       "      <td>Understanding political polarization using lan...</td>\n",
       "      <td>Bhiksha Raj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>35a8802facb4441787017ac5c630a8fa0f2413bd</td>\n",
       "      <td>Prolonged school closure during the pandemic t...</td>\n",
       "      <td>Bhiksha Raj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3bd320ddb25886417ae90011b00f13f5d558097b</td>\n",
       "      <td>BASS: Block-wise Adaptation for Speech Summari...</td>\n",
       "      <td>Bhiksha Raj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4e6a004e4f9a3b489004a2efb5b25b0bcd0f48b5</td>\n",
       "      <td>Understanding Political Polarisation using Lan...</td>\n",
       "      <td>Bhiksha Raj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>593a603354c09d151440ae044de1d80324a2ab01</td>\n",
       "      <td>An Approach to Ontological Learning from Weak ...</td>\n",
       "      <td>Bhiksha Raj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5a3307b2e64bbcaff1202e261b8a83f7d03418a8</td>\n",
       "      <td>Rethinking Voice-Face Correlation: A Geometry ...</td>\n",
       "      <td>Bhiksha Raj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>611f9ee6eef0936462cd78f371798d0699951c59</td>\n",
       "      <td>Paaploss: A Phonetic-Aligned Acoustic Paramete...</td>\n",
       "      <td>Bhiksha Raj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>7333be530df311b3148e9857ce9f481975cf0a9b</td>\n",
       "      <td>Improving Perceptual Quality, Intelligibility,...</td>\n",
       "      <td>Bhiksha Raj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>740488982dee323d559f2dae70b1f4b3aa5f7171</td>\n",
       "      <td>Approach to Learning Generalized Audio Represe...</td>\n",
       "      <td>Bhiksha Raj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>74664618ad3b44eb191ba96fdff5b93f27a29ced</td>\n",
       "      <td>Training on Foveated Images Improves Robustnes...</td>\n",
       "      <td>Bhiksha Raj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>8665c864d71df1e918d2010778fc06712f4e5550</td>\n",
       "      <td>Imprecise Label Learning: A Unified Framework ...</td>\n",
       "      <td>Bhiksha Raj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>a6e3a10a6286967413e3406374bbeea533640030</td>\n",
       "      <td>The Hidden Dance of Phonemes and Visage: Unvei...</td>\n",
       "      <td>Bhiksha Raj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>ac856b6b7b3f32fb34320b7170526d3ab15ba5f3</td>\n",
       "      <td>Fairness Continual Learning Approach to Semant...</td>\n",
       "      <td>Bhiksha Raj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>dc157eba8bdb4cfe6ee65566d8295939ac5b4b37</td>\n",
       "      <td>PaintSeg: Training-free Segmentation via Painting</td>\n",
       "      <td>Bhiksha Raj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>e146e5221c124d93f69516c5ae7e1b7b1822848e</td>\n",
       "      <td>TAPLoss: A Temporal Acoustic Parameter Loss fo...</td>\n",
       "      <td>Bhiksha Raj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>feecd2cfb7871a818ba514e8b4b3f9da482f17bc</td>\n",
       "      <td>Synergy between human and machine approaches t...</td>\n",
       "      <td>Bhiksha Raj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>06dc7b3d8cbc40fb4e39b42de1bc664deaacca74</td>\n",
       "      <td>High school students’ data modeling practices ...</td>\n",
       "      <td>Carolyn Rose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0c0d8ea1c1745e7b56bc3b1513a715ae3df30c44</td>\n",
       "      <td>Linguistic representations for fewer-shot rela...</td>\n",
       "      <td>Carolyn Rose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>117e1323677cb5d78ece0fd07b5cfa81618f4866</td>\n",
       "      <td>Using counterfactual contrast to improve compo...</td>\n",
       "      <td>Carolyn Rose</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     paperId  \\\n",
       "0   2107b867cb8f8afa30a9a940288d7c8b657f8aa5   \n",
       "1   376f494126d1ea4f571ea0263c43ac2b6331800a   \n",
       "2   405e3910e06c9efe7e660b8697bcb4bab4e92f48   \n",
       "3   8ccda6de0223bcd897d5dc0efc8f33222a899d0d   \n",
       "4   10127fa44054eb985ede206113b96aac3a96fd80   \n",
       "5   5579d38636b898c6a67ad67a16a80dd83be0f8d4   \n",
       "6   5c920b2326282d93ad2ac3d1cb8f746bd7ab6f50   \n",
       "7   9364720b2ab9ac67bc08e2b0b49aadded3d4e2e5   \n",
       "8   9e8f125ef479af7e95ee5b8949b24e750c7df367   \n",
       "9   bcefc74b20649fd41ea05d87a3fa512d2559fc8d   \n",
       "10  161bf3f0705ef8e088f53b383363338daac9af44   \n",
       "11  465ec2212d865e875e64638b3dd1ecaac21c5ddd   \n",
       "12  100eb82862a66e264686d015934c97c54bdadb4f   \n",
       "13  610d9958390ab83515d0d81e19f8e5264faf8e9b   \n",
       "14  7e13fcb7b7bae202fb9087e87abaa71a4b19a3e3   \n",
       "15  d24d60719e90e69749a75c160cb760d1d9fca44a   \n",
       "16  f524f119afc13cc07ca15998c10b9509e9e9b0b5   \n",
       "17  f7e995c3cae465963ecaa8c9b4ce8b9b4323a71b   \n",
       "18  aab2ed83bc3739a20e90ae1d97dcf45f3bc8e508   \n",
       "19  f3e237e794bc4cd8df7f3e31d0caa2f7ee8cd06b   \n",
       "20  f547c7ec86cbc0989e87f0e23f7e0b2cfc5259c3   \n",
       "21  72cce47fd053bf916314d89a8174726c58c05e02   \n",
       "22  06a8f2e3c4266196b008851f1ec7ef9f340809da   \n",
       "23  2670612b5e11297cd9b98f4d7ff796725f77fe35   \n",
       "24  4b8d3ede673ddeab9dfb5184da6b748d7a526754   \n",
       "25  9799c17fd287bb9e8d231fe032c6dbf9c0c9d675   \n",
       "26  f743324682d5d50db9b114fa60b908f09c10c9a0   \n",
       "27  02a626bd8538ecb675bd2bcd8f5985274e965d00   \n",
       "28  0773228ecc4c1f2d729c0ae5764c77c1c9bb9573   \n",
       "29  283dbaa4da4beafa5e5719095bcc88e63d17815e   \n",
       "30  3859f18277f0c5876a53411b07f80d65254c52e5   \n",
       "31  4d35540aaf993c8fa7e1fa5fc6a990f1eb830263   \n",
       "32  52b48ab5d7d87642395818bea1ff804ff6dd0bd3   \n",
       "33  cf152ac1b3c9daea5b48f858acc13193a83df185   \n",
       "34  d898963243ad4b177b799f197a7732395e165cf6   \n",
       "35  f1ebdd8c99aa33284e3604c28b72efa9dc46047c   \n",
       "36  f7254ae607056ba5522c10dbcf21b394967b6d42   \n",
       "37  078f86c6a691806cc71bbef1e734f75690db0ffc   \n",
       "38  0a8d38686b18f28aae1222529e6b9e8a60cab1c2   \n",
       "39  100da279ee981960884a12dfc5a0697c24ed315a   \n",
       "40  11c50900f50036fb3247be7c83849a8774a4ba60   \n",
       "41  22c9eb4868c5cabb26d132e0a160b9a093579f08   \n",
       "42  35a8802facb4441787017ac5c630a8fa0f2413bd   \n",
       "43  3bd320ddb25886417ae90011b00f13f5d558097b   \n",
       "44  4e6a004e4f9a3b489004a2efb5b25b0bcd0f48b5   \n",
       "45  593a603354c09d151440ae044de1d80324a2ab01   \n",
       "46  5a3307b2e64bbcaff1202e261b8a83f7d03418a8   \n",
       "47  611f9ee6eef0936462cd78f371798d0699951c59   \n",
       "48  7333be530df311b3148e9857ce9f481975cf0a9b   \n",
       "49  740488982dee323d559f2dae70b1f4b3aa5f7171   \n",
       "50  74664618ad3b44eb191ba96fdff5b93f27a29ced   \n",
       "51  8665c864d71df1e918d2010778fc06712f4e5550   \n",
       "52  a6e3a10a6286967413e3406374bbeea533640030   \n",
       "53  ac856b6b7b3f32fb34320b7170526d3ab15ba5f3   \n",
       "54  dc157eba8bdb4cfe6ee65566d8295939ac5b4b37   \n",
       "55  e146e5221c124d93f69516c5ae7e1b7b1822848e   \n",
       "56  feecd2cfb7871a818ba514e8b4b3f9da482f17bc   \n",
       "57  06dc7b3d8cbc40fb4e39b42de1bc664deaacca74   \n",
       "58  0c0d8ea1c1745e7b56bc3b1513a715ae3df30c44   \n",
       "59  117e1323677cb5d78ece0fd07b5cfa81618f4866   \n",
       "\n",
       "                                                title             profName  \n",
       "0   Zero-Shot and Few-Shot Stance Detection on Var...  Alexander Hauptmann  \n",
       "1   SPAE: Semantic Pyramid AutoEncoder for Multimo...  Alexander Hauptmann  \n",
       "2   STMT: A Spatial-Temporal Mesh Transformer for ...  Alexander Hauptmann  \n",
       "3   DocumentNet: Bridging the Data Gap in Document...  Alexander Hauptmann  \n",
       "4   The Inside Story: Towards Better Understanding...           Alon Lavie  \n",
       "5   Towards Multilingual Automatic Dialogue Evalua...           Alon Lavie  \n",
       "6   Results of WMT23 Metrics Shared Task: Metrics ...           Alon Lavie  \n",
       "7                    Appropriateness is all you need!           Alon Lavie  \n",
       "8   Towards Multilingual Automatic Open-Domain Dia...           Alon Lavie  \n",
       "9   Simple LLM Prompting is State-of-the-Art for R...           Alon Lavie  \n",
       "10  Latent Positional Information is in the Self-A...   Alexander Rudnicky  \n",
       "11  Transformer Working Memory Enables Regular Lan...   Alexander Rudnicky  \n",
       "12  SYNTACC : Synthesizing Multi-Accent Speech By ...     Alexander Waibel  \n",
       "13  KIT’s Multilingual Speech Translation System f...     Alexander Waibel  \n",
       "14  Convoifilter: A case study of doing cocktail p...     Alexander Waibel  \n",
       "15  Incremental Blockwise Beam Search for Simultan...     Alexander Waibel  \n",
       "16  End-to-End Evaluation for Low-Latency Simultan...     Alexander Waibel  \n",
       "17     FINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN     Alexander Waibel  \n",
       "18  AdapITN: A Fast, Reliable, and Dynamic Adaptiv...     Alexander Waibel  \n",
       "19  Train Global, Tailor Local: Minimalist Multili...     Alexander Waibel  \n",
       "20  Towards Efficient Simultaneous Speech Translat...     Alexander Waibel  \n",
       "21  Towards Open-Domain Twitter User Profile Infer...  Alexander Hauptmann  \n",
       "22  Advancing Regular Language Reasoning in Linear...   Alexander Rudnicky  \n",
       "23              Structured Dialogue Discourse Parsing   Alexander Rudnicky  \n",
       "24  A Vector Quantized Approach for Text to Speech...   Alexander Rudnicky  \n",
       "25  Overview of Robust and Multilingual Automatic ...   Alexander Rudnicky  \n",
       "26  Learning to Ask Questions for Zero-shot Dialog...   Alexander Rudnicky  \n",
       "27  Assessment and Therapy Goal Planning Using Fre...     Brian MacWhinney  \n",
       "28             Automation of Language Sample Analysis     Brian MacWhinney  \n",
       "29  The role of novelty stimuli in second language...     Brian MacWhinney  \n",
       "30  Using diagnostic feedback to enhance the devel...     Brian MacWhinney  \n",
       "31  A New Benchmark of Aphasia Speech Recognition ...     Brian MacWhinney  \n",
       "32  Collaborative Commentary for Understanding Com...     Brian MacWhinney  \n",
       "33  Establishing the DementiaBank Delaware Corpus:...     Brian MacWhinney  \n",
       "34  Evaluating Picture Description Speech for Deme...     Brian MacWhinney  \n",
       "35  Multilingual Alzheimer’s Dementia Recognition ...     Brian MacWhinney  \n",
       "36  DementiaBank: Theoretical Rationale, Protocol,...     Brian MacWhinney  \n",
       "37  FREDOM: Fairness Domain Adaptation Approach to...          Bhiksha Raj  \n",
       "38  UTOPIA: Unconstrained Tracking Objects without...          Bhiksha Raj  \n",
       "39  SoftMatch: Addressing the Quantity-Quality Tra...          Bhiksha Raj  \n",
       "40  Fixed Inter-Neuron Covariability Induces Adver...          Bhiksha Raj  \n",
       "41  Understanding political polarization using lan...          Bhiksha Raj  \n",
       "42  Prolonged school closure during the pandemic t...          Bhiksha Raj  \n",
       "43  BASS: Block-wise Adaptation for Speech Summari...          Bhiksha Raj  \n",
       "44  Understanding Political Polarisation using Lan...          Bhiksha Raj  \n",
       "45  An Approach to Ontological Learning from Weak ...          Bhiksha Raj  \n",
       "46  Rethinking Voice-Face Correlation: A Geometry ...          Bhiksha Raj  \n",
       "47  Paaploss: A Phonetic-Aligned Acoustic Paramete...          Bhiksha Raj  \n",
       "48  Improving Perceptual Quality, Intelligibility,...          Bhiksha Raj  \n",
       "49  Approach to Learning Generalized Audio Represe...          Bhiksha Raj  \n",
       "50  Training on Foveated Images Improves Robustnes...          Bhiksha Raj  \n",
       "51  Imprecise Label Learning: A Unified Framework ...          Bhiksha Raj  \n",
       "52  The Hidden Dance of Phonemes and Visage: Unvei...          Bhiksha Raj  \n",
       "53  Fairness Continual Learning Approach to Semant...          Bhiksha Raj  \n",
       "54  PaintSeg: Training-free Segmentation via Painting          Bhiksha Raj  \n",
       "55  TAPLoss: A Temporal Acoustic Parameter Loss fo...          Bhiksha Raj  \n",
       "56  Synergy between human and machine approaches t...          Bhiksha Raj  \n",
       "57  High school students’ data modeling practices ...         Carolyn Rose  \n",
       "58  Linguistic representations for fewer-shot rela...         Carolyn Rose  \n",
       "59  Using counterfactual contrast to improve compo...         Carolyn Rose  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(info.head(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 2107b867cb8f8afa30a9a940288d7c8b657f8aa5.txt exists\n",
      "177\n",
      "## PAPERID\n",
      "2107b867cb8f8afa30a9a940288d7c8b657f8aa5\n",
      "## TITLE\n",
      "Zero-Shot and Few-Shot Stance Detection on Varied Topics via Conditional Generation\n",
      "## PROFNAME\n",
      "Alexander Hauptmann\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_md_len = 0\n",
    "max_md_text = ''\n",
    "for paperId in info['paperId'].values[:1]:\n",
    "    cleaned_paper_file_path = f'../data/cleaned_papers/{paperId}.txt'\n",
    "    if os.path.exists(cleaned_paper_file_path):\n",
    "        print(f'File {paperId}.txt exists')\n",
    "        text_block = ''\n",
    "        for feat in info.columns:\n",
    "            text_block += f'## {feat.upper()}\\n'\n",
    "            text_block += f'{info[info[\"paperId\"] == paperId][feat].values[0]}\\n'\n",
    "        if len(text_block) > max_md_len:\n",
    "            max_md_len = len(text_block)\n",
    "            max_md_text = text_block\n",
    "\n",
    "print(max_md_len)\n",
    "print(max_md_text)\n",
    "\n",
    "        # # write to top of file\n",
    "        # with open(cleaned_paper_file_path, \"r+\") as f:\n",
    "        #     prev_content = f.read()  # Read existing content\n",
    "        #     f.seek(0)  # Move to start\n",
    "        #     f.write(text_block + prev_content)  # Prepend with new content\n",
    "        #     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ## PAPERID\n",
      " 376f494126d1ea4f571ea0263c43ac2b6331800a\n",
      " ## TITLE\n",
      " SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs\n",
      " ## PROFNAME\n",
      " Alexander Hauptmann\n",
      " \n",
      "\n",
      " ## PAPERID\n",
      " 405e3910e06c9efe7e660b8697bcb4bab4e92f48\n",
      " ## TITLE\n",
      " STMT: A Spatial-Temporal Mesh Transformer for MoCap-Based Action Recognition\n",
      " ## PROFNAME\n",
      " Alexander Hauptmann\n",
      " \n",
      "\n",
      " ## PAPERID\n",
      " 8ccda6de0223bcd897d5dc0efc8f33222a899d0d\n",
      " ## TITLE\n",
      " DocumentNet: Bridging the Data Gap in Document Pre-training\n",
      " ## PROFNAME\n",
      " Alexander Hauptmann\n",
      " \n",
      "\n",
      " ## PAPERID\n",
      " 10127fa44054eb985ede206113b96aac3a96fd80\n",
      " ## TITLE\n",
      " The Inside Story: Towards Better Understanding of Machine Translation Neural Evaluation Metrics\n",
      " ## PROFNAME\n",
      " Alon Lavie\n",
      " \n",
      "\n",
      " ## PAPERID\n",
      " 5579d38636b898c6a67ad67a16a80dd83be0f8d4\n",
      " ## TITLE\n",
      " Towards Multilingual Automatic Dialogue Evaluation\n",
      " ## PROFNAME\n",
      " Alon Lavie\n",
      " \n",
      "\n",
      " ## PAPERID\n",
      " 5c920b2326282d93ad2ac3d1cb8f746bd7ab6f50\n",
      " ## TITLE\n",
      " Results of WMT23 Metrics Shared Task: Metrics Might Be Guilty but References Are Not Innocent\n",
      " ## PROFNAME\n",
      " Alon Lavie\n",
      " \n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for paperId in info['paperId'].values[1:]:\n",
    "    cleaned_paper_file_path = f'../data/cleaned_papers/{paperId}.txt'\n",
    "    if os.path.exists(cleaned_paper_file_path):\n",
    "        # print(f'File {paperId}.txt exists')\n",
    "        text_block = f'\\n '\n",
    "        for feat in info.columns:\n",
    "            text_block += f'## {feat.upper()}\\n '\n",
    "            text_block += f'{info[info[\"paperId\"] == paperId][feat].values[0]}\\n '\n",
    "        print(text_block)\n",
    "    i += 1\n",
    "    if i > 5:\n",
    "        break\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    #     # Add metadata every K characters\n",
    "    #     K = 2000\n",
    "    #     new_txt = ''\n",
    "    #     with open(cleaned_paper_file_path, \"r+\") as f:\n",
    "    #         prev_content = f.read()\n",
    "    #         for i in range(0, len(prev_content), K):\n",
    "    #             new_txt += text_block + prev_content[i:i+K]\n",
    "    #         f.close()\n",
    "    # annotated_paper_file_path = f'data/annotated_papers/{paperId}.txt'\n",
    "    # with open(annotated_paper_file_path, \"w\") as f:\n",
    "    #     f.write(new_txt)\n",
    "    #     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example path = 'data/cleaned_papers/2b2d9ee18507aa89a7f1ecba0bf68844c7d9aa75.txt'\n",
    "\n",
    "\n",
    "\n",
    "def get_metadata(info, path):\n",
    "    if os.path.exists('../'+path):\n",
    "        text_block = ''\n",
    "        paperId = path[20: -4]\n",
    "        print(paperId)\n",
    "        for feat in info.columns:\n",
    "            if feat == 'PROFNAME':\n",
    "                text_block += f'## AUTHOR\\n'\n",
    "                text_block += f'{info[info[\"paperId\"] == paperId][feat].values[0]}\\n'\n",
    "            else:\n",
    "                text_block += f'## {feat.upper()}\\n'\n",
    "                text_block += f'{info[info[\"paperId\"] == paperId][feat].values[0]}\\n'\n",
    "        return text_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2b2d9ee18507aa89a7f1ecba0bf68844c7d9aa75\n",
      "## PAPERID\n",
      "2b2d9ee18507aa89a7f1ecba0bf68844c7d9aa75\n",
      "## TITLE\n",
      "Grounding Language Models to Images for Multimodal Generation\n",
      "## PROFNAME\n",
      "Daniel Fried\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_metadata(info, 'data/cleaned_papers/2b2d9ee18507aa89a7f1ecba0bf68844c7d9aa75.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    paperId  \\\n",
      "6  5c920b2326282d93ad2ac3d1cb8f746bd7ab6f50   \n",
      "\n",
      "                                               title    profName  \n",
      "6  Results of WMT23 Metrics Shared Task: Metrics ...  Alon Lavie  \n",
      "                                    paperId  \\\n",
      "6  5c920b2326282d93ad2ac3d1cb8f746bd7ab6f50   \n",
      "\n",
      "                                               title    profName  \n",
      "6  Results of WMT23 Metrics Shared Task: Metrics ...  Alon Lavie  \n",
      "                                    paperId  \\\n",
      "6  5c920b2326282d93ad2ac3d1cb8f746bd7ab6f50   \n",
      "\n",
      "                                               title    profName  \n",
      "6  Results of WMT23 Metrics Shared Task: Metrics ...  Alon Lavie  \n",
      "## PAPERID\n",
      "5c920b2326282d93ad2ac3d1cb8f746bd7ab6f50\n",
      "## TITLE\n",
      "Results of WMT23 Metrics Shared Task: Metrics Might Be Guilty but References Are Not Innocent\n",
      "## PROFNAME\n",
      "Alon Lavie\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_metadata(info, '../data/cleaned_papers/f9a5af5b21563b9bdd09630a8dec62d515479678.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
