{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "- what is the author id of this professor?\n",
    "- what is the paperId of this paper?\n",
    "- what are the papers of this author?\n",
    "- what papers were published in this in this venue (conference)?\n",
    "- What is the H- index of Professor X?\n",
    "- What is the author citation count of Professor X? (authorCitationCount)\n",
    "- What is the most cited paper from this faculty member?\n",
    "- What is the most cited paper from this faculty member and its URL?\n",
    "- Who are the authors of the most cited paper?\n",
    "- who is the first author of this given paper (user gives title)?\n",
    "- How many papers has this faculty member published in open access journals?\n",
    "- What are the journals that this faculty member has published in?\n",
    "- What are the journals that this faculty member has published in, and how many papers in each journal?\n",
    "- What are the fields of study of this faculty member? (fieldsOfStudy)\n",
    "- Which venue was this paper published in?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'data/paper_jsons'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A. Lavie_1784914.json', 'Alexander Hauptmann_7661726_145788702.json', 'Alexander I. Rudnicky_1783635_3156164.json', 'Alexander Waibel_2064429921_1724972.json', 'B. MacWhinney_2414040.json', 'B. Raj_1681921.json', 'C. Rosé_35959897.json', 'Chenyan Xiong_144628574.json', 'Chenyan Xiong_144628574_2139787803.json', 'Chenyan Xiong_2139787803.json', 'Daniel Fried_47070750.json', 'Daphne Ippolito_7975935.json', 'David R. Mortensen_3407646.json', 'E. Xing_143977260.json', 'Emma Strubell_2268272.json', 'Eric Nyberg_144287919.json', 'Fernando Diaz_145472333.json', 'Graham Neubig_1700325.json', 'Jamie Callan_144987107.json', 'Jeffrey P. Bigham_1744846.json', 'Justine Cassell_145431806.json', 'Lei Li_143900005.json', 'Lori S. Levin_1686960.json', 'Louis-Philippe Morency_49933077.json', 'Lu Jiang_39978626.json', 'M. Ganapathiraju_32747279.json', 'Maarten Sap_2729164.json', 'Malihe Alikhani_2715920.json', 'Matthew R. Gormley_1762110.json', 'Matthias Grabmair_2869551.json', 'Mona T. Diab_1700007_2138579860.json', 'N. Sadeh_2464164.json', 'R. Stern_1697819.json', 'Rita Singh_153915824.json', 'Roni Rosenfeld_88507334.json', 'S. Fahlman_1758714.json', 'S. Welleck_2129663.json', 'Shinji Watanabe_1746678.json', 'T. Mitamura_1706595.json', 'Taylor Berg-Kirkpatrick_1400419309.json', 'Tom Michael Mitchell_40975594.json', 'William W. Cohen_50056360.json', 'Yiming Yang_46286308_35729970.json', 'Yonatan Bisk_3312309.json', 'Yulia Tsetkov_2073587169_145317727.json']\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "json_files = [pos_json for pos_json in os.listdir(base_dir) if pos_json.endswith('.json')]\n",
    "json_files.sort()\n",
    "print(json_files)\n",
    "print(len(json_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to get questions:\n",
    "class FacultyPublicationAnalysis:\n",
    "    def __init__(self, json_path):\n",
    "        self.df = pd.read_json(json_path)\n",
    "        self.json_path = json_path\n",
    "        self.df = self.df\n",
    "        self.prof_name = self.df['profName'].iloc[0]  \n",
    "        self.results = []\n",
    "\n",
    "    def add_result(self, question, answer, document_name=\"\", notes=\"\"):\n",
    "        self.results.append({\n",
    "            \"Question\": question,\n",
    "            \"Answer\": answer,\n",
    "            \"Document\":  self.json_path,\n",
    "            \"Notes\": notes\n",
    "        })\n",
    "\n",
    "    def get_authorId(self):\n",
    "        author_id = set(self.df['authorId'])\n",
    "        if len(author_id) >1:\n",
    "            author_id = ', '.join([str(x) for x in author_id])\n",
    "        else:\n",
    "            author_id = author_id.pop()\n",
    "        self.add_result(f\"What is the author ID of {self.prof_name}?\", str(author_id))\n",
    "\n",
    "    def get_hIndex(self):\n",
    "        h_index = set(self.df['authorHIndex'])\n",
    "        if len(h_index) >1:\n",
    "            h_index = ', '.join([str(x) for x in h_index])\n",
    "        else:\n",
    "            h_index = h_index.pop()\n",
    "        self.add_result(f\"What is the H-index of {self.prof_name}?\", str(h_index))\n",
    "        \n",
    "    def get_paperId(self, title):\n",
    "        paper_id = self.df[self.df['title'] == title]['paperId'].iloc[0]\n",
    "        self.add_result(f\"What is the paper ID of '{title}'?\", str(paper_id), title)\n",
    "\n",
    "    def get_OpenAccessCount(self):\n",
    "        # How many papers has this faculty member published in open access journals?\n",
    "        open_access_papers = self.df[self.df['isOpenAccess'] == True].shape[0]\n",
    "        self.add_result(f\"How many papers has {self.prof_name} published in open access journals?\", str(open_access_papers))\n",
    "\n",
    "    def get_authors_papers(self):\n",
    "        papers = self.df['title'].tolist()\n",
    "        self.add_result(f\"What are the papers of {self.prof_name}?\", ', '.join(papers))\n",
    "\n",
    "\n",
    "    def get_author_CitationCount(self):\n",
    "        citation_count = self.df['authorCitationCount'].max()\n",
    "        self.add_result(f\"What is the author citation count of {self.prof_name}?\", str(citation_count))\n",
    "\n",
    "    def get_journals(self):\n",
    "        journals = self.df['journal'].apply(lambda x: x.get('name') if isinstance(x, dict) else None).dropna().unique()\n",
    "        journals_string = ', '.join(journals)\n",
    "        self.add_result(f\"What journals has {self.prof_name} published in?\", journals_string)\n",
    "\n",
    "    def get_journal_count(self):\n",
    "        journals = self.df['journal'].apply(lambda x: x.get('name') if isinstance(x, dict) else None).dropna()\n",
    "        journal_counts = journals.value_counts().to_dict()\n",
    "        self.add_result(f\"What are the journals and how many papers has {self.prof_name} published in each?\", str(journal_counts))\n",
    "\n",
    "    def get_venues(self):\n",
    "        journals_filtered = [journal for journal in self.df['journal'].apply(lambda x: x.get('name') if isinstance(x, dict) else None).unique() if journal is not None]\n",
    "        journals_string = ', '.join(journals_filtered)\n",
    "        venues = self.df['venue'].unique()\n",
    "        self.add_result(f\"What venues has {self.prof_name} published in?\", ', '.join(venues))\n",
    "    \n",
    "    \n",
    "    def get_fieldsOfStudy(self):\n",
    "        fields = self.df['fieldsOfStudy'].explode().dropna().unique()\n",
    "        self.add_result(f\"What are the fields of study of {self.prof_name}?\", ', '.join(fields))\n",
    "\n",
    "    def get_most_cited_paper(self):\n",
    "        most_cited = self.df.loc[self.df['citationCount'].idxmax()]\n",
    "        self.add_result(f\"What is the most cited paper from {self.prof_name}?\", most_cited['title'])\n",
    "        url = self.get_pdfurl(most_cited['title'])\n",
    "        self.add_result(f\"What is the url of the most cited paper from {self.prof_name}?\", url)\n",
    "        authors = self.get_paper_authors(most_cited['title'])\n",
    "        self.add_result(f\"Who are the authors of the most cited paper from {self.prof_name}?\", authors)\n",
    "        return most_cited['title']\n",
    "    \n",
    "    def get_pdfurl(self, title): # asked ChatGpt because was getting none errr before and my handling was not working\n",
    "        pdf_data = self.df[self.df['title'] == title]['openAccessPdf']\n",
    "        if not pdf_data.empty and pd.notna(pdf_data.iloc[0]):\n",
    "            try:\n",
    "                url = pdf_data.iloc[0].get('url', 'openAccessPdf not available')\n",
    "            except AttributeError:\n",
    "                url = 'openAccessPdf data format unexpected'\n",
    "        else:\n",
    "            url = 'openAccessPdf not available'\n",
    "        return url\n",
    "\n",
    "\n",
    "    def get_paper_journal(self, title):\n",
    "        journal = self.df[self.df['title'] == title]['journal'].apply(lambda x: x.get('name') if isinstance(x, dict) else None).iloc[0]\n",
    "        return journal\n",
    "\n",
    "    def get_paper_venue(self, title):\n",
    "        venue = self.df[self.df['title'] == title]['venue'].values[0]\n",
    "        return venue\n",
    "    \n",
    "    def get_paper_citations(self, title):\n",
    "        citations = self.df[self.df['title'] == title]['citationCount'].values[0]\n",
    "        return citations\n",
    "    \n",
    "    def get_paperId(self, title):\n",
    "        paper_id = self.df[self.df['title'] == title]['paperId'].values[0]\n",
    "        return paper_id\n",
    "    \n",
    "    def get_paper_authors(self, title, return_list = False):\n",
    "        authors = self.df[self.df['title'] == title]['authors'].iloc[0]\n",
    "        author_names = [author['name'] for author in authors] \n",
    "        if return_list is False: # so we can get first authors\n",
    "            author_names = ', '.join(author_names)\n",
    "        return author_names\n",
    "   \n",
    "    def get_papers_from_venue(self, venue_name):\n",
    "        papers = self.df[self.df['venue'] == venue_name]['title'].tolist()\n",
    "        question = f\"What papers were published in the venue {venue_name}?\"\n",
    "        return papers\n",
    "        # self.add_result(f\"What papers were published in the venue {venue_name}?\", ', '.join(papers), notes=venue_name)\n",
    "    \n",
    "    def export_to_df(self):\n",
    "        return pd.DataFrame(self.results)\n",
    "\n",
    "    def export_to_csv(self, filename='results.csv'):\n",
    "        pd.DataFrame(self.results).to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_json = 3\n",
    "combined_json_df = pd.DataFrame()\n",
    "combined_results_df = pd.DataFrame()\n",
    "\n",
    "for json_file in json_files:\n",
    "    analysis = FacultyPublicationAnalysis(f'{base_dir}/{json_file}')\n",
    "    analysis.get_authorId() # What is the author ID of the faculty member?\n",
    "    analysis.get_authors_papers() # What are the papers of the faculty member?\n",
    "    analysis.get_hIndex() # What is the H-index of the faculty member?\n",
    "    analysis.get_author_CitationCount() # What is the author citation count of the faculty member?\n",
    "    analysis.get_journals() # What journals has the faculty member published in?\n",
    "    analysis.get_journal_count() # What are the journals and how many papers has the faculty member published in each?\n",
    "    analysis.get_fieldsOfStudy() # What are the fields of study of the faculty member?\n",
    "    analysis.get_OpenAccessCount() # How many papers has this faculty member published in open access journals?\n",
    "    analysis.get_venues() # What venues has the faculty member published in?\n",
    "    most_cited_title = analysis.get_most_cited_paper() # What is the most cited paper from the faculty member?\n",
    "\n",
    "    analysis_df = analysis.df\n",
    "    combined_json_df = pd.concat([combined_json_df, analysis_df], ignore_index=True)\n",
    "    \n",
    "    result_df = analysis.export_to_df()\n",
    "    \n",
    "    samples = samples_per_json\n",
    "    randomly_sampled_papers = analysis_df['title'].sample(min(len(analysis_df), samples), ignore_index=True).values\n",
    "    new_questions = []\n",
    "    for paper in randomly_sampled_papers:\n",
    "        journal = analysis.get_paper_journal(paper)\n",
    "        question_1 = f'What journal was the paper \"{paper}\" published in?'\n",
    "        \n",
    "        venue = analysis.get_paper_venue(paper)\n",
    "        question_2 = f'What venue was the paper \"{paper}\" published in?'\n",
    "        \n",
    "        citations = analysis.get_paper_citations(paper)\n",
    "        question_3 = f'How many citations does the paper \"{paper}\" have?'\n",
    "        \n",
    "        authors = analysis.get_paper_authors(paper)\n",
    "        question4 = f'Who are the authors of the paper \"{paper}\"?'\n",
    "        \n",
    "        author = authors.split(',')[0]\n",
    "        question5 = f'Who is the first author of the paper \"{paper}\"?'\n",
    "        \n",
    "        paper_id = analysis.get_paperId(paper)\n",
    "        question6 = f'What is the paper ID of the paper \"{paper}\"?'\n",
    "        question7 = f'What paper has the paper ID {paper_id}?'\n",
    "        \n",
    "        new_data = [\n",
    "        {\"Question\": question_1, \"Answer\": journal, \"Document\": json_file, \"Notes\": \"\"},\n",
    "        {\"Question\": question_2, \"Answer\": venue, \"Document\": json_file, \"Notes\": \"\"},\n",
    "        {\"Question\": question_3, \"Answer\": citations, \"Document\": json_file, \"Notes\": \"\"},\n",
    "        {\"Question\": question4, \"Answer\": authors, \"Document\": json_file, \"Notes\": \"\"},\n",
    "        {\"Question\": question5, \"Answer\": author, \"Document\": json_file, \"Notes\": \"\"},\n",
    "        {\"Question\": question6, \"Answer\": paper_id, \"Document\": json_file, \"Notes\": \"\"},\n",
    "        {\"Question\": question7, \"Answer\": paper, \"Document\": json_file, \"Notes\": \"\"}\n",
    "        ]\n",
    "        new_results_df = pd.DataFrame(new_data)\n",
    "        result_df = pd.concat([result_df, new_results_df], ignore_index=True)\n",
    "    combined_results_df = pd.concat([combined_results_df, result_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_json_df.to_csv('data/paper_logs/combined_json_data.csv', index=False)\n",
    "combined_results_df.to_csv('data/paper_logs/combined_qa_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most cited faculty member is Eric P. Xing\n",
      "Number of citations: 46108\n",
      "The most cited paper is 'Identification of Nonlinear Latent Hierarchical Models'\n"
     ]
    }
   ],
   "source": [
    "# Most cited faculy member (overall)\n",
    "most_cited_faculty = combined_json_df.loc[combined_json_df['authorCitationCount'].idxmax()]['profName']\n",
    "most_citations = combined_json_df['authorCitationCount'].max()\n",
    "most_cited_paper = combined_json_df.loc[combined_json_df['authorCitationCount'].idxmax()]['title']\n",
    "\n",
    "print(f\"The most cited faculty member is {most_cited_faculty}\")\n",
    "print(f\"Number of citations: {most_citations}\")\n",
    "print(f\"The most cited paper is '{most_cited_paper}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most cited faculty member is Eric P. Xing\n",
      "Number of citations: 680\n",
      "The most cited paper is 'Judging LLM-as-a-judge with MT-Bench and Chatbot Arena'\n"
     ]
    }
   ],
   "source": [
    "# Most cited faculy member (2023)\n",
    "most_cited_faculty = combined_json_df.loc[combined_json_df['citationCount'].idxmax()]['profName']\n",
    "most_citations = combined_json_df['citationCount'].max()\n",
    "most_cited_paper = combined_json_df.loc[combined_json_df['citationCount'].idxmax()]['title']\n",
    "\n",
    "print(f\"The most cited faculty member is {most_cited_faculty}\")\n",
    "print(f\"Number of citations: {most_citations}\")\n",
    "print(f\"The most cited paper is '{most_cited_paper}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "profName\n",
       "Shinji Watanabe            58\n",
       "Graham Neubig              27\n",
       "Yiming Yang                24\n",
       "Chenyan Xiong              20\n",
       "Bhiksha Raj                20\n",
       "Louis-Philippe Morency     16\n",
       "Yulia Tsvetkov             16\n",
       "Maarten Sap                13\n",
       "Emma Strubell              10\n",
       "Brian MacWhinney           10\n",
       "Alexander Waibel            9\n",
       "Taylor Berg-Kirkpatrick     9\n",
       "Yonatan Bisk                8\n",
       "Jeffrey Bigham              8\n",
       "Mona Diab                   8\n",
       "Lei Li                      8\n",
       "Malihe Alikhani             7\n",
       "David R Mortensen           7\n",
       "Alexander Rudnicky          7\n",
       "Rita Singh                  7\n",
       "Alon Lavie                  6\n",
       "Daniel Fried                6\n",
       "Lu Jiang                    6\n",
       "Jamie Callan                5\n",
       "Alexander Hauptmann         5\n",
       "Carolyn Rose                5\n",
       "Matt Gormley                4\n",
       "Norman Sadeh                4\n",
       "Daphne Ippolito             4\n",
       "Eric P. Xing                4\n",
       "William Cohen               4\n",
       "Eric Nyberg                 4\n",
       "Justine Cassell             3\n",
       "Fernando-Diaz               3\n",
       "Roni Rosenfeld              3\n",
       "Tom Mitchell                3\n",
       "Matthias Grabmair           3\n",
       "Lori S Levin                3\n",
       "Madhavi Ganapathiraju       2\n",
       "Teruko Mitamura             2\n",
       "Sean Welleck                2\n",
       "Richard Stern               1\n",
       "Scott Fahlman               1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most no of publications in 2023, open Access\n",
    "prof_name_counts = combined_json_df['profName'].value_counts().sort_values(ascending=False)\n",
    "# len(prof_name_counts)\n",
    "prof_name_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which faculty member has the most publications in open access journals in 2023?\n",
      "Shinji Watanabe\n",
      "Which faculty member has the second most publications in open access journals in 2023?\n",
      "Graham Neubig\n",
      "Which faculty member has the most publications in open access journals in 2023?\n",
      "Yiming Yang\n",
      "Which faculty member has the least publications in open access journals in 2023?\n",
      "Scott Fahlman\n"
     ]
    }
   ],
   "source": [
    "print('Which faculty member has the most publications in open access journals in 2023?')\n",
    "print(prof_name_counts.index[0])\n",
    "print('Which faculty member has the second most publications in open access journals in 2023?')\n",
    "print(prof_name_counts.index[1])\n",
    "print('Which faculty member has the most publications in open access journals in 2023?')\n",
    "print(prof_name_counts.index[2])\n",
    "print('Which faculty member has the least publications in open access journals in 2023?')\n",
    "print(prof_name_counts.index[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'data/paper_jsons'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A. Lavie_1784914.json', 'Alexander Hauptmann_7661726_145788702.json', 'Alexander I. Rudnicky_1783635_3156164.json', 'Alexander Waibel_2064429921_1724972.json', 'B. MacWhinney_2414040.json', 'B. Raj_1681921.json', 'C. Rosé_35959897.json', 'Chenyan Xiong_144628574.json', 'Chenyan Xiong_144628574_2139787803.json', 'Chenyan Xiong_2139787803.json', 'Daniel Fried_47070750.json', 'Daphne Ippolito_7975935.json', 'David R. Mortensen_3407646.json', 'E. Xing_143977260.json', 'Emma Strubell_2268272.json', 'Eric Nyberg_144287919.json', 'Fernando Diaz_145472333.json', 'Graham Neubig_1700325.json', 'Jamie Callan_144987107.json', 'Jeffrey P. Bigham_1744846.json', 'Justine Cassell_145431806.json', 'Lei Li_143900005.json', 'Lori S. Levin_1686960.json', 'Louis-Philippe Morency_49933077.json', 'Lu Jiang_39978626.json', 'M. Ganapathiraju_32747279.json', 'Maarten Sap_2729164.json', 'Malihe Alikhani_2715920.json', 'Matthew R. Gormley_1762110.json', 'Matthias Grabmair_2869551.json', 'Mona T. Diab_1700007_2138579860.json', 'N. Sadeh_2464164.json', 'R. Stern_1697819.json', 'Rita Singh_153915824.json', 'Roni Rosenfeld_88507334.json', 'S. Fahlman_1758714.json', 'S. Welleck_2129663.json', 'Shinji Watanabe_1746678.json', 'T. Mitamura_1706595.json', 'Taylor Berg-Kirkpatrick_1400419309.json', 'Tom Michael Mitchell_40975594.json', 'William W. Cohen_50056360.json', 'Yiming Yang_46286308_35729970.json', 'Yonatan Bisk_3312309.json', 'Yulia Tsetkov_2073587169_145317727.json']\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "json_files = [pos_json for pos_json in os.listdir(base_dir) if pos_json.endswith('.json')]\n",
    "json_files.sort()\n",
    "print(json_files)\n",
    "print(len(json_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['profName', 'authorId', 'authorName', 'authorUrl', 'authorHIndex',\n",
       "       'authorAffiliations', 'authorPaperCount', 'authorCitationCount',\n",
       "       'paperId', 'externalIds', 'url', 'title', 'abstract', 'venue', 'year',\n",
       "       'referenceCount', 'citationCount', 'influentialCitationCount',\n",
       "       'isOpenAccess', 'openAccessPdf', 'fieldsOfStudy', 'journal', 'authors'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(f'{base_dir}/{json_files[1]}')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{7661726, 145788702}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the author id of this professor?\n",
    "set(df.authorId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('https://aclanthology.org/2023.findings-acl.198.pdf',\n",
       " 'https://www.semanticscholar.org/paper/72cce47fd053bf916314d89a8174726c58c05e02')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to get the url \n",
    "list(df.openAccessPdf[0].values())[0], df.url[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the H-index of Professor X?\n",
    "h_index = df.authorHIndex.max()\n",
    "h_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the most cited paper from this faculty member?\n",
    "most_cited_paper = df.loc[df['citationCount'].idxmax()]['title']\n",
    "most_cited_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://arxiv.org/pdf/2306.17842'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get url from title\n",
    "title = 'SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs'\n",
    "url = df[df['title'] == title]['openAccessPdf']\n",
    "url.values[0]['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArXiv\n",
      "arXiv.org\n"
     ]
    }
   ],
   "source": [
    "# get journal from title\n",
    "title = 'SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs'\n",
    "journal = df[df['title'] == title]['journal'].apply(lambda x: x.get('name') if isinstance(x, dict) else None).iloc[0]\n",
    "print(journal)\n",
    "\n",
    "journal = df[df['title'] == title]['venue'].values[0]\n",
    "print(journal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs',\n",
       " 'http://arxiv.org/pdf/2306.17842')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the most cited paper from this faculty member and its URL?\n",
    "most_cited_paper = df.loc[df['citationCount'].idxmax()]['title']\n",
    "most_cited_url = list(df.loc[df['citationCount'].idxmax()]['openAccessPdf'].values())[0]\n",
    "most_cited_paper, most_cited_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lijun Yu',\n",
       " 'Yong Cheng',\n",
       " 'Zhiruo Wang',\n",
       " 'Vivek Kumar',\n",
       " 'Wolfgang Macherey',\n",
       " 'Yanping Huang',\n",
       " 'David A. Ross',\n",
       " 'Irfan Essa',\n",
       " 'Yonatan Bisk',\n",
       " 'Ming Yang',\n",
       " 'K. Murphy',\n",
       " 'A. Hauptmann',\n",
       " 'Lu Jiang']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Who are the authors of the most cited paper?\n",
    "most_cited_authors = df.loc[df['citationCount'].idxmax()]['authors']\n",
    "author_names = [author['name'] for author in most_cited_authors]\n",
    "author_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lijun Yu'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# who is the first author of this paper?\n",
    "most_cited_authors = df.loc[df['citationCount'].idxmax()]['authors']\n",
    "author_names = [author['name'] for author in most_cited_authors]\n",
    "author_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lijun Yu, Yong Cheng, Zhiruo Wang, Vivek Kumar, Wolfgang Macherey, Yanping Huang, David A. Ross, Irfan Essa, Yonatan Bisk, Ming Yang, K. Murphy, A. Hauptmann, Lu Jiang'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Who are the authors of the paper [title]?\n",
    "title = 'SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs'\n",
    "author_names = df[df['title']==title]['authors']\n",
    "author_names = [author['name'] for author in most_cited_authors]\n",
    "test = ', '.join(author_names)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_citations = df['citationCount'].sum()\n",
    "total_citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Annual Meeting of the Association for Computational Linguistics, Computer Vision and Pattern Recognition, Conference on Empirical Methods in Natural Language Processing'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the DataFrame to exclude 'arXiv.org' from venues and get the unique venues\n",
    "conferences_last_year = df[df['venue'] != 'arXiv.org']['venue'].unique()\n",
    "conferences_string = ', '.join(conferences_last_year)\n",
    "conferences_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many papers has this faculty member published in open access journals?\n",
    "open_access_papers = df[df['isOpenAccess'] == True].shape[0]\n",
    "open_access_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ArXiv, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "journals_filtered = [journal for journal in df['journal'].apply(lambda x: x.get('name') if isinstance(x, dict) else None).unique() if journal is not None]\n",
    "journals_string = ', '.join(journals_filtered)\n",
    "journals_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Conference on Empirical Methods in Natural Language Processing'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which venue was this paper published in?\n",
    "paper_title = 'DocumentNet: Bridging the Data Gap in Document Pre-training'\n",
    "venue = df[df['title'] == paper_title]['venue'].values[0]\n",
    "venue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Zero-Shot and Few-Shot Stance Detection on Varied Topics via Conditional Generation'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.title[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Towards Open-Domain Twitter User Profile Infer...\n",
       "1    Zero-Shot and Few-Shot Stance Detection on Var...\n",
       "2    SPAE: Semantic Pyramid AutoEncoder for Multimo...\n",
       "3    STMT: A Spatial-Temporal Mesh Transformer for ...\n",
       "4    DocumentNet: Bridging the Data Gap in Document...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arXiv.org'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which venue was this paper published in?\n",
    "venue = df[df['title'] == df.title[2]]['venue'].values[0]\n",
    "venue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arXiv.org'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = 'SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs'\n",
    "# Which venue was this paper published in?\n",
    "paper_title = title\n",
    "venue = df[df['title'] == paper_title]['venue'].values[0]\n",
    "venue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "samples = 3\n",
    "\n",
    "randomly_sampled_papers = df['title'].sample(min(len(df), samples), ignore_index=True).values\n",
    "for title in randomly_sampled_papers:\n",
    "    journal = analysis.get_paper_journal(title)\n",
    "    question = f'What journal was the paper \"{title}\" published in?'\n",
    "    \n",
    "    venue = analysis.get_paper_venue(title)\n",
    "    citations = analysis.get_paper_citations(title)\n",
    "    authors = analysis.get_paper_authors(title)\n",
    "    author = authors.split(',')[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
