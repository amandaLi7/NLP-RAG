{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "- what is the author id of this professor?\n",
    "- what is the paperId of this paper?\n",
    "- what are the papers of this author?\n",
    "- what papers were published in this in this venue (conference)?\n",
    "- What is the H- index of Professor X?\n",
    "- What is the author citation count of Professor X? (authorCitationCount)\n",
    "- What is the most cited paper from this faculty member?\n",
    "- What is the most cited paper from this faculty member and its URL?\n",
    "- Who are the authors of the most cited paper?\n",
    "- who is the first author of this given paper (user gives title)?\n",
    "- How many papers has this faculty member published in open access journals?\n",
    "- What are the journals that this faculty member has published in?\n",
    "- What are the journals that this faculty member has published in, and how many papers in each journal?\n",
    "- What are the fields of study of this faculty member? (fieldsOfStudy)\n",
    "- Which venue was this paper published in?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'data/paper_jsons'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A. Lavie_1784914.json', 'Alexander Hauptmann_7661726_145788702.json', 'Alexander I. Rudnicky_1783635_3156164.json', 'Alexander Waibel_2064429921_1724972.json', 'B. MacWhinney_2414040.json', 'B. Raj_1681921.json', 'C. RosÃ©_35959897.json', 'Chenyan Xiong_144628574.json', 'Chenyan Xiong_144628574_2139787803.json', 'Chenyan Xiong_2139787803.json', 'Daniel Fried_47070750.json', 'Daphne Ippolito_7975935.json', 'David R. Mortensen_3407646.json', 'E. Xing_143977260.json', 'Emma Strubell_2268272.json', 'Eric Nyberg_144287919.json', 'Fernando Diaz_145472333.json', 'Graham Neubig_1700325.json', 'Jamie Callan_144987107.json', 'Jeffrey P. Bigham_1744846.json', 'Justine Cassell_145431806.json', 'Lei Li_143900005.json', 'Lori S. Levin_1686960.json', 'Louis-Philippe Morency_49933077.json', 'Lu Jiang_39978626.json', 'M. Ganapathiraju_32747279.json', 'Maarten Sap_2729164.json', 'Malihe Alikhani_2715920.json', 'Matthew R. Gormley_1762110.json', 'Matthias Grabmair_2869551.json', 'Mona T. Diab_1700007_2138579860.json', 'N. Sadeh_2464164.json', 'R. Stern_1697819.json', 'Rita Singh_153915824.json', 'Roni Rosenfeld_88507334.json', 'S. Fahlman_1758714.json', 'S. Welleck_2129663.json', 'Shinji Watanabe_1746678.json', 'T. Mitamura_1706595.json', 'Taylor Berg-Kirkpatrick_1400419309.json', 'Tom Michael Mitchell_40975594.json', 'William W. Cohen_50056360.json', 'Yiming Yang_46286308_35729970.json', 'Yonatan Bisk_3312309.json', 'Yulia Tsetkov_2073587169_145317727.json']\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "json_files = [pos_json for pos_json in os.listdir(base_dir) if pos_json.endswith('.json')]\n",
    "json_files.sort()\n",
    "print(json_files)\n",
    "print(len(json_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(json_files)):\n",
    "  json_path = f'{base_dir}/{json_files[i]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = f'{base_dir}/{json_files[0]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set({3,4}).pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to get questions:\n",
    "class FacultyPublicationAnalysis:\n",
    "    def __init__(self, json_path):\n",
    "        self.df = pd.read_json(json_path)\n",
    "        self.json_path = json_path\n",
    "        self.df = self.df\n",
    "        self.prof_name = self.df['profName'].iloc[0]  \n",
    "        self.results = []\n",
    "\n",
    "    def add_result(self, question, answer, document_name=\"\", notes=\"\"):\n",
    "        self.results.append({\n",
    "            \"Question\": question,\n",
    "            \"Answer\": answer,\n",
    "            \"Document\":  self.json_path,\n",
    "            \"Notes\": notes\n",
    "        })\n",
    "\n",
    "    def get_authorId(self):\n",
    "        author_id = set(self.df['authorId'])\n",
    "        if len(author_id) >1:\n",
    "            author_id = ', '.join([str(x) for x in author_id])\n",
    "        else:\n",
    "            author_id = author_id.pop()\n",
    "        self.add_result(f\"What is the author ID of {self.prof_name}?\", str(author_id))\n",
    "\n",
    "    def get_hIndex(self):\n",
    "        h_index = set(self.df['authorHIndex'])\n",
    "        if len(h_index) >1:\n",
    "            h_index = ', '.join([str(x) for x in h_index])\n",
    "        else:\n",
    "            h_index = h_index.pop()\n",
    "        self.add_result(f\"What is the H-index of {self.prof_name}?\", str(h_index))\n",
    "        \n",
    "    def get_paperId(self, title):\n",
    "        paper_id = self.df[self.df['title'] == title]['paperId'].iloc[0]\n",
    "        self.add_result(f\"What is the paper ID of '{title}'?\", str(paper_id), title)\n",
    "\n",
    "    def get_OpenAccessCount(self):\n",
    "        # How many papers has this faculty member published in open access journals?\n",
    "        open_access_papers = self.df[self.df['isOpenAccess'] == True].shape[0]\n",
    "        self.add_result(f\"How many papers has {self.prof_name} published in open access journals?\", str(open_access_papers))\n",
    "\n",
    "    def get_authors_papers(self):\n",
    "        papers = self.df['title'].tolist()\n",
    "        self.add_result(f\"What are the papers of {self.prof_name}?\", ', '.join(papers))\n",
    "\n",
    "\n",
    "    def get_author_CitationCount(self):\n",
    "        citation_count = self.df['authorCitationCount'].max()\n",
    "        self.add_result(f\"What is the author citation count of {self.prof_name}?\", str(citation_count))\n",
    "\n",
    "    def get_journals(self):\n",
    "        journals = self.df['journal'].apply(lambda x: x.get('name') if isinstance(x, dict) else None).dropna().unique()\n",
    "        journals_string = ', '.join(journals)\n",
    "        self.add_result(f\"What journals has {self.prof_name} published in?\", journals_string)\n",
    "\n",
    "    def get_journal_count(self):\n",
    "        journals = self.df['journal'].apply(lambda x: x.get('name') if isinstance(x, dict) else None).dropna()\n",
    "        journal_counts = journals.value_counts().to_dict()\n",
    "        self.add_result(f\"What are the journals and how many papers has {self.prof_name} published in each?\", str(journal_counts))\n",
    "\n",
    "    def get_venues(self):\n",
    "        journals_filtered = [journal for journal in self.df['journal'].apply(lambda x: x.get('name') if isinstance(x, dict) else None).unique() if journal is not None]\n",
    "        journals_string = ', '.join(journals_filtered)\n",
    "        venues = self.df['venue'].unique()\n",
    "        self.add_result(f\"What venues has {self.prof_name} published in?\", ', '.join(venues))\n",
    "    \n",
    "    \n",
    "    def get_fieldsOfStudy(self):\n",
    "        fields = self.df['fieldsOfStudy'].explode().dropna().unique()\n",
    "        self.add_result(f\"What are the fields of study of {self.prof_name}?\", ', '.join(fields))\n",
    "\n",
    "    def get_most_cited_paper(self):\n",
    "        most_cited = self.df.loc[self.df['citationCount'].idxmax()]\n",
    "        self.add_result(f\"What is the most cited paper from {self.prof_name}?\", most_cited['title'])\n",
    "        url = self.get_pdfurl(most_cited['title'])\n",
    "        self.add_result(f\"What is the url of the most cited paper from {self.prof_name}?\", url)\n",
    "        return most_cited['title']\n",
    "    \n",
    "    def get_pdfurl(self, title):\n",
    "        url = self.df[self.df['title'] == title]['openAccessPdf']\n",
    "        url = url.values[0]['url']\n",
    "        return url\n",
    "    \n",
    "    def get_paper_journal(self, title):\n",
    "        journal = self.df[self.df['title'] == title]['journal'].apply(lambda x: x.get('name') if isinstance(x, dict) else None).iloc[0]\n",
    "        return journal\n",
    "\n",
    "    def get_paper_venue(self, title):\n",
    "        venue = self.df[self.df['title'] == title]['venue'].values[0]\n",
    "        return venue\n",
    "    \n",
    "    def get_paper_citations(self, title):\n",
    "        citations = self.df[self.df['title'] == title]['citationCount'].values[0]\n",
    "        return citations\n",
    "    \n",
    "    def get_paperId(self, title):\n",
    "        paper_id = self.df[self.df['title'] == title]['paperId'].values[0]\n",
    "        return paper_id\n",
    "    \n",
    "    def get_paper_authors(self, title, return_list = False):\n",
    "        authors = self.df[self.df['title'] == title]['authors'].iloc[0]\n",
    "        author_names = [author['name'] for author in authors] \n",
    "        if return_list is False: # so we can get first authors\n",
    "            author_names = ', '.join(author_names)\n",
    "        return author_names\n",
    "   \n",
    "    def get_papers_from_venue(self, venue_name):\n",
    "        papers = self.df[self.df['venue'] == venue_name]['title'].tolist()\n",
    "        question = f\"What papers were published in the venue {venue_name}?\"\n",
    "        return papers\n",
    "        # self.add_result(f\"What papers were published in the venue {venue_name}?\", ', '.join(papers), notes=venue_name)\n",
    "    \n",
    "    def export_to_csv(self, filename='results.csv'):\n",
    "        pd.DataFrame(self.results).to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = FacultyPublicationAnalysis(json_path=json_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.get_authorId() # What is the author ID of the faculty member?\n",
    "analysis.get_authors_papers() # What are the papers of the faculty member?\n",
    "analysis.get_hIndex() # What is the H-index of the faculty member?\n",
    "analysis.get_author_CitationCount() # What is the author citation count of the faculty member?\n",
    "analysis.get_journals() # What journals has the faculty member published in?\n",
    "analysis.get_journal_count() # What are the journals and how many papers has the faculty member published in each?\n",
    "analysis.get_fieldsOfStudy() # What are the fields of study of the faculty member?\n",
    "analysis.get_OpenAccessCount() # How many papers has this faculty member published in open access journals?\n",
    "analysis.get_venues() # What venues has the faculty member published in?\n",
    "most_cited_title = analysis.get_most_cited_paper() # What is the most cited paper from the faculty member?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = analysis.df\n",
    "csv_path = base_dir + '/results.csv'\n",
    "analysis.export_to_csv(csv_path)\n",
    "results_df = pd.read_csv(csv_path) # re read to get customn questions added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "samples = 2\n",
    "randomly_sampled_papers = analysis_df['title'].sample(min(len(analysis_df), samples), ignore_index=True).values\n",
    "new_questions = []\n",
    "for paper in randomly_sampled_papers:\n",
    "    journal = analysis.get_paper_journal(paper)\n",
    "    question_1 = f'What journal was the paper \"{paper}\" published in?'\n",
    "    \n",
    "    venue = analysis.get_paper_venue(paper)\n",
    "    question_2 = f'What venue was the paper \"{paper}\" published in?'\n",
    "    \n",
    "    citations = analysis.get_paper_citations(paper)\n",
    "    question_3 = f'How many citations does the paper \"{paper}\" have?'\n",
    "    \n",
    "    authors = analysis.get_paper_authors(paper)\n",
    "    question4 = f'Who are the authors of the paper \"{paper}\"?'\n",
    "    \n",
    "    author = authors.split(',')[0]\n",
    "    question5 = f'Who is the first author of the paper \"{paper}\"?'\n",
    "    \n",
    "    paper_id = analysis.get_paperId(paper)\n",
    "    question6 = f'What is the paper ID of the paper \"{paper}\"?'\n",
    "    question7 = f'What paper has the paper ID {paper_id}?'\n",
    "    \n",
    "    new_data = [\n",
    "    {\"Question\": question_1, \"Answer\": journal, \"Document\": json_path, \"Notes\": \"\"},\n",
    "    {\"Question\": question_2, \"Answer\": venue, \"Document\": json_path, \"Notes\": \"\"},\n",
    "    {\"Question\": question_3, \"Answer\": citations, \"Document\": json_path, \"Notes\": \"\"},\n",
    "    {\"Question\": question4, \"Answer\": authors, \"Document\": json_path, \"Notes\": \"\"},\n",
    "    {\"Question\": question5, \"Answer\": author, \"Document\": json_path, \"Notes\": \"\"},\n",
    "    {\"Question\": question6, \"Answer\": paper_id, \"Document\": json_path, \"Notes\": \"\"},\n",
    "    {\"Question\": question7, \"Answer\": paper, \"Document\": json_path, \"Notes\": \"\"}\n",
    "    ]\n",
    "    new_results_df = pd.DataFrame(new_data)\n",
    "    results_df = pd.concat([results_df, new_results_df], ignore_index=True)\n",
    "\n",
    "results_df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Simple LLM Prompting is State-of-the-Art for Robust and Multilingual Dialogue Evaluation',\n",
       "       'Appropriateness is all you need!',\n",
       "       'Results of WMT23 Metrics Shared Task: Metrics Might Be Guilty but References Are Not Innocent'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = analysis.df\n",
    "samples = 3\n",
    "df['title'].sample(min(len(df), samples), ignore_index=True).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'data/paper_jsons'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A. Lavie_1784914.json', 'Alexander Hauptmann_7661726_145788702.json', 'Alexander I. Rudnicky_1783635_3156164.json', 'Alexander Waibel_2064429921_1724972.json', 'B. MacWhinney_2414040.json', 'B. Raj_1681921.json', 'C. RosÃ©_35959897.json', 'Chenyan Xiong_144628574.json', 'Chenyan Xiong_144628574_2139787803.json', 'Chenyan Xiong_2139787803.json', 'Daniel Fried_47070750.json', 'Daphne Ippolito_7975935.json', 'David R. Mortensen_3407646.json', 'E. Xing_143977260.json', 'Emma Strubell_2268272.json', 'Eric Nyberg_144287919.json', 'Fernando Diaz_145472333.json', 'Graham Neubig_1700325.json', 'Jamie Callan_144987107.json', 'Jeffrey P. Bigham_1744846.json', 'Justine Cassell_145431806.json', 'Lei Li_143900005.json', 'Lori S. Levin_1686960.json', 'Louis-Philippe Morency_49933077.json', 'Lu Jiang_39978626.json', 'M. Ganapathiraju_32747279.json', 'Maarten Sap_2729164.json', 'Malihe Alikhani_2715920.json', 'Matthew R. Gormley_1762110.json', 'Matthias Grabmair_2869551.json', 'Mona T. Diab_1700007_2138579860.json', 'N. Sadeh_2464164.json', 'R. Stern_1697819.json', 'Rita Singh_153915824.json', 'Roni Rosenfeld_88507334.json', 'S. Fahlman_1758714.json', 'S. Welleck_2129663.json', 'Shinji Watanabe_1746678.json', 'T. Mitamura_1706595.json', 'Taylor Berg-Kirkpatrick_1400419309.json', 'Tom Michael Mitchell_40975594.json', 'William W. Cohen_50056360.json', 'Yiming Yang_46286308_35729970.json', 'Yonatan Bisk_3312309.json', 'Yulia Tsetkov_2073587169_145317727.json']\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "json_files = [pos_json for pos_json in os.listdir(base_dir) if pos_json.endswith('.json')]\n",
    "json_files.sort()\n",
    "print(json_files)\n",
    "print(len(json_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['profName', 'authorId', 'authorName', 'authorUrl', 'authorHIndex',\n",
       "       'authorAffiliations', 'authorPaperCount', 'authorCitationCount',\n",
       "       'paperId', 'externalIds', 'url', 'title', 'abstract', 'venue', 'year',\n",
       "       'referenceCount', 'citationCount', 'influentialCitationCount',\n",
       "       'isOpenAccess', 'openAccessPdf', 'fieldsOfStudy', 'journal', 'authors'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(f'{base_dir}/{json_files[1]}')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{7661726, 145788702}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the author id of this professor?\n",
    "set(df.authorId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('https://aclanthology.org/2023.findings-acl.198.pdf',\n",
       " 'https://www.semanticscholar.org/paper/72cce47fd053bf916314d89a8174726c58c05e02')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to get the url \n",
    "list(df.openAccessPdf[0].values())[0], df.url[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the H-index of Professor X?\n",
    "h_index = df.authorHIndex.max()\n",
    "h_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the most cited paper from this faculty member?\n",
    "most_cited_paper = df.loc[df['citationCount'].idxmax()]['title']\n",
    "most_cited_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://arxiv.org/pdf/2306.17842'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get url from title\n",
    "title = 'SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs'\n",
    "url = df[df['title'] == title]['openAccessPdf']\n",
    "url.values[0]['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArXiv\n",
      "arXiv.org\n"
     ]
    }
   ],
   "source": [
    "# get journal from title\n",
    "title = 'SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs'\n",
    "journal = df[df['title'] == title]['journal'].apply(lambda x: x.get('name') if isinstance(x, dict) else None).iloc[0]\n",
    "print(journal)\n",
    "\n",
    "journal = df[df['title'] == title]['venue'].values[0]\n",
    "print(journal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs',\n",
       " 'http://arxiv.org/pdf/2306.17842')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the most cited paper from this faculty member and its URL?\n",
    "most_cited_paper = df.loc[df['citationCount'].idxmax()]['title']\n",
    "most_cited_url = list(df.loc[df['citationCount'].idxmax()]['openAccessPdf'].values())[0]\n",
    "most_cited_paper, most_cited_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lijun Yu',\n",
       " 'Yong Cheng',\n",
       " 'Zhiruo Wang',\n",
       " 'Vivek Kumar',\n",
       " 'Wolfgang Macherey',\n",
       " 'Yanping Huang',\n",
       " 'David A. Ross',\n",
       " 'Irfan Essa',\n",
       " 'Yonatan Bisk',\n",
       " 'Ming Yang',\n",
       " 'K. Murphy',\n",
       " 'A. Hauptmann',\n",
       " 'Lu Jiang']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Who are the authors of the most cited paper?\n",
    "most_cited_authors = df.loc[df['citationCount'].idxmax()]['authors']\n",
    "author_names = [author['name'] for author in most_cited_authors]\n",
    "author_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lijun Yu'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# who is the first author of this paper?\n",
    "most_cited_authors = df.loc[df['citationCount'].idxmax()]['authors']\n",
    "author_names = [author['name'] for author in most_cited_authors]\n",
    "author_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lijun Yu, Yong Cheng, Zhiruo Wang, Vivek Kumar, Wolfgang Macherey, Yanping Huang, David A. Ross, Irfan Essa, Yonatan Bisk, Ming Yang, K. Murphy, A. Hauptmann, Lu Jiang'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Who are the authors of the paper [title]?\n",
    "title = 'SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs'\n",
    "author_names = df[df['title']==title]['authors']\n",
    "author_names = [author['name'] for author in most_cited_authors]\n",
    "test = ', '.join(author_names)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_citations = df['citationCount'].sum()\n",
    "total_citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Annual Meeting of the Association for Computational Linguistics, Computer Vision and Pattern Recognition, Conference on Empirical Methods in Natural Language Processing'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the DataFrame to exclude 'arXiv.org' from venues and get the unique venues\n",
    "conferences_last_year = df[df['venue'] != 'arXiv.org']['venue'].unique()\n",
    "conferences_string = ', '.join(conferences_last_year)\n",
    "conferences_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many papers has this faculty member published in open access journals?\n",
    "open_access_papers = df[df['isOpenAccess'] == True].shape[0]\n",
    "open_access_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ArXiv, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "journals_filtered = [journal for journal in df['journal'].apply(lambda x: x.get('name') if isinstance(x, dict) else None).unique() if journal is not None]\n",
    "journals_string = ', '.join(journals_filtered)\n",
    "journals_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Conference on Empirical Methods in Natural Language Processing'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which venue was this paper published in?\n",
    "paper_title = 'DocumentNet: Bridging the Data Gap in Document Pre-training'\n",
    "venue = df[df['title'] == paper_title]['venue'].values[0]\n",
    "venue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Zero-Shot and Few-Shot Stance Detection on Varied Topics via Conditional Generation'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.title[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Towards Open-Domain Twitter User Profile Infer...\n",
       "1    Zero-Shot and Few-Shot Stance Detection on Var...\n",
       "2    SPAE: Semantic Pyramid AutoEncoder for Multimo...\n",
       "3    STMT: A Spatial-Temporal Mesh Transformer for ...\n",
       "4    DocumentNet: Bridging the Data Gap in Document...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arXiv.org'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which venue was this paper published in?\n",
    "venue = df[df['title'] == df.title[2]]['venue'].values[0]\n",
    "venue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arXiv.org'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = 'SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs'\n",
    "# Which venue was this paper published in?\n",
    "paper_title = title\n",
    "venue = df[df['title'] == paper_title]['venue'].values[0]\n",
    "venue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "samples = 3\n",
    "\n",
    "randomly_sampled_papers = df['title'].sample(min(len(df), samples), ignore_index=True).values\n",
    "for title in randomly_sampled_papers:\n",
    "    journal = analysis.get_paper_journal(title)\n",
    "    question = f'What journal was the paper \"{title}\" published in?'\n",
    "    \n",
    "    venue = analysis.get_paper_venue(title)\n",
    "    citations = analysis.get_paper_citations(title)\n",
    "    authors = analysis.get_paper_authors(title)\n",
    "    author = authors.split(',')[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
