{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "- what is the author id of this professor?\n",
    "- what is the paperId of this paper?\n",
    "- what are the papers of this author?\n",
    "- what papers were published in this in this venue (conference)?\n",
    "- What is the H- index of Professor X?\n",
    "- What is the author citation count of Professor X? (authorCitationCount)\n",
    "- What is the most cited paper from this faculty member?\n",
    "- What is the most cited paper from this faculty member and its URL?\n",
    "- Who are the authors of the most cited paper?\n",
    "- who is the first author of this given paper (user gives title)?\n",
    "- How many papers has this faculty member published in open access journals?\n",
    "- What are the journals that this faculty member has published in?\n",
    "- What are the journals that this faculty member has published in, and how many papers in each journal?\n",
    "- What are the fields of study of this faculty member? (fieldsOfStudy)\n",
    "- Which venue was this paper published in?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '../data/paper_jsons'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A. Hauptmann_145788702.json', 'A. Lavie_1784914.json', 'A. Rudnicky_3156164.json', 'A. Waibel_1724972.json', 'A. Waibel_2064429921.json', 'Alexander Hauptmann_7661726.json', 'Alexander I. Rudnicky_1783635.json', 'B. MacWhinney_2414040.json', 'B. Raj_1681921.json', 'C. Rose_35959897.json', 'Chenyan Xiong_144628574.json', 'Chenyan Xiong_2139787803.json', 'Daniel Fried_47070750.json', 'Daphne Ippolito_7975935.json', 'David R. Mortensen_3407646.json', 'E. Xing_143977260.json', 'Emma Strubell_2268272.json', 'Eric Nyberg_144287919.json', 'Fernando Diaz_145472333.json', 'Graham Neubig_1700325.json', 'Jamie Callan_144987107.json', 'Jeffrey P. Bigham_1744846.json', 'Justine Cassell_145431806.json', 'Lei Li_143900005.json', 'Lori S. Levin_1686960.json', 'Louis-Philippe Morency_49933077.json', 'Lu Jiang_39978626.json', 'M. Ganapathiraju_32747279.json', 'Maarten Sap_2729164.json', 'Malihe Alikhani_2715920.json', 'Matthew R. Gormley_1762110.json', 'Matthias Grabmair_2869551.json', 'Mona T. Diab_1700007.json', 'Mona T. Diab_2138579860.json', 'N. Sadeh_2464164.json', 'R. Stern_1697819.json', 'Rita Singh_153915824.json', 'Roni Rosenfeld_88507334.json', 'S. Fahlman_1758714.json', 'S. Welleck_2129663.json', 'Shinji Watanabe_1746678.json', 'T. Mitamura_1706595.json', 'Taylor Berg-Kirkpatrick_1400419309.json', 'Tom Michael Mitchell_40975594.json', 'William W. Cohen_50056360.json', 'Yiming Yang_35729970.json', 'Yiming Yang_46286308.json', 'Yonatan Bisk_3312309.json', 'Yulia Tsvetkov_145317727.json', 'Yulia Tsvetkov_2073587169.json']\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "json_files = [pos_json for pos_json in os.listdir(base_dir) if pos_json.endswith('.json')]\n",
    "json_files.sort()\n",
    "print(json_files)\n",
    "print(len(json_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to get questions:\n",
    "class FacultyPublicationAnalysis:\n",
    "    def __init__(self, json_path):\n",
    "        self.df = pd.read_json(json_path)\n",
    "        self.json_path = json_path\n",
    "        self.df = self.df\n",
    "        self.prof_name = self.df['profName'].iloc[0]  \n",
    "        self.results = []\n",
    "\n",
    "    def add_result(self, question, answer, document_name=\"\", notes=\"\"):\n",
    "        self.results.append({\n",
    "            \"Question\": question,\n",
    "            \"Answer\": answer,\n",
    "            \"Document\":  self.json_path,\n",
    "            \"Notes\": notes\n",
    "        })\n",
    "\n",
    "    def get_authorId(self):\n",
    "        author_id = set(self.df['authorId'])\n",
    "        if len(author_id) >1:\n",
    "            author_id = ', '.join([str(x) for x in author_id])\n",
    "        else:\n",
    "            author_id = author_id.pop()\n",
    "        self.add_result(f\"What is the author ID of {self.prof_name}?\", str(author_id))\n",
    "\n",
    "    def get_hIndex(self):\n",
    "        h_index = set(self.df['authorHIndex'])\n",
    "        if len(h_index) >1:\n",
    "            h_index = ', '.join([str(x) for x in h_index])\n",
    "        else:\n",
    "            h_index = h_index.pop()\n",
    "        self.add_result(f\"What is the H-index of {self.prof_name}?\", str(h_index))\n",
    "        \n",
    "    def get_paperId(self, title):\n",
    "        paper_id = self.df[self.df['title'] == title]['paperId'].iloc[0]\n",
    "        self.add_result(f\"What is the paper ID of '{title}'?\", str(paper_id), title)\n",
    "\n",
    "    def get_OpenAccessCount(self):\n",
    "        # How many papers has this faculty member published in open access journals?\n",
    "        open_access_papers = self.df[self.df['isOpenAccess'] == True].shape[0]\n",
    "        self.add_result(f\"How many papers has {self.prof_name} published in open access journals?\", str(open_access_papers))\n",
    "\n",
    "    def get_authors_papers(self):\n",
    "        papers = self.df['title'].tolist()\n",
    "        self.add_result(f\"What are the papers of {self.prof_name}?\", ', '.join(papers))\n",
    "\n",
    "\n",
    "    def get_author_CitationCount(self):\n",
    "        citation_count = self.df['authorCitationCount'].max()\n",
    "        self.add_result(f\"What is the author citation count of {self.prof_name}?\", str(citation_count))\n",
    "\n",
    "    def get_journals(self):\n",
    "        journals = self.df['journal'].apply(lambda x: x.get('name') if isinstance(x, dict) else None).dropna().unique()\n",
    "        journals_string = ', '.join(journals)\n",
    "        self.add_result(f\"What journals has {self.prof_name} published in?\", journals_string)\n",
    "\n",
    "    def get_journal_count(self):\n",
    "        journals = self.df['journal'].apply(lambda x: x.get('name') if isinstance(x, dict) else None).dropna()\n",
    "        journal_counts = journals.value_counts().to_dict()\n",
    "        if len(journal_counts) > 1:\n",
    "            journal_counts = ', '.join([f\"{count} in {journal}\" for journal, count in journal_counts.items()])\n",
    "        else:\n",
    "            journal_counts = 'No journal data available.'\n",
    "        \n",
    "        self.add_result(f\"What are the journals and how many papers has {self.prof_name} published in each?\", str(journal_counts))\n",
    "\n",
    "    def get_venues(self):\n",
    "        journals_filtered = [journal for journal in self.df['journal'].apply(lambda x: x.get('name') if isinstance(x, dict) else None).unique() if journal is not None]\n",
    "        journals_string = ', '.join(journals_filtered)\n",
    "        venues = self.df['venue'].unique()\n",
    "        self.add_result(f\"What venues has {self.prof_name} published in?\", ', '.join(venues))\n",
    "    \n",
    "    \n",
    "    def get_fieldsOfStudy(self):\n",
    "        fields = self.df['fieldsOfStudy'].explode().dropna().unique()\n",
    "        self.add_result(f\"What are the fields of study of {self.prof_name}?\", ', '.join(fields))\n",
    "\n",
    "    def get_most_cited_paper(self):\n",
    "        most_cited = self.df.loc[self.df['citationCount'].idxmax()]\n",
    "        self.add_result(f\"What is the most cited paper from {self.prof_name}?\", most_cited['title'])\n",
    "        url = self.get_pdfurl(most_cited['title'])\n",
    "        self.add_result(f\"What is the url of the most cited paper from {self.prof_name}?\", url)\n",
    "        authors = self.get_paper_authors(most_cited['title'])\n",
    "        self.add_result(f\"Who are the authors of the most cited paper from {self.prof_name}?\", authors)\n",
    "        tldr = self.get_paper_tldr(most_cited['title'])\n",
    "        self.add_result(f\"TLDR/Summary of the most cited paper from {self.prof_name}?\", tldr)\n",
    "        abstract = self.get_paper_abstract(most_cited['title'])\n",
    "        self.add_result(f\"Abstract of the most cited paper from {self.prof_name}?\", abstract)\n",
    "        return most_cited['title']\n",
    "    \n",
    "    def get_pdfurl(self, title): # asked ChatGpt because was getting none errr before and my handling was not working\n",
    "        pdf_data = self.df[self.df['title'] == title]['openAccessPdf']\n",
    "        if not pdf_data.empty and pd.notna(pdf_data.iloc[0]):\n",
    "            try:\n",
    "                url = pdf_data.iloc[0].get('url', 'openAccessPdf not available')\n",
    "            except AttributeError:\n",
    "                url = 'openAccessPdf data format unexpected'\n",
    "        else:\n",
    "            url = 'openAccessPdf not available'\n",
    "        return url\n",
    "\n",
    "\n",
    "    def get_paper_journal(self, title):\n",
    "        journal = self.df[self.df['title'] == title]['journal'].apply(lambda x: x.get('name') if isinstance(x, dict) else None).iloc[0]\n",
    "        volume =  self.df[self.df['title'] == title]['journal'].apply(lambda x: x.get('volume') if isinstance(x, dict) else None).iloc[0]\n",
    "        pages =  self.df[self.df['title'] == title]['journal'].apply(lambda x: x.get('pages') if isinstance(x, dict) else None).iloc[0]\n",
    "        \n",
    "        journal_edited = None\n",
    "        \n",
    "        if (volume is not None) and (pages is None):\n",
    "            journal_edited = f\"{journal}, volume: {volume}\"\n",
    "        if (pages is not None) and (volume is None):\n",
    "            journal_edited = f'{journal}, pages: {pages}'\n",
    "        if (volume is not None) and (pages is not None):\n",
    "            journal_edited = f\"{journal}, volume: {volume}, pages: {pages}\"\n",
    "        \n",
    "        if journal_edited is None:\n",
    "            journal_edited = journal\n",
    "        else:\n",
    "            journal = f'{journal_edited}; {journal}'\n",
    "        \n",
    "        return journal\n",
    "\n",
    "    def get_paper_venue(self, title):\n",
    "        venue = self.df[self.df['title'] == title]['venue'].values[0]\n",
    "        return venue\n",
    "    \n",
    "    def get_paper_citations(self, title):\n",
    "        citations = self.df[self.df['title'] == title]['citationCount'].values[0]\n",
    "        return citations\n",
    "    \n",
    "    def get_paperId(self, title):\n",
    "        paper_id = self.df[self.df['title'] == title]['paperId'].values[0]\n",
    "        return paper_id\n",
    "    \n",
    "    def get_paper_authors(self, title, return_list = False):\n",
    "        authors = self.df[self.df['title'] == title]['authors'].iloc[0]\n",
    "        author_names = [unidecode(author['name']) for author in authors] \n",
    "        if return_list is False: # so we can get first authors\n",
    "            author_names = ', '.join(author_names)\n",
    "        return author_names\n",
    "   \n",
    "    def get_papers_from_venue(self, venue_name):\n",
    "        papers = self.df[self.df['venue'] == venue_name]['title'].tolist()\n",
    "        question = f\"What papers were published in the venue {venue_name}?\"\n",
    "        return papers\n",
    "        # self.add_result(f\"What papers were published in the venue {venue_name}?\", ', '.join(papers), notes=venue_name)\n",
    "    \n",
    "    def get_paper_tldr(self, title):\n",
    "        tldr = self.df[self.df['title'] == title]['tldr'].tolist()[0]\n",
    "        return tldr\n",
    "    \n",
    "    def get_paper_abstract(self, title):\n",
    "        abstract = self.df[self.df['title'] == title]['abstract'].tolist()[0]\n",
    "        return abstract\n",
    "    \n",
    "    \n",
    "    def export_to_df(self):\n",
    "        return pd.DataFrame(self.results)\n",
    "\n",
    "    def export_to_csv(self, filename='results.csv'):\n",
    "        pd.DataFrame(self.results).to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_json = 3\n",
    "combined_json_df = pd.DataFrame()\n",
    "combined_results_df = pd.DataFrame()\n",
    "\n",
    "for json_file in json_files:\n",
    "    json_file_path = f'{base_dir}/{json_file}'\n",
    "    analysis = FacultyPublicationAnalysis(json_file_path)\n",
    "    analysis.get_authorId() # What is the author ID of the faculty member?\n",
    "    analysis.get_authors_papers() # What are the papers of the faculty member?\n",
    "    analysis.get_hIndex() # What is the H-index of the faculty member?\n",
    "    analysis.get_author_CitationCount() # What is the author citation count of the faculty member?\n",
    "    analysis.get_journals() # What journals has the faculty member published in?\n",
    "    analysis.get_journal_count() # What are the journals and how many papers has the faculty member published in each?\n",
    "    analysis.get_fieldsOfStudy() # What are the fields of study of the faculty member?\n",
    "    analysis.get_OpenAccessCount() # How many papers has this faculty member published in open access journals?\n",
    "    analysis.get_venues() # What venues has the faculty member published in?\n",
    "    most_cited_title = analysis.get_most_cited_paper() # What is the most cited paper from the faculty member?\n",
    "\n",
    "    analysis_df = analysis.df\n",
    "    combined_json_df = pd.concat([combined_json_df, analysis_df], ignore_index=True)\n",
    "    \n",
    "    result_df = analysis.export_to_df()\n",
    "    \n",
    "    samples = samples_per_json\n",
    "    randomly_sampled_papers = analysis_df['title'].sample(min(len(analysis_df), samples), ignore_index=True).values\n",
    "    new_questions = []\n",
    "    for paper in randomly_sampled_papers:\n",
    "        journal = analysis.get_paper_journal(paper)\n",
    "        question_1 = f'What journal was the paper \"{paper}\" published in?'\n",
    "        \n",
    "        venue = analysis.get_paper_venue(paper)\n",
    "        question_2 = f'What venue was the paper \"{paper}\" published in?'\n",
    "        \n",
    "        citations = analysis.get_paper_citations(paper)\n",
    "        question_3 = f'How many citations does the paper \"{paper}\" have?'\n",
    "        \n",
    "        authors = analysis.get_paper_authors(paper)\n",
    "        question4 = f'Who are the authors of the paper \"{paper}\"?'\n",
    "        \n",
    "        author = authors.split(',')[0]\n",
    "        question5 = f'Who is the first author of the paper \"{paper}\"?'\n",
    "        \n",
    "        paper_id = analysis.get_paperId(paper)\n",
    "        question6 = f'What is the paper ID of the paper \"{paper}\"?'\n",
    "        question7 = f'What paper has the paper ID {paper_id}?'\n",
    "        \n",
    "        tldr = analysis.get_paper_tldr(paper)\n",
    "        question8 = f\"What is the summary/TLDR of the paper '{paper}'?\"\n",
    "        \n",
    "        abstract = analysis.get_paper_abstract(paper)\n",
    "        # question9 = f\"What is the abstract of the paper '{paper}'?\"\n",
    "        \n",
    "        new_data = [\n",
    "        {\"Question\": question_1, \"Answer\": journal, \"Document\": json_file_path, \"Notes\": \"\"},\n",
    "        {\"Question\": question_2, \"Answer\": venue, \"Document\": json_file_path, \"Notes\": \"\"},\n",
    "        {\"Question\": question_3, \"Answer\": citations, \"Document\": json_file_path, \"Notes\": \"\"},\n",
    "        {\"Question\": question4, \"Answer\": authors, \"Document\": json_file_path, \"Notes\": \"\"},\n",
    "        {\"Question\": question5, \"Answer\": author, \"Document\": json_file_path, \"Notes\": \"\"},\n",
    "        {\"Question\": question6, \"Answer\": paper_id, \"Document\": json_file_path, \"Notes\": \"\"},\n",
    "        {\"Question\": question7, \"Answer\": paper, \"Document\": json_file_path, \"Notes\": \"\"},\n",
    "        {\"Question\": question8, \"Answer\": tldr, \"Document\": json_file_path, \"Notes\": \"\"},\n",
    "        # {\"Question\": question9, \"Answer\": abstract, \"Document\": json_file_path, \"Notes\": \"\"}\n",
    "        ]\n",
    "        \n",
    "        new_results_df = pd.DataFrame(new_data)\n",
    "        result_df = pd.concat([result_df, new_results_df], ignore_index=True)\n",
    "    combined_results_df = pd.concat([combined_results_df, result_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_json_df.to_csv('../data/paper_logs/combined_json_data.csv', index=False)\n",
    "combined_results_df.to_csv('../data/paper_logs/combined_qa_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is the the most cited faculty member?\n",
      "Yiming Yang\n",
      "What is the number of citations of the most cited faculty member? 47104\n",
      "The most cited paper is 'Accelerating Diffusion-based Combinatorial Optimization Solvers by Progressive Distillation'\n"
     ]
    }
   ],
   "source": [
    "# Most cited faculy member (overall)\n",
    "most_cited_faculty = combined_json_df.loc[combined_json_df['authorCitationCount'].idxmax()]['profName']\n",
    "most_citations = combined_json_df['authorCitationCount'].max()\n",
    "most_cited_paper = combined_json_df.loc[combined_json_df['authorCitationCount'].idxmax()]['title']\n",
    "\n",
    "\n",
    "print(f\"Who is the the most cited faculty member?\")\n",
    "print(most_cited_faculty)\n",
    "print(f\"What is the number of citations of the most cited faculty member? {most_citations}\")\n",
    "print(f\"The most cited paper is '{most_cited_paper}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is the the most cited faculty member i?\n",
      "Eric P. Xing\n",
      "What is the number of citations of the most cited in 2023 faculty member? 690\n",
      "The most cited paper is 'Judging LLM-as-a-judge with MT-Bench and Chatbot Arena'\n"
     ]
    }
   ],
   "source": [
    "# Most cited faculy member (2023)\n",
    "most_cited_faculty = combined_json_df.loc[combined_json_df['citationCount'].idxmax()]['profName']\n",
    "most_citations = combined_json_df['citationCount'].max()\n",
    "most_cited_paper = combined_json_df.loc[combined_json_df['citationCount'].idxmax()]['title']\n",
    "\n",
    "print(f\"Who is the the most cited faculty member i?\")\n",
    "print(most_cited_faculty)\n",
    "print(f\"What is the number of citations of the most cited in 2023 faculty member? {most_citations}\")\n",
    "print(f\"The most cited paper is '{most_cited_paper}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "profName\n",
       "Shinji Watanabe            58\n",
       "Graham Neubig              27\n",
       "Yiming Yang                25\n",
       "Bhiksha Raj                20\n",
       "Louis-Philippe Morency     16\n",
       "Yulia Tsvetkov             16\n",
       "Maarten Sap                13\n",
       "Emma Strubell              10\n",
       "Brian MacWhinney           10\n",
       "Chenyan Xiong              10\n",
       "Alexander Waibel            9\n",
       "Taylor Berg-Kirkpatrick     9\n",
       "Yonatan Bisk                8\n",
       "Jeffrey Bigham              8\n",
       "Mona Diab                   8\n",
       "Lei Li                      8\n",
       "Alexander Rudnicky          7\n",
       "David R Mortensen           7\n",
       "Rita Singh                  7\n",
       "Malihe Alikhani             7\n",
       "Lu Jiang                    6\n",
       "Alon Lavie                  6\n",
       "Daniel Fried                6\n",
       "Alexander Hauptmann         5\n",
       "Jamie Callan                5\n",
       "Carolyn Rose                5\n",
       "Matt Gormley                4\n",
       "Norman Sadeh                4\n",
       "Daphne Ippolito             4\n",
       "Eric P. Xing                4\n",
       "William Cohen               4\n",
       "Eric Nyberg                 4\n",
       "Roni Rosenfeld              3\n",
       "Fernando-Diaz               3\n",
       "Lori S Levin                3\n",
       "Tom Mitchell                3\n",
       "Justine Cassell             3\n",
       "Matthias Grabmair           3\n",
       "Madhavi Ganapathiraju       2\n",
       "Teruko Mitamura             2\n",
       "Sean Welleck                2\n",
       "Richard Stern               1\n",
       "Scott Fahlman               1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most no of publications in 2023, open Access\n",
    "prof_name_counts = combined_json_df['profName'].value_counts().sort_values(ascending=False)\n",
    "# len(prof_name_counts)\n",
    "prof_name_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which faculty member has the most publications in open access journals in 2023?\n",
      "Shinji Watanabe\n",
      "Which faculty member has the second most publications in open access journals in 2023?\n",
      "Graham Neubig\n",
      "Which faculty member has the third most publications in open access journals in 2023?\n",
      "Yiming Yang\n",
      "Which faculty member has the least publications in open access journals in 2023?\n",
      "Scott Fahlman\n"
     ]
    }
   ],
   "source": [
    "print('Which faculty member has the most publications in open access journals in 2023?')\n",
    "print(prof_name_counts.index[0])\n",
    "print('Which faculty member has the second most publications in open access journals in 2023?')\n",
    "print(prof_name_counts.index[1])\n",
    "print('Which faculty member has the third most publications in open access journals in 2023?')\n",
    "print(prof_name_counts.index[2])\n",
    "print('Which faculty member has the least publications in open access journals in 2023?')\n",
    "print(prof_name_counts.index[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'data/paper_jsons'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A. Lavie_1784914.json', 'Alexander Hauptmann_7661726.json', 'Alexander Hauptmann_7661726_145788702.json', 'Alexander I. Rudnicky_1783635_3156164.json', 'Alexander Waibel_2064429921_1724972.json', 'B. MacWhinney_2414040.json', 'B. Raj_1681921.json', 'C. Rosé_35959897.json', 'Chenyan Xiong_144628574.json', 'Chenyan Xiong_144628574_2139787803.json', 'Chenyan Xiong_2139787803.json', 'Daniel Fried_47070750.json', 'Daphne Ippolito_7975935.json', 'David R. Mortensen_3407646.json', 'E. Xing_143977260.json', 'Emma Strubell_2268272.json', 'Eric Nyberg_144287919.json', 'Fernando Diaz_145472333.json', 'Graham Neubig_1700325.json', 'Jamie Callan_144987107.json', 'Jeffrey P. Bigham_1744846.json', 'Justine Cassell_145431806.json', 'Lei Li_143900005.json', 'Lori S. Levin_1686960.json', 'Louis-Philippe Morency_49933077.json', 'Lu Jiang_39978626.json', 'M. Ganapathiraju_32747279.json', 'Maarten Sap_2729164.json', 'Malihe Alikhani_2715920.json', 'Matthew R. Gormley_1762110.json', 'Matthias Grabmair_2869551.json', 'Mona T. Diab_1700007_2138579860.json', 'N. Sadeh_2464164.json', 'R. Stern_1697819.json', 'Rita Singh_153915824.json', 'Roni Rosenfeld_88507334.json', 'S. Fahlman_1758714.json', 'S. Welleck_2129663.json', 'Shinji Watanabe_1746678.json', 'T. Mitamura_1706595.json', 'Taylor Berg-Kirkpatrick_1400419309.json', 'Tom Michael Mitchell_40975594.json', 'William W. Cohen_50056360.json', 'Yiming Yang_46286308_35729970.json', 'Yonatan Bisk_3312309.json', 'Yulia Tsetkov_2073587169_145317727.json']\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "json_files = [pos_json for pos_json in os.listdir(base_dir) if pos_json.endswith('.json')]\n",
    "json_files.sort()\n",
    "print(json_files)\n",
    "print(len(json_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['profName', 'authorId', 'authorName', 'authorUrl', 'authorHIndex',\n",
       "       'authorAffiliations', 'authorPaperCount', 'authorCitationCount',\n",
       "       'paperId', 'externalIds', 'url', 'title', 'abstract', 'venue', 'year',\n",
       "       'referenceCount', 'citationCount', 'influentialCitationCount',\n",
       "       'isOpenAccess', 'openAccessPdf', 'fieldsOfStudy', 'journal', 'authors'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(f'{base_dir}/{json_files[1]}')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'profName': 'Carolyn Rose',\n",
       "  'authorId': '7661726',\n",
       "  'authorName': 'Alexander Hauptmann',\n",
       "  'authorUrl': 'https://www.semanticscholar.org/author/7661726',\n",
       "  'authorHIndex': 81,\n",
       "  'authorAffiliations': [],\n",
       "  'authorPaperCount': 543,\n",
       "  'authorCitationCount': 25325,\n",
       "  'paperId': '72cce47fd053bf916314d89a8174726c58c05e02',\n",
       "  'externalIds': {'DBLP': 'conf/acl/WenXHH23',\n",
       "   'DOI': '10.18653/v1/2023.findings-acl.198',\n",
       "   'CorpusId': 259859135},\n",
       "  'url': 'https://www.semanticscholar.org/paper/72cce47fd053bf916314d89a8174726c58c05e02',\n",
       "  'title': 'Towards Open-Domain Twitter User Profile Inference',\n",
       "  'abstract': ',',\n",
       "  'venue': 'Annual Meeting of the Association for Computational Linguistics',\n",
       "  'year': 2023,\n",
       "  'referenceCount': 61,\n",
       "  'citationCount': 0,\n",
       "  'influentialCitationCount': 0,\n",
       "  'isOpenAccess': True,\n",
       "  'openAccessPdf': {'url': 'https://aclanthology.org/2023.findings-acl.198.pdf',\n",
       "   'status': None},\n",
       "  'fieldsOfStudy': ['Computer Science'],\n",
       "  'journal': {'pages': '3172-3188'},\n",
       "  'authors': [{'authorId': '4428136', 'name': 'Haoyang Wen'},\n",
       "   {'authorId': '123034558', 'name': 'Zhenxin Xiao'},\n",
       "   {'authorId': '144547315', 'name': 'E. Hovy'},\n",
       "   {'authorId': '7661726', 'name': 'Alexander Hauptmann'}]}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open(f'{base_dir}/{json_files[1]}') as f:\n",
    "    data = json.load(f)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://api.semanticscholar.org/graph/v1/paper/7848d4b4e6ba0897a85cebb6467e94eb0b60d583?fields=tldr\n",
    "API_KEY = os.environ.get('S2APIKEY')\n",
    "import requests\n",
    "if not API_KEY:\n",
    "    raise EnvironmentError(\"S2_API_KEY environment variable not set.\")\n",
    "# Set up the headers with the API key\n",
    "headers = {\n",
    "    \"x-api-key\": API_KEY\n",
    "}\n",
    "fields = 'tldr'\n",
    "id = '27ca2d927421035e10b48c96a96db32224f1f8e6'\n",
    "response = requests.get( # following their git modules\n",
    "    f'https://api.semanticscholar.org/graph/v1/paper/{id}?',\n",
    "    headers=headers,\n",
    "    params={'fields': fields}\n",
    ")\n",
    "\n",
    "tldr = response.json() # '27ca2d927421035e10b48c96a96db32224f1f8e6'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tldr.keys(), tldr.values()\n",
    "tldr['tldr']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'profName': 'Carolyn Rose',\n",
       "  'authorId': '7661726',\n",
       "  'authorName': 'Alexander Hauptmann',\n",
       "  'authorUrl': 'https://www.semanticscholar.org/author/7661726',\n",
       "  'authorHIndex': 81,\n",
       "  'authorAffiliations': [],\n",
       "  'authorPaperCount': 543,\n",
       "  'authorCitationCount': 25325,\n",
       "  'paperId': '72cce47fd053bf916314d89a8174726c58c05e02',\n",
       "  'externalIds': {'DBLP': 'conf/acl/WenXHH23',\n",
       "   'DOI': '10.18653/v1/2023.findings-acl.198',\n",
       "   'CorpusId': 259859135},\n",
       "  'url': 'https://www.semanticscholar.org/paper/72cce47fd053bf916314d89a8174726c58c05e02',\n",
       "  'title': 'Towards Open-Domain Twitter User Profile Inference',\n",
       "  'abstract': ',',\n",
       "  'venue': 'Annual Meeting of the Association for Computational Linguistics',\n",
       "  'year': 2023,\n",
       "  'referenceCount': 61,\n",
       "  'citationCount': 0,\n",
       "  'influentialCitationCount': 0,\n",
       "  'isOpenAccess': True,\n",
       "  'openAccessPdf': {'url': 'https://aclanthology.org/2023.findings-acl.198.pdf',\n",
       "   'status': None},\n",
       "  'fieldsOfStudy': ['Computer Science'],\n",
       "  'journal': {'pages': '3172-3188'},\n",
       "  'authors': [{'authorId': '4428136', 'name': 'Haoyang Wen'},\n",
       "   {'authorId': '123034558', 'name': 'Zhenxin Xiao'},\n",
       "   {'authorId': '144547315', 'name': 'E. Hovy'},\n",
       "   {'authorId': '7661726', 'name': 'Alexander Hauptmann'}],\n",
       "  'tldr': None}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['tldr'] = tldr['tldr']['text']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the author id of this professor?\n",
    "set(df.authorId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to get the url \n",
    "list(df.openAccessPdf[0].values())[0], df.url[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the H-index of Professor X?\n",
    "h_index = df.authorHIndex.max()\n",
    "h_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the most cited paper from this faculty member?\n",
    "most_cited_paper = df.loc[df['citationCount'].idxmax()]['title']\n",
    "most_cited_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get url from title\n",
    "title = 'SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs'\n",
    "url = df[df['title'] == title]['openAccessPdf']\n",
    "url.values[0]['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get journal from title\n",
    "title = 'SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs'\n",
    "journal = df[df['title'] == title]['journal'].apply(lambda x: x.get('name') if isinstance(x, dict) else None).iloc[0]\n",
    "print(journal)\n",
    "\n",
    "journal = df[df['title'] == title]['venue'].values[0]\n",
    "print(journal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the most cited paper from this faculty member and its URL?\n",
    "most_cited_paper = df.loc[df['citationCount'].idxmax()]['title']\n",
    "most_cited_url = list(df.loc[df['citationCount'].idxmax()]['openAccessPdf'].values())[0]\n",
    "most_cited_paper, most_cited_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Who are the authors of the most cited paper?\n",
    "most_cited_authors = df.loc[df['citationCount'].idxmax()]['authors']\n",
    "author_names = [author['name'] for author in most_cited_authors]\n",
    "author_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# who is the first author of this paper?\n",
    "most_cited_authors = df.loc[df['citationCount'].idxmax()]['authors']\n",
    "author_names = [author['name'] for author in most_cited_authors]\n",
    "author_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Who are the authors of the paper [title]?\n",
    "title = 'SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs'\n",
    "author_names = df[df['title']==title]['authors']\n",
    "author_names = [author['name'] for author in most_cited_authors]\n",
    "test = ', '.join(author_names)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_citations = df['citationCount'].sum()\n",
    "total_citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to exclude 'arXiv.org' from venues and get the unique venues\n",
    "conferences_last_year = df[df['venue'] != 'arXiv.org']['venue'].unique()\n",
    "conferences_string = ', '.join(conferences_last_year)\n",
    "conferences_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many papers has this faculty member published in open access journals?\n",
    "open_access_papers = df[df['isOpenAccess'] == True].shape[0]\n",
    "open_access_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journals_filtered = [journal for journal in df['journal'].apply(lambda x: x.get('name') if isinstance(x, dict) else None).unique() if journal is not None]\n",
    "journals_string = ', '.join(journals_filtered)\n",
    "journals_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which venue was this paper published in?\n",
    "paper_title = 'DocumentNet: Bridging the Data Gap in Document Pre-training'\n",
    "venue = df[df['title'] == paper_title]['venue'].values[0]\n",
    "venue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.title[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which venue was this paper published in?\n",
    "venue = df[df['title'] == df.title[2]]['venue'].values[0]\n",
    "venue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs'\n",
    "# Which venue was this paper published in?\n",
    "paper_title = title\n",
    "venue = df[df['title'] == paper_title]['venue'].values[0]\n",
    "venue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "samples = 3\n",
    "\n",
    "randomly_sampled_papers = df['title'].sample(min(len(df), samples), ignore_index=True).values\n",
    "for title in randomly_sampled_papers:\n",
    "    journal = analysis.get_paper_journal(title)\n",
    "    question = f'What journal was the paper \"{title}\" published in?'\n",
    "    \n",
    "    venue = analysis.get_paper_venue(title)\n",
    "    citations = analysis.get_paper_citations(title)\n",
    "    authors = analysis.get_paper_authors(title)\n",
    "    author = authors.split(',')[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
